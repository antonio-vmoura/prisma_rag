Document Title,Authors,Publication Year,Title: Skin,Abstract: Skin,First Removal,Abstract: Traditional ML,Second Removal,Duplication Status,Third Removal,Accepted or not,Proposed Model,Tasks (Objectives),Used Databases, Proposed Methodology, Evaluation Metrics and Results,Abstract,DOI,Author Keywords,Article Citation Count,PDF Link
Enhanced Skin Lesions Classification Using Deep Convolutional Networks,Mohamed E.H.; El-Behaidy W.H.,2019,1,1,0,0,0,Unique,0,,,,,,,"The recent development of machine learning and deep learning techniques for medical image analysis has led to the development of intelligent diagnosis systems that can help doctors make a better diagnosis to the patients' diseases. In particular, skin diagnostics is a field where these new techniques can be applied with a high rate of accuracy. This study aims to enhance the accuracy of skin lesions classification based on two factors. The first is deeply trained all layers of implemented pre-trained models. Whereas, the second is balancing the number of images within the seven classes of dataset used. The state-of-the-art convolutional neural networks MobileNet and DenseNet-121 were trained on HAM10000 dataset. The two models pass through three phases; preprocessing, training and evaluation. Firstly, the dataset is down sampled, splitted and augmented to resolve misbalancing problem. Then, both models are deeply trained and finally they are evaluated against baseline models without balancing the classes. Multiple metrics were used to evaluate our models; precision, recall, F1-score, specificity and ROC AUC. In addition, the micro-average and macro-average of all previous metrics to extend to multi-classification. The accuracy of MobileNet and DenseNet-121 reach 82.6% and 71.9% on unseen testing images, respectively on the original dataset (i.e. before balancing the dataset). Whereas, they reach 92.7% and 91.2% on unseen testing images, respectively after balancing the dataset. This enhancement proves the necessity of existence of balanced dataset for training, to have better performance. Furthermore, MobileNet after balancing dataset has out performed the highest accuracy of ISIC 2018 challenge on the same dataset by 4.2%. For that, this model is the recommended one as it is a light-weight model, suitable for mobile applications used by dermatologists and its accuracy is comparably equal to DenseNet121. © 2019 IEEE.",10.1109/ICICIS46948.2019.9014823,Convolution neural networks; Deep learning; MobileNet; multi-class classification; skin cancer; skin lesions,49,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083367637&doi=10.1109%2fICICIS46948.2019.9014823&partnerID=40&md5=ba19c224cbcd4941a3291f02ef6dd866
Melanoma lesion detection and segmentation using deep region based convolutional neural network and fuzzy C-means clustering,Nida N.; Irtaza A.; Javed A.; Yousaf M.H.; Mahmood M.T.,2019,0,1,0,0,0,Unique,0,,,,,,,"Objective: Melanoma is a dangerous form of the skin cancer responsible for thousands of deaths every year. Early detection of melanoma is possible through visual inspection of pigmented lesions over the skin, treated with simple excision of the cancerous cells. However, due to the limited availability of dermatologists, the visual inspection alone has the limited and variable accuracy that leads the patient to undergo a series of biopsies and complicates the treatment. In this work, a deep learning method is proposed for automated Melanoma region segmentation using dermoscopic images to overcome the challenges of automated Melanoma region segmentation within dermoscopic images. Materials and methods: A deep region based convolutional neural network (RCNN) precisely detects the multiple affected regions in the form of bounding boxes that simplify localization through Fuzzy C-mean (FCM) clustering. Our method constitutes of three step process: skin refinement, localization of Melanoma region, and finally segmentation of Melanoma. We applied the proposed method on benchmark dataset ISIC-2016 by International Symposium on biomedical images (ISBI) having 900 training and 376 testing Melanoma dermatological images. Main findings: The performance is evaluated for Melanoma segmentation using various quantitative measures. Our method achieved average values of pixel level specificity (SP) as 0.9417, pixel level sensitivity (SE) as 0.9781, F1 _ s core as 0.9589, pixel level accuracy (Ac) as 0.948. In addition, average dice score (Di) of segmentation was recorded as 0.94, which represents good segmentation performance. Moreover, Jaccard coefficient (Jc) averaged value on entire testing images was 0.93. Comparative analysis with the state of art methods and the results have demonstrated the superiority of the proposed method. Conclusion: In contrast with state of the art systems, the RCNN is capable to compute deep features with amen representation of Melanoma, and hence improves the segmentation performance. The RCNN can detect features for multiple skin diseases of the same patient as well as various diseases of different patients with efficient training mechanism. Series of experiments towards Melanoma detection and segmentation validates the effectiveness of our method. © 2019 Elsevier B.V.",10.1016/j.ijmedinf.2019.01.005,CAD tool; Fuzzy C-Means; Melanoma segmentation; RCNN; Region proposal,182,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060342436&doi=10.1016%2fj.ijmedinf.2019.01.005&partnerID=40&md5=c9b53545517b14eee55108dfd539fc98
