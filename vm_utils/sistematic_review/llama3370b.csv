Document Title,Authors,Publication Year,Title: Skin,Abstract: Skin,First Removal,Abstract: Traditional ML,Second Removal,Duplication Status,Third Removal,Accepted or not,Proposed Model,Tasks (Objectives),Used Databases,Proposed Methodology,Evaluation Metrics and Results,Abstract,DOI,Author Keywords,Article Citation Count,PDF Link
"Super-Resolution of Medical Images Using Real ESRGAN","Nandal P.; Pahal S.; Khanna A.; Rogerio Pinheiro P.",2024,0,1,0,0,0,First occurrence,0,,,,"","","Rich details in an image are constantly vital for medical image analysis to detect a broad extent of medical ailments. The diagnosis will be best served if the image is accessible in high resolution and the small details are preserved. Image super-resolution techniques based on deep learning can assist us in extracting spatial features from a low-resolution image captured with current technologies. The updated variant of the super-resolution technique known as Real Enhanced Super-Resolution Generative Adversarial Networks (Real-ESRGAN), which produces 2D real-world images with excellent perceptual quality, is used in the present work. We investigate the suggested approach using four distinct medical image types: 1) brain MRI images from the BraTS dataset; 2) dermoscopy images from the ISIC skin cancer dataset; 3) cardiac ultrasound images from the CAMUS dataset; and 4) chest x-rays images from the MIMIC-CXR dataset. The employed architecture achieves improved visual results in comparison to the alternative innovative techniques for super-resolution. The observed findings are evaluated and contrasted both qualitatively and quantitatively with conventional approaches in terms of PSNR, SSIM, and MSE, and an improvement of up to 12% is obtained. © 2013 IEEE.",10.1109/ACCESS.2024.3497002,"Deep learning; generative adversarial network; medical image enhancement; Real-ESRGAN",9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209664749&doi=10.1109%2fACCESS.2024.3497002&partnerID=40&md5=d79764a5f556d7e59aa897709e7e3d4a
"Dual residual learning of frequency fingerprints in detecting synthesized biomedical imagery","Sharafudeen M.; S.S. V.C.",2025,0,1,0,0,0,Unique,0,,,,"","","Artificial synthesis of biomedical imagery is an evolving threat yet under-addressed. The integrity of medical imaging is important for accurate diagnosis and treatment. This study addresses the potential threat of fabricated biomedical imagery, focusing on synthetic dermatological lesions and CT nodules. The Representation Similarity Matrix measured the quantitative authenticity to account for similarities of synthesized data with authentic data. The study explores traces of manipulation from frequency signatures of synthesized imagery. We propose a novel combinatorial architecture, the Dual Residual Network (DRN), capturing hidden residual traces from low-frequency fingerprints of synthetic data and exposing hidden forgeries. DRN achieves near-perfect detection rates with an accuracy of 98.80% for CT nodules and 98.97% for lesions. Equal Error Rates of the model on the two datasets exhibited a marginal improvement of 57.87% in the CT nodules compared to the skin lesions. Sensitivity and specificity play a significant role in medical diagnostics. The model achieved sensitivities of 99.31% and 98.45% and specificity of 98.80% and 99.60% for each dataset, respectively. Further verification of the frequency traces was performed by analyzing gradients in the target concepts that led to decision-making. This study equips the medical field with a powerful tool to combat the evolving threat of synthetic fraud, safeguarding patient and client safety. The potential of the technique extends beyond healthcare, offering a blueprint for tackling synthetic data across diverse domains. © 2025 Elsevier B.V.",10.1016/j.asoc.2025.112930,"Biomedical imaging; Frequency fingerprinting; Gradient mapping; Residual Networks; Synthesized imagery",0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219528261&doi=10.1016%2fj.asoc.2025.112930&partnerID=40&md5=705ca61d90f4754f76b579fa5bbd8561
"Segmentation and Classification of Skin Cancer Diseases Based on Deep Learning: Challenges and Future Directions","Khalaf A.D.; Hamdan H.; Abdul Halin A.; Manshor N.",2025,1,1,0,0,0,First occurrence,0,,,,"","","Deep Learning (DL) techniques have significantly improved the diagnostic accuracy in healthcare, particularly for detecting and classifying skin cancer. Such technological advancements will assist healthcare professionals in delivering more accurate, efficient, and timely diagnoses, ultimately improving patient outcomes and facilitating early detection and treatment. Medical imaging technologies such as magnetic resonance imaging (MRI) and computed tomography (CT) are critical for diagnosing dermatological conditions. However, interpreting these images can be challenging due to overlapping structures and varying image quality. This study explores the application of DL in skin cancer diagnosis, focusing on advances in image segmentation and classification. DL-based models are reviewed specifically by convolutional neural networks (CNNs), and evaluations on their effectiveness for skin lesion detection are provided. This study also examines the critical challenges of deploying DL models in clinical practice, covering issues including dataset diversity, model interpretability, and real-world implementation feasibility. It further explores the selection of network architectures and data preprocessing techniques, emphasizing their influence on model performance. In summary, this study identifies research gaps and suggests future directions for enhancing DL models for dermatological applications.  © 2013 IEEE.",10.1109/ACCESS.2025.3569170,"Augmentation; classification; convolutional neural networks; deep learning; detection; segmentation; skin cancer; understandable artificial intelligence",0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005363551&doi=10.1109%2fACCESS.2025.3569170&partnerID=40&md5=17ff7a53dec5a1cd6eddcb12759c5436
"Ensemble Fusion: Skin Cancer Detection using ResNet, EfficientNet, and VGG Architectures","S. Thakur; S. Sharma",2024,1,1,0,0,0,Unique,0,Accepted,"Ensemble model (ResNet, EfficientNet, VGG16)",classify skin lesions as malignant or benign with high accuracy.,HAM10000,"Rigorous preprocessing was applied to images, followed by training an ensemble model that combines ResNet, EfficientNet, and VGG16 architectures.","Accuracy: 99.1% on the test dataset.","Skin cancer detection is crucial for timely intervention and improved patient outcomes. This study addresses the challenge of early detection accuracy through the utilization of advanced machine learning techniques. Leveraging the HAM1000 dataset, comprising high-resolution dermatoscopic images, rigorous preprocessing techniques were applied to enhance image quality and feature extraction. Our methodology involved training an ensemble model incorporating state-of-the-art architectures such as ResNet, EfficientNet, and VGG16. This ensemble approach harnesses the diverse capabilities of these models, leveraging their strengths in feature representation and learning.Experimental results demonstrate outstanding performance, with the ensemble model achieving a remarkable accuracy of $99.1\%$ on test dataset in classifying skin lesions as malignant or benign. This achievement under-scores the effectiveness of ensemble modeling in skin cancer detection, particularly when integrating powerful architectures like ResNet, EfficientNet, and VGG16.Furthermore, our study highlights the importance of robust preprocessing techniques in optimizing model performance and ensuring reliable diagnostic outcomes. The findings of this research have significant implications for clinical practice, offering a promising avenue for improving early detection rates and ultimately enhancing patient outcomes.Future research endeavors may explore the integration of additional datasets and validation on diverse populations to further validate the efficacy and generalizability of the proposed ensemble approach.",10.1109/ICCCNT61001.2024.10726235,"Skin cancer detection;Machine learning;Ensemble modeling;HAM1000 dataset;Preprocessing techniques;Diagnostic accuracy;ResNet50;EfficientNet;VGG16",,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10726235
"GAN-Alz: Synthetic Data Generation for Multiclass Alzheimer’s Classification","R. R. Nair; T. Babu; G. Ramasamy; T. Singh; X. Yuan",2024,0,1,0,0,0,Unique,0,,,,"","","Accurate detection of skin cancer, particularly melanoma, is crucial for effective treatment and patient survival. This study explores the use of Convolutional Neural Networks (CNNs) enhanced by Generative Adversarial Networks (GANs) for skin cancer detection. CNNs have shown remarkable performance in image classification tasks but often require extensive labeled datasets, which are scarce in medical domains. To address this, GANs are employed to generate synthetic skin lesion images, augmenting the dataset and improving the model’s generalization capability. The proposed approach integrates a pre-trained CNN architecture fine-tuned with a combination of real and GANgenerated images, enhancing the network’s ability to distinguish between benign and malignant lesions. Experimental results demonstrate that the inclusion of GAN-augmented data improves the model’s accuracy by $7 \%$, achieving an overall accuracy of $94 \%$, with precision and recall rates of $92 \%$ and $93 \%$, respectively. These findings suggest that the GAN-augmented CNN model offers a promising solution for automated skin cancer screening",10.1109/SPARC61891.2024.10828935,"Generative Adversarial Network(GAN);Over Sampling;Vgg16;Efficient Net;Resnet;Inception Net",1,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10828935
Computing rational border curves of melanoma and other skin lesions from medical images with bat algorithm,"G'alvez, Akemi and Fister, Iztok and Osaba, Eneko and Fister, Iztok and Ser, Javier Del and Iglesias, Andr'es",2019,1,1,0,0,0,Unique,0,,,,"","","Border detection of melanoma and other skin lesions from images is an important step in the medical image processing pipeline. Although this task is typically carried out manually by the dermatologists, some recent papers have applied evolutionary computation techniques to automate this process. However, these works are only focused on the polynomial case, ignoring the more powerful (but also more difficult) case of rational curves. In this paper, we address this problem with rational B'ezier curves by applying the bat algorithm, a popular bio-inspired swarm intelligence technique for optimization. Experimental results on two examples of medical images of melanomas show that this method is promising, as it outperforms the polynomial approach and can be applied to medical images without further pre/post-processing.",10.1145/3319619.3326873,,,https://doi.org/10.1145/3319619.3326873
On Image Prefiltering for Skin Lesion Characterization Utilizing Deep Transfer Learning,"Delibasis, K.; Georgakopoulos, S. V.; Tasoulis, S. K.; Maglogiannis, I.; Plagianakos, V. P.",2020,1,1,0,0,0,Unique,0,,,,"","","Skin cancer is one of the most diagnosed cancers according to the World Health Organization and one of the most malignant. Unfortunately, still the available annotated data are in most cases not enough to successfully train deep learning algorithms that would allow highly accurate predictions. In this paper, we propose the utilization of transfer learning to fine-tune the parameters at the very last layers of a pre-trained a deep learning neural network. We expect that a limited number of skin lesion images is enough to affect significantly the later data-specific layers. Furthermore, we propose a pre-process step for skin lesion images that segments and crops the lesion, whereas smooths the effect of image masking, thus enhancing the network’s classification capabilities. The reported results are very promising, since the overall accuracy, as well as the accuracy of individual class classification improved in 7 out of the 8 classes, suggesting future developments in medical diagnosis through pre-trained deep learning models and specialized image prefiltering.",10.1007/978-3-030-48791-1_29,"Convolutional Neural Networks (CNN); Skin Lesion Classification; Cancer detection; Image pre-processing",,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-030-48791-1_29
"A review on smartphone skin cancer diagnosis apps in evaluation and benchmarking: coherent taxonomy, open issues and recommendation pathway solution","Zaidan A.A.; Zaidan B.B.; Albahri O.S.; Alsalem M.A.; Albahri A.S.; Yas Q.M.; Hashim M.",2018,1,1,0,0,0,First occurrence,0,,,,"","","This research aims to review the attempts of researchers in response to the new and disruptive technology of skin cancer applications in terms of evaluation and benchmarking, in order to identify the research landscape from the literature into a cohesive taxonomy. An extensive search was conducted for articles dealing with ‘skin cancer’, ‘apps’ and ‘smartphone’ or ‘mHealth’ in different variations to find all the relevant articles in three main databases, namely, “Web of Science”, “Science Direct”, and “IEEE explore”. These databases are considered wide enough to cover medical and technical literature. The final classification scheme outcome of the dataset contained 110 articles that were classified into four classes: development and design; analytical; evaluative and comparative; and review and survey studies. Afterwards, another filtering process was achieved based on the evaluation criteria error rate within the dataset, time complicity and reliability, which are used in skin cancer applications. The final classification scheme outcome of the dataset contained 89 articles distributed in mapping and crossover with four sections concluded from 110 articles. Development and design studies, analytical studies, evaluative and comparative studies and articles of reviews and surveys comprised of 48.3146%, 22.4719%, 16.8539% (15), and 12.3595% (11) of the reviewed articles, respectively. The basic features of this evolving approach were identified in these aspects. We also determined open issues in terms of evaluation and benchmarking that hamper the utility of this technology. Furthermore, with the exception of the 89 papers reviewed, the new recommendation pathway solution was described in order to improve the measurement process for smartphone-based skin cancer diagnosis applications. © 2018, IUPESM and Springer-Verlag GmbH Germany, part of Springer Nature.",10.1007/s12553-018-0223-9,"Mobile health; Real-time apps; Skin cancer diagnosis, evaluation and benchmarking, smartphone",82,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052206797&doi=10.1007%2fs12553-018-0223-9&partnerID=40&md5=2ae673fb60ac157328673d6d0cb31ad1
"Generalizability vs. robustness: Investigating medical imaging networks using adversarial examples","Paschali M.; Conjeti S.; Navarro F.; Navab N.",2018,0,1,0,0,0,Unique,0,,,,"","","In this paper, for the first time, we propose an evaluation method for deep learning models that assesses the performance of a model not only in an unseen test scenario, but also in extreme cases of noise, outliers and ambiguous input data. To this end, we utilize adversarial examples, images that fool machine learning models, while looking imperceptibly different from original data, as a measure to evaluate the robustness of a variety of medical imaging models. Through extensive experiments on skin lesion classification and whole brain segmentation with state-of-the-art networks such as Inception and UNet, we show that models that achieve comparable performance regarding generalizability may have significant variations in their perception of the underlying data manifold, leading to an extensive performance gap in their robustness. © Springer Nature Switzerland AG 2018.",10.1007/978-3-030-00928-1_56,,96,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054088746&doi=10.1007%2f978-3-030-00928-1_56&partnerID=40&md5=3c70e668d961ec47185a600f36b674b1
"Comprehensive insights into evaluation and benchmarking of real-time skin detectors: Review, open issues & challenges, and recommended solutions","Yas Q.M.; Zaidan A.A.; Zaidan B.B.; Rahmatullah B.; Abdul Karim H.",2018,1,1,0,0,0,Unique,0,,,,"","","Evaluation and benchmarking of real-time skin detectors remain challenging because of multiple evaluation attributes that must be considered. Numerous evaluation and benchmarking techniques have been proposed, but they exhibit several limitations. Fixing multiple attributes based on benchmarking approaches by using other attributes limits reliable real-time skin detection. This paper presents comprehensive insights into the evaluation and benchmarking of real-time skin detectors on the basis of two critical directions. Current evaluation criteria highlight conflicting issues and benchmarking techniques to identify weak points, and possible solutions are discussed. The findings are as follows: (1) open issues and challenges to evaluation and benchmarking are emphasized; and (2) decision making using multiple criteria such as reliability, time complexity, and error rate within a dataset is used for evaluating and benchmarking real-time skin detectors to come up with solutions for future directions. © 2017 Elsevier Ltd",10.1016/j.measurement.2017.09.027,"Evaluation and benchmarking; Multi-criteria analysis; Multi-criterion decision making; Skin detector",64,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030544821&doi=10.1016%2fj.measurement.2017.09.027&partnerID=40&md5=2b31ff96b3f340c71219cdc6eaf02b07
Technique standards for skin lesion imaging a delphi consensus statement,"Katragadda C.; Finnane A.; Soyer H.P.; Marghoob A.A.; Halpern A.; Malvehy J.; Kittler H.; Hofmann-Wellenhof R.; Da Silva D.; Abraham I.; Curiel-Lewandrowski C.",2017,1,1,0,0,0,Unique,0,,,,"","","IMPORTANCE Variability in the metrics for image acquisition at the total body, regional, close-up, and dermoscopic levels impacts the quality and generalizability of skin images. Consensus guidelines are indicated to achieve universal imaging standards in dermatology. OBJECTIVE To achieve consensus among members of the International Skin Imaging Collaboration (ISIC) on standards for image acquisition metrics using a hybrid Delphi method. EVIDENCE REVIEW Delphi study with 5 rounds of ratings and revisions until relative consensus was achieved. The initial set of statements was developed by a core group (CG) on the basis of a literature review and clinical experience followed by 2 rounds of rating and revisions. The consensus process was validated by an extended group (EG) of ISIC members through 2 rounds of scoring and revisions. In all rounds, respondents rated the draft recommendations on a 1 (strongly agree) to 5 (strongly disagree) scale, explained ratings of less than 5, and optionally provided comments. At any stage, a recommendation was retained if both mean and median rating was 4 or higher. RESULTS The initial set of 45 items (round 1) was expanded by the CG to 56 variants in round 2, subsequently reduced to 42 items scored by the EG in round 3, yielding an EG set of 33 recommendations (rounds 4 and 5): General recommendation (1 guideline), lighting (5), background color (3), field of view (3), image orientation (8), focus/depth of field (3), resolution (4), scale (3), color calibration (2), and image storage (1). CONCLUSIONS AND RELEVANCE This iterative process of ratings and comments yielded a strong consensus on standards for skin imaging in dermatology practice. Adoption of these methods for image standardization is likely to improve clinical practice, information exchange, electronic health record documentation, harmonization of clinical studies and database development, and clinical decision support. Feasibility and validity testing under real-world clinical conditions is indicated. © 2017 American Medical Association.",10.1001/jamadermatol.2016.3949,,40,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014680612&doi=10.1001%2fjamadermatol.2016.3949&partnerID=40&md5=1fbab5a602bb93e37cc24372d256a84a
Radiomics improves cancer screening and early detection,"Gillies R.J.; Schabath M.B.",2020,0,1,0,0,0,Unique,0,,,,"","","Imaging is a key technology in the early detection of cancers, including X-ray mammography, low-dose CT for lung cancer, or optical imaging for skin, esophageal, or colorectal cancers. Historically, imaging information in early detection schema was assessed qualitatively. However, the last decade has seen increased development of computerized tools that convert images into quantitative mineable data (radiomics), and their subsequent analyses with artificial intelligence (AI). These tools are improving diagnostic accuracy of early lesions to define risk and classify malignant/ aggressive from benign/indolent disease. The first section of this review will briefly describe the various imaging modalities and their use as primary or secondary screens in an early detection pipeline. The second section will describe specific use cases to illustrate the breadth of imaging modalities as well as the benefits of quantitative image analytics. These will include optical (skin cancer), X-ray CT (pancreatic and lung cancer), X-ray mammography (breast cancer), multiparametric MRI (breast and prostate cancer), PET (pancreatic cancer), and ultrasound elastography (liver cancer). Finally, we will discuss the inexorable improvements in radiomics to build more robust classifier models and the significant limitations to this development, including access to well-annotated databases, and biological descriptors of the imaged feature data. © 2020 American Association for Cancer Research.",10.1158/1055-9965.EPI-20-0075,,113,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098796016&doi=10.1158%2f1055-9965.EPI-20-0075&partnerID=40&md5=e6f6418aa8b70876c6bfe35d92091053
Machine Learning in Melanoma Diagnosis. Limitations About to be Overcome; [Uso del aprendizaje automático en el diagnóstico del melanoma. Limitaciones por superar],"González-Cruz C.; Jofre M.A.; Podlipnik S.; Combalia M.; Gareau D.; Gamboa M.; Vallone M.G.; Faride Barragán-Estudillo Z.; Tamez-Peña A.L.; Montoya J.; América Jesús-Silva M.; Carrera C.; Malvehy J.; Puig S.",2020,0,1,0,0,0,Unique,0,,,,"","","Background: Automated image classification is a promising branch of machine learning (ML) useful for skin cancer diagnosis, but little has been determined about its limitations for general usability in current clinical practice. Objective: To determine limitations in the selection of skin cancer images for ML analysis, particularly in melanoma. Methods: Retrospective cohort study design, including 2,849 consecutive high-quality dermoscopy images of skin tumors from 2010 to 2014, for evaluation by a ML system. Each dermoscopy image was assorted according to its eligibility for ML analysis. Results: Of the 2,849 images chosen from our database, 968 (34%) met the inclusion criteria for analysis by the ML system. Only 64.7% of nevi and 36.6% of melanoma met the inclusion criteria. Of the 528 melanomas, 335 (63.4%) were excluded. An absence of normal surrounding skin (40.5% of all melanomas from our database) and absence of pigmentation (14.2%) were the most common reasons for exclusion from ML analysis. Discussion: Only 36.6% of our melanomas were admissible for analysis by state-of-the-art ML systems. We conclude that future ML systems should be trained on larger datasets which include relevant non-ideal images from lesions evaluated in real clinical practice. Fortunately, many of these limitations are being overcome by the scientific community as recent works show. © 2020 AEDV",10.1016/j.ad.2019.09.002,"Artificial Intelligence; Convolutional neural networks; Dermoscopy; Image classification; Machine learning; Melanoma; Skin cancer",13,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082808971&doi=10.1016%2fj.ad.2019.09.002&partnerID=40&md5=7bbb4a5e8546a23d9be34598da7f38ce
Using deep learning for dermatologist-level detection of suspicious pigmented skin lesions from wide-field images,"Soenksen L.R.; Kassis T.; Conover S.T.; Marti-Fuster B.; Birkenfeld J.S.; Tucker-Schwartz J.; Naseem A.; Stavert R.R.; Kim C.C.; Senna M.M.; Avilés-Izquierdo J.; Collins J.J.; Barzilay R.; Gray M.L.",2021,1,1,0,0,0,Unique,0,,,,"","","A reported 96,480 people were diagnosed with melanoma in the United States in 2019, leading to 7230 reported deaths. Early-stage identification of suspicious pigmented lesions (SPLs) in primary care settings can lead to improved melanoma prognosis and a possible 20-fold reduction in treatment cost. Despite this clinical and economic value, efficient tools for SPL detection are mostly absent. To bridge this gap, we developed an SPL analysis system for wide-field images using deep convolutional neural networks (DCNNs) and applied it to a 38,283 dermatological dataset collected from 133 patients and publicly available images. These images were obtained from a variety of consumer-grade cameras (15,244 nondermoscopy) and classified by three board-certified dermatologists. Our system achieved more than 90.3% sensitivity (95% confidence interval, 90 to 90.6) and 89.9% specificity (89.6 to 90.2%) in distinguishing SPLs from nonsuspicious lesions, skin, and complex backgrounds, avoiding the need for cumbersome individual lesion imaging. We also present a new method to extract intrapatient lesion saliency (ugly duckling criteria) on the basis of DCNN features from detected lesions. This saliency ranking was validated against three board-certified dermatologists using a set of 135 individual wide-field images from 68 dermatological patients not included in the DCNN training set, exhibiting 82.96% (67.88 to 88.26%) agreement with at least one of the top three lesions in the dermatological consensus ranking. This method could allow for rapid and accurate assessments of pigmented lesion suspiciousness within a primary care visit and could enable improved patient triaging, utilization of resources, and earlier treatment of melanoma. Copyright © 2021 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works",10.1126/scitranslmed.abb3652,,116,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101698746&doi=10.1126%2fscitranslmed.abb3652&partnerID=40&md5=57c5efcec77b7a835206aee69138f440
"Using feature maps to unpack the CNN ‘Black box’ theory with two medical datasets of different modality","Azam S.; Montaha S.; Fahim K.U.; Rafid A.K.M.R.H.; Mukta M.S.H.; Jonkman M.",2023,0,1,0,0,0,Unique,0,,,,"","","Convolutional neural networks (CNNs) have been established for a comprehensive range of computer vision problems across several benchmarks. Visualization and analysis of feature maps generated by convolutional layers can be an effective approach to explore the hidden and complex characteristic of a CNN model. Convolutional layers provide diverse feature maps however, the extent of this diversity needs to be explored. This research attempts to provide five insights of the ‘Black box’ mechanism of CNNs, using skin cancer dermoscopy and lung scan computed tomography (CT) Scan datasets by statistically analyzing layer by layer (three convolutional layers) feature maps using 17 geometrical and 6 intensity-based features to determine the characteristics and level of diversity. Significance and difference of the feature maps layer by layer, black feature maps analysis, difference of the feature maps to each other and to the original image, variations among the feature maps when running the model multiple times and inter-class variation among the feature maps for different iteration are explored. Various statistical methods including T-test, analysis of variance (ANOVA), mean, median, mean squared error (MSE), peak signal to noise ratio (PSNR), structural similarity index (SSIM), root mean squared error (RMSE), dice similarity score (DSC), universal image quality index (UQI) and Spectral angle mapper (SAM) are employed. Experimental results show that for the skin cancer dermoscopy dataset, a large number of black feature maps are produced (20–60%) while the proportion of black feature maps for the CT Scan dataset is comparatively low (2–20%). This demonstrates that for different datasets, feature maps with diverse characteristics can be produced. The layer by layer differences between the feature maps is evaluated using T-tests and ANOVA for seventeen geometrical features and six intensity-based features. For both datasets across most of the geometrical features and across most of the intensity-based features a significant diversity can be observed. The difference of the feature maps to each other and to the original image is quite high, with MSE values for the dermoscopy and CT Scan datasets in the range of 1860–31,399 and 171–6089, respectively, PSNR 3–15 and 10–25, SSIM values of 0.01–0.84 and 0.3–0.81, RMSE values of 0.81–1 and 0.21–1, DSC values of 0.37–0.53 and 0.47–0.75, UQI values of 0.02–0.86 and 0.01–0.88 and SAM values of 0.12–1.53 and 0.19–1.55 for the dermoscopy and CT Scan datasets respectively. When running the model multiple times (three iterations), a notable iteration by iteration diversity is found in terms of mean, median, maximum and minimum values for most of the geometrical features. The inter-class variation among the feature maps for different iterations and layers are evaluated based on the F-value of the ANOVA test. For the dermoscopy dataset, the highest mean F-value is found for layer 1 and iteration 3 while for the CT scan dataset the highest mean F-value is found for layer 3 and iteration 3 indicating that for these feature maps the highest inter-class dissimilarity is generated. The findings of this study may aid in exploring the complex mechanism of convolutional layers, kernels and feature maps. © 2023",10.1016/j.iswa.2023.200233,"ANOVA test; Black box; Convolutional neural network; Feature map analysis; Geometric feature; T-test",12,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159372463&doi=10.1016%2fj.iswa.2023.200233&partnerID=40&md5=0a35beaca70aecf58a9a29121d71bf13
Fungal Skin Disease Classification Using the Convolutional Neural Network,"Nigat T.D.; Sitote T.M.; Gedefaw B.M.",2023,1,1,0,0,0,Unique,0,,,,"","","Skin is the outer cover of our body, which protects vital organs from harm. This important body part is often affected by a series of infections caused by fungus, bacteria, viruses, allergies, and dust. Millions of people suffer from skin diseases. It is one of the common causes of infection in sub-Saharan Africa. Skin disease can also be the cause of stigma and discrimination. Early and accurate diagnosis of skin disease can be vital for effective treatment. Laser and photonics-based technologies are used for the diagnosis of skin disease. These technologies are expensive and not affordable, especially for resource-limited countries like Ethiopia. Hence, image-based methods can be effective in reducing cost and time. There are previous studies on image-based diagnosis for skin disease. However, there are few scientific studies on tinea pedis and tinea corporis. In this study, the convolution neural network (CNN) has been used to classify fungal skin disease. The classification was carried out on the four most common fungal skin diseases: tinea pedis, tinea capitis, tinea corporis, and tinea unguium. The dataset consisted of a total of 407 fungal skin lesions collected from Dr. Gerbi Medium Clinic, Jimma, Ethiopia. Normalization of image size, conversion of RGB to grayscale, and balancing the intensity of the image have been carried out. Images were normalized to three sizes: 120 × 120, 150 × 150, and 224 × 224. Then, augmentation was applied. The developed model classified the four common fungal skin diseases with 93.3% accuracy. Comparisons were made with similar CNN architectures: MobileNetV2 and ResNet 50, and the proposed model was superior to both. This study may be an important addition to the very limited work on the detection of fungal skin disease. It can be used to build an automated image-based screening system for dermatology at an initial stage.  © 2023 Tsedenya Debebe Nigat et al.",10.1155/2023/6370416,,25,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161236442&doi=10.1155%2f2023%2f6370416&partnerID=40&md5=61ca06e7b6895c78c71d529030b152fa
Cutting-edge Deep Learning Solutions for Precise Identification and Definition of Skin Cancer Lesions,"Mohadikar R.S.; Kotadi C.; Dhule C.",2024,1,1,0,0,0,Unique,0,,,,"","","This study uses three different types of convolutional neural networks (CNNs), Inception, VGG16, and DenseNet, to look into cutting-edge deep learning methods for accurately identifying the suggested models are trained on a large and varied dataset that includes high-resolution dermatoscopic images of different types and states of skin cancer. It is known that the Inception model makes good use of computer resources, and it can also capture features very well. Because it has a deep design, VGG16 is great at picking up small patterns and features inside skin tumors, which makes diagnosis more accurate. Using dense connection patterns, DenseNet encourages information flow and gradient transmission, which helps the network pick up on small differences in the features of lesions. The rough cross-validation and tests on separate datasets are used to see how well these models work. The comparison looks at things like sensitivity, specificity, and general accuracy to see how well each model can find and describe skin cancer spots. The paper discuss these deep learning model and found the accuracy for Inception as 92.63, the VGG16 more close to with accuracy with 84.7 and out of this three model DenseNet proven better accuracy with 93.33. The study also looks into how easy it is to understand the models, using focus maps and feature graphics to show how decisions are made. The findings show that deep learning could help improve the diagnosis of skin cancer, with each design showing its own strengths. The results add to the current discussion about using deep learning for medical picture analysis and also show how these models can be used in real-life therapeutic situations. Ultimately, this study shows how to better and more accurately find skin cancer spots, which will allow for earlier treatment and better results for patients.  © 2024 IEEE.",10.1109/ICICET59348.2024.10616331,"Convolutional Neural Networks; Deep Learning; Diagnostic Accuracy; Inception; Skin Cancer",0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201194342&doi=10.1109%2fICICET59348.2024.10616331&partnerID=40&md5=d37a6ffab86fb2a231c9ef83084e9475