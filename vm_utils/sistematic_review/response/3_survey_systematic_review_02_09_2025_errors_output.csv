"Proposed_Model","Skin_Task","Architecture_Type","Combines_Methods","Main_Objective","Feature_Extraction","Cancer_Type","Database_Used","Number_Images","Balanced_Dataset","Image_Preprocessing","Validation_Type","Transfer_Learning","Data_Augmentation","Compared_Baselines","Evaluation_Metrics","Best_Result","Compared_SOTA","Tested_Different_Datasets","Limitations","Document Title"
"Improved SSD (Single Shot Detector) with ResNet18 backbone","Yes","Adaptation","No","Classification and Detection","Yes","Not informed (Citrus)","ISIC2018 datasets, but not specified in the input row","2,500 images taken from a testing bench of a waxing machine","Not informed","Not informed","mAP (mean average precision) and mean detection time as the speed index","Not informed","Not informed","Yes, compared with MobileNetV3, ESPNetV2, VoVNet39, and ResNet18 backbones","mAP (mean average precision), AP for normal, skin lesion, and mechanical damage detection","87.89% mAP accuracy, 94.72%, 85.79%, and 83.17% AP accuracy for detecting normal, skin lesion, and mechanical damage respectively.","Yes, compared with original SSD model","No (tested on ISIC2018 datasets but not specified in the input row)","Not informed","Real-time classification and detection of citrus based on improved single short multibox detecter; [基于改进SSD的柑橘实时分类检测]"
"Attention-guided Deep Convolutional Neural Networks (D-CNN)","Yes","Adaptation","No","Classification","Yes","Various skin cancers","Not informed (ISIC dataset is mentioned but not specified in the input row)","Not informed","No, due to absence of balanced class images and difference between images of same class","Not informed","Classification results with attention boosts accuracy by approximately 12%","Yes (fine-tuning is mentioned)","Not informed","No, but compared to normal D-CNN architecture without attention mechanism","Accuracy and classification results with attention boosts accuracy by approximately 12%","Approximately 12% boost in accuracy with attention mechanism","Yes (compared to original D-CNN model)","No, tested on skin cancer images but not specified which dataset is used","Not informed","Attention-guided deep convolutional neural networks for skin cancer classification"
"Non-linear optical microscopy (NLO) techniques: TPF, FLIM, SHG, and CARS","No","Not applicable","Yes, multimodal NLO microscopy is a combination of different techniques","Imaging with sub-cellular resolution, high penetration depth, endogenous contrast specificity, and pinhole-less optical sectioning capability","No (label-free)","Not informed","Various samples: collagen in tissue, amylopectin from starch granules, sarcomere structure of fresh muscle, elastin in skin, NADH in cells, and lipid droplets in cells","Not informed","No (different techniques used for different samples)","Not applicable","High image contrast and quantitative estimate of sample orientation using polarization-resolved non-linear optical microscopy","Not applicable","Not informed","No, but compared to other imaging techniques such as fluorescence microscopy","Image contrast and quantitative estimate of sample orientation using polarization-resolved non-linear optical microscopy","High image contrast and quantitative estimate of sample orientation using polarization-resolved non-linear optical microscopy","Yes, compared to other imaging techniques such as fluorescence microscopy","No (tested on various samples but not specified which dataset is used)","Not informed","Label-Free Non-linear Multimodal Optical Microscopy—Basics, Development, and Applications"
"Deep learning Convolutional Neural Network (CNN)","Yes","Adaptation","No","Melanoma recognition and diagnosis","Yes","Melanoma","More than 120,000 dermoscopic images of skin neoplasms with corresponding diagnoses","130 melanocytic lesions (107 benign nevi and 23 melanomas)","No (benign nevi vs. melanoma)","Gentian violet surgical skin markings were applied to some images, which affected the CNN's performance","Sensitivity, specificity, area under the curve (AUC) of receiver operating characteristic (ROC) curve for diagnostic classification in unmarked, marked, and cropped images","Not applicable","Not informed","Yes, compared to CNN's performance with and without gentian violet skin markings","Sensitivity (95.7%), specificity (84.1%), AUC of ROC curve (0.969) for unmarked images; sensitivity (100%), specificity (45.8%), AUC of ROC curve (0.922) for marked images","Highest sensitivity and specificity were achieved when cropping the dermoscopic images to focus on the melanocytic lesion, with a sensitivity of 100%, specificity of 97.2%, and AUC of ROC curve of 0.993","Yes (compared to other CNN architectures)","No (tested on same dataset used for training the model)","Skin markings significantly interfered with the CNN's correct diagnosis, increasing false-positive rate","Association between Surgical Skin Markings in Dermoscopic Images and Diagnostic Performance of a Deep Learning Convolutional Neural Network for Melanoma Recognition"
"Combination of human and artificial intelligence using a CNN","Yes","Adaptation","Yes, combination of human (dermatologists) and AI (CNN)","Skin cancer classification into five diagnostic categories or binary classification as benign or malignant","Yes, using deep learning techniques to train a CNN","Melanoma and nevi","11,444 dermoscopic images divided into five diagnostic categories","300 biopsy-verified skin lesions used for testing the combined classifier","No (class imbalance in binary problem)","Not informed","Accuracy, sensitivity, and specificity of the combination of human and AI classifiers compared to individual classifiers","Not applicable","Not informed","Yes, comparison with individual CNN classifier and dermatologists' performance","Accuracy (82.95%), sensitivity (89%) for multiclass task; accuracy not reported but sensitivity of 86.1% for binary classification by the best individual classifier (CNN)","Combination of human and AI classifiers achieved an accuracy of 82.95%, which was higher than the best individual classifier","Yes, comparison with state-of-the-art CNN architectures","No (tested on same dataset used for training)","Class imbalance in binary problem affected specificity of combined classifier","Superior skin cancer classification by the combination of human and artificial intelligence"
"Convolutional Neural Network (CNN)","Yes","Adaptation","No, single CNN model used for classification","Multiclass skin cancer image classification into five diagnostic categories or binary classification as benign or malignant","Yes, using novel deep learning techniques to train the CNN","Melanoma and nevi (primary end-point), multiple diagnoses including basal cell carcinoma (secondary end-point)","11,444 dermoscopic images covering dermatologic diagnoses commonly faced in skin cancer screenings","300 biopsy-verified images used for testing the CNN's performance compared to 112 dermatologists","No (class imbalance in binary problem)","Not informed","Sensitivity, specificity of the CNN and dermatologists' performance on primary end-point; sensitivity, specificity for secondary end-point with five diagnostic categories","Not applicable","Not informed","Yes, comparison with human experts (112 dermatologists) in multiclass skin cancer image classification","Sensitivity and specificity of CNN and dermatologists' performance on primary end-point; sensitivity and specificity for secondary end-point with five diagnostic categories","CNN outperformed dermatologists at a significant level (p < 0.001) in multiclass skin cancer image classification, achieving higher sensitivity and specificity compared to human experts","Yes, comparison with state-of-the-art CNN architectures for skin cancer image classification tasks","No (tested on same dataset used for training)","CNN outperformed dermatologists in multiclass skin cancer image classification but did not achieve perfect performance","Systematic outperformance of 112 dermatologists in multiclass skin cancer image classification by convolutional neural networks"
"Separable-Unet with stochastic weight averaging","Yes, skin lesion segmentation (SLS)","Adaptation","No, single model used for SLS","Efficient and accurate melanoma region segmentation in dermoscopy images","Yes, using separable convolutional block and U-Net architectures to capture context feature channel correlation and higher semantic feature information","Melanomas (specifically addressed) and non-melanomas (also segmented)","Three publicly available datasets: ISIC 2016 Skin Lesion Challenge, ISIC 2017 Skin Lesion Challenge, PH2 dataset","Not specified in the text but mentioned as 'three publicly available datasets'","No (class imbalance not explicitly stated)","Not informed","Dice coefficient and Jaccard index for SLS performance on three different datasets","Not applicable","Not informed","Yes, comparison with other state-of-the-art methods in skin lesion segmentation (SLS)","Dice coefficient and Jaccard index for SLS performance on three different datasets","Proposed approach achieved an average Dice coefficient of 93.03% and Jaccard index of 89.25% for ISIC 2016 dataset, outperforming other state-of-the-art methods in skin lesion segmentation (SLS)","Yes, comparison with current best-performing method on the same hardware configuration","No (tested on three publicly available datasets: ISIC 2016 Skin Lesion Challenge, ISIC 2017 Skin Lesion Challenge, PH2 dataset)","Not explicitly stated","Efficient skin lesion segmentation using separable-Unet with stochastic weight averaging"
"Automated deep learning software (Google Cloud AutoML)","Yes, skin lesion classification","Adaptation","No, single model used for each dataset","Develop medical image diagnostic classifiers by health-care professionals with no coding experience","Yes, using neural architecture search framework to automatically develop deep learning architectures","Multiple types of diseases (e.g. diabetic retinopathy, age-related macular degeneration, skin lesions)","Five publicly available open-source datasets: MESSIDOR, Guangzhou Medical University and Shiley Eye Institute version 3, HAM10000, NIH CXR14 dataset","Not specified in the text but mentioned as 'five publicly available datasets'","No (class imbalance not explicitly stated)","Not informed","Internal validation using sensitivity, specificity, positive predictive value and area under precision recall curve for each dataset","Not applicable","Not informed","Yes, comparison with state-of-the-art performing deep learning algorithms on the same datasets","Sensitivity, specificity, positive predictive value and area under precision recall curve for each dataset","Automated deep learning models showed comparable discriminative performance and diagnostic properties to expertly designed models in binary classification tasks (sensitivity: 73.3-97%; specificity: 67-100%) but lower performance in multiple classification tasks (sensitivity: 38-100%, specificity: 67-100%)","Yes, comparison with current best-performing deep learning algorithms on the same datasets","No (tested on five publicly available open-source datasets)","Quality of open-access datasets and absence of measurement for precision were major limitations","Automated deep learning design for medical image classification by health-care professionals with no coding experience: a feasibility study"
"Deep learning techniques (various)","Yes, skin cancer diagnosis","Adaptation","No, single models used for each type of cancer","Cancer diagnosis using deep learning: a bibliographic review","Yes, various techniques (CNNs, GANs, DANs, RBM, SAE, CAE, RNNs, LTSM, M-CNN, MIL-CNN) used for feature extraction and image analysis","Multiple types of cancers: breast cancer, lung cancer, brain cancer, skin cancer","Not specified in the text but mentioned as 'various datasets' for each type of cancer","Not specified in the text but mentioned as 'large number of images' used for training and testing deep learning models","No (class imbalance not explicitly stated)","Yes, pre-processing step included in deep learning framework","Various evaluation metrics: ROC curve, AUC, F1 score, accuracy, specificity, sensitivity, precision, dice-coefficient, average accuracy, Jaccard index","Not applicable","Yes, data augmentation techniques used to increase size of training dataset","No (compared with state-of-the-art deep learning models for each type of cancer)","Various evaluation metrics: ROC curve, AUC, F1 score, accuracy, specificity, sensitivity, precision, dice-coefficient, average accuracy, Jaccard index","Deep learning techniques showed improved performance compared to traditional methods (e.g. ABCD method) for cancer diagnosis","Yes, comparison with state-of-the-art deep learning models for each type of cancer","No (tested on various datasets for each type of cancer)","Not explicitly stated","Cancer diagnosis using deep learning: A bibliographic review"
"Deep region based convolutional neural network (RCNN) and Fuzzy C-means clustering","Yes, melanoma lesion detection and segmentation","Adaptation","No, single models used for each task","Automated Melanoma region segmentation using dermoscopic images","Yes, deep features extracted by RCNN for melanoma detection and segmentation","Melanoma","ISIC-2016 benchmark dataset (900 training and 376 testing Melanoma dermatological images)","Not specified in the text but mentioned as 'large number of images' used for training and testing RCNN model","No (class imbalance not explicitly stated)","Yes, skin refinement step included in proposed method","Quantitative measures: pixel level specificity, sensitivity, F1 score, accuracy, dice score, Jaccard coefficient","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for melanoma segmentation and detection","Quantitative measures: pixel level specificity, sensitivity, F1 score, accuracy, dice score, Jaccard coefficient","RCNN achieved average values of pixel level specificity (SP) as 0.9417, pixel level sensitivity (SE) as 0.9781, F1 _ s core as 0.9589, and pixel level accuracy (Ac) as 0.948 for melanoma segmentation","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on ISIC-2016 benchmark dataset)","Not explicitly stated","Melanoma lesion detection and segmentation using deep region based convolutional neural network and fuzzy C-means clustering"
"Bio-inspired deep-CNN pipeline","Yes, skin cancer early diagnosis (melanoma)","Adaptation","No, single model used for task","Early diagnosis of melanomas using non-invasive methodologies based on morphological analysis of the skin lesion","Yes, deep features extracted by CNN pipeline for early detection and classification of melanoma","Melanoma (most aggressive type of skin cancer)","Not specified in the text but mentioned as 'benchmark dataset' used to evaluate performance of proposed pipeline","10 images used for training and testing deep learning model","No (class imbalance not explicitly stated)","Yes, morphological analysis included in proposed method","Quantitative measures: accuracy, precision, recall, F1-score, AUC-ROC curve","Not applicable","No (not mentioned as part of the proposed pipeline)","Yes, comparison with previous approaches confirmed good performance of proposed pipeline","Quantitative measures: accuracy, precision, recall, F1-score, AUC-ROC curve","Proposed deep-CNN pipeline achieved high accuracy and robustness in early diagnosis of melanomas compared to traditional methods (e.g. ABCDE method)","Yes, comparison with state-of-the-art approaches demonstrated good performance of proposed pipeline","No (tested on benchmark dataset used for evaluation)","Not explicitly stated","Bio-inspired deep-CNN pipeline for skin cancer early diagnosis"
"Not applicable (biological analysis)","Yes, psoriasis","N/A","No","Analysis of circulating soluble programmed death 1 (PD-1), neuropilin 1 (NRP-1) and human leukocyte antigen-G (HLA-G) in psoriatic patients","Not applicable","No, psoriasis is a skin condition","57 psoriatic patients and 29 controls","N/A","Yes (no class imbalance mentioned)","Not applicable","Statistical analysis: ELISA method, PASI, BSA, PGA","No","N/A","Yes (compared with control group)","Soluble NRP-1 concentration was significantly higher in psoriatic patients compared to controls, while soluble PD-1 and sHLA-G concentrations were not significantly different between the groups.","Increased concentrations of sNRP-1 may be indicative of impaired immune tolerance mechanisms in psoriasis","Yes (compared with control group)","No","Not explicitly stated","Analysis of circulating soluble programmed death 1 (PD-1), neuropilin 1 (NRP-1) and human leukocyte antigen-G (HLA-G) in psoriatic patients"
"Two-dimensional phasor-based approach (μMAPPS) and clustering algorithm","No, cancer xenografts in mice","Adaptation","Yes, combines μMAPPS with tissue morphology information for disease diagnosis","Automated tumor micro-architecture analysis using polarization-dependent second harmonic imaging","Yes, extracts collagen fibrils microscopic parameters (orientation and anisotropy) at a mesoscopic level","Two cancer xenografts in mice","Not specified in the text but mentioned as 'histopathology sections' from two cancer xenografts in mice","Not specified in the text but mentioned as 'few mm in size'","No (class imbalance not explicitly stated)","Yes, preprocessing step included in μMAPPS approach for tissue analysis","Quantitative measures: fibril entropy parameter to identify tumor edges and automatic segmentation","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with standard histopathology for disease diagnosis","Quantitative measures: fibril entropy parameter to identify tumor edges and automatic segmentation","μMAPPS approach combined with tissue morphology information has potential to become a support to standard histopathology in diseases diagnosis","Yes, comparison with state-of-the-art methods for cancer diagnosis using label-free imaging techniques","No (tested on two cancer xenografts in mice)","Not explicitly stated","Whole-section tumor micro-architecture analysis by a two-dimensional phasor-based approach applied to polarization-dependent second harmonic imaging"
"Computer-assisted diagnosis (CAD) systems using dermoscopy and spectroscopy-based techniques","Yes, skin cancer detection in adults","Adaptation","No, single models used for each task","To determine the accuracy of CAD systems for diagnosing cutaneous invasive melanoma and atypical intraepidermal melanocytic variants, BCC or cSCC in adults","Yes, dermoscopy-based CAD (Derm-CAD) and spectroscopy-based CAD (Spectro-CAD) used to extract lesion features for diagnosis","Melanoma, Basal Cell Carcinoma (BCC), Cutaneous Squamous Cell Carcinoma (cSCC)","ISIC-2016 benchmark dataset and other datasets not specified in the text","9602 lesions from 23 study cohorts for Derm-CAD, and 6336 lesions from 16 study cohorts for Spectro-CAD","No (class imbalance not explicitly stated)","Yes, dermoscopy-based preprocessing step included in proposed method","Quantitative measures: sensitivity, specificity, accuracy, F1 score, and Jaccard coefficient","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with dermoscopy-based diagnosis","Quantitative measures: sensitivity, specificity, accuracy, F1 score, and Jaccard coefficient","Derm-CAD had a pooled sensitivity of 90.1% (95% CI 84.0% to 94.0%) and specificity of 74.3% (95% CI 63.6% to 82.7%), while Spectro-CAD had a pooled sensitivity of 92.9% (95% CI 83.7% to 97.1%) and specificity of 43.6% (95% CI 24.8% to 64.5%)","Yes, CAD systems demonstrated high sensitivity but low specificity compared to dermoscopy-based diagnosis","No (tested on various datasets not specified in the text)","Insufficient data available for community settings and keratinocyte cancers","Computer-assisted diagnosis techniques (dermoscopy and spectroscopy-based) for diagnosing skin cancer in adults"
"Full resolution convolutional networks (FrCN)","Yes, skin lesion segmentation in dermoscopy images","Adaptation","No, single model used for task","Automated skin lesion segmentation using deep learning","Yes, full resolution features extracted by FrCN for each individual pixel of input data","Melanoma and seborrheic keratosis (benign cases)","ISBI 2017 Challenge dataset and PH2 datasets","Not specified in the text but mentioned as 'large number of images' used for training and testing FrCN model","No (class imbalance not explicitly stated)","Yes, no pre-processing operations required by proposed method","Quantitative measures: Jaccard index, segmentation accuracy","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art deep learning methods for skin lesion segmentation (FCN, U-Net, SegNet)","Quantitative measures: Jaccard index, segmentation accuracy","FrCN achieved an average Jaccard index of 77.11% and overall segmentation accuracy of 94.03% for ISBI 2017 test dataset","Yes, FrCN outperformed FCN, U-Net, and SegNet by significant margins in terms of both metrics (Jaccard index and segmentation accuracy)","No (tested on two publicly available datasets: ISBI 2017 Challenge dataset and PH2 datasets)","Not explicitly stated","Skin lesion segmentation in dermoscopy images via deep full resolution convolutional networks"
"Infrared thermography (IRT) with FLIR System AB thermal camera","No, plantar foot surface temperatures in turkeys","Not applicable","Yes, multiple methods used for image analysis and cleaning procedures","To develop a standardized IRT protocol to screen for impaired foot health in turkeys","No, temperature measurements only","Not applicable (study on animal welfare)","80 turkey toms used as subjects for the study","Not specified in the text but mentioned as 'IRT images' collected with FLIR System AB thermal camera","No, class imbalance not explicitly stated (study on temperature variation)","Yes, feet were cleaned and dried before IRT imaging","Statistical analysis of within- and between-individual temperature variation","Not applicable","No, not mentioned as part of the study protocol","Yes, comparison with different image analysis methods and cleaning procedures","Temperature measurements (Tempmin and Tempmax) in two plantar sub-regions: Footpad and whole plantar Foot surface","Footpad Tempmax was significantly higher than Footpad Tempmin before and after cleaning, indicating optimal anatomical region for future studies on turkey foot health","Yes, comparison with different image analysis methods and cleaning procedures demonstrated the importance of a strict protocol to reduce errors in temperature measurements","No (tested on same dataset: 80 turkey toms)","Not explicitly stated","Experimental factors affecting the within- and between-individual variation of plantar foot surface temperatures in turkeys (Meleagris gallopovo) recorded with infrared thermography"
"Not applicable (systematic review of existing research)","Yes, skin cancer diagnosis and detection","Adaptation","No, single methods used for each task","Survey the efforts of researchers in response to the new technology of skin cancer apps","Not applicable (review of existing research)","Skin cancer","Web of Science, Science Direct, and IEEE Xplore databases","Not specified in the text but mentioned as 'large number of images' used for training and testing skin cancer apps","No (class imbalance not explicitly stated)","Not applicable (review of existing research)","Analytical studies, evaluative or comparative study of apps, exploration of desired features for skin cancer detection","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin cancer diagnosis and detection","Quantitative measures: incidence of skin cancer, classification of malignant or benign cancer, prevention and diagnosis methods","No specific results mentioned in the text (systematic review)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method is not applicable as this study does a systematic review.","No (tested on various datasets for each type of skin cancer)","Several areas or aspects require further attention: watermarking and stenography approaches, image processing techniques","A Systematic Review on Smartphone Skin Cancer Apps: Coherent Taxonomy, Motivations, Open Challenges and Recommendations, and New Research Direction"
"Partial order label decomposition approaches for melanoma diagnosis","Yes, melanoma detection and severity assessment (Breslow index)","Adaptation","No, single models used for each task","Automated melanoma presence and severity assessment using image analysis and machine learning","Yes, extracted 100 features considering shape, color, pigment network, and texture of benign and malignant lesions","Melanoma","Interactive Atlas of Dermoscopy clinician-curated images (not specified how many)","Not specified in the text but mentioned as 'large number of images' used for training and testing models","No, class imbalance present due to varying severity levels of melanoma","Yes, image analysis step included in proposed method","Five-class classification problem: benign lesions (class 1) vs. different stages of melanoma via Breslow index (classes 2-5)","Not applicable","Yes, over-sampling techniques used to create synthetic patterns considering class structure and partial order assumption","Yes, comparison with 12 baseline nominal and ordinal classifiers including a deep learning model","Performance metrics not specified in the text but implied as accuracy or classification error rate for each class","Proposed models exploiting partial order assumption achieved better performance than baseline classifiers (not specific values provided)","Yes, comparison with state-of-the-art methods demonstrated superiority of proposed approach","No (tested on clinician-curated images from Interactive Atlas of Dermoscopy)","Not explicitly stated","Partial order label decomposition approaches for melanoma diagnosis"
"K-Means algorithm based on CIE Lab (L*A*B) color space","Yes, psoriasis disease diagnosis and segmentation","Adaptation","No, single model used for image segmentation","Accurate segmentation of psoriasis diseases images using K-Means algorithm based on CIE Lab color space","Yes, L*A*B color features extracted by K-Means clustering for disease region selection","Psoriasis (not explicitly stated as cancer)","Own database of 80 medical images of RGB psoriasis diseases images","Not specified in the text but mentioned as 'large number' used for testing and comparison with other methods","No (class imbalance not explicitly stated)","Yes, color feature extraction using L*A*B color space instead of RGB","Quantitative measures: accuracy, compared to K-Means clustering based on RGB color spaces","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with other methods for image segmentation and disease diagnosis","Accuracy: 95% on own database of 80 medical images","K-Means algorithm based on CIE Lab color space achieved higher accuracy compared to K-Means clustering based on RGB color spaces","Yes, comparison with other methods demonstrated the effectiveness and superiority of proposed method","No (tested only on own database)","Not explicitly stated","Accurate segmentation of psoriasis diseases images using k-means algorithm based on cielab (L*A*B) color space"
"Gabor filter with variable thresholding process","Yes, disease detection (skin related diseases such as tonsillitis, tumors, skin cancers)","Adaptation","No, single models used for each task","Design and implementation of high speed Gabor filter with variable thresholding process for disease detection","Yes, Gabor filter extracts features from images for disease detection","Skin cancers (not specified which type)","Not mentioned in the text","Not specified in the text","No (class imbalance not explicitly stated)","Yes, image segmentation using Gabor filter for disease detection","Manual decision making through lighting of LED's on FPGA/CPLD kit","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for disease detection and diagnosis","Manual decision making through lighting of LED's on FPGA/CPLD kit","Gabor filter with variable thresholding process achieved accurate and faster disease detection (not specified which metrics)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on FPGA/CPLD kit for manual decision making)","Not explicitly stated","Design and implementation of high speed Gabor filter with variable thresholding process for disease detection"
"Dichromatic Reflection Model and Monte Carlo simulation of light transport in multi-layered tissue (MCML)","Yes, skin pigmentation disorder diagnosis","Adaptation","No, single models used for each task","Non-invasive and objective evaluation of pigmented lesions and skin-whitening treatments using melanin types estimation","Yes, spectral reflectance data analyzed to determine skin optical parameters (melanin types)","Not applicable (skin pigmentation disorder diagnosis)","Realistic Skin Model (RSM) of the Advanced Systems Analyses Program (ASAP) software and observational studies involving 110 participants","Not specified in the text but mentioned as 'large number of images' used for training and testing MCML model","No (class imbalance not explicitly stated)","Yes, skin spectral information provided by spectrophotometer analyzed using inverse procedure to determine melanin types","Quantitative measures: absolute error of 8.82% and comparison with literature values for different skin tones based on Fitzpatrick classification","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed system in estimating melanin types and skin pigmentation disorders diagnosis","Quantitative measures: absolute error, accuracy, sensitivity, specificity","Proposed system estimated correctly with an absolute error of 8.82% for different skin tones based on Fitzpatrick classification","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method in estimating melanin types and skin pigmentation disorders diagnosis","No (tested on Realistic Skin Model (RSM) and observational studies involving 110 participants)","Not explicitly stated","Modelling and analysis of skin pigmentation"
"Skin cancer detection algorithm (https://rcnn.modelderm.com)","Yes, diagnosis of benign and malignant skin neoplasms","Adaptation","No, single model used for each task","Assessment of deep neural networks for the diagnosis of benign and malignant skin neoplasms in comparison with dermatologists: A retrospective validation study","Yes, convolutional neural network (CNN) extracts features from clinical images","Benign and malignant skin neoplasms","Severance Hospital dataset (40,331 clinical images from 10,426 cases: 1,222 malignant cases and 9,204 benign cases)","Not specified in the text but mentioned as 'large number of images' used for training and testing model","No (class imbalance not explicitly stated)","Yes, unprocessed clinical photographs were used to train and test algorithm","Quantitative measures: area under the curve (AUC), sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV) ","Not applicable","No (not mentioned as part of proposed method)","Yes, comparison with dermatologists' diagnoses in real-world practice and experimental settings","Quantitative measures: AUC, sensitivity, specificity, PPV, NPV ","Algorithm achieved an AUC of 0.863 (95% CI 0.852–0.875) for determining malignancy using unprocessed clinical photographs","Yes, comparison with dermatologists' diagnoses demonstrated that algorithm performed similarly in experimental settings but inferiorly in real-world practice ","No (tested on Severance Hospital dataset)","Exclusive use of high-quality clinical photographs taken in hospitals and lack of ethnic diversity in study population","Assessment of deep neural networks for the diagnosis of benign and malignant skin neoplasms in comparison with dermatologists: A retrospective validation study"
"Residual neural network (ResNet) with various optimization algorithms","Yes, medical imaging disease diagnosis including skin diseases","Adaptation","No, single models used for each task","Optimization of ResNet algorithm for medical imaging disease diagnosis","Yes, deep features extracted by ResNet for various diseases including skin cancer","Multiple types: lung tumor, skin disease (melanoma), breast cancer, brain disease (Alzheimer's), diabetes, hematological disease","Not specified in the text but mentioned as 'large number of images' used for training and testing ResNet model","Not specified in the text but mentioned as 'large number of images' used for training and testing ResNet model","No (class imbalance not explicitly stated)","Yes, various preprocessing techniques including data enhancement and normalization applied to medical imaging datasets","Quantitative measures: accuracy, sensitivity, specificity, F1 score, dice coefficient, Jaccard index","Yes, transfer learning used for fine-tuning ResNet model on specific disease datasets","Yes, data augmentation techniques including rotation, flipping, and color jittering applied to medical imaging datasets","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","Quantitative measures: accuracy, sensitivity, specificity, F1 score, dice coefficient, Jaccard index","ResNet achieved good results in clinical diagnosis, staging, metastasis, treatment decision, and target area delineation for various diseases including skin cancer","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on specific disease datasets)","Not explicitly stated","Progress of residual neural network optimization algorithm for medical imaging disease diagnosis; [医学影像疾病诊断的残差神经网络优化算法研究进展]"
"Explainable fully connected visual words with SURF and shallow artificial neural network","Yes, skin cancer classification (benign vs malignant pattern)","Adaptation","No, single models used for each task","Classification of skin cancer confocal images using visual words and interpretability analysis","Yes, SURF features extracted from confocal images to form a visual vocabulary (visual words)","Skin cancer (benign vs malignant pattern)","Not specified in the text but mentioned as 'confocal images' used for training and testing","Not specified in the text but mentioned as 'large number of confocal images' used for training and testing","No (class imbalance not explicitly stated)","Yes, SURF features extracted from raw confocal image data","Quantitative measures: accuracy, precision, recall, F1 score, ROC-AUC curve","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin cancer classification and interpretability analysis","Quantitative measures: accuracy, precision, recall, F1 score, ROC-AUC curve","Not specified in the text but mentioned as 'initial results' showing improved performance of proposed method compared to state-of-the-art methods","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method for skin cancer classification and interpretability analysis","No (tested on confocal images dataset)","Not explicitly stated","Explainable fully connected visual words for the classification of skin cancer confocal images: Interpreting the influence of visual words in classifying benign vs malignant pattern"
"Multi-scale and multi-network ensemble (MSM-CNN) using transfer learning","Yes, skin lesion classification","Adaptation","Yes, combines results from multiple networks trained on different image scales","To investigate the effect of image size for skin lesion classification using pre-trained CNNs and transfer learning","Yes, deep features extracted by EfficientNetB0, EfficientNetB1, and SeReNeXt-50 networks","Skin cancer (not specified which type)","ISIC skin lesion classification challenge datasets","Not specified in the text but mentioned as 'large number of images' used for training and testing MSM-CNN model","No (class imbalance not explicitly stated)","Yes, image cropping is a better strategy compared to image resizing","Quantitative measures: balanced multi-class accuracy on ISIC 2018 skin lesion classification challenge test set","Yes, pre-trained CNNs adapted for skin lesion diagnosis using transfer learning","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods on ISIC 2018 skin lesion classification challenge test set","Quantitative measures: balanced multi-class accuracy","MSM-CNN algorithm yields a balanced multi-class accuracy of 86.2% on the ISIC 2018 skin lesion classification challenge test set","Yes, MSM-CNN is currently second ranked algorithm on the live leaderboard for ISIC 2018 skin lesion classification challenge test set","No (tested only on ISIC datasets)","Not explicitly stated","Transfer learning using a multi-scale and multi-network ensemble for skin lesion classification"
"Convolutional Neural Network (CNN)","Yes, melanoma and nevus classification","Adaptation","No, single model used for each task","To investigate whether AI support improves the accuracy of dermatologists in classifying dermoscopic images of melanoma and nevi","Yes, deep features extracted by CNN for image classification","Melanoma","Unique set of 1200 dermoscopic images (100 unique images per dermatologist)","Not specified in the text but mentioned as 'large number' used for training and testing CNN model","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed method","Quantitative measures: specificity, sensitivity, accuracy, confidence levels of dermatologists","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with personal experience alone and AI support for image classification","Quantitative measures: specificity, sensitivity, accuracy, confidence levels of dermatologists","AI support increased mean sensitivity (59.4% to 74.6%) and mean accuracy (65.0% to 73.6%) compared to personal experience alone for image classification","Yes, AI-based tools showed improved performance in skin lesion classification compared to traditional methods","No (tested on unique set of dermoscopic images)","Not explicitly stated","Artificial intelligence and its effect on dermatologists' accuracy in dermoscopic melanoma image classification: Web-based survey study"
"Deep convolutional neural network (CNN)","No, bovine tuberculosis status prediction in dairy cows","Adaptation","Yes, synthetic minority over sampling technique used to balance data and improve accuracy","Predicting bovine tuberculosis (bTB) status of dairy cows from mid-infrared spectral data of milk using deep learning","Yes, CNN extracts features from MIR spectra for bTB prediction","Bovine Tuberculosis (bTB)","National bTB testing program dataset (over 40,500 herd breakdowns) and individual cow life–history data","Not specified in the text but mentioned as 'large number of images' used for training CNN model","No (class imbalance not explicitly stated), balanced using synthetic minority over sampling technique","Yes, spectra converted to PNG images and resized to 53 × 20-pixel before feeding into CNN","Quantitative measures: accuracy, validation loss, sensitivity, specificity","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for bTB prediction and disease phenotype classification","Quantitative measures: accuracy, validation loss, sensitivity, specificity","Deep CNN achieved a high accuracy (95%) after training on synthesized data using synthetic minority over sampling technique","Yes, proposed method demonstrated improved performance compared to state-of-the-art methods for bTB prediction and disease phenotype classification","No (tested on national bTB testing program dataset)","Not explicitly stated","Predicting bovine tuberculosis status of dairy cows from mid-infrared spectral data of milk using deep learning"
"Youzhi AI software","Yes, skin tumor diagnosis and classification","Adaptation","No, single model used for each task","Diagnostic capacity of Youzhi AI-assisted decision-making software in real-world clinical settings","Yes, dermoscopic images and clinical images analyzed by Youzhi AI software to extract features for diagnosis","Skin tumors (benign and malignant)","Real-world data from China-Japan Friendship Hospital (106 patients with confirmed skin tumor diagnoses)","Not specified in the text but mentioned as 'large number of images' used for training and testing Youzhi AI software","No (class imbalance not explicitly stated)","Yes, dermoscopic and clinical image preprocessing included in proposed method","Quantitative measures: diagnostic accuracy, sensitivity, specificity, positive predictive value, negative predictive value, F-measure, Matthews correlation coefficient","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with dermatologists' diagnostic accuracy in real-world clinical settings","Quantitative measures: diagnostic accuracy, sensitivity, specificity, positive predictive value, negative predictive value, F-measure, Matthews correlation coefficient","Youzhi AI software achieved higher diagnostic accuracy than dermatologists for skin tumor types through dermoscopic image recognition (P = 0.01)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method in certain aspects","No (tested on real-world data from China-Japan Friendship Hospital)","Diagnostic accuracy lower than laboratory data sets","Diagnostic capacity of skin tumor artificial intelligence-assisted decision-making software in real-world clinical settings"
"Deep Neural Networks (DNNs)","Yes, skin cancer diagnosis and treatment prediction","Adaptation","No, single models used for each task","Empowering medical professionals in diagnosing skin cancer and predicting treatment options using augmented intelligence","Yes, DNNs extracted features from images of 174 disorders","Skin Cancer (malignancy detection)","Edinburgh dataset (1,300 images; 10 disorders) and SNU dataset (2,201 images; 134 disorders)","220,680 images of 174 disorders used for training","No (class imbalance not explicitly stated)","Yes, pre-processing step included in DNNs framework","Quantitative measures: area under the curves (AUC) for malignancy detection and primary treatment suggestion; mean top-1 and top-5 accuracies for multi-class classification","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with medical professionals' performance improved by using DNNs-assisted diagnosis and treatment prediction","Quantitative measures: AUC for malignancy detection and primary treatment suggestion; mean top-1 and top-5 accuracies for multi-class classification","DNNs achieved high accuracy in predicting malignancy (AUC = 0.937 ± 0.004) and suggesting primary treatment options (SNU dataset)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on Edinburgh and SNU datasets)","Not explicitly stated","Augmented Intelligence Dermatology: Deep Neural Networks Empower Medical Professionals in Diagnosing Skin Cancer and Predicting Treatment Options for 134 Skin Disorders"
"Convolutional Neural Network (CNN) with weighted extreme learning machine (wELM)","No, prostate cancer mpMRI lesion classification","Adaptation","Yes, CNN and wELM used together for feature extraction and classification","Understanding tumor foci classification using multiparametric MRI based on convolutional neural network","Yes, features extracted from intermediate layers of CNN and fed into wELM","Prostate cancer","SPIE-AAPM-NCI PROSTATEx Challenges dataset (320 biopsy samples of lesions from 201 prostate cancer patients)","Not specified in the text but mentioned as 'large number' used for training and testing CNN model","No, imbalanced distribution among output categories taken into consideration using wELM","Yes, registration and lesion-based normalization steps included before feeding images to CNN","Tenfold cross-validation with holdout cohort from two sources for testing best performing model","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison made between CNN end-to-end training and CNN-wELM combination","Performance metrics not specified in text but implied to be related to classification accuracy","CNN-wELM combination showed substantial performance compared to CNN end-to-end training model for prostate cancer mpMRI lesion classification","Yes, comparison made with state-of-the-art methods for prostate cancer mpMRI lesion classification","No (tested on SPIE-AAPM-NCI PROSTATEx Challenges dataset)","Not explicitly stated","A deep dive into understanding tumor foci classification using multiparametric MRI based on convolutional neural network"
"Multiplexed tissue immunofluorescence (MxIF) method","Yes, skin biomarkers in response to monkeypox virus infection","Adaptation","No, single models used for each task","Comparison of multiplexed immunofluorescence imaging and chromogenic immunohistochemistry of skin biomarkers in response to monkeypox virus infection","Yes, MxIF method extracts features at the single cell level using automated image processing","Monkeypox virus-induced inflammatory skin lesions (not explicitly stated as cancer)","Retrospective study in 11 rhesus monkeys with archived tissue samples","Not specified in the text but mentioned as 'thousands of cells' analyzed using MxIF method","No (class imbalance not explicitly stated)","Yes, highly fixed (up to 30 days) tissue samples used for analysis","Quantitative measures: H-score and automated single cell quantification by MxIF","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with manual chromogenic immunohistochemistry (IHC) double stains and H-scoring","Quantitative measures: consistency between MxIF results and H-score for all markers except phosphorylated ERK1/2","MxIF method showed directional consistency with H-scores for most protein markers, but not for phosphorylated ERK1/2","Yes, comparison demonstrated the potential of MxIF as a useful tool in infectious disease research","No (tested on retrospective study data from 11 rhesus monkeys)","Phosphorylated ERK1/2 showed inconsistent results between H-score and MxIF, potential for improvement with automated segmentation using machine learning","Comparison of multiplexed immunofluorescence imaging to chromogenic immunohistochemistry of skin biomarkers in response to monkeypox virus infection"
"Faster, region-based CNN (FRCNN)","Yes, skin cancer classification system for pigmented skin lesions","Adaptation","No, single model used for each task","Development of a skin cancer classification system using deep learning","Yes, FRCNN extracts features from clinical images of pigmented skin lesions","Multiple types: malignant melanoma and basal cell carcinoma (benign tumors)","5846 clinical images of pigmented skin lesions from 3551 patients","Not specified in the text but mentioned as 'large number of images' used for training and testing FRCNN model","No (class imbalance not explicitly stated)","Yes, bounding-box annotations provided to rest of the images (4732) for training dataset","Quantitative measures: accuracy, sensitivity, specificity, false positive rates and positive predictive values","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with board-certified dermatologists (BCDs) and dermatologic trainees (TRNs)","Quantitative measures: accuracy, sensitivity, specificity","FRCNN achieved an accuracy of 86.2% for six-class classification and 91.5% for two-class classification (benign or malignant)","Yes, FRCNN outperformed BCDs and TRNs in terms of diagnostic accuracy","No (tested on a single dataset of clinical images of pigmented skin lesions)","Not explicitly stated","The development of a skin cancer classification system for pigmented skin lesions using deep learning"
"Convolutional Neural Network (CNN)","Yes, skin lesion classification and diagnosis","Adaptation","No, single model used for each task","Comparison of conventional image analyser versus CNN in a prospective data set of 1,981 skin lesions","Yes, deep features extracted by CNN for classification and diagnosis","Melanoma (281 malignant lesions) and other benign lesions (1700)","Prospectively acquired dermoscopic dataset of 1981 skin lesions from 435 patients","Not specified in the text but mentioned as 'large number' used for training and testing CNN model","No (class imbalance not explicitly stated)","Yes, dermoscopic images pre-processed before feeding into CNN model","Quantitative measures: sensitivity, specificity, receiver operating characteristic (ROC)-area under the curve (AUC) and pairwise comparisons of sensitivities, specificities, and ROC-AUCs","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with conventional image analyser (CIA) showed superior performance by CNN model","Quantitative measures: sensitivity, specificity, ROC-AUC and pairwise comparisons of sensitivities, specificities, and ROC-AUCs","CNN achieved a sensitivity of 77.6%, specificity of 95.3% and ROC-AUC of 0.945 for skin lesion classification and diagnosis","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed CNN model","No (tested on prospectively acquired dermoscopic dataset)","Not explicitly stated","Past and present of computer-assisted dermoscopic diagnosis: performance of a conventional image analyser versus a convolutional neural network in a prospective data set of 1,981 skin lesions"
"Integrated deep convolutional networks for segmentation and classification","Yes, multiple skin lesions diagnostics via integrated deep convolutional networks","Adaptation","No, single models used for each task (segmentation and classification)","Automated diagnosis of various skin lesions through medical dermoscopy images using an integrated diagnostic framework","Yes, deep features extracted by FrCN for segmentation stage and Inception-v3/ResNet-50/Inception-ResNet-v2/DenseNet-201 classifiers for classification stage","Multiple types of skin lesions (benign and malignant)","ISIC 2016, ISIC 2017, and ISIC 2018 datasets with proper balancing, segmentation, and augmentation","Not specified in the text but mentioned as 'large number of images' used for training and testing integrated deep learning model","Yes (proper balancing performed on each dataset)","Yes, skin lesion boundary segmentation stage using FrCN","Quantitative measures: F1-score, weighted prediction accuracy","Not applicable","Yes, data augmentation techniques used to increase size of training dataset","Yes, comparison with state-of-the-art methods for skin lesion segmentation and classification","Quantitative measures: F1-score, weighted prediction accuracy","ResNet-50 classifier exhibited superior performance with overall weighted prediction accuracies of 79.95% (ISIC 2016), 81.57% (ISIC 2017), and 89.28% (ISIC 2018) for multiple skin lesions diagnostics","Yes, comparison demonstrated the superior performance of ResNet-50 classifier over other classifiers used in this study","No (tested on ISIC 2016, ISIC 2017, and ISIC 2018 datasets)","Not explicitly stated","Multiple skin lesions diagnostics via integrated deep convolutional networks for segmentation and classification"
"Dense-Unet: a novel multiphoton in vivo cellular image segmentation model based on convolutional neural network","Yes, skin cell segmentation from MPM images","Adaptation","No, single models used for each task","Automatic segmentation of multiphoton microscopy (MPM) in vivo images using deep learning","Yes, dense concatenation and feature reuse to deepen the depth of network architecture","Not applicable (skin cell segmentation)","In-house dataset from dorsal forearm skin cells with a resolution of 128×128 pixels","60 training images taken using femtosecond Ti:Sa laser running at 735 nm","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed method for MPM image enhancement and denoising","Quantitative measures: accuracy, loss value, Dice coefficient, F1-Score","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with U-Net and Seg-Net for MPM image segmentation","Quantitative measures: accuracy, loss value, Dice coefficient, F1-Score","Dense-Unet achieved an accuracy of 92.54%, a lower loss value of 0.1681, and a higher Dice coefficient value of 90.60%","Yes, Dense-Unet outperformed U-Net by 3.95% in terms of accuracy and Seg-Net by 7.56% in terms of F1-Score","No (tested on in-house dataset from dorsal forearm skin cells)","Not explicitly stated","Dense-unet: A novel multiphoton in vivo cellular image segmentation model based on a convolutional neural network"
"Not applicable (study on patient perspective and acceptance of AI in skin cancer diagnostics)","Yes, melanoma diagnosis","N/A","No","To evaluate patients' view and concerns about artificial intelligence in melanoma diagnostics","Not applicable (study on patient perspective)","Melanoma","N/A","N/A","No (not relevant to study on patient perspective and acceptance of AI in skin cancer diagnostics)","Not applicable (study on patient perspective)","Descriptive analysis, statistical tests to investigate associations between sociodemographic data and selected items","N/A","N/A","No","Support for use of AI in medical approaches (94%), willingness to make health data available anonymously (88%)","Patients with a previous history of melanoma were more amenable to the use of AI applications for early detection even at home, and preferred an application scenario where physician and AI classify lesions independently.","No","N/A","Patients' concerns about insufficient data protection, impersonality and susceptibility to errors","Artificial Intelligence in Skin Cancer Diagnostics: The Patients' Perspective"
"Multi-agent learning neural network and Bayesian model","Yes, real-time skin detectors based on IoT","Adaptation","No, single models used for each task","Develop a new methodology for evaluating and benchmarking multi-agent learning neural network and Bayesian model for real-time skin detectors based on Internet of things (IoT)","Yes, feature extraction using different colour spaces: RGB, YIQ, normalised RGB","Not specified in the text but mentioned as 'skin' detection","Real-time camera-based cloud IoT dataset with caption images (not specified number of images)","Not specified in the text but mentioned as 'large number of images' used for training and testing multi-agent learning neural network model","No (class imbalance not explicitly stated)","Yes, skin detection approach developed by applying multi-agent learning based on different colour spaces","Multi-criteria decision-making (MCDM) method: technique for order preference by similarity to ideal solution and multi-layer analytic hierarchy process","Not applicable","No (not mentioned as part of the proposed methodology)","Yes, comparison with state-of-the-art methods for real-time skin detection based on IoT","Multi-criteria decision-making metrics: reliability, time complexity, error rate within a dataset","Normalised RGB colour space had the highest value and was the most recommended of all spaces (best result not specified in terms of specific metric)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed methodology","No (tested on real-time camera-based cloud IoT dataset)","Not explicitly stated","Multi-agent learning neural network and Bayesian model for real-time IoT skin detectors: a new evaluation and benchmarking methodology"
"Convolutional Neural Networks (CNN)","Yes, skin cancer classification","Adaptation","No, single models used for each task","Effects of label noise on deep learning-based skin cancer classification","Yes, CNN extracts features from dermatoscopic images","Melanoma and nevi (skin cancers)","804 images labeled by dermatologists or biopsy-verified labels","Not specified in the text but mentioned as 'large number of images' used for training and testing CNN model","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed method","4-fold cross validation with dermatological or biopsy-verified diagnosis as ground truth","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin cancer classification","Accuracy and confidence intervals","High accuracy achieved: 75.03% (95% CI: 74.39–75.66%) on dermatological labels and 73.80% (95% CI: 73.10–74.51%) on biopsy-verified labels when using identical ground truths for training and test","Yes, comparison with state-of-the-art methods demonstrated the sensitivity of CNN to label noise","No (tested on a single dataset)","Highly sensitive to label noise; future work should use biopsy-verified training images","Effects of Label Noise on Deep Learning-Based Skin Cancer Classification"
"AlexNet deep neural network (DNN)","Yes, high-throughput quantitative histology in systemic sclerosis skin disease","Adaptation","No, single model used for each task","Development of a new histopathological outcome measure for SSc using computer vision technology","Yes, deep features extracted by DNN from stained sections of SSc skin","Systemic sclerosis (SSc)","Two independent cohorts: primary cohort (n = 6) and secondary cohort (n = 60 SSc and 16 controls)","Not specified in the text but mentioned as 'large number of images' used for training and testing DNN model","No (class imbalance not explicitly stated)","Yes, trichrome-stained biopsy sections were photomicrographed before analysis by DNN","Quantitative measures: correlation between Fibrosis Scores and mRSS, Scleroderma Skin Severity Score (4S), longitudinal changes in mRSS on a per patient basis","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with modified Rodnan skin score (mRSS) and Scleroderma Skin Severity Score (4S)","Quantitative measures: correlation between Fibrosis Scores and mRSS, Scleroderma Skin Severity Score (4S), longitudinal changes in mRSS on a per patient basis","DNN-derived Fibrosis Score significantly correlated with 4S (R = 0.69, p = 3 × 10-17)","Yes, proposed method demonstrated improved performance compared to traditional outcome measures for SSc","No (tested on two independent cohorts: primary and secondary)","Not explicitly stated","High-throughput quantitative histology in systemic sclerosis skin disease using computer vision"
"Semi-automated treatment planning including 3D printable applicator holders","Yes, complex skin brachytherapy for malignant skin diseases","Adaptation","No, single models used for each task","Automated treatment planning and 3D printable applicator holders in complex skin HDR-BT","Yes, auto-generated treatment plans using computed tomography simulation images (CT) for feature extraction","Malignant skin diseases","Not specified in the text but mentioned as 'clinical cases' used to test and implement proposed methodology","Not specified in the text but mentioned as 'large number of images' used for training and testing auto-planning system","No (class imbalance not explicitly stated)","Yes, CT simulation images pre-processed to generate treatment plans","Quantitative measures: coverage achieved at prescription depth, D90 for clinical test case","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with standard clinical plan generation process and manual treatment planning","Quantitative measures: coverage achieved at prescription depth, D90 for clinical test case","Auto-planning system achieved higher quality plans compared to standard clinical workflow (D90 of 100.29% vs 93.5%)","Yes, proposed methodology demonstrated improved treatment plan quality and reduced complexity in HDR-BT","No (tested on various clinical cases)","Not explicitly stated","Development and clinical implementation of semi-automated treatment planning including 3D printable applicator holders in complex skin brachytherapy"
"Not specified (review of various deep learning approaches)","Yes, skin lesion segmentation and classification","Adaptation","No, single models used for each task","Review of deep learning algorithms performance in skin lesion segmentation","Yes, various techniques (convolutional neural network) used for feature extraction and image analysis","Melanoma","Not specified but mentioned as 'large training dataset' needed to overcome challenges of dermoscopic skin lesion images","Not specified in the text but mentioned as 'thousands of images' used for training and testing deep learning models","No (class imbalance not explicitly stated)","Yes, image preprocessing techniques described briefly","Quantitative measures: Jaccard coefficient, sensitivity, specificity, accuracy","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparative analysis with state-of-the-art techniques and models presented in review","Quantitative measures: Jaccard coefficient, sensitivity, specificity, accuracy","Not specified (review presents various results from different studies)","Yes, comparison with state-of-the-art techniques and models demonstrated the importance of deep learning algorithms in skin lesion segmentation","No (tested on various datasets but not explicitly stated which ones)","Lack of large training dataset makes problems even more challenging","Deep learning approaches towards skin lesion segmentation and classification from dermoscopic images - a review"
"Convolutional neural network (CNN) based on two datasets","Yes, cutaneous disease diagnosis in the Chinese population","Adaptation","No, single models used for each task","Deep learning-based classifier developed with dermoscopic images shows comparable performance to 164 dermatologists in cutaneous disease diagnosis","Yes, deep features extracted by CNN for skin tumor and psoriasis classification","Skin tumors (BCC, melanocytic nevus, seborrheic keratosis) and psoriasis","Two datasets: Dataset I (7192 dermoscopic images) and Dataset II (3115 dermoscopic images)","Not specified in the text but mentioned as 'modest number of dermoscopic images' used for training CNN model","No (class imbalance not explicitly stated)","Yes, skin refinement step included in proposed method","Quantitative measures: accuracy, sensitivity, specificity, Kappa coefficients","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with 164 dermatologists in a reader study with 130 dermoscopic images","Quantitative measures: accuracy, sensitivity, specificity, Kappa coefficients","CNN achieved comparable performance to 164 dermatologists for skin tumor and psoriasis classification (accuracy of multi-class model was 81.49% ± 0.88%)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on two datasets: Dataset I and Dataset II)","Not explicitly stated","Deep learning-based, computer-aided classifier developed with dermoscopic images shows comparable performance to 164 dermatologists in cutaneous disease diagnosis in the Chinese population"
"Pre-trained VGG19 CNN network","Yes, blue-white veil classification in dermoscopy images of skin lesions","Adaptation","No, single model used for binary classification task","Assessment of whether the blue-white veil is present or absent within the lesion using CNN","Yes, pre-trained VGG19 network extracts features from dermoscopy images","Not specified in the text (skin lesions)","PH2 dataset","Not specified in the text but mentioned as 'prepared images' used for training and testing CNN model","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed method","Binary classification task: presence or absence of blue-white veil within the lesion","Yes, pre-trained VGG19 network used for transfer learning","No (not mentioned as part of the proposed method)","Not explicitly stated but compared with Three-Point Checklist of Dermatology screening method","Binary classification metrics: accuracy, precision, recall, F1-score","CNN achieved good results in assessing whether blue-white veil is present or absent within the lesion using PH2 dataset","Not explicitly stated but compared with Three-Point Checklist of Dermatology screening method","No (tested on PH2 dataset)","Not explicitly stated","Blue-White Veil Classification in Dermoscopy Images of the Skin Lesions Using Convolutional Neural Networks"
"Region-Based Convolutional Neural Network (RCNN)","Yes, keratinocytic skin cancer detection on the face","Adaptation","No, single model used for each task","Automated localization and diagnosis of skin cancer using deep learning algorithm","Yes, convolutional neural networks (CNN) extracted features from image crops to locate and diagnose cancer","Keratinocytic skin cancer on the face","Validation data sets obtained from 3 hospitals between January 1, 2010, and September 30, 2018 (2844 images from 673 patients)","924538 possible lesions extracted from 182348 clinical photographs used for training RCNN model","No (class imbalance not explicitly stated)","Yes, image crops were created and annotated manually or automatically based on image findings","Quantitative measures: area under the receiver operating characteristic curve, F1 score, Youden index score","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with performance of dermatologists, residents, non-dermatologic physicians and general public without medical background","Quantitative measures: area under the receiver operating characteristic curve, F1 score, Youden index score","RCNN achieved an area under the receiver operating characteristic curve for validation data set (673 patients) was 0.910 and sensitivity and specificity of 76.8% and 90.6%, respectively at a high-sensitivity cutoff threshold.","Yes, RCNN showed comparable accuracy with dermatologists' performance","No (tested on validation data sets obtained from 3 hospitals)","Not explicitly stated","Keratinocytic Skin Cancer Detection on the Face Using Region-Based Convolutional Neural Network"
"EfficientNet-B4 architecture","Yes, psoriasis classification and diagnosis using dermoscopic images","Adaptation","No, single model used for each task","Automated classification of papulosquamous skin diseases (psoriasis) using deep learning","Yes, EfficientNet-B4 architecture extracts features from dermoscopic images","Psoriasis and other papulosquamous skin diseases","7033 dermoscopic images collected from the Department of Dermatology, Peking Union Medical College Hospital (China)","Not specified in the text but mentioned as 'large number of images' used for training and testing EfficientNet-B4 model","No (class imbalance not explicitly stated)","Yes, dermoscopic images pre-processed before feeding into EfficientNet-B4 architecture","Five-fold cross-validation on the training set to compare classification performance of EfficientNet-B4 over different networks commonly used in previous studies","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with board-certified dermatologists' diagnoses and performance on par with them for psoriasis classification","Sensitivity, specificity, accuracy, F1 score, AUC-ROC curve","EfficientNet-B4 achieved mean sensitivity of 0.929± 0.028 and specificity of 0.952 ± 0.004 for psoriasis classification in the four-class task","Yes, comparison with state-of-the-art methods demonstrated comparable performance to board-certified dermatologists' diagnoses","No (tested on a single dataset collected from Peking Union Medical College Hospital)","Not explicitly stated","A convolutional neural network trained with dermoscopic images of psoriasis performed on par with 230 dermatologists"
"Machine learning and deep convolutional neural networks (CNNs) for automatic classification of radiation-induced skin reactions","Yes, erythema measurement and severity scoring in radiation dermatitis","Adaptation","No, single models used for each task","Development of machine learning models for artificial intelligence assisted measurement and severity scoring of radiation-induced dermatitis","Yes, deep features extracted by CNNs for erythema recognition and grading","Radiation-induced skin reactions (RISR)","2263 distinct images from 209 patients used for training and testing machine learning models","Not specified in the text but mentioned as 'large number of images' used for training and testing CNN model","No (class imbalance not explicitly stated)","Yes, digital skin imaging method ScarletredⓇ Vision used to convert 2D digital skin images using CIELAB color space","Quantitative measures: accuracy, sensitivity, specificity for erythema recognition and grading","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed system","Quantitative measures: accuracy, sensitivity, specificity for erythema recognition and grading","Ensemble CNN based on bagging and majority voting shows an accuracy, sensitivity and specificity of 87%, 90%, and 82% for a 2-class problem, respectively.","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed system","No (tested on dataset from single-center study)","Not explicitly stated","The mathematics of erythema: Development of machine learning models for artificial intelligence assisted measurement and severity scoring of radiation induced dermatitis"
"Various AI-based technologies (shallow and deep machine learning, neural networks)","Yes, skin cancer detection","Adaptation","No, single models used for each task","Identify and group different types of AI-based technologies used to detect and classify skin cancer","Yes, deep features extracted by neural networks for skin cancer detection","Skin cancer (not specified which type)","Not specified in the text but mentioned as '906 papers' retrieved from IEEE Xplore, ACM DL, and Ovid MEDLINE databases","Not specified in the text but mentioned as 'large number of images' used for training and testing AI models","No (class imbalance not explicitly stated)","Yes, image preprocessing steps included in proposed methods","Various evaluation metrics: accuracy, precision, recall, F1 score, ROC-AUC curve","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin cancer detection and classification","Various evaluation metrics: accuracy, precision, recall, F1 score, ROC-AUC curve","Studies that used smaller data sets reported higher accuracy (up to 11 evaluation metrics were used)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method in some cases","No (tested on various datasets but not specified which ones)","Reliability of shallow and deep models was questionable due to varied use of evaluation metrics and image types","Artificial intelligence for skin cancer detection: Scoping review"
"Convolutional Neural Network (CNN) based methods","Yes, vitiligo diagnosis","Adaptation","No, single models used for each task","Design and assessment of CNN-based methods for vitiligo diagnosis","Yes, deep features extracted by CNN for vitiligo detection and segmentation","Vitiligo (depigmented non-melanocytic lesions)","Two datasets: Chinese in-house dataset (2,876 images) and world-wide public dataset (1,341 images)","Not specified in the text but mentioned as 'large number of images' used for training and testing CNN models","No (class imbalance not explicitly stated)","Yes, close-up image preprocessing included in proposed method","Quantitative measures: F1 score, AUC, specificity, sensitivity metrics","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with human raters from different experience levels","Quantitative measures: F1 score, AUC, specificity, sensitivity metrics","CNNs achieved a comparable or higher performance compared to expert and intermediate raters for vitiligo diagnosis in both datasets","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on two different datasets)","Not explicitly stated","Design and Assessment of Convolutional Neural Network Based Methods for Vitiligo Diagnosis"
"Convolutional Neural Networks (CNNs)","Yes, skin cancer classification","Adaptation","No, single models used for each task","Automated skin cancer classification using CNN-based classifiers compared with clinicians","Yes, deep features extracted by CNNs for skin cancer classification","Melanoma and other types of skin cancers","Not specified in the text but mentioned as 'holdout/out-of-distribution data set' used for testing","Not specified in the text but mentioned as 'large number of images' used for training and testing CNN models","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed method","Comparison with human experts: sensitivity, specificity, accuracy, F1 score, area under the receiver operating characteristic curve (AUC-ROC) and other metrics","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with human experts demonstrated superior or at least equivalent performance of CNN-based classifiers","Sensitivity, specificity, accuracy, F1 score, AUC-ROC and other metrics","CNN-based classifiers showed superior or at least equivalent performance compared to clinicians in all included studies (19)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on various datasets but not explicitly stated which ones were used for testing)","Almost all studies conducted in highly artificial settings based exclusively on single images of suspicious lesions and did not represent full range of patient populations and melanoma subtypes encountered in clinical practice","Skin cancer classification via convolutional neural networks: systematic review of studies involving human experts"
"Convolutional Neural Networks (CNNs) with a 4-layer U-Net architecture","Yes, automated extraction of skin wound healing biomarkers from in vivo label-free multiphoton microscopy images","Adaptation","No, single models used for each task (wound section and in vivo z-stacks)","Automated image processing and quantification of wound geometry and metabolism using MPM images","Yes, deep features extracted by CNNs to segment MPM images and quantify wound healing biomarkers","Not specified (skin wounds in general)","MPM image dataset with 380 distinct images for wound section CNN and 5,848 images for in vivo z-stacks CNN","Not specified but mentioned as 'large number of images' used for training and testing CNNs","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed method to prepare MPM images for segmentation","Quantitative measures: accuracy, epidermal/dermal thickness, wound depth, wound width, % re-epithelialization, optical redox ratio","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with hand-traced outputs for six unstained wound sections and 69 wound edge z-stacks from eight mice","Quantitative measures: accuracy, epidermal/dermal thickness, wound depth, wound width, % re-epithelialization, optical redox ratio","CNNs achieved overall accuracy of 92.83% for MPM wound section CNN and 89.66% for in vivo z-stack CNN","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on a single dataset)","Not explicitly stated","Automated Extraction of Skin Wound Healing Biomarkers From In Vivo Label-Free Multiphoton Microscopy Using Convolutional Neural Networks"
"Convolutional Neural Network (CNN) architectures","Yes, skin cancer classification on dermoscopic images","Adaptation","No, single models used for each task","Establish a benchmark for neural network robustness in skin cancer classification","Yes, deep features extracted by CNN architectures for skin cancer classification","Melanoma and Nevus (skin neoplasms)","Proprietary dermoscopic image database: Skin Archive Munich (SAM), SAM-corrupted (SAM-C) and SAM-perturbed (SAM-P)","319 unmodified images in the SAM dataset","No, class imbalance not explicitly stated","Yes, image transformations used to create OOD robustness benchmark","Out-of-distribution (OOD) data: corruptions and perturbations applied to images in the SAM dataset","Not applicable","No, not mentioned as part of the proposed method","Yes, comparison with four different CNN architectures on OOD data","Accuracy and prediction stability over small image changes","CNNs showed susceptibility to corruptions and perturbations in the benchmark dataset","No explicit comparison with state-of-the-art methods, but provides a frame of reference for future evaluations","Yes, tested on three different datasets: SAM, SAM-C, and SAM-P","Not explicitly stated","A benchmark for neural network robustness in skin cancer classification"
"Xy-SkinNet (two-step strategy: region segmentation and information fusion)","Yes, classification of six common skin diseases","Adaptation","No, single model used for each task","Development of a Chinese database (Xiangya-Derm) and AI-assisted classification research on six common skin diseases","Yes, convolutional neural network (CNN) applied to extract features from input images","Not specified in the text but mentioned as 'six common skin diseases'","Xiangya-Derm database (over 150,000 clinical images of 571 different skin diseases)","Over 150,000 clinical images used for training and testing Xy-SkinNet model","No (class imbalance not explicitly stated)","Yes, image segmentation step included in proposed method","Comparison with human experts: 31 dermatologists of varied experiences","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with average accuracy of dermatologists (78.15%) and top 3 accuracy achieved by Xy-SkinNet model (84.77%))","Accuracy (top 1, top 2, top 3) and comparison with human experts' performance","Xy-SkinNet achieved a top 3 accuracy of 84.77%, exceeding the average accuracy of dermatologists (78.15%) for classification of six common skin diseases","Yes, Xiangya-Derm database and proposed model demonstrated superior performance compared to state-of-the-art methods","No (tested on Xiangya-Derm database)","Not explicitly stated","The classification of six common skin diseases based on xiangya-derm: Development of a chinese database for artificial intelligence"
"Image processing algorithm for extracting porphyrin fluorescence","Yes, age-dependent changes in porphyrins from fluorescence images of ultraviolet photography","Adaptation","No, single image processing algorithm used for each task","Quantitative assessment of age-dependent changes in porphyrins using fluorescence images by image processing","Yes, extraction of number, area, and mean intensity of porphyrin fluorescence from images","Not applicable (study focused on normal skin)","3595 healthy Japanese individuals aged 16-85 years with cheek sites under UV-LED excitation","Not specified in the text but mentioned as 'large number of images' used for training and testing image processing algorithm","No (class imbalance not explicitly stated)","Yes, preprocessing step included in proposed algorithm","Quantitative measures: accuracy, sensitivity, precision","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with existing methods for skin health record and analysis","Quantitative measures: accuracy, sensitivity, precision","Proposed algorithm achieved verification results of 71%, 72%, and 88% respectively for accuracy, sensitivity, and precision","Yes, comparison with existing methods demonstrated the superiority of proposed method","No (tested on a single dataset)","Not explicitly stated","Quantitative Assessment of Age-dependent Changes in Porphyrins from Fluorescence Images of Ultraviolet Photography by Image Processing"
"Not applicable (survey study on acceptance of AI-based mobile apps for skin cancer diagnostics)","Yes, skin cancer diagnosis and screening","N/A (not a model architecture)","No (single methods used for each task)","To examine how and to what extent individuals are willing to accept AI-based mobile apps for skin cancer diagnostics, with a focus on younger age groups","Not applicable (survey study not focused on feature extraction)","Skin cancer","Anonymous online survey data from participants below 35 years of age recruited through social media channels (Facebook, LinkedIn, Xing) with a total of 728 participants in the analysis","Not applicable (survey study not focused on image-based tasks)","No (class imbalance not explicitly stated)","N/A (not an image processing task)","Descriptive analysis and statistical tests to evaluate participants' attitudes toward mobile apps for skin examination","Not applicable (survey study not focused on transfer learning)","No (not mentioned as part of the survey study)","Yes, comparison with previous studies that included other age groups to determine similarities and differences in preferences and concerns","Positive attitude toward AI-based apps, willingness to use mobile diagnostic systems, accuracy requirements for app versions, data security concerns, trust issues, lack of personal interaction as dominant concerns among negative-minded participants","66.5% (484/728) of participants expressed a positive attitude toward the use of AI-based apps and preferred assistance system with high accuracy (>65%) and transparency in decision-making process","Yes, comparison with previous studies that included other age groups to determine similarities and differences in preferences and concerns","No (tested on anonymous online survey data from participants below 35 years of age)","Not explicitly stated","Digital natives' preferences on mobile artificial intelligence apps for skin cancer diagnostics: Survey study"
"Convolutional Neural Networks (CNNs) with integrated patient data","Yes, skin cancer classification","Adaptation","Yes, combines image features and patient data for improved performance","Integrating patient data into CNN-based diagnostic algorithms for skin cancer classification","Yes, deep features extracted by CNN from images and integrated with patient data","Skin cancer (melanoma not specified)","Not specified in the text but mentioned as 'various datasets' used across studies","Not specified in the text but mentioned as 'large number of images' used for training and testing CNN models","No (class imbalance not explicitly stated)","Yes, preprocessing steps included in proposed method to prepare image features for integration with patient data","Quantitative measures: accuracy, sensitivity, specificity, F1 score, etc.","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin cancer classification and diagnosis","Quantitative measures: accuracy, sensitivity, specificity, F1 score, etc.","Patient data integration improved performance in different skin lesion classification tasks (average improvement not specified)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on various datasets across studies but specific details not provided)","Unclear how individual patient data enhance classification performance in multiclass problems","Integrating patient data into skin cancer classification using convolutional neural networks: Systematic review"
"Convolutional neural networks (CNNs) and patient data","Yes, skin cancer classification (melanoma/nevus)","Adaptation","No, single models used for each task","Improving skin cancer classification by combining CNN-based histologic whole slide image analysis and patient data","Yes, deep features extracted by CNNs for skin cancer classification","Skin cancer (melanoma/nevus)","431 WSIs from two different laboratories","Not specified in the text but mentioned as 'large number of images' used for training and testing CNN model","No (class imbalance not explicitly stated)","Yes, histologic whole slide image analysis included in proposed method","Quantitative measures: AUROC, balanced accuracy","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin cancer classification and data fusion","Quantitative measures: AUROC, balanced accuracy","CNN on its own achieved best performance (AUROC = 92.30% ± 0.23%) but incorporating patient data improved balanced accuracy to 86.72% ± 0.36%","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on a single dataset)","Not explicitly stated","Combining CNN-based histologic whole slide image analysis and patient data to improve skin cancer classification"
"Artificial Intelligence (AI)-based tool for skin condition diagnosis","Yes, skin condition diagnosis by primary care physicians and nurse practitioners in teledermatology practices","Adaptation","No, single AI-based model used for each task","To evaluate an artificial intelligence (AI)-based tool that assists with diagnoses of dermatologic conditions","Yes, deep features extracted by AI-based tool for skin condition diagnosis","Not specified in the text but mentioned as 'dermatologic cases' which may include various types of cancers and non-cancers","Enriched set of cases representing 120 different skin conditions from a teledermatology practice serving 11 sites","1048 retrospective cases (672 female [64.2%]; median age, 43 [interquartile range, 30-56] years)","No (class imbalance not explicitly stated)","Yes, AI-based tool used for interpreting clinical images and associated medical history","Multiple-reader, multiple-case diagnostic study with reference diagnoses provided by a panel of 3 dermatologists","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with traditional methods for skin condition diagnosis and teledermatology practices","Diagnostic agreement with reference diagnoses provided by a panel of 3 dermatologists, diagnostic accuracy for biopsy-confirmed cases, biopsy and referral rates, review time, and diagnostic confidence","AI assistance was significantly associated with higher agreement with reference diagnoses (10% increase for PCPs and 12% increase for NPs)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed AI-based tool","No (tested on a single dataset from a teledermatology practice serving 11 sites)","Not explicitly stated","Development and Assessment of an Artificial Intelligence-Based Tool for Skin Condition Diagnosis by Primary Care Physicians and Nurse Practitioners in Teledermatology Practices"
"Deep learning based framework using EfficientNet-b4 as backbone and auxiliary classifiers","Yes, diagnosing multiple skin diseases in a clinical environment","Adaptation","No, single models used for each task","Accurate classification of common dermatoses using deep learning framework","Yes, deep features extracted by EfficientNet-b4 and auxiliary classifiers for skin disease diagnosis","Multiple types: basal cell carcinoma (BCC), melanocytic nevus (MN), port wine stain (PWS)","Dataset of 13,603 dermatologist-labeled dermoscopic images from a tertiary class hospital in China","Not specified in the text but mentioned as 'large number of images' used for training and testing deep learning model","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed framework","Quantitative measures: accuracy, sensitivity, specificity, area under curve (AUC), t-SNE for internal image features learned by the model","Pre-trained weights on ImageNet used as backbone of CNN architecture","No (not mentioned as part of proposed framework)","Yes, comparison with three widely used CNN models and board-certificated dermatologists for diagnostic accuracy","Quantitative measures: accuracy, sensitivity, specificity, area under curve (AUC), t-SNE for internal image features learned by the model","Proposed framework achieved an overall accuracy of 0.948 and AUC of 0.985 in classifying common dermatoses","Yes, proposed framework outperformed existing models with highest AUC value","No (tested on dataset from a tertiary class hospital in China)","Not explicitly stated","A Deep Learning Based Framework for Diagnosing Multiple Skin Diseases in a Clinical Environment"
"Novel transfer learning approach with deep convolutional neural network (DCNN) model","Yes, skin cancer classification and diabetic foot ulcer detection","Adaptation","No, single models used for each task","Medical imaging with limited labeled data using transfer learning approach","Yes, deep features extracted by DCNN model for medical image analysis","Skin cancer and breast cancer","Large unlabeled medical image datasets (not specified) and small amount of labeled images","Not specified in the text but mentioned as 'large number' used for training and testing DCNN model","No (class imbalance not explicitly stated)","Yes, preprocessing step included in proposed method","Quantitative measures: F1-score, accuracy, precision, recall","Yes, transfer learning approach used to fine-tune DCNN model on small labeled dataset","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for medical image classification and diabetic foot ulcer detection","Quantitative measures: F1-score, accuracy, precision, recall","Proposed approach achieved an F1-score value of 98.53% for skin cancer classification and 97.51% for breast cancer scenario when using transfer learning","Yes, proposed method outperformed state-of-the-art methods in both scenarios","No (tested on same dataset used to train the model)","Not explicitly stated","Novel transfer learning approach for medical imaging with limited labeled data"
"Convolutional neural network (CNN) based on ResNet-50","Yes, diagnosis and classification of rosacea","Adaptation","No, single model used for each task","Accurate identification of rosacea using clinical photos","Yes, deep features extracted by CNN for diagnosis and classification of rosacea","Rosacea (3 subtypes: erythematotelangiectatic, papulopustular, phymatous)","24,736 photos comprising of 18,647 photos of patients with rosacea and 6089 photos of patients with other skin diseases","Not specified in the text but mentioned as 'large number of images' used for training and testing CNN model","No (class imbalance not explicitly stated)","Yes, preprocessing step included in proposed method to prepare clinical photos for analysis by CNN","Quantitative measures: accuracy, precision, area under the receiver operating characteristic curve","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with diagnoses by dermatologists of different expertise levels showed that CNN system is capable of identifying rosacea with accuracy and precision comparable to experienced dermatologist","Quantitative measures: accuracy, precision, area under the receiver operating characteristic curve","CNN achieved an overall accuracy and precision of 0.914 and 0.898 for detection of rosacea, respectively; accuracy of classifying 3 subtypes of rosacea was 83.9%, 74.3%, and 80.0% respectively.","Yes, CNN system showed superior performance compared to resident doctors or attending physicians","No (tested on dataset comprising photos from patients with rosacea and other skin diseases)","Not explicitly stated","A novel convolutional neural network for the diagnosis and classification of rosacea: Usability study"
"Binary skin lesion classifier","Yes, melanoma and nevus classification","Adaptation","No, single models used for each task","Reducing the impact of confounding factors on skin cancer classification via image segmentation","Yes, deep features extracted by neural network for melanoma and nevus classification","Melanoma and Nevus","HAM (human against machine) and ISIC (International Skin Imaging Collaboration)","Not specified in the text but mentioned as 'large number of images' used for training and testing neural network model","No (class imbalance not explicitly stated)","Yes, image segmentation step included to remove lesion-adjacent confounding factors","Quantitative measures: balanced accuracy, precision, recall, F1 score, AUC-ROC curve","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with unsegmented classifiers demonstrated improved performance for segmented classifiers on HAM dataset","Quantitative measures: balanced accuracy, precision, recall, F1 score, AUC-ROC curve","Segmented classifiers showed a higher overall balanced accuracy (75.6%) than the unsegmented classifiers (66.7%) when trained on HAM dataset","Yes, comparison with state-of-the-art methods demonstrated improved performance for segmented classifiers","No (tested on HAM and ISIC datasets)","Image segmentation step might introduce new pitfalls that require further investigations","Reducing the impact of confounding factors on skin cancer classification via image segmentation: Technical Model Study"
"Self-attention Progressive Growing of GANs (SPGGAN) with Two-Timescale Update Rule (TTUR)","Yes, skin lesion detection and classification","Adaptation","No, single models used for data augmentation and generation","Data augmentation using GAN-based approach to generate realistic but diverse skin lesion images","Yes, self-attention mechanism in SPGGAN generates fine-grained features from all feature locations","Melanoma","HAM10000 dataset (used for data generation and classification tasks)","Not specified in the text but mentioned as 'large number of images' used for training SPGGAN model","No, class imbalance not explicitly stated","Yes, skin lesion images pre-processed using SPGGAN to generate realistic and diverse images","Quantitative measures: sensitivity (recall), precision, accuracy, F1 score","Not applicable","Yes, data augmentation performed using GAN-based approach with SPGGAN-TTUR","Yes, comparison with non-augmented and augmented counterparts (with classical DA) demonstrated statistically significant improvements in sensitivity","Quantitative measures: sensitivity (recall), precision, accuracy, F1 score","SPGGAN-TTUR achieved sensitivity improvement of 13.8% over melanoma class compared to non-augmented counterpart and 8.6% compared to augmented counterpart with classical DA","Yes, proposed approach demonstrated statistically significant improvements in sensitivity (p-value <0.05) over state-of-the-art methods","No, tested on HAM10000 dataset only","Not explicitly stated","Data augmentation for skin lesion using self-attention based progressive generative adversarial network"
"174-multiclass AI algorithm","Yes, skin disease diagnosis using teledermatology","Adaptation","No, single model used for multiple diseases","Assessing the diagnostic performance and potential clinical utility of a deep neural network in teledermatology","Yes, AI algorithm extracts features from patient images to aid diagnosis","Not specified (multiple skin conditions)","Consecutive patients who submitted images for teledermatology evaluation at a single centre","340 cases from 281 patients met study inclusion criteria","No, class imbalance not explicitly stated","Yes, image quality and patient skin type affected algorithm performance","Prospective diagnostic accuracy study with reader study including nine healthcare providers (3 dermatologists, 3 dermatology residents and 3 general practitioners)","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with human experts (dermatologists, residents, general practitioners) in reader study","Top-1 accuracy and balanced top-1 accuracy for multiple diseases","AI algorithm achieved a balanced top-1 accuracy of 47.6% when limited to diagnoses on which it had been explicitly trained","Yes, AI algorithm performance compared with human experts in reader study","No (tested on consecutive patients at a single centre)","Algorithm performance was associated with patient skin type and image quality","Performance of a deep neural network in teledermatology: a single-centre prospective diagnostic study"
"Integrated Deep Convolutional Neural Network (iDCNN_aMSL) model","Yes, dermoscopic differentiation of early melanomas from atypical nevi","Adaptation","Yes, combines clinical data with dermoscopic images for improved accuracy","Support dermatologists in the classification and management of atypical melanocytic skin lesions (aMSL)","Yes, deep features extracted by DCNN model from both dermoscopic images and clinical/anamnestic data","Melanoma","idScore dataset of 979 challenging aMSL cases (630 training, 135 validation, 214 testing)","Not specified in the text but mentioned as 'large number' used for training and testing DCNN model","No (class imbalance not explicitly stated)","Yes, dermoscopic images pre-processed before feeding into iDCNN_aMSL model","Quantitative measures: AUC, SE, SP, accuracy","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with DCNN_aMSL and intuitive diagnosis by dermatologists demonstrated superiority of iDCNN_aMSL model","Quantitative measures: AUC, SE, SP, accuracy","iDCNN_aMSL achieved an AUC = 90.3 %, SE = 86.5 % and SP = 73.6 % for lesion classification study","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed iDCNN_aMSL model","No (tested on idScore dataset)","Not explicitly stated","A new deep learning approach integrated with clinical data for the dermoscopic differentiation of early melanomas from atypical nevi"
"Hierarchical neural network with channel and spatial attention modules","Yes, skin cancer diagnosis","Adaptation","No, single models used for each task","Explainable skin lesion diagnosis using taxonomies","Yes, hierarchical neural network extracts features from dermoscopy images with the help of channel and spatial attention modules","Skin cancer (melanoma)","ISIC 2017 and ISIC 2018 datasets for skin lesion diagnosis","Not specified in the text but mentioned as 'large number of images' used for training and testing hierarchical neural network model","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed method to prepare dermoscopy images for analysis by hierarchical neural network","Quantitative measures: accuracy, precision, recall, F1 score, and other metrics used to evaluate performance of proposed model on ISIC datasets","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin cancer diagnosis and explainability demonstrated competitive results by proposed approach","Quantitative measures: accuracy, precision, recall, F1 score, etc.","Proposed hierarchical neural network achieved competitive results in two dermoscopy data sets (ISIC 2017 and ISIC 2018) with improved explainability compared to state-of-the-art methods","Yes, comparison demonstrated that proposed approach provides insightful information about its decisions, thus increasing the safety of the model for skin cancer diagnosis","No (tested on ISIC datasets)","Not explicitly stated","Explainable skin lesion diagnosis using taxonomies"
"CNN-based classifiers","Yes, melanoma image classification","Adaptation","No, single models used for each task","To understand the effects of masking in melanoma image classification with CNNs and to standardize image preprocessing","Yes, deep features extracted by CNN-based classifiers for skin lesion images","Melanoma","ISIC2016, ISIC2018, MedNode datasets (skin lesion images)","Not specified in the text but mentioned as 'large number of images' used for training and testing CNN-based classifiers","No (class imbalance not explicitly stated)","Yes, different strategies of image masking applied to skin lesion images: rectangular masks, circular masks, full masking, and image cropping","10-fold cross-validation for performance metrics evaluation","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for melanoma image classification and preprocessing standardization","Performance metrics: accuracy, precision, recall, F1 score, AUC-ROC","Cropping is the best strategy to maintain classification performance and reduce training times as well (best result not specified in terms of specific metric values)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method for preprocessing standardization","No (tested on ISIC2016, ISIC2018, and MedNode datasets)","CNNs have a tendency to focus on pixels of healthy skin when no malignant features can be identified","The Effects of Masking in Melanoma Image Classification with CNNs Towards International Standards for Image Preprocessing"
"Hybrid Deep Neural Networks (HDNN) integrating Multi-Layer Perceptron (MLP) network and Convolutional Neural Network","Yes, Hand, Foot, and Mouth Disease (HFMD) diagnosis using images and clinical data","Adaptation","Yes, combines image classification with clinical symptoms for improved disease diagnosis and classification performance","Digital Diagnosis of HFMD Using Hybrid Deep Neural Networks","Yes, features extracted from both branches (MLP network and CNN) are merged to form an integrated feature","Hand, Foot, and Mouth Disease (HFMD)","Not specified in the text but mentioned as 'image data only', 'clinical data only' and 'both sources of data'","20 images used for training and testing","No (class imbalance not explicitly stated)","Yes, image preprocessing step included in proposed method","Cross-validated experiments with accuracy as evaluation metric","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with typical MLP model and CNN model for image classification and clinical symptoms based disease classification","Accuracy","Proposed HDNN achieved accuracy of 99%-100% in diagnosing HFMD","No (not mentioned as part of the proposed method)","Yes, tested on image data only, clinical data only and both sources of data","Not explicitly stated","Digital Diagnosis of Hand, Foot, and Mouth Disease Using Hybrid Deep Neural Networks"
"Multi-agent technology for SM diagnostics","Yes, early diagnosis of skin melanoma (SM)","Adaptation","No, single multi-agent system used for each task","Evaluation of the use of multi-agent technology in the diagnosis of SM","Yes, various agents and teams involved in feature extraction and decision-making process","Skin melanoma (SM)","Samara Regional Clinical Oncological Dispensary database","Not specified in the text but mentioned as 'large number of patients' used for training and testing multi-agent system","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed method","Quantitative measures: share of 1–2 stages of MC, one-year mortality rate, proportion of patients with SM who were actively identified","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with previous years' data demonstrated improvement in early diagnosis and active detection of skin melanoma","Quantitative measures: share of 1–2 stages of MC, one-year mortality rate, proportion of patients with SM who were actively identified","Multi-agent technology reduced the one-year mortality rate by 48.3% and increased the growth rate of newly detected number of patients with early stage SM (stage 1-2) compared to increase in total number of cases","Yes, comparison with previous years' data demonstrated improvement in early diagnosis and active detection of skin melanoma","No (tested on Samara Regional Clinical Oncological Dispensary database)","Not explicitly stated","Medical and organizational approaches to early diagnosis of skin melanoma"
"Comprehensive method for analyzing dermatoscopic images using multi-Otsu methods and morphological segmentation","Yes, acne disease diagnosis and monitoring on facial skin","Adaptation","No, single models used for each task","Development of a comprehensive method for analyzing dermatoscopic images to monitor external manifestations of acne disease during treatment","Yes, color segmentation and gradations of skin inflammations extracted using multi-Otsu methods and morphological segmentation","Acne (acne vulgaris)","Not specified in the text but mentioned as 'dermatoscopic images' used for training and testing proposed method","Not specified in the text but mentioned as 'large number of images' used for training and testing proposed method","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed method using OpenCV library","Quantitative measures: calculation of red gradations to detect boundaries of inflammation, geometric parameters and percentage of lesions in relation to healthy facial skin","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for acne disease diagnosis and monitoring on facial skin","Quantitative measures: calculation of red gradations to detect boundaries of inflammation, geometric parameters and percentage of lesions in relation to healthy facial skin","Proposed method allows effective control of the condition of the skin from acne during treatment by analyzing degree of inflammatory processes and area of lesions","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method for acne disease diagnosis and monitoring on facial skin","No (tested on dermatoscopic images)","Not explicitly stated","DEVELOPMENT OF A COMPREHENSIVE METHOD FOR THE DERMATOSCOPIC IMAGES ANALYSIS OF THE FACIAL SKIN WITH ACNE"
"ESPNet and DenseNet for mitosis classification","Yes, melanoma cancer dataset used in the study","Adaptation","No, single models used for each task (mitosis classification)","Precise detection of mitotic figures using machine learning techniques","Yes, deep features extracted by CNN-based models for mitosis classification","Melanoma and breast cancer","Primary melanoma dataset (6 whole slide images) and MITOS breast biopsy dataset","Not specified in the text but mentioned as 'large number of images' used for training and testing CNN models","No (class imbalance not explicitly stated)","Yes, raw RGB images of mitosis and non-mitosis samples with their corresponding labels used as training input","Quantitative performance metrics: sensitivity, specificity, F-score, precision, recall, accuracy","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with other architectures (ResNet and ShuffleNet) on MITOS dataset","Quantitative performance metrics: sensitivity, specificity, F-score, precision, recall, accuracy","DenseNet achieved best results on MITOS dataset: precision of 0.939, recall of 0.916, and F-score of 0.927 for mitosis classification","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method (DenseNet)","No (tested on primary melanoma dataset and MITOS breast biopsy dataset)","Not explicitly stated","Machine learning techniques for mitoses classification"
"Not applicable (study on existing techniques)","Yes, skin cancer detection","Adaptation","No, single models used for each task","Early detection of cancer using machine learning and deep learning techniques","Yes, various feature extraction methods mentioned (PCA, LDA, SVD)","Multiple types: breast, brain, lung, liver, skin","Not specified in the text but mentioned as 'various datasets' used for each type of cancer","Not specified in the text but mentioned as 'large number of images' used for training and testing models","No (class imbalance not explicitly stated)","Yes, various preprocessing methods mentioned (ACM, PSO, UNet, watershed etc.)","Various evaluation metrics: accuracy, sensitivity, specificity, F1 score, AUC-ROC curve","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for cancer detection and classification","Various evaluation metrics: accuracy, sensitivity, specificity, F1 score, AUC-ROC curve","Not specified in the text (study on existing techniques)","Yes, comparison with state-of-the-art methods demonstrated the effectiveness of various machine learning and deep learning techniques for cancer detection and classification","No (tested on various datasets but not specific ones mentioned)","Not explicitly stated","Detail Study of Different Algorithms for Early Detection of Cancer"
"Deep learning model (DLM) for anatomical region mapping","Yes, automated macro- and micro-anatomical region mapping of skin photographs","Adaptation","No, single models used for each task","Improved diagnosis by automated anatomical region mapping in clinical patient pictures","Yes, deep features extracted by DLM for anatomical region mapping and disease diagnosis","Not specified (general dermatology)","Three datasets: macro-anatomy (6000 patient pictures), micro-anatomy (182 pictures of ear region), DD with 3347 pictures of 16 diseases determined by dermatologists in clinical settings","Not specified in the text but mentioned as 'large number of images' used for training and testing DLM model","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed method to generate body region maps from patient pictures","Quantitative measures: precision, sensitivity with 95% CI for macro-anatomy and micro-anatomy; DD performance improvement when trained with both lesion pictures and locations","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with DLM trained only on lesion pictures for disease diagnosis","Quantitative measures: precision and sensitivity with 95% CI; DD performance improvement when trained with both lesion pictures and locations","DLM achieved average precision of 85%, sensitivity of 84% for macro-anatomy, and improved DD performance by 6% (McNemar test P-value 0.0009) compared to DLM trained only on lesion pictures","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method in anatomical region mapping and disease diagnosis","No (tested on three datasets: macro-anatomy, micro-anatomy, DD)","Not explicitly stated","Improved diagnosis by automated macro- and micro-anatomical region mapping of skin photographs"
"Dense atrous spatial pyramid pooling (DenseASPP) and attention mechanism based on U-Net","Yes, skin lesion image segmentation","Adaptation","No, single models used for each task","Accurate segmentation of skin lesions using DenseASPP and attention mechanism","Yes, multi-scale feature information extracted by DenseASPP module","Skin disease (not specified as melanoma or other types)","ISIC2016 official public dataset","Not specified in the text but mentioned as 'large number of images' used for training and testing DenseASPP model","No (class imbalance not explicitly stated)","Yes, skin refinement step included in proposed method","Quantitative measures: mean Intersection over Union (mIOU), sensitivity (SE), precision (PC), accuracy (ACC), Dice coefficient (Dice)","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin lesion segmentation and detection","Quantitative measures: mIOU, SE, PC, ACC, Dice coefficient","DenseASPP model achieved average values of mIOU as 0.9018, SE as 0.9459, PC as 0.9487, and ACC as 0.9681 for skin lesion segmentation","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on ISIC2016 official public dataset)","Not explicitly stated","Image segmentation of skin lesions based on dense atrous spatial pyramid pooling and attention mechanism"
"Semi-Isotropic L-shaped network (SIL-Net)","Yes, dermoscopic image segmentation","Adaptation","No, single models used for each task","Precise segmentation of the lesion region using deep learning algorithms","Yes, Patch Embedding Weak Correlation (PEWC) module and Depth Separable Transpose Convolution (DSTC) based up-sampling module used to extract effective features","Skin cancer detection and therapy","ISIC-2017, ISIC-2018, PH2 dermoscopy benchmark datasets, CVC-ClinicDB and Kvasir-SEG intestinal polyp datasets","Not specified in the text but mentioned as 'large number of images' used for training and testing SIL-Net model","No (class imbalance not explicitly stated)","Yes, patch embedding process included in proposed method","Quantitative measures: Dice coefficient (DICE), Mean Intersection over Union (MIoU)","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for dermoscopic image segmentation and intestinal polyp detection","Quantitative measures: Dice coefficient (DICE), Mean Intersection over Union (MIoU)","SIL-Net achieved state-of-the-art performance on all five datasets, with DICE values of 89.63%, 93.47%, and 95.11% for ISIC-2017, ISIC-2018, and PH2 respectively","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on dermoscopy benchmark datasets)","Not explicitly stated","SIL-Net: A Semi-Isotropic L-shaped network for dermoscopic image segmentation"
"Multi-class CNN and six binary CNNs (game theory approach)","Yes, melanoma detection","Adaptation","No, single models used for each task with game theory approach to combine predictions","Computer-aided diagnosis of melanoma using deep neural networks and game theory","Yes, EfficientNetB5 backbone used in multi-class CNN and binary CNNs","Melanoma","ISIC dataset (8917 lesions: melanoma (1113), nevi (6705) and benign keratosis (1099))","Not specified in the text but mentioned as 'large number of images' used for training and testing CNN models","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed framework","Quantitative measures: area under receiver operating curve (AUROC), balanced accuracy (BACC)","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with existing methods for melanoma detection and diagnosis","Quantitative measures: AUROC, BACC","Proposed framework achieved an area under receiver operating curve (AUROC) of 0.93 for melanoma, 0.96 for nevus and 0.97 for benign keratosis","Yes, proposed method outperformed existing methods in this task with improved balanced accuracy (BACC)","No (tested on ISIC dataset only)","Not explicitly stated","Computer Aided Diagnosis of Melanoma Using Deep Neural Networks and Game Theory: Application on Dermoscopic Images of Skin Lesions"
"Radiochemotherapy (RCHT) with intensity-modulated RT (IMRT) and 3D image guidance","No, anal squamous cell carcinoma treatment","Adaptation","Yes, combination of radiotherapy and chemotherapy","Treatment of anal squamous cell carcinoma (ASCC) with RCHT and IMRT","No, not mentioned as part of the proposed method","Anal Squamous Cell Carcinoma (ASCC)","Mono-institutional series of 131 patients","Not specified in the text but mentioned as 'large number of images' used for training and testing IMRT model","No (class imbalance not explicitly stated)","Yes, image guidance accepted included 2D IGRT or 3D IGRT","Multivariate analysis: FFLR, OS, CFS, DMFS and PS","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with traditional radiotherapy methods","FFLR, OS, CFS, DMFS and PS","IMRT reduced severe acute gastro-intestinal (GI) and severe skin acute toxicity in comparison with 3DcRT","Yes, IMRT considered standard of care for ASCC treatment","No (tested on mono-institutional series of 131 patients)","Not explicitly stated","Anal squamous cell carcinoma: Impact of radiochemotherapy evolution over years and an explorative analysis of MRI prediction of tumor response in a mono-institutional series of 131 patients"
"Parallel branches network based on Transformer (MFC and ViT)","Yes, skin melanoma segmentation","Adaptation","No, single models used for each task","Accurate segmentation of the lesion area using a parallel network architecture based on Transformer","Yes, multiple residual frequency channel attention (MFC) and visual transformer (ViT) networks extract features from images","Melanoma","ISIC 2018 dataset for dermoscopy image segmentation","Not specified in the text but mentioned as 'large number of images' used for training and testing network","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed method","Quantitative measures: IoU, Dice coefficient","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with latest skin melanoma segmentation networks demonstrated improved performance","Quantitative measures: IoU, Dice coefficient","IoU and Dice coefficients achieved were 90.15% and 94.82%, respectively","Yes, proposed network outperformed latest skin melanoma segmentation networks in terms of accuracy","No (tested on ISIC 2018 dataset)","Not explicitly stated","Application of a parallel branches network based on Transformer for skin melanoma segmentation"
"Convolution Neural Network (CNN) with transfer learning","Yes, skin cancer detection and classification","Adaptation","No, single model used for each task","Automated skin cancer identification using deep learning","Yes, CNN extracts features from dermoscopic images","Multiple types of skin cancers: Basal Cell Carcinoma (BCC), Melanoma and Squamous Cell Carcinoma (SCC)","Dataset comprised of 10,000 clinical images","Not specified in the text but mentioned as 'large number of images' used for training and testing CNN model","No (class imbalance not explicitly stated)","Yes, image pre-processing includes classification, removing duplicates, sharpening, resizing","Quantitative measures: validation loss, Top-2 accuracy, Top-3 accuracy","Yes, transfer learning used to fine-tune the model for skin cancer detection","No (not mentioned as part of the proposed method)","Yes, comparison with different models demonstrated the effectiveness of proposed system","Quantitative measures: validation loss, Top-2 accuracy, Top-3 accuracy","Proposed system achieved high prediction accuracy using transfer learning and fine-tuning","Yes, comparison with state-of-the-art models demonstrated the superiority of proposed method","No (tested on a single dataset)","Not explicitly stated","Skin Cancer Detection using Deep Learning"
"Convolutional Neural Network (CNN) integrated with Long Short-Term Memory (LSTM) network","No, forecasting solar photosynthetic photon flux density under cloud cover effects","Adaptation","Yes, CNN and LSTM networks combined for predictive model","Forecasting near real-time (5-min) PPFD in a sub-tropical region Queensland, Australia","Yes, deep features extracted by CNN-LSTM network to predict short-term PPFD","No, related to solar radiation and photosynthesis","Real-time sky images captured through Total Sky Imager (TSI-440) in Queensland, Australia","Not specified in the text but mentioned as 'large number of images' used for training CNN-LSTM model","No (class imbalance not explicitly stated)","Yes, advanced sky image segmentation to reveal cloud chromatic features into statistical values","Quantitative measures: correlation coefficient, root mean square error, mean absolute error, relative error, Nash Sutcliffe’s coefficient, Legate and McCabe’s Index","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with competing algorithms: CNN, LSTM, deep neural network, extreme learning machine, multivariate adaptive regression spline","Quantitative measures: correlation coefficient, root mean square error, mean absolute error, relative error, Nash Sutcliffe’s coefficient, Legate and McCabe’s Index","CNN-LSTM model yielded a testing performance with correlation coefficient r = 0.92, RMSE = 210.31 μ mol of photons m−2 s−1, MAE = 150.24 μ mol of photons m−2 s−1, RRMSE = 24.92%, and ENS = 0.85","Yes, proposed method outperformed SZA-based models for forecasting solar radiation under cloud cover effects","No (tested on real-time sky images captured in Queensland, Australia)","Not explicitly stated","Forecasting solar photosynthetic photon flux density under cloud cover effects: novel predictive model using convolutional neural network integrated with long short-term memory network"
"Semisupervised deep learning algorithm","Yes, melanoma detection and classification","Adaptation","Yes, combines dermoscopic features with scoring rule from the 3-point checklist using ranking loss function","Automate skin lesion recognition by integrating human knowledge and artificial intelligence","Yes, deep learning algorithm extracts relevant features for melanoma classification","Melanoma","Small annotated dataset with disease and dermoscopic feature labels (not specified) + large unlabeled dataset with only disease label","Not specified in the text but mentioned as 'large number of images' used for training and testing semisupervised model","No (class imbalance not explicitly stated)","Yes, dermoscopic features extracted from images using deep learning algorithm","5-fold cross-validation with mean accuracy of 0.8943 and standard deviation of 0.0115 for melanoma classification","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with human annotators showed that semisupervised model can outperform them in some cases","Mean accuracy and standard deviation for melanoma classification under 5-fold cross-validation","Semisupervised model achieved mean accuracy of 0.8943 (SD 0.0115) with AUC values ranging from 0.76 to 0.9036 for dermoscopic feature detection","Yes, comparison showed that semisupervised learning framework can help combine semantic knowledge with computer algorithm to arrive at more accurate and interpretable diagnostic result","No (tested on small annotated dataset + large unlabeled dataset)","Not explicitly stated","Issues in Melanoma Detection: Semisupervised Deep Learning Algorithm Development via a Combination of Human and Artificial Intelligence"
"Model soups (averaging weights of multiple models)","Yes, dermoscopic melanoma-nevus skin cancer classification","Adaptation","No, single model used for each task but with averaged weights from multiple models","Improving performance of dermoscopic skin cancer classifiers using model soups","Yes, pre-trained models fine-tuned on seven different image resolutions and then averaged","Melanoma and Nevus (skin cancers)","Multi-source dataset with holdout and external components","Not specified in the text but mentioned as 'large number of images' used for training and testing model soups","No (class imbalance not explicitly stated)","Yes, image preprocessing included in fine-tuning pre-trained models on different resolutions","Quantitative measures: generalisation to other clinics, robustness against small image changes and calibration of confidences with predictive uncertainties","Pre-trained models used as starting point for fine-tuning","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin cancer classification and detection","Quantitative measures: generalisation to other clinics, robustness against small image changes and calibration of confidences with predictive uncertainties","Model soups improved performance on external component (generalisation) while maintaining performance on holdout component","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method for skin cancer classification and detection","No (tested on multi-source dataset)","Not explicitly stated","Model soups improve performance of dermoscopic skin cancer classifiers"
"MNet-10: a shallow convolutional neural network (CNN) model","Yes, medical image analysis for various types of cancer and diseases","Adaptation","No, single models used for each task with optimal configuration","Developing a robust shallow CNN model performing ablation study on medical images assessing the effectiveness of applying optimal data augmentation technique","Yes, deep features extracted by MNet-10 model using photometric and geometric augmentation techniques","Multiple types of cancer: breast cancer, skin cancer, brain tumor, COVID chest X-ray, tympanic membrane, chest computed tomography (CT) scan, and breast cancer ultrasound","Eight medical datasets with different modalities: mammogram dataset, skin cancer dataset, brain tumor magnetic resonance imaging (MRI), COVID chest X-ray, tympanic membrane, chest CT scan, breast cancer microscopic biopsy, and breast cancer ultrasound","Not specified in the text but mentioned as 'large number of images' used for training and testing MNet-10 model","No (class imbalance not explicitly stated)","Yes, photometric and geometric augmentation techniques applied to datasets before generating models","Quantitative measures: accuracy on various medical image analysis tasks","Not applicable","Yes, optimal data augmentation technique used with MNet-10 model for improving performance","Yes, comparison with VGG16, InceptionV3, and ResNet50 models on best-performing augmented datasets","Quantitative measures: accuracy on various medical image analysis tasks","MNet-10 model achieved test accuracy of up to 99.82% on chest CT scan dataset using photometric augmentation technique","Yes, comparison with state-of-the-art models demonstrated the superiority of MNet-10 model in medical image analysis tasks","No (tested on various datasets for each type of cancer and disease)","Not explicitly stated","MNet-10: A robust shallow convolutional neural network model performing ablation study on medical images assessing the effectiveness of applying optimal data augmentation technique"
"Machine learning (ML) model for image analysis","Yes, diagnosis of dermatological conditions using AI as a diagnostic decision support tool","Adaptation","No, single ML model used for each task","Prospective validation of an image analysis ML model as a diagnostic decision support tool for the diagnosis of dermatological conditions","Yes, deep features extracted by ML model for skin disease classification and detection","Not specified in the text (focus on general dermatology)","100 consecutive patients with skin problems from central Catalonia","Not specified in the text but mentioned as 'anonymized pictures of skin diseases' used for training and testing ML model","No (class imbalance not explicitly stated)","Yes, anonymization and introduction to ML model interface included in proposed method","Quantitative measures: precision, sensitivity, specificity, accuracy of ML model compared with GP and dermatologist assessments","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with current established workflow for teledermatology consultations","Quantitative measures: precision, sensitivity, specificity, accuracy of ML model compared with GP and dermatologist assessments","Not specified in the text (results still being analyzed)","Yes, comparison with current established workflow for teledermatology consultations","No (tested on a single dataset of 100 consecutive patients from central Catalonia)","Not explicitly stated","Using Artificial Intelligence as a Diagnostic Decision Support Tool in Skin Disease: Protocol for an Observational Prospective Cohort Study"
"Machine learning and deep learning based computational techniques","Yes, skin cancer detection and diagnosis","Adaptation","No, single models used for each task","Automated cancer detection in medical images using machine learning and deep learning based computational techniques","Yes, various features extracted by machine learning algorithms (SVM, GMM) and deep learning methods for cancer diagnosis","Multiple types of cancers: cervical cancer, oral cancer, breast cancer, brain cancer, skin cancer","Not specified in the text but mentioned as 'various datasets' used for training and testing machine learning models","Not specified in the text but mentioned as 'large number of images' used for training and testing deep learning models","No (class imbalance not explicitly stated)","Yes, image modalities used for cancer diagnosis include various preprocessing steps","Quantitative measures: accuracy, classification performance metrics such as sensitivity, specificity, precision, F1 score","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for cancer diagnosis and classification","Quantitative measures: accuracy, sensitivity, specificity, precision, F1 score","Machine learning algorithms (SVM, GMM) achieved excellent performance in classification of cancerous and normal tissue images, while deep learning dominated the field of medical image analysis with accuracies up to 100%","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on various datasets for each type of cancer)","Not explicitly stated","A Review on Automated Cancer Detection in Medical Images using Machine Learning and Deep Learning based Computational Techniques: Challenges and Opportunities"
"FSPBO-DQN: SeGAN based segmentation and Fractional Student Psychology Optimization enabled Deep Q Network","Yes, skin cancer detection in IoT applications","Adaptation","No, single models used for each task (pre-processing, segmentation, and cancer detection)","Effective skin cancer detection method using FSPBO-based DQN in wireless network scenario","Yes, deep features extracted by SeGAN for image segmentation","Skin cancer","Not specified in the text but mentioned as 'large number of images' used for training and testing FSPBO-DQN model","Not specified in the text but mentioned as 'large number of images' used for training and testing FSPBO-DQN model","No (class imbalance not explicitly stated)","Yes, Type II Fuzzy System and cuckoo search optimization algorithm filter employed to remove noise from images","Quantitative measures: accuracy, sensitivity, specificity","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin cancer detection and segmentation","Quantitative measures: accuracy, sensitivity, specificity","FSPBO-DQN achieved higher performance with values of 92.364% accuracy, 93.20% sensitivity, and 92.63% specificity for skin cancer detection","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on a large number of images but no specific dataset mentioned)","Not explicitly stated","FSPBO-DQN: SeGAN based segmentation and Fractional Student Psychology Optimization enabled Deep Q Network for skin cancer detection in IoT applications"
"Fractal signatures (SSPF and SSTF) with Linear Discriminant Analysis (LDA) classifier","Yes, multi-class skin lesion classification using dermoscopic images","Adaptation","No, single models used for each task","Automated multi-class skin lesion classification using fractal signatures and LDA classifier","Yes, fractal signatures (SSPF and SSTF) extracted from dermoscopic images","Not specified in the text but mentioned as 'skin lesions'","ISIC database from 2019 containing 25,331 images divided into eight highly unbalanced classes","25,331 (training: 20,266 and testing: 5,065)","No (highly unbalanced dataset with marked imbalance affecting minority classes)","Yes, images of different sizes and resolutions pre-processed for analysis","Accuracy, sensitivity, specificity, precision, and mean ±1 standard deviation reported for both training and testing datasets","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method using SSTF with LDA classifier","Accuracy, sensitivity, specificity, precision, and mean ±1 standard deviation reported for both training and testing datasets","SSTF with LDA classifier achieved 87% accuracy, 63% sensitivity, 89% specificity, and 65% precision for simultaneous classification of 4 classes; 88% accuracy, 41% sensitivity, 92% specificity, and 46% precision for simultaneous classification of 7 classes","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method using SSTF with LDA classifier","No (tested on ISIC database from 2019)","Highly unbalanced dataset and marked imbalance affecting minority classes","Multi-class skin lesion classification using prism- and segmentation-based fractal signatures"
"Various AI/ML algorithms (not specified)","Yes, early detection of skin cancer","Adaptation","No, single models used for each type of skin cancer","Early diagnosis of skin cancers using AI/ML algorithms in community and primary care settings","Yes, various features extracted by AI/ML algorithms for early detection of skin cancer","Melanoma, Squamous Cell Carcinoma (SCC), Basal Cell Carcinoma (BCC)","Not specified in the text but mentioned as 'large number of studies' used to identify AI/ML algorithms for early detection of skin cancer","Not specified in the text but mentioned as 'hundreds of thousands of images' used to train and test AI/ML models","No (class imbalance not explicitly stated)","Yes, various preprocessing steps included in AI/ML algorithms for early detection of skin cancer","Diagnostic accuracy: mean diagnostic accuracy for melanoma (89.5%), SCC (85.3%), and BCC (87.6%)","Not applicable","No (not mentioned as part of the AI/ML algorithms)","Yes, comparison with traditional methods for early detection of skin cancer","Diagnostic accuracy: mean diagnostic accuracy for melanoma (89.5%), SCC (85.3%), and BCC (87.6%)","AI/ML algorithms showed reasonable mean diagnostic accuracy for early detection of skin cancer, but widespread adoption into community and primary care practice cannot currently be recommended until efficacy in these populations is shown.","Yes, comparison with state-of-the-art methods demonstrated the superiority of AI/ML algorithms","No (tested on various datasets for each type of skin cancer)","Heterogeneity of AI/ML methods and study designs; incomplete reporting in studies; few studies used data from populations with low prevalence of skin cancers","Artificial intelligence and machine learning algorithms for early detection of skin cancer in community and primary care settings: a systematic review"
"Convolutional Neural Networks (CNNs)","Yes, classification of skin cancer","Adaptation","No, single model used for each task","Classification of skin tumors based on Raman spectra analysis using CNNs","Yes, deep features extracted by CNNs from Raman spectra to classify skin cancer","Skin cancer (melanoma, basal cell carcinoma, squamous cell carcinoma)","617 cases of skin neoplasms (615 patients) with 70 melanomas, 122 basal cell carcinomas, 12 squamous cell carcinomas and 413 benign tumors","Not specified in the text but mentioned as 'large number of spectra' used for training and testing CNN models","No (class imbalance not explicitly stated)","Yes, data preprocessing included to avoid overfitting by dividing dataset into training set (80%) and test set (20%))","Quantitative measures: ROC AUCs for classifying malignant vs benign tumors, melanomas vs pigmented tumors, and melanomas vs seborrheic keratosis","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with projection on latent structures approach demonstrated that CNNs outperformed it","Quantitative measures: ROC AUCs for classifying malignant vs benign tumors, melanomas vs pigmented tumors, and melanomas vs seborrheic keratosis","CNN achieved high performance with ROC AUCs of 0.96 (malignant vs benign), 0.90 (melanoma vs pigmented tumor) and 0.92 (melanoma vs seborrheic keratosis)","Yes, CNN outperformed state-of-the-art methods for skin cancer classification","No (tested on a single dataset of 617 cases of skin neoplasms)","Not explicitly stated","Classification of skin cancer using convolutional neural networks analysis of Raman spectra"
"Not applicable (systematic review of existing XAI methods)","Yes, skin cancer recognition","Adaptation","No, single models used for each task","Explainable artificial intelligence in skin cancer recognition: A systematic review","Not applicable (review of existing methods)","Skin neoplasms (skin cancer)","Various datasets used by included studies, not specified in the text","Not specified in the text but mentioned as 'large number of images' used for training and testing DNNs","No (class imbalance not explicitly stated)","Yes, various preprocessing steps included in reviewed studies","Quantitative measures: accuracy, sensitivity, specificity, F1 score, AUC-ROC","Not applicable (review of existing methods)","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art XAI methods for skin cancer detection and recognition","Quantitative measures: accuracy, sensitivity, specificity, F1 score, AUC-ROC","XAI is commonly applied during the development of DNNs for skin cancer detection, but systematic evaluation of its usefulness in this scenario is lacking.","Yes, comparison with state-of-the-art XAI methods demonstrated the need for further research on evaluating the performance and confidence of humans using CAD systems with XAI","No (tested on various datasets used by included studies)","Systematic evaluation of XAI's usefulness in skin cancer detection is lacking","Explainable artificial intelligence in skin cancer recognition: A systematic review"
"3D total-body photography","Yes, monitoring of nevi (moles)","Not applicable","No, single modality used for each task","Monitoring of nevi using 3D total-body photography and dermoscopy in a general population-based cohort study","Yes, digital images captured by 3D total-body photography to facilitate identification of new and changing nevi","Melanoma (not explicitly stated but implied as potential outcome)","Australian General Population-Based Cohort Study dataset (149 participants aged 20-70 years from South East Queensland, Australia)","Not specified in the text but mentioned as 'large number of images' captured by 3D total-body photography","No (class imbalance not explicitly stated)","Yes, dermoscopy and image analysis used to monitor nevi","Patient-reported experience surveys at halfway study time point (18 months) and final study time point (36 months)","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with traditional methods for monitoring nevi","Patient-reported experience surveys: trust in technology, comfort level, intended future use, and willingness to pay","Most participants (69.1% at 18 months and 69.8% at 36 months) stated they completely trusted 3D total-body imaging for diagnosis and monitoring of their nevi","Yes, comparison with traditional methods demonstrated the potential benefits of using 3D total-body photography for monitoring nevi","No (tested on Australian General Population-Based Cohort Study dataset)","Potential barriers to uptake: trust in technology, digital privacy, cost, and travel requirements","The Experience of 3D Total-Body Photography to Monitor Nevi: Results from an Australian General Population-Based Cohort Study"
"Various state-of-the-art algorithms","Yes, skin cancer classification from dermoscopic images","Adaptation","No, single models used for each task","Validation of artificial intelligence prediction models for skin cancer diagnosis using dermoscopy images: the 2019 International Skin Imaging Collaboration Grand Challenge","Yes, deep features extracted by machine learning algorithms for skin cancer classification","Multiple types of skin cancers (8 diseases)","HAM10000 and BCN20000 datasets (25,331 training images) plus test datasets from countries not included in the training dataset (Turkey, New Zealand, Sweden, and Argentina)","Not specified in the text but mentioned as 'large number of images' used for training and testing machine learning algorithms","No (class imbalance not explicitly stated)","Yes, pre-processing steps included in proposed method to handle image artifacts such as hair, pen markings, ulceration, etc.","Quantitative measures: balanced accuracy against HAM10000 and BCN20000 test datasets and data from countries not included in the training dataset","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with expert dermatologists' performance on a simulated setting that reflected intended clinical use","Quantitative measures: balanced accuracy against HAM10000 and BCN20000 test datasets and data from countries not included in the training dataset","The best performing algorithm achieved 58.8% balanced accuracy on the BCN20000 data, which was designed to better reflect realistic clinical scenarios.","Yes, comparison with state-of-the-art algorithms demonstrated specific deficiencies and safety issues in AI diagnostic systems for skin cancer","No (tested on HAM10000 and BCN20000 datasets plus test datasets from countries not included in the training dataset)","Specific limitations mentioned: shifted statistical distributions, disease categories not included in training data, image artifacts such as hair, pen markings, ulceration, etc.","Validation of artificial intelligence prediction models for skin cancer diagnosis using dermoscopy images: the 2019 International Skin Imaging Collaboration Grand Challenge"
"AI4Leprosy: AI-enabled image-based diagnosis assistant for leprosy","Yes, leprosy detection and classification using skin images and clinical data","Adaptation","No, single models used for each task","Accelerating global leprosy elimination through AI-driven diagnosis assistant","Yes, deep features extracted by CNN-based AI algorithm from skin images and clinical data","Leprosy","Open-source dataset of 1229 collected skin images and 585 sets of metadata from Brazilian leprosy national referral center","Not specified in the text but mentioned as 'large number' used for training and testing AI models","No (class imbalance not explicitly stated)","Yes, skin images pre-processed using standardized process before feeding into AI algorithm","Quantitative measures: classification accuracy, area under curve (AUC), elastic-net logistic regression","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for leprosy diagnosis and classification","Quantitative measures: classification accuracy, area under curve (AUC), elastic-net logistic regression","AI4Leprosy achieved high classification accuracy of 90% and AUC of 96.46% for leprosy diagnosis using combination of skin images and clinical data","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on open-source dataset from Brazilian leprosy national referral center)","Future validation needed to gather larger datasets and collect images using smartphone cameras in real-world settings","Reimagining leprosy elimination with AI analysis of a combination of skin lesion images with demographic and clinical data"
"Tandem and cylinder as an intracavitary brachytherapy device","No, carcinoma of the cervix treatment (not skin-related)","Adaptation","Yes, combination with external beam radiotherapy for definitive and adjuvant treatments","Evaluation of local control and toxicities in carcinoma of the cervix using tandem and cylinder as brachytherapy applicator","No (not applicable to this study)","Carcinoma of the cervix","Not specified, but mentioned as a tertiary care hospital dataset from January 2014 to December 2018","Not specified in the text","No (class imbalance not explicitly stated)","Yes, imaging for local control and monitoring of toxicities using Common Terminology Criteria for Adverse Events version 5.0","Statistical analysis using SPSS Version 20.0 to evaluate results","Not applicable (not a machine learning model)","No (not mentioned as part of the study)","Yes, comparison with standard brachytherapy applicators for carcinoma cervix treatment","Local control rate, acute and late toxicities using Common Terminology Criteria for Adverse Events version 5.0","83.87% local control achieved in cases treated with tandem and cylinder as intracavitary brachytherapy device","Yes, comparison with standard brachytherapy applicators demonstrated similar toxicities and local control rates","No (tested on a single dataset from January 2014 to December 2018)","Required dose prescription to point A was not possible in all patients due to limitations of OARs, long-term follow-up needed for patterns of failure and recurrence-free survival","To evaluate the use of tandem and cylinder as an intracavitary brachytherapy device for carcinoma of the cervix with regard to local control and toxicities"
"Various AI methods (supervised, unsupervised, deep learning) for cancer diagnosis","Yes, skin cancer diagnosis","Adaptation","No, single models used for each type of cancer","Cancer diagnosis using artificial intelligence: a review","Yes, AI methods extract relevant features from medical images and genomic data","Multiple types of cancers (breast, lung, liver, skin cancer, leukaemia)","Not specified in the text but mentioned as 'benchmark datasets' for each type of cancer","Not specified in the text but mentioned as 'large number of images' used for training and testing AI models","No (class imbalance not explicitly stated)","Yes, image preprocessing step included in proposed method","Quantitative measures: accuracy, sensitivity, specificity, false-positive rate","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for cancer diagnosis and treatment","Quantitative measures: accuracy, sensitivity, specificity, false-positive rate","AI methods showed improved performance compared to traditional methods for cancer diagnosis and treatment","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on benchmark datasets for each type of cancer)","Challenges in AI development: data quality, model interpretability, and clinical application","Cancer diagnosis using artificial intelligence: a review"
"Artificial intelligence-based skin cancer early detection system","Yes, skin cancer diagnosis for all skin tones","Adaptation","No, single model used for each task","Develop and evaluate an artificial intelligence-based skin cancer early detection system for all skin tones using clinical images","Yes, deep learning features extracted from generated images of darker skin tones to improve generalizability of skin cancer detection","Skin cancer","Publicly available skin image repositories (mostly light-skin images) and newly generated images for darker skin tones","Not specified in the text but mentioned as 'large number of images' used to develop robust model","No, class imbalance not explicitly stated","Yes, image blending technique may be used to generate realistic images for darker skin tones","Quantitative and qualitative evaluation: human expert ratings, non-expert ratings, quantitative image quality assessment","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with existing light-skin image repositories and models for skin cancer detection","Quantitative metrics: accuracy, sensitivity, specificity; qualitative evaluation by human experts and non-experts","Expected to improve generalizability of skin cancer detection and assist family physicians and dermatologists in evaluating skin lesion severity and diagnosing skin lesions","Yes, comparison with existing models for skin cancer detection demonstrated the need for more diverse image repositories","No (tested on publicly available light-skin images and newly generated darker skin tone images)","Not explicitly stated","Leveraging Artificial Intelligence to Improve the Diversity of Dermatological Skin Color Pathology: Protocol for an Algorithm Development and Validation Study"
"Convolutional Neural Networks (CNNs) with transfer learning","Yes, diagnosing Lyme disease from skin lesion images","Adaptation","No, single models used for each task","Automated diagnosis of Lyme disease using CNNs and transfer learning","Yes, deep features extracted by CNNs for image classification","Lyme disease (specifically erythema migrans skin lesions)","Custom EM dataset created with expert dermatologists from Clermont-Ferrand University Hospital Center of France","Not specified in the text but mentioned as 'large number of images' used for training and testing CNN models","No (class imbalance not explicitly stated)","Yes, skin lesion dataset HAM10000 pre-trained on ImageNet to improve performance","Quantitative measures: accuracy, AUC, precision, sensitivity, specificity","Yes, custom transfer learning from ImageNet pre-trained models and pre-training with HAM10000 dataset","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for Lyme disease diagnosis using CNNs","Quantitative measures: accuracy, AUC, precision, sensitivity, specificity","Customized ResNet50 architecture achieved best classification accuracy of 84.42% ±1.36 and AUC of 0.9189±0.0115 for Lyme disease diagnosis","Yes, comparison with state-of-the-art methods demonstrated the effectiveness of proposed method","No (tested on custom EM dataset)","Not explicitly stated","Exploring convolutional neural networks with transfer learning for diagnosing Lyme disease from skin lesion images"
"ExAID: A multimodal explanation framework for computer-aided diagnosis of skin lesions","Yes, melanoma classification and detection from dermoscopic images","Adaptation","No, single models used with ExAID framework for explanations","Providing multi-modal concept-based explanations for AI-based CAD systems in dermatology","Yes, deep learning based algorithm extracts features from dermoscopic images","Melanoma","Publicly available dermoscopic image datasets (not specified which ones)","Not specified in the text but mentioned as 'range of publicly available' datasets used for evaluation","No (class imbalance not explicitly stated)","Yes, pre-processing step included in ExAID framework","Quantitative and qualitative evaluation metrics: accuracy, concept detectors accuracy up to 81.46%","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for melanoma classification and detection","Quantitative metrics: accuracy, concept detectors accuracy up to 81.46%","ExAID framework achieved high accuracies in explaining pre-trained networks (up to 81.46%) comparable to supervised networks trained end-to-end","Yes, ExAID demonstrated utility and effectiveness for multi-modal explanations in CAD-assisted scenarios even with wrong disease predictions","No (tested on publicly available dermoscopic image datasets)","Not explicitly stated","ExAID: A multimodal explanation framework for computer-aided diagnosis of skin lesions"
"Moleanalyzer Pro (market-approved CNN)","Yes, skin cancer detection","Adaptation","No, single model used for each task","Analysis of sex-related differences in the diagnostic performance of a market-approved convolutional neural network (CNN) for skin cancer detection","Yes, deep features extracted by CNN for skin lesion classification","Skin cancer (melanoma and nevi)","Open-access dermoscopic image repositories (not specified which ones were used)","1549 dermoscopic images stratified by sex (female n = 773; male n = 776)","No, under-representation of female patients in open-access training data","Yes, pre-processing step included in CNN framework","Quantitative measures: sensitivity, specificity, ROC-AUC","Not applicable (market-approved model)","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin cancer detection and classification","Quantitative measures: sensitivity, specificity, ROC-AUC","CNN achieved comparable diagnostic performance in dermoscopic images of female versus male origin (sensitivity: 87.0% vs 87.1%, specificity: 98.7% vs 96.9%, ROC-AUC: 0.984 vs 0.979)","Yes, comparison with state-of-the-art methods demonstrated no sex-related bias in the classification of skin lesions","No (tested on a single dataset of 1549 dermoscopic images)","Sex-related imbalances in open-access training data may affect generalizability and robustness of CNN model","Does sex matter? Analysis of sex-related differences in the diagnostic performance of a market-approved convolutional neural network for skin cancer detection"
"Artificial Intelligence (AI) as a decision-support system","Yes, melanoma detection and grading","Adaptation","No, single models used for each task","Cost-effectiveness of AI in detecting and grading diseases (melanoma, dental caries, diabetic retinopathy)","Yes, deep features extracted by AI algorithms for disease detection and grading","Melanoma","Markov models adapted from previous cost-effectiveness studies","Not specified in the text but mentioned as 'large number of images' used for training and testing AI model","No (class imbalance not explicitly stated)","Yes, image preprocessing steps included in proposed method","Quantitative measures: QALYs, tooth retention-years, diagnostic costs","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with standard of care for each disease type","Quantitative measures: QALYs, tooth retention-years, diagnostic costs","AI showed marginal improvements in outcomes and cost-effectiveness compared to standard of care","Yes, comparison with state-of-the-art methods demonstrated limited cost-savings and gains in outcomes for AI as decision-support system","No (tested on Markov models adapted from previous studies)","Limited evidence supporting AI as decision support from a cost-effectiveness perspective","Cost-effectiveness of Artificial Intelligence as a Decision-Support System Applied to the Detection and Grading of Melanoma, Dental Caries, and Diabetic Retinopathy"
"Artificial intelligence (AI) using neural networks for analysis of routine macroscopic and dermoscopic images","Yes, early detection of pigmented melanoma","Adaptation","No, single model used for each task","High prediction accuracy in early detection of pigmented melanoma using AI","Yes, morphological characteristics extracted by AI from dermoscopic images","Pigmented Melanoma","Not specified in the text but mentioned as 'routine macroscopic and dermoscopic images' used for training and testing AI model","Not specified in the text but mentioned as 'large number of images' used for training and testing AI model","No (class imbalance not explicitly stated)","Yes, preprocessing step included in proposed method to prepare dermoscopic images for analysis by AI","Quantitative measures: accuracy, sensitivity, specificity, precision, recall","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with dermatologists' performance in binary melanoma/nevus classification task and multiclass differentiation of various skin diseases","Quantitative measures: accuracy, sensitivity, specificity, precision, recall","AI achieved high accuracies (comparable to or better than dermatologists) in binary melanoma/nevus classification task and multiclass differentiation of various skin diseases","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed AI-based method","No (tested on routine macroscopic and dermoscopic images from a single hospital or practice)","Translation to clinical practice pending due to need for uniformly high performance across different hospitals and practices","The Rise of Artificial Intelligence-High Prediction Accuracy in Early Detection of Pigmented Melanoma; [Künstliche Intelligenz auf dem Vormarsch-Hohe Vorhersage-Genauigkeit bei der Früherkennung pigmentierter Melanome]"
"Optical coherence tomography (OCT) and noninvasive monitoring","Yes, evaluation of laser-induced skin injury and wound healing","Adaptation","No, single methods used for each task","In vivo quantitative and qualitative analysis of time-dependent biological effect of a 3.8-µm laser on mouse skin","Yes, OCT images analyzed to compute mean OACs, burnt area, and volumes","Not applicable (evaluation of laser-induced skin injury)","Mouse skin samples used for in vivo evaluation","Not specified in the text but mentioned as 'large number of images' used for OCT imaging","No (class imbalance not explicitly stated)","Yes, preprocessing step included in proposed method to analyze OCT images","Quantitative measures: mean OACs, burnt area, and volumes computed from OCT images","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for laser-induced skin injury evaluation","Quantitative measures: mean OACs, burnt area, and volumes computed from OCT images","OCT imaging showed that the cutaneous damage became more serious as radiation doses increased; quantitative parameters of burnt spots (mean OACs, areas, and volumes) were computed using Fourier-domain algorithm and 3-D visualization","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method for in vivo evaluation of laser-induced skin injury","No (tested on mouse skin samples)","Not explicitly stated","Evaluation of a 3.8-µm laser-induced skin injury and their repair with in vivo OCT imaging and noninvasive monitoring"
"Convolutional neural network (CNN) developed by MoleMap Ltd and Monash eResearch","Yes, skin cancer management using artificial intelligence as a diagnostic aid","Adaptation","No, single model used for diagnosis and decision-making support","Improving skin cancer management with SMARTI: an AI system used as a diagnostic aid in specialist dermatology setting","Yes, CNN extracts features from dermoscopic images to classify lesions as benign or malignant","Skin cancers (not specified which types)","Not specified but mentioned as 'proprietary' and developed by MoleMap Ltd and Monash eResearch","Not specified in the text but implied to be a large number of images used for training and testing CNN model","No (class imbalance not explicitly stated)","Yes, dermoscopic camera used to image skin lesions before AI analysis","Sensitivity, specificity, agreement with histopathology or treating consultant dermatologist's classification","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with teledermatology services and human expert diagnosis in specialist dermatology setting","Sensitivity, specificity, agreement with histopathology or treating consultant dermatologist's classification","Not specified but implied to be improved diagnostic accuracy and management decisions using AI-assisted system","Yes, comparison with state-of-the-art teledermatology services in specialist dermatology setting","No (tested on proprietary dataset developed by MoleMap Ltd and Monash eResearch)","Not explicitly stated","Improving Skin cancer Management with ARTificial Intelligence (SMARTI): Protocol for a preintervention/postintervention trial of an artificial intelligence system used as a diagnostic aid for skin cancer management in a specialist dermatology setting"
"Transfer learning method using pre-trained models (Xception and DenseNet201) with ImageNet dataset","Yes, skin disease diagnosis","Adaptation","No, single models used for each task","Classification of HAM10000 dataset using transfer learning method","Yes, pre-trained models (Xception and DenseNet201) with ImageNet dataset used to extract features from medical images","Skin cancer","HAM10000 dataset","Not specified in the text but mentioned as 'large number of images' used for training and testing models","No (class imbalance not explicitly stated)","Yes, real-time data augmentation method used to increase number of images in dataset","Quantitative measures: test accuracy, precision, sensitivity, F1-score","Yes, pre-trained models with ImageNet dataset transferred and used for classification of HAM10000 dataset","Yes, real-time data augmentation method used to increase number of images in dataset","No (compared results from similar studies in literature)","Quantitative measures: test accuracy, precision, sensitivity, F1-score","Xception model achieved better classification results compared to DenseNet201 model according to test accuracy, precision, sensitivity and F1-score criteria","Yes, higher performances obtained when results from this study are compared with similar studies in literature","No (tested on HAM10000 dataset)","Not explicitly stated","Implementing of Transfer Learning Method in the Diagnosis of Skin Diseases with Convolutional Neural Networks; [Evrisimsel Sinir Aglan ile Cilt Hastaliklarmm Tanismda Transfer Ogrenme Yonteminin Uygulanmasi]"
"Synergy-Net: Artificial Intelligence at the Service of Oncological Prevention","Yes, malignant skin tumours diagnosis and detection","Adaptation","No, single models used for each task","Early oncological diagnosis based on integration of AI and clinical data management system","Yes, Machine Learning and Deep Learning techniques used to extract features from screening data (anamnestic information, blood tests, instrumental and diagnostic images)","Multiple types: lung cancer, breast cancer, colorectal cancer, gastrointestinal carcinomas, prostate cancer, thyroid cancer, malignant skin tumours","Not specified in the text but mentioned as 'screening data' used for training and testing AI system","Not specified in the text but mentioned as 'large number of images' used for training and testing Deep Learning models","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed method to assist operator in analysis of screening data","Quantitative measures: accuracy, precision, recall, F1 score, AUC-ROC curve","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for early oncological diagnosis and detection","Quantitative measures: accuracy, precision, recall, F1 score, AUC-ROC curve","Synergy-Net system assists operator in analysis of screening data by suggesting portions of information to focus on (e.g. regions in X-ray image)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method for early oncological diagnosis and detection","No (tested on various datasets but specific details not provided)","Not explicitly stated","Synergy-Net: Artificial Intelligence at the Service of Oncological Prevention"
"Hierarchical Outlier Detection (HOD) loss based approach","Yes, detecting the long-tail of unseen conditions in dermatology","Adaptation","No, single models used for each task","Detecting subtle differences resulting from a different pathology or condition using out-of-distribution (OOD) detection","Yes, recent representation learning methods (BiT, SimCLR, MICLe) used to improve feature extraction and OOD performance","Multiple dermatological conditions with varying risk levels and skin types","Custom benchmark dataset ensuring that outlier conditions are disjoint between the model training, validation, and test sets","Not specified in the text but mentioned as 'large number of images' used for training and testing HOD loss based approach","No (class imbalance not explicitly stated)","Yes, pre-processing steps included in proposed method to prepare data for OOD detection","Quantitative measures: accuracy, precision, recall, F1 score, AUC-ROC curve","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with leading methods that leverage outlier data during training and recent representation learning methods","Quantitative measures: accuracy, precision, recall, F1 score, AUC-ROC curve","HOD loss based approach outperforms leading methods in OOD detection for dermatological conditions with varying risk levels and skin types","Yes, comparison demonstrates the superiority of proposed method over baseline approaches","No (tested on custom benchmark dataset)","Not explicitly stated","Does your dermatology classifier know what it doesn't know? Detecting the long-tail of unseen conditions"
"Pact-Net: Parallel CNNs and Transformers for medical image segmentation","Yes, skin lesion segmentation","Adaptation","Yes, combines CNNs and Transformers to extract local and global features","Medical image segmentation using Pact-Net","Yes, uses channel and spatial attention mechanism and multi-scale mechanism to fuse global information extracted by Transformers into local features extracted by CNNs","Skin damage (not specified as melanoma or other types of skin cancer)","ISIC 2016, ISIC 2017, ISIC 2018 datasets for evaluation and comparison with state-of-the-art methods","Not specified in the text but mentioned as 'large number of images' used for training and testing Pact-Net model","No (class imbalance not explicitly stated)","Yes, skin refinement step included in proposed method","Quantitative measures: accuracy, precision, recall, F1 score, IoU, Dice coefficient","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin lesion segmentation and medical image segmentation","Quantitative measures: accuracy, precision, recall, F1 score, IoU, Dice coefficient","Pact-Net achieved indicators of 86.95%, 79.31% and 84.14% on ISIC 2016, ISIC 2017 and ISIC 2018 datasets respectively","Yes, comparison with state-of-the-art methods demonstrated the predominance of Pact-Net for skin lesion segmentation","No (tested only on ISIC 2016, ISIC 2017 and ISIC 2018 datasets)","Not explicitly stated","Pact-Net: Parallel CNNs and Transformers for medical image segmentation"
"TGDAUNet: Transformer and GCNN based dual-branch attention UNet","Yes, medical image segmentation (skin cancer)","Adaptation","Yes, combines CNNs with Transformers at multiple scales","Accurate segmentation of lesions in medical images using TGDAUNet","Yes, dual-branch backbone network extracts high-level and low-level feature information from both CNNs and Transformers","Skin cancer (ISIC-2016 and ISIC-2017 datasets)","Multiple medical image segmentation datasets: CVC-ClinicDB, Kvasir-SEG, ETIS, CVC-ColonDB, CVC-300, ISIC-2016, ISIC-2017","Not specified in the text but mentioned as 'large number of images' used for training and testing TGDAUNet model","No (class imbalance not explicitly stated)","Yes, polarised self-attentive module reduces impact of redundant information caused by multiple scales","Quantitative measures: accuracy, precision, recall, F1 score, dice coefficient, Jaccard index","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with current popular methods for medical image segmentation and skin cancer detection","Quantitative measures: accuracy, precision, recall, F1 score, dice coefficient, Jaccard index","TGDAUNet outperformed other methods on multiple datasets (CVC-ClinicDB, Kvasir-SEG, ETIS, CVC-ColonDB, CVC-300, ISIC-2016, ISIC-2017)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on multiple datasets but results not explicitly stated for each dataset separately)","Not explicitly stated","TGDAUNet: Transformer and GCNN based dual-branch attention UNet for medical image segmentation"
"Machine learning (ML) and deep learning (DL) algorithms, including CNNs","Yes, skin cancer detection using machine learning and deep learning algorithms","Adaptation","No, single models used for each task","Comparative study on skin cancer detection using machine learning and deep learning algorithms","Yes, CNNs used for feature extraction in DL techniques","Skin cancer (melanoma)","ISIC archive dataset of dermoscopic images","Not specified in the text but mentioned as 'large number of images' used for training and testing models","No (class imbalance not explicitly stated)","Yes, data augmentation techniques applied to improve performance","Quantitative measures: test accuracy, validation accuracy, F1 score, precision, recall, ROC-AUC curve","Yes, transfer learning models used (e.g. MobileNetv2)","Yes, data augmentation techniques applied to improve performance","Yes, comparison with other machine learning algorithms and deep learning architectures","Quantitative measures: test accuracy, validation accuracy, F1 score, precision, recall, ROC-AUC curve","Customized CNN model achieved an accuracy of 98.02% on the augmentation dataset","Yes, comparison with state-of-the-art models demonstrated the effectiveness of proposed techniques","No (tested on ISIC archive dataset)","Not explicitly stated","Comparative study and analysis on skin cancer detection using machine learning and deep learning algorithms"
"Extreme Learning Machine (ELM)","Yes, medical imaging for skin and other organs","Adaptation","No, single model used for each task","Comprehensive review of ELM on medical imaging","Yes, deep features extracted by ELM for various medical image processing tasks","Multiple types of cancers: brain, lungs, skin, eyes, breasts, and cervix","Various reference datasets linked to human body organs (not specified in the text)","Not specified in the text but mentioned as 'large number of images' used for training and testing ELM model","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed method","Quantitative measures: accuracy, sensitivity, specificity, F1 score, etc.","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for medical image processing and ELM-based models","Quantitative measures: accuracy, sensitivity, specificity, F1 score, etc.","ELM achieved high levels of accuracy comparable to traditional learning algorithms in various medical imaging tasks","Yes, comparison with state-of-the-art methods demonstrated the effectiveness and efficiency of ELM-based models for medical image processing","No (tested on various reference datasets linked to human body organs)","Not explicitly stated","A comprehensive review of extreme learning machine on medical imaging"
"Enhanced U-Net segmentation with ensemble convolutional neural network (E-CNN) and whale-electric fish optimization (W-EFO)","Yes, automated skin disease classification","Adaptation","No, single models used for each task","Automated diagnosis of various skin diseases using enhanced U-Net segmentation and E-CNN","Yes, deep features extracted by Enhanced U-Net segmentation with W-EFO optimization","Not specified (various skin diseases)","Not specified in the text but mentioned as 'diverse data sources'","Not specified in the text but mentioned as 'large number of images' used for training and testing E-CNN model","No (class imbalance not explicitly stated)","Yes, pre-processing steps included: grey-level conversion, hair removal, contrast enhancement","Quantitative measures: accuracy, precision, recall, F1 score, AUC-ROC curve","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with conventional models demonstrated improved performance using W-EFO optimization and E-CNN","Quantitative measures: accuracy, precision, recall, F1 score, AUC-ROC curve","Proposed model achieved effective performance on diverse skin disease classification tasks","Yes, comparison with state-of-the-art models demonstrated improved results using W-EFO optimization and E-CNN","No (tested on various datasets from 'diverse data sources')","Not explicitly stated","Enhanced U-Net segmentation with ensemble convolutional neural network for automated skin disease classification"
"Deep ensemble learning using a demographic machine learning risk stratifier","Yes, binary classification of skin lesions (melanoma or benign keratosis-like lesions)","Adaptation","Yes, combines deep learning and machine learning techniques to improve performance","To improve the performance of standard CNN architectures in skin lesion classification by providing a machine learning-derived risk score from patient demographic data","Yes, deep features extracted by convolutional neural networks (CNNs) for skin lesion classification","Melanoma and benign keratosis-like lesions","HAM10000 dataset with ground-truth diagnoses of either melanoma or benign keratosis-like lesions","1,340 patients (n=2,200) images used for training and testing","Yes, equal representation of each class in train, validation, and test sets","Not explicitly stated but assumed to be part of the pre-processing step before feeding into CNNs","Quantitative measures: area under the receiver operating characteristic curve (AUC), accuracy, specificity, sensitivity","No, not mentioned as a technique used in this study","Not explicitly stated but assumed to be part of the pre-processing step before feeding into CNNs","Yes, comparison with standard CNN architectures and deep ensemble networks (Ei)","Quantitative measures: AUC, accuracy, specificity, sensitivity","Deep ensemble learning using a demographic machine learning risk stratifier achieved an average test AUC of 0.88±0.03 for skin lesion classification","Yes, demonstrated significant improvement in performance compared to standard CNN architectures (Ni)","No, tested on HAM10000 dataset only","Not explicitly stated","Deep ensemble learning using a demographic machine learning risk stratifier for binary classification of skin lesions using dermatoscopic images"
"CFF-Net (Cross Feature Fusion Network)","Yes, skin lesion segmentation","Adaptation","Yes, combines CNN and MLP for feature extraction","Accurate segmentation of skin lesions from dermoscopy images using CFF-Net","Yes, dual branches in encoder: CNN branch extracts local features while MLP branch establishes global-spatial-dependencies and global-channel-dependencies","Melanoma (skin tumor)","Four publicly available skin lesion datasets: ISIC 2018, ISIC 2017, ISIC 2016, PH2","Not specified in the text but mentioned as 'large number of images' used for training and testing CFF-Net model","No (class imbalance not explicitly stated)","Yes, auxiliary prediction task introduced to learn global geometric information highlighting boundary of skin lesion","Quantitative measures: Jaccard Index score, accuracy, precision, recall, F1-score","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art models such as U-Net","Quantitative measures: Jaccard Index score, accuracy, precision, recall, F1-score","CFF-Net outperformed U-Net in four public skin lesion datasets (ISIC 2018, ISIC 2017, ISIC 2016, PH2) with increased average Jaccard Index scores: from 79.71% to 81.86%, from 78.03% to 80.21%, from 82.58% to 85.38%, and from 84.18% to 89.71%","Yes, CFF-Net demonstrated superior performance compared to state-of-the-art models","No (tested on four public skin lesion datasets)","Not explicitly stated","Dynamically aggregating MLPs and CNNs for skin lesion segmentation with geometry regularization"
"Convolutional Neural Network (CNN)","Yes, skin cancer dermoscopy and lung scan computed tomography (CT) Scan datasets","Adaptation","No, single models used for each task","Unpacking the CNN 'Black box' theory using feature maps analysis","Yes, deep features extracted by convolutional layers for skin cancer dermoscopy and lung scan CT Scan datasets","Skin cancer (dermatoscopy) and Lung Cancer (CT Scan)","Two medical datasets of different modality: skin cancer dermoscopy dataset and lung scan computed tomography (CT) Scan dataset","Not specified in the text but mentioned as 'large number of images' used for training and testing CNN model","No (class imbalance not explicitly stated)","Yes, skin refinement step included in proposed method","Quantitative measures: T-test, ANOVA test, mean, median, MSE, PSNR, SSIM, RMSE, DSC, UQI and SAM","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for feature map analysis in CNNs","Quantitative measures: T-test, ANOVA test, mean, median, MSE, PSNR, SSIM, RMSE, DSC, UQI and SAM","CNN produced diverse characteristics of feature maps with different datasets (skin cancer dermoscopy dataset vs. CT Scan dataset)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method for unpacking CNN 'Black box' theory using feature map analysis","No (tested on two medical datasets: skin cancer dermoscopy and lung scan CT Scan)","Not explicitly stated","Using feature maps to unpack the CNN ‘Black box’ theory with two medical datasets of different modality"
"Convolutional Neural Network (CNN)","Yes, skin cancer prediction","New architecture","No, single model used for task","Predicting skin cancer from an image of the skin using deep learning techniques","Yes, CNN extracts features from images to predict skin cancer","Melanoma and other types of skin cancers (not specified)","Not informed","Not informed","No (class imbalance not explicitly stated)","Yes, preprocessing step included in the model development process","Accuracy and loss functions used to evaluate performance of CNN model","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin cancer prediction using deep learning techniques","Accuracy and loss functions used to evaluate performance of CNN model","Not specified in the text (only mentioned that accuracy and loss functions are used to evaluate performance)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on a dataset not explicitly stated)","Not informed","Design and development of deep learning model for predicting skin cancer and deployed using a mobile app"
"Deep learning based features fusion and selection framework","Yes, multiclass skin lesion localization and classification","Adaptation","Yes, combines multiple CNN models (Xception, ResNet-50, ResNet-101, VGG16) for feature extraction and fusion using convolutional sparse image decomposition fusion approach","Skin lesion segmentation and classification using deep learning framework","Yes, custom 26-layered CNN architecture used for skin lesion region segmentation, followed by transfer learning on pre-trained CNN models (Xception, ResNet-50, ResNet-101, VGG16) to extract deep features vectors","Skin cancer","HAM10000, ISIC2018, ISIC2019, PH2 datasets","Not specified in the text but mentioned as 'large number of images' used for training and testing proposed approach","No (class imbalance not explicitly stated)","Yes, contrast enhancement based modified bio-inspired multiple exposure fusion approach used for pre-processing dermoscopic images","Quantitative measures: accuracy, precision, recall, F1 score, AUC-ROC curve","Yes, transfer learning applied on pre-trained CNN models (Xception, ResNet-50, ResNet-101, VGG16) for feature extraction and classification","No (not mentioned as part of the proposed approach)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed approach in terms of accuracy and quantitative evaluation metrics","Quantitative measures: accuracy, precision, recall, F1 score, AUC-ROC curve","Proposed approach achieved an accuracy of 98.57%, 98.62%, 93.47%, and 98.98% on HAM10000, ISIC2018, ISIC2019, and PH2 datasets respectively","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed approach in terms of accuracy and quantitative evaluation metrics","No (tested on HAM10000, ISIC2018, ISIC2019, PH2 datasets)","Not explicitly stated","Multiclass skin lesion localization and classification using deep learning based features fusion and selection framework for smart healthcare"
"Multi-Site Cross-Organ Calibration based Deep Learning (MuSClD)","Yes, automated diagnosis of non-melanoma skin cancer","Adaptation","No, single model used for each task","Mitigate domain shift between training and testing data using off-target organ calibration","Yes, deep features extracted by MuSClD for non-melanoma skin cancer subtyping","Non-melanoma skin cancer (NMSC), including basal cell carcinoma (BCC) and squamous cell carcinomas (SCC-In Situ and SCC-Invasive)","Australian cohort (training, n = 85) and Swiss cohort (held-out testing, n = 352)","Not specified in the text but mentioned as 'large number of images' used for training and testing MuSClD model","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed method to mitigate domain shift","Quantitative measures: one-vs. rest AUC, Wasserstein distances between sites for color, contrast, and brightness metrics","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with baseline NMSC-subtyping without calibration demonstrated improved performance using MuSClD","Quantitative measures: one-vs. rest AUC, Wasserstein distances between sites for color, contrast, and brightness metrics","MuSClD reduced the Wasserstein distances between Australian and Swiss cohorts in terms of color, contrast, and brightness metrics (p < 0.01), and improved NMSC-subtyping performance: BCC (AUC = 0.92 vs 0.87, p = 0.01), SCC-In Situ (AUC = 0.87 vs 0.73, p = 0.15) and SCC-Invasive (AUC = 0.92 vs 0.82, p = 1e-5)","Yes, comparison with state-of-the-art methods demonstrated improved performance using MuSClD","No (tested on Australian and Swiss cohorts)","Not explicitly stated","Multi-site cross-organ calibrated deep learning (MuSClD): Automated diagnosis of non-melanoma skin cancer"
"Hybrid model of machine learning models (CNNs, SVM, Naïve Bayes, K-NN classifiers)","Yes","Adaptation","Yes, multiple machine learning algorithms used for classification and feature extraction","Automated skin cancer detection using dermoscopic images","Yes, deep features extracted by CNNs for image analysis and classification","Melanoma (1196 images) and benign skin lesions (1439 images)","International Skin Image Collaboration (ISIC) dataset","Not specified in the text but mentioned as 'large number of images' used for training and testing machine learning models","No, class imbalance not explicitly stated","Yes, preprocessing step included in proposed method (image acquisition, segmentation)","Quantitative measures: accuracy, precision, recall, F1 score","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin cancer detection and classification","Quantitative measures: accuracy, precision, recall, F1 score","CNNs achieved highest accuracy (99.5%) among all machine learning algorithms used in the proposed model","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed hybrid model","No (tested on ISIC dataset)","Not explicitly stated","Skin Cancer Classification Utilizing a Hybrid Model of Machine Learning Models Trained on Dermoscopic Images"
"Multiple models proposed (see list of papers)","Yes, skin lesion classification and segmentation","Adaptation","No, single models used for each task or paper","Medical Image Computing and Computer-Assisted Intervention","Yes, various techniques (e.g. Generative Pathology Image Classifier, Volumetric Organ Segmentation) proposed for feature extraction","Multiple types of cancers mentioned (melanoma, prostate cancer)","Not specified in the text but implied to be multiple datasets used across various papers","Not specified in the text but likely large number of images used for training and testing models","No (class imbalance not explicitly stated, although some papers mention handling class imbalance)","Yes, preprocessing steps mentioned in various papers (e.g. data augmentation, normalization)","Various evaluation metrics mentioned across papers (accuracy, precision, recall, F1 score, etc.)","Not applicable or not explicitly stated for most papers","Yes, some papers mention using data augmentation techniques to increase size of training dataset","Some papers compare with state-of-the-art methods and show improved performance","Various evaluation metrics mentioned across papers (accuracy, precision, recall, F1 score, etc.)","Not specified in the text as results vary across different papers","Some papers compare with state-of-the-art methods and show improved performance","No (tested on various datasets for each paper)","Not explicitly stated, although some papers mention limitations of their proposed method","26th International Conference on Medical Image Computing and Computer-Assisted Intervention , MICCAI 2023"
"Deep transfer learning and sparrow search algorithm (SpaSA)","Yes, skin cancer diagnosis","Adaptation","No, single models used for each task","Threshold-based automatic approach for skin cancer detection, classification, and segmentation using SpaSA optimizer","Yes, deep features extracted by pre-trained CNN models (e.g. VGG16, MobileNet) for skin cancer diagnosis","Skin cancer (melanoma and non-melanoma)","Five public datasets: 'skin cancer segmentation and classification', 'PH2', 'ISIC 2019 and 2020 Melanoma', 'Melanoma Classification (HAM10K)', and 'skin diseases image'","Not specified in the text but mentioned as 'large number of images' used for training and testing CNN models","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed method","Quantitative measures: loss, accuracy, F1-score, AUC, IoU, dice, hinge, and squared hinge","Yes, pre-trained CNN models used for feature extraction","No (not mentioned as part of the proposed method)","Yes, comparison with 13 related studies demonstrated the superiority of proposed approach","Quantitative measures: loss, accuracy, F1-score, AUC, IoU, dice, hinge, and squared hinge","MobileNet pre-trained model achieved best reported overall accuracy (98.27%) for 'ISIC 2019 and 2020 Melanoma' dataset","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed approach","No (tested on five public datasets)","Not explicitly stated","Skin cancer diagnosis based on deep transfer learning and sparrow search algorithm"
"Transfer learning method with various activation functions","Yes, melanoma detection and classification from skin cancer diagnosis","Adaptation","No, single models used for each task","Classification of melanoma using deep learning algorithms with various activation functions","Yes, convolutional neural network (CNN) extracts features from skin lesion images","Melanoma and skin cancer","Datasets collected from patients for experimental purpose","Not specified in the text but mentioned as 'various datasets' used for training and testing models","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed method","Model accuracy using various activation functions","Yes, transfer learning method used for classification of melanoma","No (not mentioned as part of the proposed method)","No (compared with state-of-the-art methods not explicitly stated)","Model accuracy using various activation functions","Not specified in the text, but implies that transfer learning method with various activation functions achieved good results for melanoma detection and classification","No (not compared with state-of-the-art methods)","Yes, tested on datasets collected from patients","Not explicitly stated","Activation Functions for Analysis of Skin Lesion and Melanoma Cancer Detection"
"Transfer learning with fine-tuning using pre-trained deep learning algorithms","Yes, melanoma classification and detection","Adaptation","No, single models used for each task","Automated Melanoma Classification System: Data Augmentation using Transfer Learning","Yes, pre-trained deep learning algorithms (EfficientNetB0, Mobile-Net, InceptionV3, XceptionV3, VGG19, ResNet152V2) used for feature extraction and fine-tuning","Melanoma","Not specified in the text but mentioned as 'dataset' with classes of malignant or benign skin lesions","Not specified in the text but mentioned as 'large number of images' used for training and testing models","No (class imbalance not explicitly stated)","Yes, preprocessing step included data organization, normalization, and data augmentation","Quantitative measures: Accuracy, Precision, F1 Score","Yes, pre-trained deep learning algorithms fine-tuned for melanoma classification","Yes, used as part of preprocessing step to increase size of training dataset","Yes, comparison with state-of-the-art models (EfficientNetB0, Mobile-Net, InceptionV3, XceptionV3, VGG19, ResNet152V2) for melanoma classification and detection","Quantitative measures: Accuracy, Precision, F1 Score","Efficient-Net outperformed all other models in melanoma detection with an accuracy of 92%","Yes, comparison with state-of-the-art models demonstrated the superiority of proposed method","No (tested on a dataset not specified)","Not explicitly stated","Transfer Learning for Automated Melanoma Classification System: Data Augmentation"
"Mihm AI model (combination of supervised and semi-supervised learning)","Yes, detection and classification of skin lesions","Adaptation","Yes, combination of supervised and semi-supervised learning for improved performance","High-fidelity detection, subtyping, and localization of five skin neoplasms using AI model Mihm","Yes, deep features extracted by Mihm AI model for lesion classification and localization","Five main types of skin lesions: melanocytic lesions, basal cell carcinoma, atypical squamous lesions, verruca vulgaris, seborrheic keratosis","PathologyWatch (PW) laboratory dataset (2188 random WSIs for supervised training and 5161 WSIs for weakly supervised learning)","Not specified in the text but mentioned as 'large number of images' used for training and testing Mihm AI model","No (class imbalance not explicitly stated, although sensitivity values are provided for each type of lesion)","Yes, pre-processing step included in proposed method to prepare WSIs for analysis by Mihm AI model","Quantitative measures: sensitivity and specificity for each type of skin lesion","Not applicable (Mihm AI model trained from scratch on large dataset)","No (not mentioned as part of the proposed method, although weakly supervised learning subset used to augment training data)","Yes, comparison with state-of-the-art methods for skin lesion detection and classification","Quantitative measures: sensitivity and specificity for each type of skin lesion","Mihm AI model achieved high sensitivity values (98.91% to 86.91%) for detecting five main types of skin lesions, with subtyping, localization, and margin status provided as additional features","Yes, Mihm AI model demonstrated improved performance compared to state-of-the-art methods for skin lesion detection and classification","No (tested on PathologyWatch laboratory dataset)","Not explicitly stated","High-fidelity detection, subtyping, and localization of five skin neoplasms using supervised and semi-supervised learning"
"Novel pipeline consisting of segmentation network and classification network","Yes, skin lesion segmentation and classification","Adaptation","No, single models used for each task","Efficient implementation of skin lesions' segmentation and classification tasks using dermoscopic images and clinical metadata","Yes, multi-scale feature maps synthesized by decoder in segmentation network and cross-modal features exploited in classification network","Skin cancer (not specified which type)","ISIC 2018, PH2 for segmentation; ISIC 2019&2020 combined dataset for classification","Not specified in the text but mentioned as 'large number of images' used for training and testing models","No (class imbalance not explicitly stated)","Yes, lesion masks generated by best segmentation model used to crop images before classification","Quantitative measures: Jaccard index, AUC, accuracy","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin lesion segmentation and classification","Quantitative measures: Jaccard index, AUC, accuracy","Proposed pipeline achieved a Jaccard index of 83.31% and 90.14% in skin lesion segmentation, an AUC of 97.98%, and an Accuracy of 92.63% in skin lesion classification","Yes, proposed method demonstrated superior performance compared to state-of-the-art methods for both tasks","No (tested on ISIC 2018, PH2, ISIC 2019&2020 datasets)","Not explicitly stated","Learning from dermoscopic images in association with clinical metadata for skin lesion segmentation and classification"
"Ensemble learning method using XGBoost","Yes, skin cancer detection","Adaptation","No, single model used for each task","Skin cancer detection using CT image features and ensemble learning","Yes, convolutional neural network (CNN) used to extract features from skin cancer images","Various types of skin cancers","Not specified in the text but mentioned as 'skin cancer images'","Not specified in the text but implied that a large number of images were used for training and testing XGBoost model","No (class imbalance not explicitly stated)","Yes, image processing step included before feature extraction using CNN","Quantitative measures: sensitivity, specificity, accuracy","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with other ensemble-learning methods used in this study","Quantitative measures: sensitivity, specificity, accuracy","XGBoost achieved performance measures such as sensitivity = 97.95%, specificity = 97.00% and accuracy = 97.45%","Yes, XGBoost method showed better results compared to other ensemble-learning methods used in this study","No (tested on a dataset of skin cancer images)","Not explicitly stated","Skin cancer detection using image features and ensemble learning"
"Deep Convolutional Neural Network (DCNN)","Yes, melanoma classification","Adaptation","No, single model used for each task","Automated detection of melanomas using DCNN","Yes, deep features extracted by DCNN for melanoma classification","Melanoma","ISIC 2020 dataset (dermoscopic images)","Not specified in the text but mentioned as 'large number of cancer samples' used for training and testing DCNN model","No (class imbalance not explicitly stated)","Yes, dermoscopic images pre-processed before feeding into DCNN model","Quantitative measures: accuracy, precision, recall, specificity, F1 score","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for melanoma classification and detection","Quantitative measures: accuracy, precision, recall, specificity, F1 score","DCNN grouper attained precision of about 90.42%, 81.41% and 88.23% respectively on ISIC datasets from 2020","Yes, proposed method demonstrated high performance compared to other cutting-edge networks","No (tested only on ISIC 2020 dataset)","Not explicitly stated","Design and Implementation of Convolutional Neural Network Model for Melanoma Classification"
"Categorical Weighting Domination (CWD) for imbalanced classification","Yes, skin cancer diagnosis and classification","Adaptation","No, single model used with CWD approach to handle imbalance data","Improving efficiency of DCNN for classifying multi-class medical images on imbalanced datasets","Yes, feature extraction based on backbone models (EfficientNets, MobileNets, DenseNets) and customizing fully connected layers","Skin cancer (melanoma and nevus)","ISIC2018 benchmark dataset and Chest X-ray dataset","Not specified in the text but mentioned as 'large number of images' used for training and testing DCNN models","No (imbalanced datasets with majority and minority categories)","Yes, data augmentation approach combined with CWD to handle imbalance data","Quantitative measures: recall, precision, specificity, F1 score using various DCNN backbones","Not applicable","Yes, used in combination with CWD for handling imbalanced datasets","Yes, comparison with existing methods (data augmentation, downsampling, customizing loss function, focal loss method) to handle imbalance data","Quantitative measures: recall, precision, specificity, F1 score using various DCNN backbones","CWD approach achieved higher performance than other methods in some specific evaluation criteria (e.g., 2.73% improvement in recall and 5.16% improvement in recall) on ISIC2018 dataset with EfficientNet and DenseNet backbones, respectively.","Yes, comparison demonstrated the superiority of CWD approach over other methods for handling imbalanced datasets","No (tested only on ISIC2018 benchmark dataset)","Not explicitly stated","Categorical Weighting Domination for Imbalanced Classification with Skin Cancer in Intelligent Healthcare Systems"
"Dual Transfer Learning (DTL) approach","Yes, skin cancer and breast cancer detection","Adaptation","No, single models used for each task with fine-tuning on unclassified images of the same disease","Improving performance of pre-trained models using DTL approach","Yes, deep features extracted by VGG16, Xception, ResNet50, and MobileNetV2 models for skin cancer and breast cancer detection","Skin cancer (ISIC2020 dataset) and Breast Cancer (ICIAR2018 dataset)","Two datasets: ISIC2020 skin cancer images and ICIAR2018 breast cancer images","Not specified in the text but mentioned as 'large number of images' used for training and testing models","No (class imbalance not explicitly stated)","Yes, data augmentation techniques applied to balance classes and increase sample size","Quantitative measures: accuracy, precision, recall, F1-score, sensitivity, specificity","Yes, fine-tuning of pre-trained models on unclassified images of the same disease","Yes, applied to balance classes and increase sample size","Yes, comparison with state-of-the-art methods for skin cancer and breast cancer detection","Quantitative measures: accuracy, precision, recall, F1-score, sensitivity, specificity","Xception model achieved highest performance (96.83% - 99.14%) on both datasets with data augmentation","Yes, proposed approach improved models' performance compared to state-of-the-art methods","No (tested on ISIC2020 and ICIAR2018 datasets)","Not explicitly stated","Incorporating a Novel Dual Transfer Learning Approach for Medical Images"
"HI-MViT: a lightweight model for explainable skin disease classification based on modified MobileViT","Yes, skin disease classification (dermatology)","Adaptation","No, single models used for each task","Develop an explainable lightweight skin disease high-precision classification model that can be deployed to the mobile terminal","Yes, deep features extracted by HI-MViT using ordinary convolution, Improved-MV2, MobileViT block, global pooling, and fully connected layers","Not specified (general skin disease classification)","ISIC-2018 dataset (900 images) and ISIC-2017 dataset (2000 images), PH2 dataset for generalization performance evaluation","Not specified in the text but mentioned as 'large number of images' used for training and testing HI-MViT model","No (class imbalance not explicitly stated)","Yes, skin refinement step included in proposed method","Quantitative measures: F1-Score, Accuracy, Average Precision (AP), area under the curve (AUC)","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with top five algorithms of ISIC-2018 Task 3 and ConvNeXt architecture","Quantitative measures: F1-Score, Accuracy, AP, AUC","HI-MViT achieved scores of 0.931, 0.932, 0.961, and 0.977 on F1-Score, Accuracy, Average Precision (AP), and area under the curve (AUC) respectively for ISIC-2018 dataset","Yes, HI-MViT outperformed top five algorithms of ISIC-2018 Task 3 by 6.9%, 6.8%, and 0.8% in F1-Score, AP, and AUC respectively compared to the suboptimal performance model","Yes, tested on PH2 dataset for generalization performance evaluation","Not explicitly stated","HI-MViT: A lightweight model for explainable skin disease classification based on modified MobileViT"
"Pretrained Inception V3 model with various classifiers (Naive Bayes, CNN, Random Forest, Decision Tree)","Yes, detection and classification of vitiligo skin disease","Adaptation","No, single models used for each task","Early identification of macules to avoid delays in treatments for vitiligo skin disease","Yes, features extracted using pre-trained Inception V3 model","Vitiligo (not a cancer)","Not specified in the text but mentioned as 'healthy skin images' used for training and testing models","Not specified in the text but mentioned as 'large number of images' used for training and testing Inception V3 model","No (class imbalance not explicitly stated)","Yes, image preprocessing steps included in proposed method","Quantitative measures: accuracy, recall, precision, AUC, F1-score for each classifier","Yes, pre-trained Inception V3 model used as feature extractor","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for vitiligo detection and classification","Quantitative measures: accuracy, recall, precision, AUC, F1-score for each classifier","Inception V3 with Random Forest achieved highest values of accuracy (99.9%), recall (0.999), precision (0.999), and F1-score (0.999) among all classifiers","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method for vitiligo detection and classification","No (tested on healthy skin images)","Not explicitly stated","Deep Learning based Model for Detection of Vitiligo Skin Disease using Pretrained Inception V3"
"Explainable Artificial Intelligence (XAI) and Deep Transfer Learning (DTL)","Yes, skin disease diagnosis","Adaptation","No, single models used for each task","Accurate diagnosis of skin diseases using XAI and DTL techniques","Yes, deep features extracted by CNN for skin disease diagnosis","Not specified in the text but mentioned as 'skin cancers' (implied to include melanoma)","Comprehensive datasets of diverse skin diseases data","Not specified in the text but implied to be a large number for training and testing DTL model","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed method","Quantitative measures: accuracy, efficiency, effectiveness of XAI-driven diagnostics","Yes, DTL used to improve diagnostic outcomes by leveraging knowledge from other skin disease datasets","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin disease diagnosis and XAI-driven diagnostics","Quantitative measures: accuracy, efficiency, effectiveness of XAI-driven diagnostics","XAI and DTL techniques improved diagnostic outcomes by providing reliable diagnostic support using comprehensive datasets","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method in improving dermatology diagnostic outcomes","No (tested on diverse skin disease data)","Not explicitly stated","Explainable Artificial Intelligence and Deep Transfer Learning for Skin Disease Diagnosis"
"Improved face morphing attack detection method using PCA and Convolutional Neural Network","No, facial images used for face recognition and verification","Adaptation","Yes, combines Principal Component Analysis (PCA), eigenvalue, eigenvector features with Convolutional Neural Network (CNN)","Face morphing attack detection using facial images","Yes, extracted features from facial landmarks area (eyes, nose, mouth, and skin) using PCA, eigenvalue, and eigenvector techniques","No, not related to cancer diagnosis or treatment","Not specified in the text but mentioned as 'set of databases' used for generating morph images","Not specified in the text but mentioned as 'large number of images' used for training and testing CNN model","No (class imbalance not explicitly stated)","Yes, Faster Region Convolution neural network used to determine and cut important landmarks area from facial image","Quantitative measures: accuracy, FAR (False Acceptance Rate), FRR (False Rejection Rate) using DNN classifier and SVM second classifier","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for face morphing attack detection demonstrated the superiority of proposed method","Quantitative measures: accuracy, FAR, FRR using DNN classifier and SVM second classifier","DNN achieved an average accuracy of 99.02% compared to SVM with an accuracy of 98.64%","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on AMSL dataset)","Not explicitly stated","Improved Face Morphing Attack Detection Method Using PCA and Convolutional Neural Network"
"Ensemble feature selection and tabular generative adversarial networks (CTGAN)","Yes, cutaneous melanoma identification","Adaptation","Yes, combination of ensemble feature selection methods with CTGAN for data augmentation","Enhance cutaneous melanoma identification and interpretability using ensemble feature selection and tabular generative adversarial networks","Yes, two feature extraction approaches: handcrafted features (color, geometric, texture) and embedding features (ResNet-based models)","Cutaneous Melanoma","PH2 and Derm7pt public datasets containing dermoscopy images of melanoma and not-melanoma lesions","Not specified in the text but mentioned as 'large number of images' used for training and testing models","No (class imbalance problem, where a few classes have numerous samples while others are under-represented)","Yes, data augmentation with CTGAN to alleviate class imbalance issue","Quantitative measures: AUCROC values for PH2 and Derm7pt datasets","Not applicable","Yes, progressive analysis of the imbalance ratio (IR) related to synthetic samples created using CTGAN","No (compared with ensemble FS methods and linear models)","Quantitative measures: AUCROC values for PH2 and Derm7pt datasets","Combination of ensemble FS, CTGAN, and linear models achieved best predictive results with AUCROC values of 87% (PH2) and 76% (Derm7pt)","Yes, comparison with state-of-the-art methods for melanoma classification","No (tested on PH2 and Derm7pt datasets only)","Not explicitly stated","Ensemble feature selection and tabular data augmentation with generative adversarial networks to enhance cutaneous melanoma identification and interpretability"
"Comprehensive pipeline combining transfer learning, feature selection and machine-learning algorithms","Yes, skin cancer detection using CNN, Particle Swarm Optimization and Machine Learning","Adaptation","Yes, combines multiple methods: transfer learning, feature selection (Particle Swarm Optimization), machine-learning classifiers (Subspace KNN and Medium Gaussian SVM)","Explainable AI-based skin cancer detection using CNN, Particle Swarm Optimization and Machine Learning","Yes, deep features extracted by Xception architecture with task-specific layers frozen for improved performance","Skin cancer (not specified which type)","ISIC 2018 and HAM10000 datasets","Not specified in the text but mentioned as 'large number of images' used for training and testing proposed pipeline","No (class imbalance not explicitly stated)","Yes, skin refinement step included in proposed method","Quantitative measures: accuracy on ISIC 2018 and HAM10000 datasets","Yes, Xception architecture used as pre-trained model with task-specific layers frozen for improved performance","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed pipeline","Quantitative measures: accuracy on ISIC 2018 and HAM10000 datasets","Proposed pipeline achieved impressive accuracies of 98.5% and 86.1%, respectively, on ISIC 2018 and HAM10000 datasets","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed pipeline","No (tested only on ISIC 2018 and HAM10000 datasets)","Not explicitly stated","Explainable AI-Based Skin Cancer Detection Using CNN, Particle Swarm Optimization and Machine Learning"
"DermAI: AI-Driven Chatbot using ResNet-50, LLM via Chainlit, and Retrieval Augmented Generation (RAG)","Yes, enhanced dermatological diagnosis and patient interaction","Adaptation","Yes, combines multiple models for accurate classification of common skin diseases","Accurate classification of common skin diseases using AI-driven chatbot","Yes, uses ResNet-50 model and LLM via Chainlit for feature extraction","Melanoma (among others: chickenpox, shingles, impetigo, nail fungus)","Not specified in the text but mentioned as 'large number of images' used for training and testing DermAI model","Not specified in the text but mentioned as 'large number of images' used for training and testing DermAI model","Yes, dataset is balanced with a high true positive rate (92.6%) and low misclassification rate (2.17%)","Not applicable (text-based chatbot)","Quantitative measures: mean sensitivity, specificity & AUC of 99.8%, 99.9%, respectively","Yes, uses pre-trained ResNet-50 model and LLM via Chainlit for transfer learning","Not applicable (text-based chatbot)","Yes, comparison with previous studies demonstrated the superiority of DermAI in accurate classification of common skin diseases","Quantitative measures: mean sensitivity, specificity & AUC of 99.8%, 99.9%, respectively; true positive rate (92.6%); misclassification rate (2.17%)","DermAI achieved high validation accuracy (100%) for melanoma and other common skin diseases","Yes, DermAI outperforms all solutions proposed in research literature","No (tested on a single dataset not specified)","Minimal tendency to hallucinate with an average hallucination score of 7% and the model may generate grounded answers that are pertaining to the knowledge base","DermAI: An Innovative AI-Driven Chatbot for Enhanced Dermatological Diagnosis and Patient Interaction"
"Multi-level classification system combining CNN and DNN architectures with feature extraction techniques","Yes, skin cancer diagnosis (benign or malignant) and further categorization into basal cell carcinomas, squamous cell carcinomas, or melanoma","Adaptation","No, single models used for each task in two-stage classification approach","Automated skin cancer diagnosis using dermoscopic images and multi-level classification system","Yes, feature extraction techniques employed to identify most pertinent features for classification task","Skin cancer (benign or malignant), basal cell carcinomas, squamous cell carcinomas, melanoma","Not specified in the text but mentioned as 'dermoscopic images'","Not specified in the text but implied to be a large number of images used for training and testing models","No (class imbalance not explicitly stated)","Yes, image preprocessing steps included as part of proposed method","Quantitative measures: accuracy in initial cancer discrimination stage and subsequent stage","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin cancer diagnosis and classification","Quantitative measures: accuracy in initial cancer discrimination stage and subsequent stage","Linear regression classifier achieved an accuracy of 98% in the first stage and 90% in the second stage","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on dermoscopic images)","Not explicitly stated","Skin Cancer Diagnosis With Multi-Level Classification"
"Conditional adversarial segmentation and deep learning approach using EfficientNets","Yes, skin lesion sub-typing from dermoscopic images","Adaptation","No, single models used for each task","Automatic skin lesion subtyping using deep learning and conditional adversarial segmentation","Yes, EfficientNets (B2-B7) used for feature extraction and classification","Skin cancer/lesions","ISIC dataset","Not specified in the text but mentioned as 'large number of images' used for training and testing models","Yes, using SMOTE (synthetic minority oversampling TEchnique) and Reweighting methods to balance dataset","Yes, preprocessing stage included before classification","Quantitative measures: accuracy, precision, recall, F1 score, AUC-ROC curve","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin lesion classification and segmentation","Quantitative measures: accuracy, precision, recall, F1 score, AUC-ROC curve","Proposed pipeline achieved best baseline performance of 91% classification accuracy using EfficientNet B2 and optimal performance reached with EfficientNet B6 (97% accuracy)","Yes, proposed pipeline outperformed state-of-the-art performance on ISIC dataset","No (tested only on ISIC dataset)","Not explicitly stated","Conditional adversarial segmentation and deep learning approach for skin lesion sub-typing from dermoscopic images"
"Skin-CAD: Explainable deep learning classification of skin cancer from dermoscopic images","Yes, skin cancer diagnosis and classification","Adaptation","Yes, combines features from four CNNs with different topologies and deep layers","Explainable artificial intelligence (XAI) based CAD system for skin cancer classification","Yes, dual high-level CNNs features extracted using principal component analysis (PCA)","Skin Cancer (SC), classified into benign or malignant and seven subclasses of SC","Two benchmark datasets: Skin Cancer: Malignant vs. Benign and HAM10000 datasets","Not specified in the text but mentioned as 'large number of images' used for training and testing Skin-CAD model","No (class imbalance not explicitly stated)","Yes, dermoscopic imaging preprocessing included in proposed method","Quantitative measures: accuracy, precision, recall, F1 score, AUC-ROC curve","Yes, transfer learning used to improve performance on skin cancer classification task","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin cancer diagnosis and classification","Quantitative measures: accuracy, precision, recall, F1 score, AUC-ROC curve","Skin-CAD achieved maximum accuracy of 97.2% on Skin Cancer: Malignant vs. Benign dataset and 96.5% on HAM10000 dataset","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on two benchmark datasets)","Not explicitly stated","Skin-CAD: Explainable deep learning classification of skin cancer from dermoscopic images by feature selection of dual high-level CNNs features and transfer learning"
"Heuristic Segmentation Assisted Deep-Spatial Feature Learning Model","Yes, leprosy detection and classification","Adaptation","Yes, combines heuristic segmentation with deep-spatio-textural feature learning","Automated and touchless real-time leprosy diagnosis using computer-aided diagnosis (CAD) solution","Yes, hybrid features including descriptive spatio-textural textural statistics (GLCM) and AlexNet features used for accurate leprosy classification","Leprosy","Not specified in the text but mentioned as 'limited data' which is a challenge in this research area","Not specified in the text but implied to be a relatively small number of images used for training and testing the model","No (class imbalance not explicitly stated)","Yes, ROI-specific segmentation using Firefly Heuristic Driven Fuzzy C-Means clustering (FFCM) included in proposed method","Quantitative measures: accuracy, precision, recall, F-score","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods like GLCM and Convolutional Neural Network based methods demonstrated superiority of proposed model","Quantitative measures: accuracy, precision, recall, F-score","Proposed leprosy detection method exhibited superior performance (accuracy = 96.6%, precision = 99.7%, recall = 95.8%, F-score = 0.9771) over other state-of-art methods","Yes, comparison with GLCM and Convolutional Neural Network based methods demonstrated superiority of proposed model","No (tested on a relatively small number of images)","Not explicitly stated","Heuristic Segmentation Assisted Deep-Spatial Feature Learning Model for Leprosy Detection"
"Lesion-Aware Mixup Augmentation (LAMA) for skin lesion segmentation","Yes, skin lesion segmentation and detection","Adaptation","No, single models used with proposed data augmentation technique","Improving skin lesion segmentation accuracy using LAMA method for dermoscopic images with multiple lesions","Yes, deep features extracted by neural network for skin lesion segmentation and detection","Melanoma (not specified as a specific type of cancer)","ISIC 2017 Challenge dataset and MuLe test set created from ISIC 2020 images with multiple lesions per image","Not specified in the text but mentioned as 'large number of images' used for training and testing LAMA method","No (class imbalance not explicitly stated)","Yes, proposed data augmentation technique includes mixing two or more lesion images from the training set","Quantitative measures: Jaccard score, Dice score","Not applicable","Yes, LAMA method generates synthetic multi-lesion image by mixing two or more lesion images from the training set","Yes, comparison with baseline model on single-lesion and multi-lesion dermoscopic images","Quantitative measures: Jaccard score, Dice score","LAMA improved segmentation accuracy by raising the Jaccard score from 0.687 to 0.744 (8.3% improvement) and Dice score from 0.7923 to 0.8321 (5% improvement)","Yes, comparison with state-of-the-art methods demonstrated improved segmentation accuracy using LAMA method","No (tested on single-lesion ISIC 2017 test images and multi-lesion MuLe test set created from ISIC 2020 images)","Not explicitly stated","LAMA: Lesion-Aware Mixup Augmentation for Skin Lesion Segmentation"
"LiteFusionNet (Lightweight Fusion Network)","Yes, skin image classification","Adaptation","Yes, combines strengths of MobileNet and MobileNetV2 architectures for feature extraction","Medical image classification with improved performance and efficiency","Yes, deep convolutional neural networks (DCNNs) used to extract robust features from medical images","Not specified in the text but mentioned as 'medical imaging modalities' including brain MRI, skin, CT, X-ray, and histology","Publicly available medical image datasets: brain MRI, skin, CT, X-ray, and histology (not specified which specific dataset was used for each modality)","Not specified in the text but mentioned as 'large number of images' used for training and testing LitefusionNet model","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed method to prepare medical images for classification","Quantitative measures: accuracy, precision, recall, F1 score, and AUC-ROC curve","Not applicable (LitefusionNet is a new model)","No (not mentioned as part of the proposed method)","Yes, comparison with five pre-trained models demonstrated LiteFusionNet's superior performance in medical image classification","Quantitative measures: accuracy, precision, recall, F1 score, and AUC-ROC curve","LitefusionNet achieved impressive accuracies across diverse datasets: 97.33% for brain MRI, 91.11% for skin, 99.00% for CT, 98.15% for X-ray, and 92.11% for histology","Yes, LitefusionNet outperformed existing models in terms of classification accuracy","No (tested on a diverse set of publicly available medical image datasets)","Not explicitly stated","LitefusionNet: Boosting the performance for medical image classification with an intelligent and lightweight feature fusion network"
"RCSABC-Conformer (Residual Cosine Similarity Attention and Bidirectional Convolution in dual-branch network)","Yes, skin lesion image classification","Adaptation","Yes, combines CNN branch with Residual Cosine Similarity Attention (RCSA) and Transformer branch","Multi-disease classification on different modalities of skin lesion databases using interactive fusion dual-branch network","Yes, uses Convolutional Neural Network (CNN), Transformer, and Feature Couple Unit with Bidirectional Convolution strategy to extract features from images","Multiple types of skin lesions","Three datasets: clinical and dermoscopic skin lesion images, as well as a hybrid of both","Not specified in the text but mentioned as 'large number of images' used for training and testing RCSABC-Conformer model","No (class imbalance not explicitly stated)","Yes, uses pre-processing techniques to enhance image quality before feeding into network","Quantitative measures: classification accuracy on three datasets","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with advanced and classical classification methods for skin lesion image classification","Classification accuracy on three datasets: clinical, dermoscopic, and hybrid images","RCSABC-Conformer achieved improved classification accuracy by 2.40%, 5.39%, and 4.44% compared to baseline model on the three datasets respectively.","Yes, RCSABC-Conformer outperformed state-of-the-art methods for skin lesion image classification","No (tested only on three specific datasets)","Not explicitly stated","Residual cosine similar attention and bidirectional convolution in dual-branch network for skin lesion image classification"
"ESDMR-Net: Expand-Squeeze Dual Multiscale Residual Network","Yes, skin lesion segmentation (ISIC2016 and ISIC2017 datasets)","Adaptation","No, single model used for multiple tasks","Medical image segmentation using lightweight network with expand-squeeze and dual multiscale residual connections","Yes, extraction of multiscale features enables learning of contextual dependencies among semantically distinct features","Skin lesions (ISIC2016 and ISIC2017 datasets), other types: retinal vessels, digestive tract polyps, lung regions, cells","Seven datasets from five distinct examples of applications: DRIVE, CHASE, ISIC2017, ISIC2016, CVC-ClinicDB, MC, MoNuSeg","Not specified in the text but mentioned as 'large number of images' used for training and testing ESDMR-Net model","No (class imbalance not explicitly stated)","Yes, expansion operation makes all rich features with multiscale information available to squeeze operation","Quantitative measures: F1 score on seven datasets from five distinct examples of applications","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for medical image segmentation and resource-constrained networks","Quantitative measures: F1 score on seven datasets from five distinct examples of applications","ESDMR-Net achieved strong performance with an average F1 score of 0.9283% across all seven datasets, despite having significantly fewer trainable parameters (reduction of two or even three orders of magnitude)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on multiple datasets from five distinct examples of applications)","Not explicitly stated","ESDMR-Net: A lightweight network with expand-squeeze and dual multiscale residual connections for medical image segmentation"
"Regnet x006, EfficientNetv2 B0, and InceptionResnetv2 deep learning methods","Yes, skin cancer diagnosis (classification)","Adaptation","No, single models used for each task","Enhancing skin disease diagnosis through deep learning: a comprehensive study on dermoscopic image preprocessing and classification","Yes, deep features extracted by Regnet x006, EfficientNetv2 B0, and InceptionResnetv2 for skin cancer classification","Skin cancer (melanoma)","ISIC 2019 dataset (not specified which classes were used in the study)","Not specified in the text but mentioned as 'large number of images' used for training and testing deep learning models","No (class imbalance not explicitly stated)","Yes, preprocessing steps included: hair removal, cropping, segmentation, applying a median filter to dermoscopic images","Quantitative measures: accuracy, sensitivity, specificity","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin cancer classification and diagnosis","Quantitative measures: accuracy, sensitivity, specificity","Regnet x006 achieved best accuracy value of 0.858 in squamous cell carcinoma and basal cell carcinoma classification experiment","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method for skin cancer diagnosis","No (tested on ISIC 2019 dataset)","Not explicitly stated","Enhancing Skin Disease Diagnosis Through Deep Learning: A Comprehensive Study on Dermoscopic Image Preprocessing and Classification"
"S-MobileNet","Yes, skin lesion classification","Adaptation","No, single model used for each task","End-to-end deep convolutional neural network based skin lesion classification framework","Yes, S-MobileNet extracts features from images during image preprocessing","7 different types of skin lesions (not specified in the text)","HAM10000 dataset (consists of 10,000 dermatoscopic images from different populations and is publicly available through the International Skin Imaging Collaboration (ISIC) Archive)","Not specified in the text but mentioned as 'large number of images' used for training and testing S-MobileNet model","No (class imbalance not explicitly stated)","Yes, modified version of a Gaussian filtering algorithm and SFTA applied for image segmentation and feature extraction","Quantitative measures: loss, accuracy, precision, F1-score","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin lesion classification and detection","Quantitative measures: loss, accuracy, precision, F1-score","S-MobileNet achieved improved performance when applying preprocessing technique, Mish activation function outperformed Relu, and compressed S-MobileNet outperformed S-MobileNet for skin lesion classification","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on HAM10000 dataset)","Not explicitly stated","A novel end-to-end deep convolutional neural network based skin lesion classification framework"
"Explainable deep inherent learning method","Yes, multi-classes skin lesion classification (seven types of skin lesions)","Adaptation","No, single model used for each task","To provide explanation and trustworthiness to AI-based diagnosis systems in dermatology","Yes, deep features extracted by inherent learning method for skin lesion classification","Not specified (seven types of skin lesions)","HAM10000 dataset (challenging dataset used for evaluation)","60 images used in the study","No (class imbalance not explicitly stated)","Yes, preprocessing step included as part of inherent learning method","Explainable AI techniques: occlusion sensitivity and X-AI framework for local and global explanation","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","Accuracy and other metrics not specified in the text","Not explicitly stated but implies that the proposed method provides better explanation and trustworthiness to AI-based diagnosis systems","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on HAM10000 dataset)","Not explicitly stated","Explainable deep inherent learning for multi-classes skin lesion classification"
"Gated Recurrent Unit (GRU) Network with Improved Orca Predation Algorithm (IOPA)","Yes, skin cancer detection","Adaptation","No, single models used for each task","Prompt skin cancer detection using GRU/IOPA system","Yes, deep features extracted by GRU Network for skin cancer detection","Skin cancer (not specified which type)","HAM10000 dataset (large collection of skin lesion images)","Not specified in the text but mentioned as 'large number' used for training and testing GRU/IOPA system","No (class imbalance not explicitly stated)","Yes, preprocessing step included to enhance image quality and extract relevant features","Quantitative measures: sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), accuracy","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with eight existing techniques commonly used for skin cancer diagnosis","Quantitative measures: sensitivity, specificity, PPV, NPV, accuracy","GRU/IOPA system achieved superior performance in terms of sensitivity (0.95), specificity (0.97), PPV (0.95), NPV (0.96), and accuracy compared to existing methods","Yes, GRU/IOPA system outperformed other existing methods for skin cancer diagnosis","No (tested on HAM10000 dataset)","Not explicitly stated","A deep learning outline aimed at prompt skin cancer detection utilizing gated recurrent unit networks and improved orca predation algorithm"
"SNC_Net: integrating handcrafted and deep learning-based features using dermoscopy images","Yes, skin cancer detection (8 types)","Adaptation","Yes, combines handcrafted and deep learning-based features for classification","Automated skin cancer detection from dermoscopic images using SNC_Net model","Yes, uses convolutional neural network (CNN) to extract features from dermoscopy images","8 types of skin cancer: actinic keratosis (AKs), dermatofibroma (DFa), melanoma (MELa), basal cell carcinoma (BCCa), squamous cell carcinoma (SCCa), melanocytic nevus (MNi), vascular lesion (VASn), and benign keratosis (BKs)","ISIC 2019 dataset for skin cancer detection","Not specified in the text but mentioned as 'large number of images' used to train and validate SNC_Net model","No (class imbalance not explicitly stated)","Yes, dermoscopy image preprocessing included in proposed method","Quantitative measures: accuracy, precision, recall, F1 score, Ablation study to validate performance of SNC_Net model","Not applicable (SNC_Net is a custom-built model)","No (not mentioned as part of the proposed method)","Yes, comparison with four baseline models: EfficientNetB0, MobileNetV2, DenseNet-121, and ResNet-101","Quantitative measures: accuracy, precision, recall, F1 score","SNC_Net achieved an accuracy of 97.81%, a precision of 98.31%, a recall of 97.89%, and an F1 score of 98.10% for skin cancer detection","Yes, SNC_Net outperformed six state-of-the-art (SOTA) classifiers in terms of accuracy, precision, recall, and F1 score","No (tested on ISIC 2019 dataset)","Not explicitly stated","SNC_Net: Skin Cancer Detection by Integrating Handcrafted and Deep Learning-Based Features Using Dermoscopy Images"
"Deep learning models (various) and Naturalize augmentation technique","Yes, eight-class skin cancer classification","Adaptation","No, single models used for each task","Precise and efficient diagnostic methodologies for skin cancer using AI-driven deep learning","Yes, pre-trained ImageNet architectures and Vision Transformer models used for feature extraction","Skin cancer (eight-class classification)","ISIC2019 dataset with Naturalized 2.4K ISIC2019 and groundbreaking Naturalized 7.2K ISIC2019 datasets created using the 'Naturalize' augmentation technique","Not specified in the text but mentioned as 'large number of images' used for training and testing deep learning models","Yes, class imbalance addressed through Naturalize augmentation technique","Yes, skin cancer image segmentation using Segment Anything Model (SAM) included in proposed method","Quantitative measures: confusion matrices, classification reports, visual analyses using Score-CAM across diverse dataset variations","Yes, pre-trained ImageNet architectures and Vision Transformer models used for transfer learning","Yes, Naturalize augmentation technique introduced to counteract class imbalance in skin cancer datasets","No (compared with state-of-the-art deep learning methods but not explicitly stated)","Quantitative measures: confusion matrices, classification reports, visual analyses using Score-CAM across diverse dataset variations","100% average accuracy, precision, recall, and F1-score achieved within the Naturalized 7.2K ISIC2019 dataset","Yes (compared with state-of-the-art deep learning methods but not explicitly stated)","No (tested on ISIC2019 dataset and its variations created using Naturalize augmentation technique)","Not explicitly stated","Naturalize Revolution: Unprecedented AI-Driven Precision in Skin Cancer Classification Using Deep Learning"
"Hybrid models: CNN+RF for COVID-19 CT dataset, VGG16 for COVID-19 X-ray dataset, MobileNetV2 for Monkeypox dataset","Yes, rapid detection of pandemic diseases (COVID-19 and Monkeypox)","Adaptation","Yes, combination of CNN and ML methods used in hybrid models","Development of a user-friendly AI-based clinical decision support system for rapid detection of pandemic diseases: COVID-19 and Monkeypox","Yes, deep features extracted by CNN models (CNN+RF, VGG16, MobileNetV2) used in hybrid models","COVID-19 and Monkeypox","Not specified in the text but mentioned as 'datasets' for each disease","Not specified in the text but implied to be a large number of images used for training and testing models","No (class imbalance not explicitly stated)","Yes, pre-processing steps included in proposed method","Quantitative measures: accuracy, precision, recall, F1-score performance metrics","Yes, transfer learning models used for detection of Monkeypox and COVID-19 from skin lesion images and chest X-Ray images respectively","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed hybrid models","Quantitative measures: accuracy, precision, recall, F1-score performance metrics","Highest classification values obtained for each dataset were as follows: %91.71 accuracy, %92.07 precision, %90.29 recall and %91.71 F1-score for COVID-19 CT dataset; %99.56 accuracy, %100 precision, %99.12 recall and %99.55 F1-score for COVID-19 X-ray dataset; and %90.38 accuracy, %93.32 precision, %88.11 recall and %90.64 F1-score for Monkeypox dataset","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed hybrid models","No (tested on datasets specific to each disease)","Not explicitly stated","A user-friendly AI-based clinical decision support system for rapid detection of pandemic diseases: Covid-19 and Monkeypox"
"Grid-Based Structural and Dimensional Explainable Deep Convolutional Neural Network (ECNN)","Yes, skin cancer classification","Adaptation","No, single model used for each task","Accurate and interpretable skin cancer classification using explainable deep convolutional neural networks","Yes, VGG-16 architecture extracts hierarchical characteristics of skin lesion images","Skin cancer (benign and malignant)","ISIC dataset (10,015 dermascope images) and MNIST dataset (2357 images of malignant and benign oncological diseases)","Not specified in the text but mentioned as 'large number' used for training and testing ECNN model","No (class imbalance not explicitly stated)","Yes, adaptive thresholding is employed to extract region of interest (ROI) from skin lesion images","Quantitative measures: accuracy, CSI values, TP rate, FPR and FNR","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin cancer classification: lightweight CNN, DenseNet, CNN, Efficient Net-B0, ECNN and COA-CAN","Quantitative measures: accuracy, CSI values, TP rate, FPR and FNR","ECNN achieved accuracy of 96% and CSI value of 97 for TP 80 using the ISIC dataset, outperforming other methods by up to 20.83%","Yes, proposed model demonstrated superiority over existing techniques in terms of accuracy and interpretability","No (tested on ISIC and MNIST datasets)","Not explicitly stated","Grid-Based Structural and Dimensional Skin Cancer Classification with Self-Featured Optimized Explainable Deep Convolutional Neural Networks"
"Transformer guided self-adaptive network (SapFormer)","Yes, skin lesion image segmentation","Adaptation","No, single model used for multi-scale feature encoding and positional feature sensing","Multi-scale skin lesion image segmentation using SapFormer","Yes, multiple hybrid transformers designed to capture global context and fine-grained detail","Skin lesions (not specified as melanoma or other types)","ISIC-2016, ISIC-2017, and ISIC-2018 datasets for skin lesions","Not specified in the text but mentioned as 'large number of images' used for training and testing SapFormer model","No (class imbalance not explicitly stated)","Yes, multi-scale feature encoding characteristics of input image are derived from pre-processing step","Quantitative measures: accuracy, IOU, DSC values on ISIC-2016, ISIC-2017, and ISIC-2018 datasets","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art models for skin lesion segmentation demonstrated superiority of SapFormer model","Quantitative measures: accuracy, IOU, DSC values on ISIC-2016, ISIC-2017, and ISIC-2018 datasets","SapFormer achieved accuracy values of 97.9 %, 94.3 %, and 95.7 % for skin lesion segmentation on ISIC-2016, ISIC-2017, and ISIC-2018 datasets respectively.","Yes, SapFormer's metrics surpassed the performance of majority of state-of-the-art models","No (tested only on ISIC-2016, ISIC-2017, and ISIC-2018 datasets)","Not explicitly stated","Transformer guided self-adaptive network for multi-scale skin lesion image segmentation"
"Deep learning using U-Net models and Harris Hawks Optimization Algorithm (HHO)","Yes, skin lesion localization and grading","Adaptation","No, single models used for each task","Aseptic approach towards skin lesion detection, classification, and segmentation using deep learning and HHO","Yes, pre-trained CNN models (VGG16, VGG19, DenseNet169, DenseNet201, MobileNet) used for feature extraction","Melanoma skin cancer","Two datasets: 'Melanoma Skin Cancer Dataset of 10000 Images' and 'Skin Cancer ISIC'","Not specified in the text but mentioned as 'large number of images' used for training and testing models","No (class imbalance not explicitly stated)","Yes, manual segmentation approach used when dataset has no masks to use while automatic segmentation approach using U-Net models is also used","Quantitative measures: loss, accuracy, Mean Absolute Error, Mean Squared Error, Mean Squared Logarithmic Error, Root Mean Squared Error","Yes, pre-trained CNN models (VGG16, VGG19, DenseNet169, DenseNet201, MobileNet) used for transfer learning","No (not mentioned as part of the proposed method)","Yes, comparison with 9 related studies demonstrated the efficiency of proposed framework","Quantitative measures: overall accuracy, precision, sensitivity, specificity, F1-score","DenseNet169 pre-trained model achieved best reported scores for 'Melanoma Skin Cancer Dataset of 10000 Images' dataset (97.08%, 98.50%, 95.38%, 98.65%, 96.92%) and MobileNet pre-trained model achieved best reported scores for 'Skin Cancer ISIC' dataset (96.06%, 83.05%, 81.05%, 97.93%, 82.03%)","Yes, comparison with state-of-the-art methods demonstrated the efficiency of proposed framework","No (tested on two publicly available datasets: 'Melanoma Skin Cancer Dataset of 10000 Images' and 'Skin Cancer ISIC')","Not explicitly stated","An aseptic approach towards skin lesion localization and grading using deep learning and harris hawks optimization"
"Hybrid feature selection technique (Chi-square, information gain, and principal component analysis)","Yes","Adaptation","No, single models used for each task","Predicting skin lesion using AI-powered deep learning model with hybrid feature selection technique","Yes, essential features discovered using mathematical-based hybrid methodologies (Chi-square, information gain, and principal component analysis)","Skin cancer","Not specified in the text but mentioned as 'extensive skin lesion datasets' available in scientific literature","Not specified in the text","No (class imbalance not explicitly stated)","Yes, dermoscopic pictures used for analysis","Machine learning algorithms with variations in parameter settings across multiple validation approaches","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin lesion classification and prediction","Not specified in the text but implied to be related to accuracy and performance metrics for machine learning models","Hybrid feature selection technique showed effective results in distinguishing between cancerous and benign skin lesions using dermoscopic pictures","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on extensive skin lesion datasets available in scientific literature)","Not explicitly stated","Enhance a System for Predicting Skin Lesion Using Hybrid Feature Selection Technique"
"Multitask learning with melanin localization model and tree-based interpretable classification model","Yes, skin lesion classification","Adaptation","No, single models used for each task","Explainable skin lesion classification with multitask learning","Yes, quantitative features extracted from cross-sectional cellular-resolution images using melanin localization model and cell nuclei segmentation models","Not specified (example of eczema used)","Not specified in the text but mentioned as 'skin surface images' for training and testing deep learning models","Not specified in the text but mentioned as 'large number of images' used for training and testing multitask learning model","No (class imbalance not explicitly stated)","Yes, skin layers and cell nuclei segmentation included in melanin localization model","Quantitative features extracted using tree-based machine learning model with eczema as an example","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison not explicitly stated but multitask learning strategy applied to enhance segmentation accuracy and benefit from shared information of features","Quantitative features extracted using tree-based machine learning model with eczema as an example (not specified in the text)","Not specified in the text, but proposed method aims to develop interpretable classification models for skin lesion diagnosis and treatment response without requiring invasive biopsies","Yes, comparison not explicitly stated but multitask learning strategy applied to enhance segmentation accuracy and benefit from shared information of features","No (tested on eczema dataset as an example)","Not explicitly stated","Explainable Skin Lesion Classification with Multitask Learning"
"Convolutional-deconvolutional based Multi-Task Learning (MTL) model","Yes, skin lesion classification and segmentation","Adaptation","No, single models used for each task but combined in MTL framework","Explainable Multi-task Learning Approach for Skin Lesion Classification","Yes, deep features extracted by convolutional-deconvolutional based model for skin lesion classification and segmentation","Skin cancer (not specified which type)","HAM-10000 dataset","Not specified in the text but mentioned as 'large number of images' used for training and testing MTL model","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed method","Quantitative measures: Accuracy, IoU Score","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art models for skin lesion classification and segmentation","Quantitative measures: Accuracy, IoU Score","MTL model achieved an Accuracy of 91.56% and IoU Score of 87.98%","Yes, MTL model outperformed state-of-the-art models for skin lesion classification and segmentation","No (tested on HAM-10000 dataset)","Not explicitly stated","Explainable Multi-task Learning Approach for Skin Lesion Classification"
"Various AI-based models (CNNs, SVMs, ensemble learning techniques)","Yes, skin cancer detection and diagnosis","Adaptation","No, single models used for each task","Comprehensive review of AI applications in skin cancer classification","Yes, deep learning algorithms (CNNs) used for feature extraction and image processing techniques","Skin cancer","Not specified but mentioned as 'large number of images' from various sources","Not specified in the text but mentioned as 'thousands of images' used to train AI models","No (class imbalance not explicitly stated)","Yes, image preprocessing techniques included in proposed method","Quantitative measures: diagnostic accuracy, efficiency, and accessibility","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with traditional methods for skin cancer detection and diagnosis","Quantitative measures: diagnostic accuracy, efficiency, and accessibility","AI-based models exhibit remarkable performance in skin cancer detection by leveraging advanced deep learning algorithms (CNNs) and image processing techniques","Yes, comparison with state-of-the-art methods demonstrated the superiority of AI-based models for skin cancer detection and diagnosis","No (tested on various datasets from Scopus, IEEE, and MDPI)","Data privacy concerns, complexities in integrating AI systems into existing workflows, need for large high-quality datasets","AI in dermatology: a comprehensive review into skin cancer detection"
"Improved EfficientNetB0 network","Yes, skin lesions classification","Adaptation","No, single model used for each task","Lightweight convolution neural network method for skin lesion classification","Yes, deep features extracted by improved EfficientNetB0 network","Skin cancer (not specified which type)","ISIC2018 dataset (HAM10000 images)","Not specified in the text but mentioned as 'large number of images' used for training and testing model","No (class imbalance not explicitly stated)","Yes, standard preprocessing steps included in proposed method","Quantitative measures: accuracy, Macro_P, Macro_R, F1-Score","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin lesion classification","Quantitative measures: accuracy, Macro_P, Macro_R, F1-Score","Improved EfficientNetB0 achieved an accuracy of 89.38% on the ISIC2018 dataset (HAM10000 images)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested only on ISIC2018 dataset)","Not explicitly stated","A Study on Skin Lesions Classification Based on Improved EfficientN etB0 Network"
"Vision Transformers (ViTs) and Convolutional Neural Networks (CNNs)","Yes, skin cancer classification","Adaptation","No, single models used for each task","Explainable skin cancer classification using deep learning and explainable artificial intelligence methods","Yes, ViTs and CNNs extract features from images for classification","Skin cancer (benign or malignant)","Freely available datasets (not specified in the text)","Not specified in the text but mentioned as 'large number of images' used for training and testing models","No, class imbalance addressed using SMOTE technique","Yes, synthetic minority oversampling technique (SMOTE) applied to address class imbalance issues","Quantitative measures: accuracy, precision, F1 score, sensitivity, specificity","Pretrained ViTs and CNNs used for classification task","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods demonstrated competitive performance of ViT models","Quantitative measures: accuracy, precision, F1 score, sensitivity, specificity","ResNet50 achieved an accuracy of 88.8%, precision of 86.9%, sensitivity of 88.6%, F1 score of 87.8%, and specificity of 88.9% for skin cancer classification","Yes, comparison with state-of-the-art methods demonstrated competitive performance of ViT models","No (tested on freely available datasets)","Not explicitly stated","Skin cancer classification using vision transformers and explainable artificial intelligence"
"EfficientNet-B1","Yes, classification of arsenic-affected skin using clinical images","Adaptation","No, single model used for task","Automate classification system for detecting arsenic-induced skin lesions using EfficientNet-B1","Yes, deep features extracted by EfficientNet-B1 for image analysis and classification","Arsenic-affected skin (not explicitly stated as cancer)","Dataset comprising healthy and arsenic-affected skin images with augmentation techniques employed to increase robustness and generalizability","Not specified in the text but mentioned as 'large number of images' used for training and testing EfficientNet-B1 model","No (class imbalance not explicitly stated)","Yes, image augmentation techniques employed to increase robustness and generalizability","Quantitative measures: accuracy","Not applicable","Yes, used for increasing robustness and generalizability of the model","Yes, comparison with other deep learning models (VGG-19, ResNet-50, MobileNetv2, EfficientNet-B0) demonstrated superiority of EfficientNet-B1","Accuracy","EfficientNet-B1 achieved highest performance of 94.69% accuracy for classification task","Yes, comparison with state-of-the-art models demonstrated the reliability and scalability of EfficientNet-B1 as a tool for automatic diagnosis in resource-constrained settings","No (tested on dataset comprising healthy and arsenic-affected skin images)","Not explicitly stated","A Deep Learning Approach to Automate Classification of Arsenic-Affected Skin using EfficientNet-B1"
"Condition-based Generative Adversarial Networks (GANs) and traditional data augmentation approaches","Yes, skin lesion classification using deep learning models","Adaptation","No, single models used for each task","Alleviation of Health Data Poverty for Skin Lesions Using ACGAN: Systematic Review","Yes, deep features extracted by VGG16 (Visual Geometry Group 16), DenseNet, Xception, and Inception-ResNet v2 models","Skin lesions","Existing dataset augmented with synthetic images generated using GANs","Not specified in the text but mentioned as 'large number of images' used for training and testing deep learning models","No (class imbalance not explicitly stated)","Yes, skin refinement step included in proposed method","Quantitative measures: accuracy, precision, recall, F1 score, AUC-ROC curve","Yes, pre-trained ImageNet weights used for initialization of deep learning models","Yes, traditional data augmentation approaches (rotation and scaling) combined with GAN-based synthetic image generation","Yes, comparison with state-of-the-art methods for skin lesion classification using deep learning models","Quantitative measures: accuracy, precision, recall, F1 score, AUC-ROC curve","DenseNet-201 with GAN Augmentation achieved an accuracy of around 82% for skin lesion classification","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on existing dataset augmented with synthetic images generated using GANs)","Overfitting observed in some models when data augmentation and early stopping were used","Alleviation of Health Data Poverty for Skin Lesions Using ACGAN: Systematic Review"
"Multimodal model using vision transformer (ViT) and soft voting strategy","Yes, skin disease diagnosis","Adaptation","Yes, combines macroscopic images, dermatopathological images, and metadata for multimodal modeling","To explore the influence of transformer-based multimodal modeling on clinicians’ decision-making with different levels of experience","Yes, deep features extracted by ViT model for skin disease diagnosis","Not specified (five skin disorders)","Multimodal dataset constructed for five skin disorders","Not specified in the text but mentioned as 'large number of images' used for training and testing ViT model","No (class imbalance not explicitly stated)","Yes, preprocessing steps included in proposed method","Quantitative measures: accuracy, AUC, diagnosis time","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with unimodal models and metadata-only situation for clinicians’ decision-making","Quantitative measures: accuracy, AUC, diagnosis time","Multimodal model achieved an accuracy of 0.98 on the external validation set","Yes, comparison with state-of-the-art methods for skin disease diagnosis and decision-making support","No (tested on constructed multimodal dataset)","Further large-scale prospective studies are necessary to confirm the results","Exploring the influence of transformer-based multimodal modeling on clinicians’ diagnosis of skin diseases: A quantitative analysis"
"Medical AI approach with three phases: educational AI stack, medical foundation stack, and system development","Yes, skin cancer detection (94% accuracy rate)","Adaptation","No, single models used for each task","Empowering undergraduate students with skills to develop healthcare applications using Medical AI","Yes, transfer learning and model architecture selection customization (Tensor-Flow, Scikit-Learn, Keras)","Skin cancer, breast cancer","Not specified in the text but mentioned as 'medical data' used for training models","Not specified in the text but mentioned as 'large number of images' used for training and testing AI models","No (class imbalance not explicitly stated)","Yes, medical data acquisition process included in proposed approach","Quantitative measures: accuracy rate, precision, model selection, and deployment environment comparison between AWS and GCP","Yes, transfer learning used for AI models development","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed approach","Quantitative measures: accuracy rate, precision, model selection, and deployment environment comparison between AWS and GCP","94% accuracy rate in skin cancer detection, over 85% precision in breast cancer prediction (tumor grade, stage, recurrence, survival), and 88% accuracy in allergy prediction using biological information","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed approach","No (tested on medical data used for training AI models)","Not explicitly stated","Empowering Future Engineers: Educational Journey from AI Fundamentals to Healthcare Innovations"
"YOLO, DenseNet201, GoogLeNet, InceptionResNetV2, and MobileNet","Yes, image-based classification of hyperpigmented skin disease","Adaptation","No, single models used for each task","Comparative study of deep learning algorithms for image-based classification of hyperpigmented skin diseases","Yes, pre-trained models (YOLO, DenseNet201, GoogLeNet, InceptionResNetV2, and MobileNet) used for feature extraction","Hyperpigmented skin disease (four most common types: cafe-au-lait spots, melasma, nevi, congenital nevus)","Small dataset split into 80% training and 20% testing (not specified in the text but mentioned as 'small' dataset)","Not specified in the text","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed method","Assessment metrics: accuracy and AUC (Area Under Curve)","Yes, pre-trained models used for transfer learning","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for image-based classification of hyperpigmented skin diseases","Assessment metrics: accuracy and AUC (Area Under Curve)","YOLO emerged as the top model due to its stable accuracy and AUC values, confirmed by confusion matrices","Yes, comparison with state-of-the-art methods demonstrated YOLO's superiority for image-based classification of hyperpigmented skin diseases","No (tested on a small dataset)","Further research needed to enhance clinical accuracy and effectiveness","A comparative study of deep learning algorithms for image-based classification of hyperpigmented skin disease"
"Convolutional Neural Networks (CNN) with SHAP values for explainability","Yes, cancer diagnosis using Raman spectroscopy","Adaptation","No, single models used for each task","Explainable Raman spectral classification for cancer diagnosis","Yes, deep features extracted by CNN from preprocessed and frequency-transformed Raman data","Not specified (tumor-associated fibroblasts)","Not specified in the text but mentioned as 'Raman spectra obtained from normal skin fibroblasts (HF) and tumor-associated fibroblasts (ZAM)'","Not applicable (spectral data used for classification)","No (class imbalance not explicitly stated)","Yes, preprocessed Raman data used as input to CNN model","Quantitative measures: precision, recall, F1-score, SHAP values for feature importance","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for Raman spectroscopy-based cancer diagnostics","Quantitative measures: precision, recall, F1-score, SHAP values for feature importance","CNN model achieved a high classification accuracy of 90.32% and demonstrated its effectiveness in distinguishing between cancerous and non-cancerous samples","Yes, comparison with state-of-the-art methods showed the superiority of proposed method","No (tested on spectral data from normal skin fibroblasts and tumor-associated fibroblasts)","Not explicitly stated","Explainable Raman Spectral Classification - Towards Clinical Practice of Cancer Diagnosis"
"Multi-Layer Machine Learning (MLML) Architecture with 3 layers","Yes, non-invasive skin cancer diagnosis on dermoscopic images","Adaptation","Yes, multiple machine learning algorithms used in each layer: decision tree, random forest, neural network, naive bayes, support vector machine (first layer), k-nearest neighbor algorithm (second layer), linear regression algorithm (third layer)","Improved skin cancer diagnosis using MLML method","Yes, fourteen feature extraction algorithms used: age, gender, region of the lesion in addition to image features","Skin cancer","Not specified in the text but mentioned as 'input dataset'","Not specified in the text but implied that a large number of images were used for training and testing MLML model","No (class imbalance not explicitly stated)","Yes, preprocessing step included in proposed method","Four metrics: accuracy, precision, recall, F1-score","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with other relevant studies in literature demonstrated superiority of proposed method","Four metrics: accuracy, precision, recall, F1-score","MLML technique achieved 88.81% accuracy, 88.89% precision, 99.17% recall, and 93.75% F1-score in classifying skin cancer images","Yes, comparison with state-of-the-art methods demonstrated superiority of proposed method","No (tested on a single dataset)","Not explicitly stated","A New Multi-Layer Machine Learning (MLML) Architecture for Non-invasive Skin Cancer Diagnosis on Dermoscopic Images"
"Double-Branch Attention Convolutional Neural Networks (DACNN)","Yes, skin cancer detection and classification","Adaptation","No, single models used for each task","A Skin Cancer Detection Framework Based on Double-Branch Attention Neural Networks","Yes, double-branch attention mechanism used to extract features of potential sick area and locally detailed features","Skin cancer (not specified which type)","Real dataset consisting of 10015 dermatoscope images","Not specified in the text but mentioned as 'large number of images' used for training and testing DACNN model","No, imbalanced categorical data alleviated using weighted loss function during model training","Yes, whole dataset divided into finer-grained categories according to natural subclasses in each category","Quantitative measures: sensitivity, accuracy, F1 score","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with recurrent attention convolutional neural network (RACNN) detection methods","Quantitative measures: sensitivity, accuracy, F1 score","DACNN achieved performance metrics of sensitivity as 0.922, accuracy as 0.942 and F1_score as 0.933 for skin cancer detection and classification","Yes, DACNN outperformed RACNN methods with improvements in sensitivity (3.48%), accuracy (2.95%) and F1 score (3.44%))","No (tested on real dataset consisting of 10015 dermatoscope images)","Not explicitly stated","A Skin Cancer Detection Framework Based on Double-Branch Attention Neural Networks"
"Deep learning-based method using U-Net for skin wound-size measurement","Yes, skin ablation and wound healing in zebrafish","Adaptation","No, single models used for each task","Optimization of laser-based method to conduct skin ablation in zebrafish and development of deep learning-based method for skin wound-size measurement","Yes, U-Net model extracts features from images of skin wounds for automatic calculation of wound area","Not applicable (study focuses on skin wound healing)","Zebrafish dataset with manually counted wound areas using ImageJ as gold standard","Not specified in the text but mentioned as 'large number of images' used for training and testing U-Net model","No (class imbalance not explicitly stated)","Yes, wound images collected and preprocessed for deep learning training","Quantitative measures: accuracy, precision, recall, F1 score, mean squared error","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with Mask-RCNN and U-Net models for skin wound judgment","Quantitative measures: accuracy, precision, recall, F1 score, mean squared error","U-Net model achieved better performance than Mask-RCNN in calculating skin wound area (proof-of-concept validation)","Yes, comparison with state-of-the-art methods for deep learning-based skin wound-size measurement","No (tested on zebrafish dataset)","Not explicitly stated","Optimization of Laser-Based Method to Conduct Skin Ablation in Zebrafish and Development of Deep Learning-Based Method for Skin Wound-Size Measurement"
"Curriculum-Based Augmented Fourier Domain Adaptation (Curri-AFDA)","Yes, medical image segmentation","Adaptation","No, single model used for domain adaptation and generalization","Robust medical image segmentation using curriculum-based augmented Fourier domain adaptation","Yes, deep features extracted by Curri-AFDA for robust medical image segmentation","Not specified in the text (Retina and Nuclei datasets used)","Multiple sites and scanners (not specified which ones)","Not specified in the text but mentioned as 'large number of images' used for training and testing Curri-AFDA model","No (class imbalance not explicitly stated)","Yes, skin refinement step included in proposed method","Quantitative measures: adaptation performance, generalization performance, robustness against corruption types and increasing severity levels","Not applicable","Yes, training-Time chained augmentation mixing used to expand data distributions while preserving domain-invariant semantics","Yes, comparison with state-of-the-art methods for medical image segmentation and adaptation","Quantitative measures: adaptation performance, generalization performance, robustness against corruption types and increasing severity levels","Curri-AFDA achieved superior adaptation and generalization performance on two segmentation tasks (Retina and Nuclei) with cross-domain datasets","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on multiple sites and scanners but not specified which ones)","Not explicitly stated","Curriculum-Based Augmented Fourier Domain Adaptation for Robust Medical Image Segmentation"
"Softflatten network (Softflatten-Net)","Yes, monkeypox classification from digital skin lesions images","Adaptation","No, single model used for each task","Automated monkeypox detection using deep convolutional neural network (CNN)","Yes, deep features extracted by Softflatten-Net for classification and feature extraction","Monkeypox (MP), Chickenpox (CP), Measles (MS)","IEEE data port (4241 skin images) and Dermnet (28771 images) datasets","Not specified in the text but mentioned as 'large number of images' used for training and testing Softflatten-Net model","No (class imbalance not explicitly stated)","Yes, skin lesion preprocessing step included in proposed method","Quantitative measures: classification accuracy, sensitivity, precision, F1 score","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art models for monkeypox detection and classification","Quantitative measures: classification accuracy, sensitivity, precision, F1 score","Softflatten-Net achieved maximum classification accuracy (Ac) of 97.25%, a sensitivity (Sen) of 92.94%, and a precision (Pr) of 96.48% in classifying MP from other categories of skin images","Yes, proposed network outperformed existing state-of-the-art models for monkeypox detection and classification","No (tested on IEEE data port and Dermnet datasets)","Not explicitly stated","Softflatten-Net: A Deep Convolutional Neural Network Design for Monkeypox Classification From Digital Skin Lesions Images"
"AI-based pipeline for analysis of 3D-confocal data","Yes, spheroid cultures on distinct ultra-low attachment plate types","Adaptation","No, single models used for each task","Multiparametric analysis of spheroids using AI-based pipeline and subcellular feature assessment","Yes, deep features extracted by AI-based pipeline for spheroid cultures on distinct ultra-low attachment plate types","Multiple cell lines: HaCaT keratinocytes, HT-29 cancer cells, MDA-MB-231 (not specified as skin-related)","Not specified in the text but mentioned as 'large number of spheroids' used for training and testing AI-based pipeline","Not specified in the text but mentioned as 'thousands of images' analyzed using brightfield microscopy","No (class imbalance not explicitly stated)","Yes, automated brightfield microscopy used for prescreening and analysis of spheroids on distinct ultra-low attachment plate types","Quantitative measures: size, eccentricity, cell proliferation, nuclear/cytoplasm ratio of transcription factors (YAP1)","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with earlier concepts on role of YAP1 in cell proliferation and differentiation of keratinocytes","Quantitative measures: size, eccentricity, cell proliferation, nuclear/cytoplasm ratio of transcription factors (YAP1)","AI-based pipeline revealed correlation between spheroid size, cell proliferation, and YAP1 expression in HaCaT keratinocytes","Yes, results show that plate type may influence outcome of experimental campaigns","No (tested on distinct ultra-low attachment plate types)","Not explicitly stated","A multiparametric analysis including single-cell and subcellular feature assessment reveals differential behavior of spheroid cultures on distinct ultra-low attachment plate types"
"Prototypical decision tree","Yes, skin lesion image classification","Adaptation","No, single model used for hierarchical skin lesion image classification","Hierarchical skin lesion image classification with prototypical decision tree","Not applicable (focus on classification)","Skin cancer (not specified which type)","Not mentioned in the correction text, but likely same dataset as original article","Not specified in the text","No information available","Not applicable (focus on classification)","Not mentioned in the correction text","Not applicable","Not mentioned in the correction text","No, this is a correction to an existing article and not a new publication with comparisons","Not specified in the correction text","Not applicable (this is a correction to an existing article)","No, this is a correction to an existing article and not a new publication with comparisons","No information available","Not explicitly stated","Correction to: Hierarchical skin lesion image classification with prototypical decision tree (npj Digital Medicine, (2025), 8, 1, (26), 10.1038/s41746-024-01395-z)"
"Novel network-level fused deep architecture with explainable artificial intelligence","Yes, multiclass skin lesion classification and localization from dermoscopic images","Adaptation","Yes, multiple models (5-block inverted residual network and 6-block inverted bottleneck network) fused at the network level using depth concatenation approach","Enhance classification and localization of skin lesions in dermoscopic images while providing explainability through artificial intelligence","Yes, global average pooling layer used for feature extraction followed by shallow neural networks for final classification","Skin cancer (multiclass)","HAM10000 and ISIC2018 publicly available datasets","Not specified in the text but mentioned as 'large number of images' used for training and testing models","No (class imbalance not explicitly stated, although data augmentation was applied to improve class balance)","Yes, novel hybrid contrast enhancement technique applied for pre-processing and dataset augmentation","Quantitative measures: classification accuracy, sensitivity, precision, F1-scores, localization of lesion regions using explainable AI techniques (LIME)","Not applicable","Yes, data augmentation applied to improve class balance and enhance lesion visibility","No (compared with state-of-the-art methods for skin cancer classification and localization not mentioned in the text)","Quantitative measures: classification accuracy, sensitivity, precision, F1-scores, localization of lesion regions using explainable AI techniques (LIME)","Proposed fused architecture achieved high classification accuracy with results of 91.3% and 90.7% on the HAM10000 and ISIC2018 datasets, respectively","Not applicable","Yes (tested on two publicly available datasets: HAM10000 and ISIC2018)","Computational resource requirements and training time are limitations of the proposed approach","Multiclass skin lesion classification and localziation from dermoscopic images using a novel network-level fused deep architecture and explainable artificial intelligence"
"InceptionV3, Xception, ResNet50V2, and DenseNet121 pre-trained models with image augmentation techniques","Yes, skin cancer diagnosis","Adaptation","No, single models used for each task","Explainable deep learning approaches for skin cancer diagnosis using XAI and pre-trained models","Yes, deep features extracted by pre-trained models (InceptionV3, Xception, ResNet50V2, DenseNet121) with image augmentation techniques to improve generalization","Skin cancer","Not specified in the text but mentioned as 'extensive evaluation' on various datasets","Not specified in the text but implied that a large number of images were used for training and testing pre-trained models","No (class imbalance not explicitly stated)","Yes, image augmentation techniques applied to improve generalization","Quantitative measures: accuracy, precision, recall, F1 score using Xception model as the best performer","Not applicable","Yes, image augmentation techniques used to deal with class imbalance and improve generalization of pre-trained models","No (compared different pre-trained models for skin cancer diagnosis)","Quantitative measures: accuracy, precision, recall, F1 score using Xception model as the best performer","Xception model achieved an accuracy of 90.15%, precision of 90.02%, recall of 90.25%, and an F1 score of 90.10% for skin cancer diagnosis","Yes, Xception model outperformed other pre-trained models (InceptionV3, ResNet50V2, DenseNet121) in terms of accuracy and precision","No (tested on various datasets but specific dataset not mentioned)","Not explicitly stated","Explainable deep learning approaches for skin cancer diagnosis"
"Yolo-Unet++ with LovaszSoftMax and IoU Loss Function (Y-UNet++-LS-IoULF) for segmentation, followed by Vision Transformer (ViT)-aided Adaptive EfficientB7 network (ViT-AEB7) for detection","Yes, skin cancer detection","Adaptation","No, single models used for each task","Automated skin cancer detection using deep learning techniques","Yes, Yolo-Unet++ with LovaszSoftMax and IoU Loss Function (Y-UNet++-LS-IoULF) extracts features from images","Skin cancers, particularly melanoma","Two datasets: dataset 1 (5000 images for training and testing), dataset 2 (200 images for training and testing)","Not specified in the text but mentioned as 'large number of images' used for training and testing models","No (class imbalance not explicitly stated)","Yes, abnormality segmentation process included before feeding images to Yolo-Unet++-LS-IoULF model","Quantitative measures: F1-score, MCC measure","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with classical-related approaches for skin cancer detection","Quantitative measures: F1-score, MCC measure","Proposed model achieved 89.91% and 84.92% in terms of F1-score and MCC measure respectively","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on two datasets: dataset 1 and dataset 2)","Not explicitly stated","A novel framework of skin cancer detection using Yolo-Unet++ segmentation model with adaptive deep learning-based classification"
"Cycle-Consistent Simplicial Adversarial Attention Adaptation Networks (Cy-CSAAANets) optimized by Banyan Tree Growth Optimization (BTGO)","Yes, melanoma skin cancer detection and classification","Adaptation","No, single models used for each task","Melanoma skin cancer detection and classification using Cy-CSAAANets + BTGO approach","Yes, feature extraction using Modified ResNet-152 (MResNet-152) network","Melanoma","Four datasets: ISIC2018, ISIC2019, ISIC2020, and HAM10000","Not specified in the text but mentioned as 'large number of images' used for training and testing Cy-CSAAANets model","No (class imbalance not explicitly stated)","Yes, noise reduction using Window-Aware Guided Image Filtering (WGIF) method","Quantitative measures: accuracy, precision, recall on four datasets","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for melanoma detection and classification","Quantitative measures: accuracy, precision, recall on four datasets","Cy-CSAAANets + BTGO approach achieved 99.2 % accuracy, 97.8 % precision, and 99.1 % recall on ISIC2018 dataset","Yes, proposed method beats existing current state-of-the-art methods for melanoma detection and classification","No (tested on four datasets: ISIC2018, ISIC2019, ISIC2020, and HAM10000)","Not explicitly stated","Melanoma skin cancer detection and classification using cycle-consistent simplicial adversarial attention adaptation networks with banyan tree growth optimization in medical image processing"
"Multi-resolution vision transformer model","Yes, skin cancer subtype classification using whole slide images (WSIs)","Adaptation","No, single models used for each task","Automated classification of subtypes of melanoma and non-melanoma skin cancer from WSIs","Yes, deep features extracted by vision transformer (ViT)-based model at multiple resolutions (10x, 20x, 40x, 400x)","Melanoma and non-melanoma skin cancers: basal cell carcinoma (BCC), squamous cell carcinoma (SCC), intraepidermal carcinoma (IEC), Melanoma, Naevi, Non-cancerous tissue","NMSCS and Heidelberg datasets (~1.13 million histological patches)","~5,147 slides from ~4,066 patients used for external validation","No (class imbalance not explicitly stated)","Yes, normalization using Macenko method prior to training model","Classification metrics: κ score with 95% confidence interval (CI), quadratic weighted Cohen's Kappa (κ) score","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin cancer classification and detection","Classification metrics: κ score with 95% CI, quadratic weighted Cohen's Kappa (κ) score","Multi-resolution model achieved an overall κ score of 0.859 on the validation set and 0.898 on the testing set for melanoma classification","Yes, comparison with state-of-the-art methods demonstrated superior performance by proposed multi-resolution model","No (tested on NMSCS and Heidelberg datasets)","Not explicitly stated","Multi-resolution vision transformer model for histopathological skin cancer subtype classification using whole slide images"
"Machine learning approach using various classification models","Yes, automated classification of skin diseases (morphea and lichen sclerosus)","Adaptation","No, single models used for each task","Automated classification of skin diseases using microscopic images: a machine learning approach","Yes, feature extraction performed using Gray-Level Co-occurrence Matrix (GLCM) and histogram-based statistical methods","Morphea and lichen sclerosus","Not specified in the text but mentioned as 'microscopic images' used for training and testing machine learning models","0","No (class imbalance not explicitly stated)","Yes, image preprocessing techniques such as resizing, Reinhard normalization, Gaussian filtering, and CLAHE histogram equalization used to enhance image quality","Accuracy, precision, recall, F1 score, with hyperparameter optimization via grid search","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin disease classification and diagnosis","Accuracy, precision, recall, F1 score","RF and K-NN models yielded a 100% in all performance metrics (accuracy, sensitivity, recall, and F1-score) using the combined feature set (GLCM + Histogram)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on microscopic images dataset for morphea and lichen sclerosus)","Not explicitly stated","Automated Classification of Skin Diseases Using Microscopic Images: A Machine Learning Approach"
"Fine-tuned ConvNeXt Models (ConvNeXtSmall and ConvNeXtBase) with Adafactor optimization technique","Yes, monkeypox disease classification","Adaptation","No, single models used for each task","Explainable clinical diagnosis through unexploited yet optimized fine-tuned ConvNeXt Models for accurate monkeypox disease classification","Yes, deep features extracted by pre-trained ConvNeXt Models and fine-tuned for monkeypox disease classification","Monkeypox","MSLD (binary class) dataset and MSLD v2.0 (multi-class) dataset","Not specified in the text but mentioned as 'large number of images' used for training and testing ConvNeXt Models","No (class imbalance not explicitly stated)","Yes, pre-processing methods assessed and adjusted with regard to computing time and performance","Quantitative measures: accuracy, recall, F1 score, precision, multiple statistical tests incorporated with explainable AI methods for better interpretability of results","Yes, transfer learning technique used to fine-tune pre-trained ConvNeXt Models","Yes, data augmentation methods assessed and adjusted with regard to computing time and performance","No (compared with state-of-the-art models for monkeypox disease classification)","Quantitative measures: accuracy, recall, F1 score, precision, multiple statistical tests incorporated with explainable AI methods for better interpretability of results","Fine-tuned TL-based ConvNeXtSmall and ConvNeXtBase architecture achieved accurate results of 99.9 % on the benchmark MSLD (binary class) dataset and 94 % on the MSLD v2.0 (multi-class) dataset for monkeypox disease classification","Yes, comparison with state-of-the-art models demonstrated the superiority of proposed framework as a substitute for current ones","No (tested on MSLD and MSLD v2.0 datasets)","Not explicitly stated","Explainable clinical diagnosis through unexploited yet optimized fine-tuned ConvNeXt Models for accurate monkeypox disease classification"
"LBO-MPAM: Ladybug Beetle Optimization-based multilayer perceptron attention module","Yes, skin lesion segmentation and automatic localization","Adaptation","No, single models used for each task","Automated detection and classification of skin cancer using dermoscopic images","Yes, deep features extracted by LBO-DAM 1-D CNN with attention modules (ULSAM and MLPAM)","Skin cancer","ISIC2020, HAM10000, melanoma detection dataset","Not specified in the text but mentioned as 'large number of images' used for training and testing LBO-MPAM model","No (class imbalance not explicitly stated)","Yes, dermoscopic image preprocessing included in proposed method","Quantitative measures: accuracy, precision, sensitivity, F1-score","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with existing methods such as IMFO-KELM, Mask RCNN, M-SVM, DCNN-9, and TL-CNN","Quantitative measures: accuracy, precision, sensitivity, F1-score","LBO-MPAM achieved classification performance of 97.02% on ISIC2020 dataset with metrics: accuracy (97.03%), precision (97.05%), sensitivity (97.58%), and F1-score (97.27%) for a total of 500 epochs","Yes, proposed method outperformed existing methods such as IMFO-KELM, Mask RCNN, M-SVM, DCNN-9, and TL-CNN on ISIC2020 dataset","No (tested only on ISIC2020 dataset)","Not explicitly stated","LBO-MPAM: Ladybug Beetle Optimization-based multilayer perceptron attention module for segmenting the skin lesion and automatic localization"
"Novel vision transformer model","Yes, monkeypox disease detection and classification","Adaptation","No, single models used for each task","Automated diagnosis of monkeypox disease using a novel vision transformer model with data augmentation techniques","Yes, deep features extracted by vision transformer model for feature extraction and classification","Monkeypox (viral disease)","Public benchmark dataset comprising skin lesions of different ages and genders","Not specified in the text but mentioned as 'large number of images' used for training and testing vision transformer model","No (class imbalance not explicitly stated)","Yes, data augmentation techniques included rotation, scaling, and flipping to enhance density of training dataset","Quantitative measures: accuracy, precision, recall, F1 score for binary and multi-class classification","Not applicable","Yes, combination of data augmentation techniques (rotation, scaling, flipping) used to enhance generalization of ML models","Yes, comparison with traditional ML and deep learning techniques for monkeypox classification","Quantitative measures: accuracy, precision, recall, F1 score for binary and multi-class classification","Proposed model achieved an accuracy of 97.63% for binary class classification and 90.61% for multi-class classification with monkeypox classes (measles, normal, HFMD, cowpox, chickenpox)","Yes, proposed approach outperformed traditional ML and deep learning techniques","No (tested on public benchmark dataset comprising skin lesions of different ages and genders)","Not explicitly stated","Novel vision transformer and data augmentation technique for efficient detection of monkeypox disease"
"Parallel cropping method integrated with Chan-Vese model and U-Net","Yes, liver segmentation and volume assessment (also tested on skin, lungs, vessels)","Adaptation","No, single models used for each task","Explainable liver segmentation and volume assessment using parallel cropping method","Yes, voxel-level features extracted by parallel cropping method for liver segmentation","Not applicable (liver disease)","LiTS dataset","Not specified in the text but mentioned as 'large number of images' used for training and testing U-Net model","No (class imbalance not explicitly stated)","Yes, parallel cropping method included in proposed pre-processing step","Quantitative measures: dice score, accuracy, precision, recall, F1-score","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for liver segmentation and volume assessment","Quantitative measures: dice score, accuracy, precision, recall, F1-score","U-Net model achieved post-processed dice score of 0.956 after integration with parallel cropping method","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method in terms of speed and accuracy","No (tested on LiTS dataset)","Not explicitly stated","Explainable Liver Segmentation and Volume Assessment Using Parallel Cropping"
"Weighted ensemble of transfer learning with test time augmentation","Yes, categorical classification of skin cancer","Adaptation","Yes, weighted average of multiple models (MobileNet, EfficientNetV2B2, Xception, ResNext101, DenseNet201)","Skin cancer detection and classification into seven categories using dermoscopy images","Yes, deep features extracted by transfer learning models for skin lesion classification","Multiple types of skin lesions: actinic keratoses, basal cell carcinoma, benign keratosis, dermatofibroma, melanocytic nevi, melanoma, vascular skin lesions","HAM10000 dataset (10,015 publicly available dermoscopy images)","Not specified in the text but mentioned as 'large number of images' used for training and testing models","No (class imbalance not explicitly stated)","Yes, image augmentation techniques used to increase size of dataset","Stratified 10-fold cross-validation with annealing learning rate scheduler and test time augmentation","Yes, five transfer learning models used as basis for ensemble: MobileNet, EfficientNetV2B2, Xception, ResNext101, DenseNet201","Yes, image augmentation techniques (e.g. rotation, flipping) used to increase size of dataset","No (compared with state-of-the-art models for skin cancer classification)","Accuracy, F1-score, recall, precision","Proposed technique attained 94.49% accuracy on HAM10000 dataset","Yes, results suggest that proposed strategy can improve accuracy of skin cancer classification compared to state-of-the-art models","No (tested only on HAM10000 dataset)","Not explicitly stated","Categorical classification of skin cancer using a weighted ensemble of transfer learning with test time augmentation"
"Fractional Gannet Humming Optimization_Deep Convolutional Neural Network (FGHO_DeepCNN)","Yes, skin cancer detection and segmentation","Adaptation","No, single models used for each task","Automated skin cancer detection using deep learning technique with Fractional Gannet Humming Optimization (FGHO)","Yes, significant features extracted by DeepCNN: Completed Local Binary Pattern (CLBP), Gray Level Co-occurrence Matrix (GLCM), Local Vector Pattern (LVP), Significant Local Binary Pattern (SLBP) and CNN features","Skin cancer","Not specified in the text but mentioned as 'dataset 1', 'dataset 2' and 'dataset 3'","Not specified in the text but mentioned as 'large number of images' used for training and testing FGHO_DeepCNN model","No (class imbalance not explicitly stated)","Yes, bilateral filter applied to input skin cancer image","Quantitative measures: Positive Predictive Value (PPV), Negative Predictive Value (NPV), True Positive Rate (TPR), and True Negative Rate (TNR) accuracy","Not applicable","Yes, image augmentation done using geometric and colour space transformation to enlarge segmented images","Yes, comparison with other techniques demonstrated the superiority of proposed FGHO_DeepCNN approach","Quantitative measures: PPV, NPV, TPR, TNR accuracy","FGHO_DeepCNN achieved excellent performance for dataset 1 (PPV = 89.80 %, NPV = 89.40 %, TPR = 94.50 %, and TNR = 94.00 %) and dataset 2 (PPV = 91.68 %, NPV = 88.46 %, TPR = 91.68 %, TNR = 91.23 %)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed FGHO_DeepCNN approach","No (tested on dataset 1, dataset 2 and dataset 3)","Not explicitly stated","Fractional gannet humming optimization enabled deep convolutional neural network for detection and segmentation of skin cancer"
"Enhanced harmonic densely connected hybrid transformer network (HarDNet) with multi-colour space tensor merging","Yes, chronic wound segmentation for darker skin tones","Adaptation","No, single model used for each task","Chronic wound segmentation using deep learning with focus on darker skin tones","Yes, enhanced feature extraction through contrast-eliminating component and multi-colour space tensor merging","Not applicable (chronic wounds)","Wound images from light-skinned patients for training, two test sets with darker skinned cases: one with ground truth and one without","Not specified in the text but mentioned as 'large number of images' used for training and testing HarDNet model","No (class imbalance not explicitly stated)","Yes, skin refinement step included in proposed method","Quantitative measures: Dice similarity coefficient (DSC), intersection over union (IoU) for chronic wound segmentation","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with baseline results and improvements demonstrated in terms of DSC (+0.1221) and IoU (+0.1270)","Quantitative measures: Dice similarity coefficient (DSC), intersection over union (IoU)","Proposed model achieved improved results for chronic wound segmentation on darker skin tones, with DSC=0.7610 and IoU=0.6620","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method in terms of accuracy and expert ratings","No (tested on two test sets: one with ground truth and one without)","Not explicitly stated","An enhanced harmonic densely connected hybrid transformer network architecture for chronic wound segmentation utilising multi-colour space tensor merging"
"Not applicable (comprehensive review of existing research)","Yes, skin cancer detection","Adaptation","No, separate reviews for traditional machine learning and deep learning methodologies","Comprehensive review of non-invasive techniques for precise cancer detection using AI","Yes, various features extracted by different methods (not specified)","Multiple types: lung, prostate, brain, skin, breast, leukemia, and colorectal cancer","Not specified in the text but mentioned as 'public databases' used for evaluation","Not specified in the text (evaluation metrics only)","No (class imbalance not explicitly stated)","Yes, preprocessing steps included in various methods reviewed","Evaluation metrics: performance (>99%), limited performance (<85%); key findings and challenges for each cancer type and methodology","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with traditional machine learning methods using deep learning methodologies","Performance (>99%), limited performance (<85%); key findings and challenges for each cancer type and methodology","Not specified (comprehensive review of existing research)","Yes, comparison with state-of-the-art methods demonstrated the superiority of deep learning methodologies in some cases","No (tested on various public databases for each cancer type and methodology)","Not explicitly stated","Transformative Advances in AI for Precise Cancer Detection: A Comprehensive Review of Non-Invasive Techniques"
"PMFSNet: Polarized multi-scale feature self-attention network","Yes, skin lesions dermoscopy (ISIC 2018) segmentation","Adaptation","No, single model used for each task","Lightweight medical image segmentation with balanced global and local feature processing","Yes, multi-scale feature enhancement module based on attention mechanisms captures long-term dependencies","Skin lesions (melanoma)","ISIC 2018 dataset for skin lesion dermoscopy segmentation","Not specified in the text but mentioned as 'large number of images' used for training and testing PMFSNet model","No (class imbalance not explicitly stated)","Yes, hierarchical structure simplifies image preprocessing step","Quantitative measures: IoU, DSC, accuracy","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for medical image segmentation and detection","Quantitative measures: IoU, DSC, accuracy","PMFSNet achieved superior performance in various segmentation tasks on different data scales even with fewer than a million parameters (IoU of 84.68%, 82.02%, 78.82%, and 76.48% on public datasets)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on ISIC 2018 dataset for skin lesion dermoscopy segmentation)","Not explicitly stated","PMFSNet: Polarized multi-scale feature self-attention network for lightweight medical image segmentation"
"UNet-Based Transfer Learning Model with Auto Encoders and binary cascade Convolutional Neural Networks (CNNs)","Yes, skin cancer segmentation and classification","Adaptation","Yes, combines UNet architecture with Auto Encoders for robust skin cancer segmentation and binary cascade CNNs for classification","Accurate and efficient segmentation and classification of skin cancer using transfer learning model","Yes, deep features extracted by UNet and Auto Encoders for image reconstruction and feature extraction","Melanoma and basal cell carcinoma","ISIC, HAM10000, PH2 Dataset, and Dermofit Image Libraries (multiple datasets used)","Not specified in the text but mentioned as 'large number of images' used for training and testing model","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed method to prepare data for segmentation and classification tasks","Quantitative measures: precision, accuracy, recall, Peak Signal-to-Noise Ratio (PSNR) greater than 42dB","Yes, transfer learning used with UNet architecture as pre-trained model","No (not mentioned as part of the proposed method)","Yes, comparison with current methods demonstrated superior performance of proposed model in terms of precision, accuracy, recall, and PSNR","Quantitative measures: precision, accuracy, recall, Peak Signal-to-Noise Ratio (PSNR) greater than 42dB","Proposed model achieved precision of 99.2%, accuracy of 98.3%, recall of 98.9% and PSNR greater than 42dB on multiple datasets","Yes, proposed model outperformed current methods in terms of precision, accuracy, recall, and PSNR","No (tested on ISIC, HAM10000, PH2 Dataset, and Dermofit Image Libraries)","Not explicitly stated","Design of an Efficient UNet-Based Transfer Learning Model for Enhancing Skin Cancer Segmentation and Classification Performance"
"YOLOv3tiny, YOLOv4tiny, YOLOv5s, YOLOv7tiny, and YOLOv8s with fusion strategy","Yes, skin cancer diagnosis (9 types)","Adaptation","Yes, fusion of predictions from multiple YOLO detectors based on confidence scores","Improved skin cancer diagnosis using a comprehensive framework incorporating compact versions of YOLO and Nvidia Jetson Nano for edge computing","Yes, deep features extracted by YOLOv3tiny, YOLOv4tiny, YOLOv5s, YOLOv7tiny, and YOLOv8s for skin cancer detection and classification","9 types of skin cancer: Actinic Keratosis, Basal Cell Carcinoma, Dermatofibroma, Melanoma, Nevus, Pigmented Benign Keratosis, Seborrheic Keratosis, Squamous Cell Carcinoma, and Vascular Lesion","ISIC datasets (not specified which specific dataset is used)","Not specified in the text but mentioned as 'large number of images' used for training and testing YOLO detectors","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed framework","Mean average precision (mAP@0.5) and precision metrics","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin cancer detection and classification","Mean average precision (mAP@0.5) and precision metrics","Fusion strategy improved overall detection accuracy from 91.5 % to 94.3 % in terms of mAP@0.5 and 89.6 % to 97.87 % in terms of precision","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on ISIC datasets)","Not explicitly stated","YOLOSkin: A fusion framework for improved skin cancer diagnosis using YOLO detectors on Nvidia Jetson Nano"
"Hypergraph Convolutional Neural Networks (HGCNs)","Yes, clinical diagnosis of monkeypox infections using skin virological images","Adaptation","No, single model used for each task","Automatic Mpoxv detection and classification in dermatological virological imaging","Yes, CNN components contribute robust feature extraction through relational modeling","Monkeypox virus (Mpoxv)","Not specified in the text but mentioned as 'freely available online'","Not specified in the text but implied to be a large number of images used for training and testing HGCNs model","No (class imbalance not explicitly stated)","Yes, low-resolution data handled through hypergraph modeling","Quantitative measures: accuracy, precision, recall, F1 Score, specificity, Micro AUC","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with conventional deep learning models for Mpoxv detection and classification","Quantitative measures: accuracy, precision, recall, F1 Score, specificity, Micro AUC","HGCNs achieved high accuracy (0.9888) and interpretable diagnostics for Mpoxv infections using Grad-CAM localization of infected regions within images","Yes, proposed model demonstrated effectiveness as a powerful tool in computational virology delivering high accuracy and interpretable diagnostics","No (tested on a single dataset not specified)","Not explicitly stated","Hypergraph convolutional neural networks for clinical diagnosis of monkeypox infections using skin virological images"
"SLCDI-DGCRIN-RBBMOA (Skin Lesions Classification in Dermoscopic Images using Optimized Dynamic Graph Convolutional Recurrent Imputation Network)","Yes, skin lesion classification","Adaptation","No, single models used for each task","Early and accurate classification of skin lesions in dermoscopic images using optimized dynamic graph convolutional recurrent imputation network (DGCRIN)","Yes, deep features extracted by Hybrid Dual Attention-guided Efficient Transformer and UNet 3+ (HDAETUNet3+) for segmentation","Multiple types of skin lesions: actinic keratosis, dermatofibroma, basal cell carcinoma, squamous cell carcinoma, benign keratosis, vascular lesion, melanocytic nevus, and melanoma","ISIC-2019 skin disease dataset (not specified in the text but mentioned as 'dataset' for training and testing)","Not specified in the text but mentioned as 'large number of images' used for training and testing DGCRIN model","No (class imbalance not explicitly stated)","Yes, pre-processing step included using Confidence Partitioning Sampling Filtering (CPSF) to remove noise, resize, and enhance image quality","Quantitative measures: accuracy, precision, recall, specificity","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with existing methods such as DNN-EAI-SLC, MSLC-CNN-OIF, and CSC-DI-DCNN for skin lesion classification","Quantitative measures: accuracy, precision, recall, specificity","Proposed SLCDI-DGCRIN-RBBMOA technique attains higher accuracy (26.36%), precision (20.69%), and specificity (30.29%) compared with existing methods","Yes, comparison demonstrated the superiority of proposed method over state-of-the-art methods for skin lesion classification","No (tested on ISIC-2019 dataset)","Not explicitly stated","Optimized Dynamic Graph-Based Framework for Skin Lesion Classification in Dermoscopic Images"
"Ensemble Pretrained Deep Learning Model (VGG16, NASNetMobile, and ResNet50V2)","Yes, melanoma skin cancer image classification","Adaptation","No, single models used for each task with ensemble learning and hard voting techniques","Design an Ensemble Pretrained Deep Learning Model for Classification of Melanoma Skin Cancer Images","Yes, deep features extracted by VGG16, NASNetMobile, and ResNet50V2 models","Melanoma skin cancer","Not specified in the text but mentioned as 'skin cancer dataset'","Not specified in the text but implied to be a large number of images used for training and testing","No (class imbalance not explicitly stated)","Yes, preprocessing steps included in proposed method","Accuracy on test portion of dataset: 91.5%","Yes, pretrained models fine-tuned for current task","No (not mentioned as part of the proposed method)","Not explicitly stated but implied to be compared with state-of-the-art methods","Accuracy on test portion of dataset: 91.5%","Ensemble model achieved accuracy of 91.5% on skin cancer dataset","Yes, ensemble model demonstrated improved diagnostic performance compared to state-of-the-art methods","No (tested on a single 'skin cancer dataset')","Not explicitly stated","Design an Ensemble Pretrained Deep Learning Model for Classification of Melanoma Skin Cancer Images"
"Dual-stage deep learning framework: U-Net with VGG16 encoder for segmentation and EfficientFormer/SwiftFormer networks for classification","Yes, skin lesion analysis (segmentation and classification)","Adaptation","No, single models used for each task","Early and accurate detection of malignant skin lesions using deep learning framework","Yes, U-Net with VGG16 encoder extracts features for segmentation","Skin cancer (malignant skin lesions)","HAM10000, ISIC 2018, and SLICE-3D datasets","10,000 training images in HAM10000 dataset","Yes, balanced data used for evaluation on HAM10000 dataset","No (not mentioned as part of the proposed method)","Quantitative measures: accuracy, F1-score, sensitivity, specificity, Jaccard index, Dice similarity coefficient","Not applicable","Yes, image augmentation techniques used to improve model performance","Yes, comparison with state-of-the-art methods for skin lesion segmentation and classification","Quantitative measures: accuracy, F1-score, sensitivity, specificity, Jaccard index, Dice similarity coefficient","EfficientFormerV2 achieved 97.11% accuracy on balanced HAM10000 dataset","Yes, proposed method demonstrated competitive performance in a highly imbalanced and clinically realistic setting","No (tested on three benchmark datasets: HAM10000, ISIC 2018, and SLICE-3D)","Not explicitly stated","Dual-stage segmentation and classification framework for skin lesion analysis using deep neural network"
"Egret Search Golden (ESG) optimization tuned distributed pooling-based BiLSTM model","Yes, melanoma detection and segmentation","Adaptation","No, single models used for each task","Early detection of melanoma using a novel deep learning approach","Yes, features extracted from Gray Level Co-occurrence Matrix and hybrid structural features","Melanoma","Not specified in the text but mentioned as 'Melanoma Skin Cancer Dataset'","Not specified in the text but mentioned as a large number of images used for training and testing model","No (class imbalance not explicitly stated)","Yes, adaptive optimized Otsu thresholding process included to segment melanoma lesions accurately from background","Quantitative measures: accuracy, sensitivity, specificity, TP values","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for melanoma detection and segmentation","Quantitative measures: accuracy, sensitivity, specificity, TP values","Model yielded impressive results on Melanoma Skin Cancer Dataset: accuracy (96.13%), sensitivity (96.06%), specificity (96.10%)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested only on Melanoma Skin Cancer Dataset)","Not explicitly stated","Melanoma Detection Using Egret Search Golden Optimization Tuned Distributed Pooling-Based Fused Deep BiLSTM Model"
"D2U-Net: a dual-path hybrid UNet architecture","Yes, skin lesion segmentation (ISIC2018 and PH2 datasets)","Adaptation","No, single models used for each task","Precise medical image segmentation using D2U-Net architecture","Yes, dual encoder-decoder paths capture both global and local features through deeper hierarchical interactions","Skin cancer (lesions)","ISIC2018, PH2 datasets for skin lesion segmentation; polyp dataset; brain tumor dataset","Not specified in the text but mentioned as 'large number of images' used for training and testing D2U-Net model","No (class imbalance not explicitly stated)","Yes, Contextual-Spectral Fusion Module (CSFM) facilitates information fusion and enhancement across multiple stages and paths","Quantitative measures: IoU, Dice coefficient","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art approaches for medical image segmentation tasks","Quantitative measures: IoU, Dice coefficient","D2U-Net achieved an average IoU of 90.5% and a Dice coefficient of 95.0% on the ISIC2018 dataset; IoU of 84.0% and a Dice coefficient of 91.2% on the PH2 dataset; average IoU of 96.15% and a Dice coefficient of 97.95% on the polyp dataset","Yes, proposed approach consistently superior to state-of-the-art approaches for medical image segmentation tasks","No (tested on ISIC2018, PH2 datasets; polyp dataset; brain tumor dataset)","Not explicitly stated","D2U-Net: a dual-path hybrid UNet architecture for precise medical image segmentation"
"MSMF-Net: Multi-Scale Feature Fusion Skin Lesion Segmentation Network","Yes, skin lesion segmentation","Adaptation (U-shaped network)","Yes, multi-scale and attention parallel module (MS-AM), attention bridging module (ABM) and decoding fusion module (DFM) used for feature fusion and information integration","Effective skin lesion segmentation using deep learning techniques","Yes, EFM module fuses features from different encoding stages and MS-AM introduces high-level semantic features at bottleneck of network","Not specified (generalized to all types of skin lesions)","Two public datasets (not specified which ones)","Not specified in the text but mentioned as 'large number of images' used for training and testing MSMF-Net model","No (class imbalance not explicitly stated)","Yes, preprocessing steps included in proposed method to enhance image quality and reduce noise","Quantitative measures: accuracy, precision, recall, F1-score, IoU, Dice coefficient","Not applicable (pre-trained models not used)","Yes, data augmentation techniques applied to increase size of training dataset and improve model robustness","Yes, comparison with state-of-the-art methods on two public datasets demonstrated the superiority of proposed method","Quantitative measures: accuracy, precision, recall, F1-score, IoU, Dice coefficient","MSMF-Net achieved best results compared to other state-of-the-art methods on two public datasets","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested only on two public datasets)","Not explicitly stated","A Multi-Location Enhanced Multi-Scale Feature Fusion Skin Lesion Segmentation Network Based on U-shaped Network"
"Two-fold-deep-learning-classifier framework using optimized mask R-CNN and Fully Convolutional Neural Networks (FCNs) + Multi-Layer Perception (MLP)","Yes, skin cancer detection","Adaptation","No, single models used for each task","Innovative two-fold deep learning based skin cancer detection model","Yes, texture features (II-BGP, LBP, GLCM), color feature (Color Correlogram and Histogram Intersection) and shape feature (Moments, Area, Perimeter, Eccentricity, Average bending energy) extracted using optimized mask R-CNN","Skin cancer","Not specified in the text but mentioned as 'collected raw image'","Not specified in the text but mentioned as 'large number of images' used for training and testing model","No (class imbalance not explicitly stated)","Yes, Min–max contrast stretching and median filtering applied to pre-process raw image","Quantitative measures: accuracy, sensitivity, precision, FPR, FNR","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin cancer detection and classification","Quantitative measures: accuracy, sensitivity, precision, FPR, FNR","Proposed model achieved a 92% detection accuracy rating, which is the highest among current models","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on 'collected raw image' dataset)","Not explicitly stated","Skin cancer detection using optimized mask R-CNN and two-fold-deep-learning-classifier framework"
"Not applicable (conference proceedings)","Yes, various skin-related tasks such as lesion diagnosis, segmentation, and analysis","Adaptation","No, multiple papers presented with different approaches","Various objectives including skin imaging collaboration, interpretability of machine intelligence in medical image computing, embodied AI and robotics for healthcare, and distributed learning","Yes, various feature extraction techniques used such as diffusion-based augmentation, attention maps, and uncertainty exploration","Not specified (various types including skin lesions)","Not applicable (conference proceedings with multiple papers using different datasets)","Not specified (multiple papers use different numbers of images)","No (class imbalance not explicitly stated for all papers)","Yes, various preprocessing techniques used such as Gaussian splatting and action graphs","Various validation metrics including accuracy, precision, recall, F1 score, and dice coefficient","Not applicable (multiple papers use different approaches to transfer learning)","Yes, various data augmentation techniques used such as diffusion-based augmentation and attention maps","No (each paper presents a new approach without comparison with baselines)","Various evaluation metrics including accuracy, precision, recall, F1 score, dice coefficient, and Jaccard index","Not applicable (multiple papers present different results)","No (each paper presents a new approach without comparison with state-of-the-art methods)","Yes, multiple papers use different datasets for evaluation and testing","Not explicitly stated","9th International Skin Imaging Collaboration Workshop, ISIC 2024, 7th International Workshop on Interpretability of Machine Intelligence in Medical Image Computing, iMIMIC 2024, Embodied AI and Robotics for HealTHcare Workshop, EARTH 2024 and 5th MICCAI Workshop on Distributed, Collaborative and Federated Learning, DeCaF 2024 held at 27th International conference on Medical Image Computing and Computer Assisted Intervention, MICCAI 2024"
"Pre-trained models: DenseNet169 and VGG16","Yes, skin cancer classification using dermoscopic images","Adaptation","No, single pre-trained models used for each task","Explainable Pre-Trained Models for Skin Cancer Classification","Yes, deep features extracted by DenseNet169 and VGG16 for skin cancer classification","Skin cancers (not specified which type)","Not specified in the text but mentioned as 'dermoscopic images'","Not specified in the text but implied to be a large number of images used for training and testing pre-trained models","No (class imbalance not explicitly stated)","Yes, preprocessing step included as part of dermoscopic image analysis","Quantitative measures: accuracy, key performance metrics (not specified which ones)","Yes, pre-trained models used for skin cancer classification task","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin cancer classification and detection","Quantitative measures: accuracy, key performance metrics (not specified which ones), explainability techniques used to enhance model interpretability","DenseNet169 achieved the highest accuracy of 90.61% while VGG16 achieved an accuracy of 84.24%","Yes, comparison with state-of-the-art methods demonstrated the effectiveness and performance of proposed pre-trained models","No (tested on dermoscopic images but not specified which dataset)","Not explicitly stated","Explainable Pre-Trained Models for Skin Cancer Classification"
"TlED-Net: triple-loop encoder-decoder architecture with dense skip connections","Yes, semantic segmentation for medical images (skin lesions and lung)","Adaptation","No, single model used for each task","Optimizing semantic segmentation via triple-loop encoder-decoder architecture with dense skip connections","Yes, deep features extracted by TlED-Net using DASPP and channel space mixed attention modules","Skin lesions (melanoma) and lung cancer","Six medical datasets: LUNG dataset and skin lesion dataset (not specified which ones)","Not specified in the text but mentioned as 'large number of images' used for training and testing TlED-Net model","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed method","Dice coefficients: up to 97.145% on LUNG dataset and 93.176% on skin lesion dataset","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with 17 state-of-the-art models demonstrated TlED-Net's superiority in semantic segmentation tasks","Dice coefficients: up to 97.145% on LUNG dataset and 93.176% on skin lesion dataset","TlED-Net achieved Dice coefficient of up to 97.145% on LUNG dataset and 93.176% on skin lesion dataset","Yes, comparison with state-of-the-art models demonstrated TlED-Net's superiority in semantic segmentation tasks","No (tested on six medical datasets)","Not explicitly stated","TlED-Net: optimizing semantic segmentation via triple-loop encoder-decoder architecture with dense skip connections"
"Hybrid deep learning architecture combining CNNs and transformers","No, various clinical situations including Alzheimer’s disease, cardiovascular disorders, skin conditions","Adaptation","Yes, combines multiple techniques: data augmentation, transfer learning, explainable AI, real-time processing, multimodal data fusion","Enhance accuracy, efficiency, and transparency of diagnostic strategies using computer vision techniques for disease detection in medical images","Yes, deep features extracted by CNNs and transformers for spatial feature extraction and long-range dependencies capture","Various clinical situations including Alzheimer’s disease, cardiovascular disorders, skin conditions (not specifically mentioned as cancer)","Diverse scientific datasets: X-rays, MRIs, CT scans, ECGs, fundus images (no specific dataset name mentioned)","Not specified in the text but mentioned as 'large number of medical images' used for training and testing","No (class imbalance not explicitly stated)","Yes, advanced preprocessing techniques applied to ensure high-quality input data","Quantitative measures: diagnostic accuracy, performance metrics (not specified in the text)","Yes, leveraging pre-trained models and fine-tuning them on specific medical datasets","Yes, information augmentation strategies applied to mitigate dataset scarcity by creating synthetic images using GANs","No (compared with state-of-the-art techniques for disease detection in medical images)","Quantitative measures: diagnostic accuracy, performance metrics (not specified in the text)","Hybrid deep learning architecture achieved extensive enhancements in diagnostic accuracy and performance","Yes, comparison with state-of-the-art techniques demonstrated superiority of proposed method","No (tested on diverse scientific datasets but no specific dataset name mentioned)","Not explicitly stated","Computer Vision for Disease Detection - An Overview of How Computer Vision Techniques Can Be Used to Detect Diseases in Medical Images, Such as X-Rays and MRIs"
"Machine learning and computer vision models for detecting, segmenting, and quantifying scale loss in fish","Yes, skin condition analysis of fish","Adaptation","No, single models used for each task (fish detection, skin segmentation, scale segmentation)","Quantification and improvement of fish welfare in salmon farming through image-based analysis","Yes, deep features extracted by machine learning models for detecting and segmenting scales loss","None mentioned (fish health indicator)","Specialized dataset created for this study (not specified as public or private)","Not specified in the text but mentioned as 'large number of images' used for training and testing models","No (class imbalance not explicitly stated)","Yes, image processing steps included in proposed method (e.g. object detection, instance segmentation)","Quantitative measures: mean average precision (mAP), frames per second (FPS), F1 score","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art models for fish detection and segmentation tasks","Quantitative measures: mAP, FPS, F1 score","Machine learning models achieved high accuracy in detecting (mAP50-95 of 87.5%), segmenting skin (98.0% with 24.15 FPS), and scale loss segmentation (F1 score of 76.3%)","Yes, comparison demonstrated the effectiveness of proposed method for quantifying scale loss in fish","No (tested on controlled setup above water)","Models not immediately applicable to real-world underwater images; requires fine-tuning with additional data","Image-based quantification of Scale Loss in Fish using Machine Learning and Computer Vision"
"EfficientNet-B1 with additional hidden and fully connected layers","Yes, melanoma detection","Adaptation","No, single model used for classification","Novel deep learning-based approach for early detection of melanoma using dermoscopic images","Yes, EfficientNet-B1 extracts features from skin lesion images","Melanoma","Not specified in the text but mentioned as 'dermatoscopic images'","Not specified in the text but implied to be a large dataset for training and testing","No (class imbalance not explicitly stated)","Yes, rotation range, zoom range, rescale applied to sharpen object edges and improve model performance","Quantitative measures: accuracy, precision, recall, F1-score using cross-validation with 10-folds","Not applicable","Yes, complete data provided to models for improved results","Yes, comparison with Res-Net and Dense-Net reported in the text (81% and 82% accuracy respectively)","Quantitative measures: accuracy, precision, recall, F1-score using cross-validation with 10-folds","86% accuracy achieved by proposed model on dermoscopic images for melanoma detection","Yes, comparison with state-of-the-art models (Res-Net and Dense-Net) demonstrated the superiority of proposed method","No (tested on a dataset not specified in the text)","Not explicitly stated","A Novel Deep Learning Based Melanoma Detection Technique Using Skin Lesion"
"PCNN-LinkNet model trained with monotonic and deep feature set","Yes, skin cancer classification","Adaptation","No, single models used for each task","Automated skin cancer classification using customized batch normalization-assisted parallel convolutional neural network (CBNPC-SCC)","Yes, various features extracted: local Gabor transitional pattern (LGTrP), multi-texton (MTH) features, threshold-based smoother function in local monotonic pattern (TS-LMP), and deep features","Skin cancer","Not specified in the text but mentioned as 'large number of images' used for training and testing CBNPC-SCC model","Not specified in the text but mentioned as 'large number of images' used for training and testing CBNPC-SCC model","No (class imbalance not explicitly stated)","Yes, new pixel estimation-based Wiener filter (NPE-WF) approach employed for preprocessing input image","Quantitative measures: accuracy, F-measure, specificity","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with traditional methods for skin cancer classification and detection","Quantitative measures: accuracy, F-measure, specificity","CBNPC-SCC model achieved a higher accuracy of 0.975, F-measure of 0.914, and specificity of 0.986","Yes, proposed method demonstrated superiority over state-of-the-art methods for skin cancer classification","No (tested on a single dataset)","Not explicitly stated","Skin Cancer Classification Using PCNN-LinkNet Model Trained with Monotonic and Deep Feature Set"
"IP-MSCD-RICCNN (Image Processing for detecting Melanoma Skin Cancer using an optimized Rotation-Invariant Coordinate Convolutional Neural Network)","Yes, melanoma skin cancer detection","Adaptation","No, single models used for each task","Automated Melanoma Skin Cancer Detection using IP-MSCD-RICCNN","Yes, GLCM features (Contrast, Correlation, Entropy, Inverse) extracted by Newton Time-Extracting Wavelet Transform (NTEWT)","Melanoma skin cancer","ISIC dataset","Not specified in the text but mentioned as 'large number of images' used for training and testing IP-MSCD-RICCNN model","No (class imbalance not explicitly stated)","Yes, pre-processing steps included: Gillijn De Moor Filter (GDMF) to remove noise, GIFCMC clustering for ROI segmentation","Quantitative measures: accuracy, precision, sensitivity","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with existing models: DI-SCD-DL-FKC, DI-SCD-CNN-TF, SCD-CD-DCNN","Quantitative measures: accuracy, precision, sensitivity","IP-MSCD-RICCNN achieved higher accuracy (26.36%), precision (32.85%), and sensitivity (16.57%) compared to existing models","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on ISIC dataset)","Not explicitly stated","IMAGE PROCESSING FOR DETECTING MELANOMA SKIN CANCER USING AN OPTIMIZED ROTATION-INVARIANT COORDINATE CONVOLUTIONAL NEURAL NETWORK"
"MixFormer: A Mixed CNN-Transformer Backbone for Medical Image Segmentation","Yes, medical image segmentation (SEG)","Adaptation","Yes, combines global and local information from Transformer and CNN architectures during the downsampling process","Enhance medical image segmentation using a mixed CNN-Transformer backbone","Yes, uses multiscale spatial-aware fusion (MSAF) module to capture interscale perspective and bridge semantic gap between encoding and decoding stages","Not specified in the text but mentioned as 'medical images' which can include skin cancer diagnosis","Various medical image datasets: Synapse, ACDC, ISIC 2018, Kvasir-SEG, CVC-ClinicDB","Not specified in the text but mentioned as 'large number of images' used for training and testing MixFormer model","No (class imbalance not explicitly stated)","Yes, CNN-based upsampling approach to recover low-level features included in proposed method","Quantitative measures: mean Dice similarity coefficient (DSC), mean Hausdorff distance (HD), intersection over union (IoU), accuracy, precision, recall, F1 score","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with mainstream segmentation networks such as CNNs and other Transformer-based structures demonstrated superior performance of MixFormer","Quantitative measures: mean Dice similarity coefficient (DSC), mean Hausdorff distance (HD), intersection over union (IoU), accuracy, precision, recall, F1 score","MixFormer achieved state-of-the-art results on various medical image datasets with a mean DSC of up to 91.01% and an mIoU of up to 0.841","Yes, demonstrated superior segmentation performance compared to most mainstream segmentation networks","Yes, tested on various medical image datasets including Synapse, ACDC, ISIC 2018, Kvasir-SEG, and CVC-ClinicDB","Not explicitly stated","MixFormer: A Mixed CNN-Transformer Backbone for Medical Image Segmentation"
"Deep learning algorithms (VGG-19, ResNet-50 v2, EfficientNetB1) for lung cancer histopathology classification","No, lung cancer diagnosis and classification","Adaptation","Yes, combination of deep learning algorithms used for image classification","Accurate categorization of lung cancer subtypes (adenocarcinoma, squamous cell carcinoma) using histopathology images","Yes, convolutional neural networks (CNNs) and pre-trained models used to extract features from histopathology images","Lung cancer (non-small cell carcinomas: adenocarcinoma, squamous cell carcinoma)","Not specified in the text but mentioned as 'histopathology slides' for training and testing deep learning models","Not specified in the text but mentioned as 'large number of images' used for training and testing deep learning models","No (class imbalance not explicitly stated)","Yes, image preprocessing steps included in proposed method to enhance accuracy","Quantitative measures: specificity, F-score, sensitivity, precision, accuracy","Yes, pre-trained models used for transfer learning and fine-tuning on lung cancer dataset","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods demonstrated improved performance using deep learning algorithms","Quantitative measures: specificity, F-score, sensitivity, precision, accuracy","Deep learning models achieved high accuracy and stability in lung cancer classification (adenocarcinoma, squamous cell carcinoma)","Yes, comparison with state-of-the-art methods demonstrated improved performance using deep learning algorithms","No (tested on histopathology slides of lung cancer patients)","Not explicitly stated","Deep Learning-Based Lung Cancer Histopathology Classification: Emphasizing Accuracy and Customisation"
"Class-aware cartilage bone segmentation network with geometry-constraint post-processing and dense skeleton graph-based non-rigid registration","No, US-CT registration in robotic intercostal ultrasound imaging","Adaptation","Yes, combines class-aware segmentation network with geometry-constraint post-processing and dense skeleton graph-based registration","Autonomous US-CT registration for robotic intercostal ultrasound imaging","Yes, deep features extracted by class-aware cartilage bone segmentation network for rib skeletons","Not applicable (focus on thoracic applications)","Five distinct CTs and two volunteer US data (ten pairs of CT-US combinations)","Not specified in the text but mentioned as 'large number of images' used for training and testing models","No (class imbalance not explicitly stated)","Yes, skin refinement step included in proposed method","Quantitative measures: Euclidean error, precision mapping performance","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with previous methods for US-CT registration and intercostal ultrasound imaging","Quantitative measures: Euclidean error, precision mapping performance","Proposed graph-based registration method can robustly and precisely map the path from CT template to individual patients (Euclidean error:2.21pm 1.11mm)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed approach","No (tested on five distinct CTs and two volunteer US data)","Not explicitly stated","Class-Aware Cartilage Segmentation for Autonomous US-CT Registration in Robotic Intercostal Ultrasound Imaging"
"Quantum Chebyshev Polynomials and Autoencoder with Long Short-Term Memory (LSTM)","Yes, skin lesion classification","Adaptation","No, single models used for each task","Efficient classification of skin lesions using an innovative automated system","Yes, features extracted using Quantum Chebyshev polynomials and refined by Autoencoder","Skin cancer (not specified which type)","ISIC2017 and HAM10000 datasets","Not specified in the text but mentioned as 'large number of images' used for training and testing model","No (class imbalance not explicitly stated)","Yes, wavelet transformations included in preprocessing step","Quantitative measures: accuracy, precision, recall, F1-score, specificity","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin lesion classification","Quantitative measures: accuracy, precision, recall, F1-score, specificity","Model achieved 99.58% accuracy on HAM10000 dataset and 98.87% accuracy on ISIC2017 dataset","Yes, proposed model surpasses current state-of-the-art in skin lesion classification","No (tested only on two datasets: ISIC2017 and HAM10000)","Not explicitly stated","Classification of Skin Lesion With Features Extraction Using Quantum Chebyshev Polynomials and Autoencoder From Wavelet-Transformed Images"
"Explainable Deep Learning Network","No, Breast Cancer Classification and Localization","Adaptation","Yes, combines deep learning network with class activation mapping for explainability","Automatic breast cancer screening using a deep learning network","Yes, deep features extracted by the proposed network for breast cancer detection and localization","Breast Cancer","Dataset composed of 9,016 images (not specified whether it's public or private)","Not specified in the text but mentioned as 'large number' used for training and testing the proposed network","No (class imbalance not explicitly stated)","Yes, preprocessing steps included in the proposed method to prepare images for analysis by deep learning network","Quantitative measures: accuracy, precision, recall, F1-score, AUC-ROC curve and class activation mapping algorithms","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for breast cancer detection and localization","Quantitative measures: accuracy, precision, recall, F1-score, AUC-ROC curve and class activation mapping algorithms","Proposed network achieved an accuracy of 93.5% on a dataset composed of 9,016 images for breast cancer detection and localization","Yes, comparison with state-of-the-art methods demonstrated the effectiveness of proposed method","No (tested only on one specific dataset)","Not explicitly stated","Explainable Deep Learning for Breast Cancer Classification and Localization"
"Automated morphometry using nuclear shape descriptors","Yes, distinguishing aggressive variants of squamous cell carcinoma from relatively benign skin proliferative lesions","Adaptation","No, single model used for each task","Automated estimation of degrees of dysplasia in non-melanoma skin cancer (NMSC)","Yes, nuclear shape descriptors extracted using automated morphometry","Squamous cell carcinoma and basal cell carcinoma","Not specified in the text but mentioned as a pilot study with limited number of samples","2500 nuclei per group used for analysis","No (class imbalance not explicitly stated)","Yes, thresholded images used to estimate quantitative parameters","Quantitative measures: circularity, aspect ratio, Feret diameters, multivariate analyses of composite parameters","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with locally occurring squamous cell carcinoma and basal cell carcinoma or benign skin lesions","Quantitative measures: circularity, aspect ratio, Feret diameters, multivariate analyses of composite parameters","Automated morphometry using nuclear shape descriptors may distinguish aggressive variants of squamous cell carcinoma from relatively benign skin proliferative lesions (p < 0.0001)","Yes, comparison with locally occurring squamous cell carcinoma and basal cell carcinoma or benign skin lesions","No (tested on a limited number of samples in a pilot study)","Not explicitly stated","Nuclear shape descriptors by automated morphometry may distinguish aggressive variants of squamous cell carcinoma from relatively benign skin proliferative lesions: a pilot study"
"Parametric finite element contact homogenisation procedure","Yes, skin friction behaviour analysis","Adaptation","No, single model used for each task","To study and quantify the effect of skin microstructure on macroscopic skin frictional response","Yes, microscopic surface topography and internal microstructure features extracted from image-based multilayer finite element models","Not applicable (skin health analysis)","Anatomically realistic two-dimensional image-based multilayer finite element model of human skin","Not specified in the text but mentioned as 'large number of images' used for training and testing models","No (class imbalance not explicitly stated)","Yes, image-based multilayer finite element model built from anatomically realistic two-dimensional skin surface topography data","Quantitative measures: macroscopic frictional response and deformation component of macroscopic friction","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with current analytical models of skin friction demonstrated limitations in accommodating complex geometry of skin microstructural constituents and nonlinear constitutive properties","Quantitative measures: macroscopic frictional response and deformation component of macroscopic friction","Results showed that the naturally complex geometry of the skin microstructure can significantly increase the deformation component of macroscopic friction, regardless of indenter size or specified local friction properties.","Yes, comparison with current analytical models demonstrated limitations and proposed methodology offered new level of mechanistic insight into plausible friction mechanisms associated with structural effects operating at microscopic scale","No (tested on anatomically realistic two-dimensional image-based multilayer finite element model)","Not explicitly stated","Skin Microstructure is a Key Contributor to Its Friction Behaviour"
"Not specified","Yes, skin cancer diagnosis and patient care","Not applicable","No","Responsible use of artificial intelligence (AI) in dermato-oncology for improved patient care","Not specified","Skin cancer","Not specified","Not specified","No (class imbalance not explicitly stated)","Good image quality required for successful use of AI and apps","Medicolegal situation, remuneration, patient care, and image quality","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with current state-of-the-art methods for skin cancer diagnosis using AI and apps","Patient care, image quality, medicolegal situation, remuneration","Responsible use of AI in dermato-oncology can improve patient care and optimize treatment outcomes","Yes, comparison with current state-of-the-art methods demonstrated the potential benefits of responsible AI use","No (tested on clinical images of skin cancer)","Medicolegal situation, remuneration, and image quality still problematic in AI use","Künstliche Intelligenz und Smartphone-Programm-Applikationen (Apps)"
"Convolutional neural networks (CNNs) and machine learning","Yes, skin cancer diagnosis using dermoscopic images of pigmented and unpigmented skin lesions","Adaptation","No, single models used for each task","Computer-assisted skin cancer diagnosis using AI-based assistance systems","Yes, deep features extracted by CNNs for image classification and feature extraction","Skin cancer (pigmented and unpigmented neoplasms)","Not specified in the text but mentioned as 'numerous studies' using machine learning algorithms","Not specified in the text but mentioned as 'large number of images' used for training and testing CNN models","No (class imbalance not explicitly stated)","Yes, dermoscopic images pre-processed using computer algorithms before classification by AI-based assistance systems","Quantitative measures: precision, accuracy, sensitivity, specificity","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with human dermatologists' performance using dermoscopic images for skin cancer diagnosis","Quantitative measures: precision, accuracy, sensitivity, specificity","AI-based assistance systems achieved comparable or even better results than human dermatologists in detecting pigmented and unpigmented neoplasms of the skin using dermoscopic images","Yes, comparison with state-of-the-art methods for computer-assisted diagnosis of skin cancer","No (tested on various datasets but not specified which ones)","Not explicitly stated","Computerassistierte Hautkrebsdiagnose"
"Deep-learning convolutional neuronal networks (CNNs)","Yes, skin cancer detection and diagnosis","Adaptation","No, single models used for each task","Automated image analysis using deep learning CNNs in dermatology","Yes, deep features extracted by CNNs for skin cancer detection and diagnosis","Skin neoplasms (skin cancer)","Publicly available databases of dermoscopic images (not specified which ones)","Not specified in the text but mentioned as 'large number' used for training CNNs","No (class imbalance not explicitly stated)","Yes, preprocessing and segmentation using handcrafted filters required for earlier systems","Clinical studies: dermatologist level diagnostic accuracy achieved by CNNs in skin cancer detection","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin cancer diagnosis and detection","Diagnostic accuracy: dermatologist level diagnostic accuracy achieved by CNNs in clinical studies","CNNs attained a dermatologist-level diagnostic accuracy in the detection of skin cancer (not specified which metrics were used)","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on publicly available databases of dermoscopic images not specified which ones)","Image artefacts: color markings and superimposed scales can impair diagnostic accuracy; AI-based systems intended as assistance, results should be carefully integrated into decision-making process by clinicians","Digitalisierte Bildverarbeitung: künstliche Intelligenz im diagnostischen Einsatz"
"Laser speckle contrast imaging (LSCI)","Yes, perfusion imaging in psoriasis lesions","Adaptation","No, single model used for both handheld and mounted measurements","Comparison of handheld versus mounted laser speckle contrast perfusion imaging in psoriasis lesions","Yes, on-surface speeds quantified using mean separation (MS) segmentation and enhanced correlation coefficient maximization (ECC)","Psoriasis","Not specified in the text but mentioned as '5 patients' with various skin locations","11 measurement pairs (mounted-handheld LSCI modes)","No (class imbalance not explicitly stated)","Yes, background correction and post-processing steps included in pipeline for data analysis","Quantitative measures: on-surface speeds, frame alignment sharpness, perfusion maps agreement between handheld and mounted measurements","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with corresponding mounted measurements on a visual basis","Quantitative measures: absolute movement-induced difference between mounted-handheld pairs after background correction, median difference","Handheld LSCI facilitated measurements on a wide range of skin areas bringing more convenience for both patients and medical staff.","Yes, comparison with corresponding mounted measurements demonstrated the feasibility of handheld perfusion imaging in clinical practice","No (tested on data from 5 patients)","Not explicitly stated","Handheld versus mounted laser speckle contrast perfusion imaging demonstrated in psoriasis lesions"
"Neuromuscular Electrical Stimulation (NMES)","Yes, prevention of pressure injuries","Adaptation","No, single modality used for treatment","Prevention of pressure injuries in critically ill patients using NMES","Not applicable (NMES is a therapeutic intervention)","None mentioned","Randomized controlled trial with 149 participants, divided into two groups: NMES group and control group","Not specified in the text but implied to be related to ultrasonography measurements of muscle thickness","No (class imbalance not explicitly stated)","Yes, ultrasonography used for measurement of gluteus maximus thickness","Relative risk and number needed to treat calculations; comparison with control group outcomes","Not applicable","No (not mentioned as part of the study design)","Yes, compared NMES treatment group with control group for efficacy and safety","Relative risk; number needed to treat; length of stay in ICU; muscle thickness measurements by ultrasonography","NMES reduced the incidence of pressure injuries (RR = 0.15) and shortened length of stay in ICU (-1.8 days)","Yes, compared with standard care for critically ill patients","No (tested on a single dataset from a randomized controlled trial)","Not explicitly stated","Efficacy and safety of neuromuscular electrical stimulation in the prevention of pressure injuries in critically ill patients: a randomized controlled trial"
"Optical scanner and 3D printer guided radiation therapy","Yes, cutaneous nasal carcinoma treatment","Adaptation","No, single modality used for each task","Effective and efficient way of treating carcinomas of the nose with high control rate and low toxicity profiles","Yes, topographical data collected using optical scan to create custom nose block bolus and lead shielding","Cutaneous nasal carcinoma (Basal cell carcinoma, Squamous cell carcinoma, Merkel cell carcinoma)","Not specified in the text but mentioned as 'retrospective chart review of 26 patients'","Not specified in the text","No (class imbalance not explicitly stated)","Yes, optical scan data used to create custom nose block bolus and lead shielding","Phantom measurements at mid-plane matched prescribed dose within ±0.5%","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with traditional single field Orthovoltage radiation therapy","Complete response rate at a median follow-up of 6 months was 88%","High control rate and low toxicity profiles achieved using optical scanner and 3D printer guided radiation therapy","Yes, proposed method showed improved results compared to traditional single field Orthovoltage radiation therapy","No (tested on retrospective chart review of 26 patients)","Not explicitly stated","Optical scan and 3D printing guided radiation therapy – an application and provincial experience in cutaneous nasal carcinoma"
"JAK/STAT and interferon signalling pathways","Yes, treatment for toxic epidermal necrolysis (TEN)","Adaptation","No, single pathway targeted by JAK inhibitors","Identification of potential druggable targets and development of effective therapy for TEN","Yes, deep visual proteomics used to quantify more than 5,000 proteins in keratinocytes and skin-infiltrating immune cells","Not applicable (TEN is a drug-induced skin reaction)","Formalin-fixed, paraffin-embedded archived skin tissue biopsies of patients with TEN","Not specified in the text but mentioned as 'archived skin tissue biopsies' used for analysis","No (class imbalance not explicitly stated)","Yes, formalin-fixed and paraffin-embedded archived skin tissue biopsies processed for proteomics analysis","In vitro experiments using tofacitinib, in vivo mouse models of TEN treated with JAK inhibitors, and clinical trials on patients with TEN","Not applicable (new pathway targeted by JAK inhibitors)","No (not mentioned as part of the proposed method)","Yes, comparison with existing treatments for TEN demonstrated superiority of JAKi therapy","Clinical and histological disease severity in mouse models and patients with TEN","JAK inhibitors (tofacitinib, baricitinib, abrocitinib or upadacitinib) showed rapid cutaneous re-epithelialization and recovery in seven patients with TEN","Yes, comparison with existing treatments for TEN demonstrated superiority of JAKi therapy","No (tested on archived skin tissue biopsies from patients with TEN)","Not explicitly stated","Spatial proteomics identifies JAKi as treatment for a lethal skin disease"
"Deep learning model combining convolutional neural network (CNN) and fully connected neural network (FCN)","Yes, STI skin lesion detection","Adaptation","Yes, combines CNN with FCN using images and metadata","Evaluation of artificial intelligence-powered screening for sexually transmitted infections-related skin lesions","Yes, deep features extracted by CNN from clinical images","Not specified (STI related skin conditions)","Melbourne Sexual Health Centre dataset collected during 2010-2023 (4913 clinical images and metadata)","4913","No (class imbalance not explicitly stated, but mentioned that STIs are less common than non-STIs)","Yes, preprocessing steps included in the development of deep learning model","Area under the ROC curve (AUC) and assessment of metadata contributions to Image-only model","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for STI skin lesion detection not explicitly stated but results show improved performance using Image+Metadata model","AUC and assessment of metadata contributions to Image-only model","Image + Metadata model achieved a significantly higher AUC of 0.893 (SD 0.018) compared to the Image-only model (p < 0.01)","Yes, results show improved performance using Image+Metadata model but comparison with state-of-the-art methods not explicitly stated","No (tested on Melbourne Sexual Health Centre dataset collected during 2010-2023)","Requires further development and evaluation with larger datasets","Evaluation of artificial intelligence-powered screening for sexually transmitted infections-related skin lesions using clinical images and metadata"
"Various Explainable AI techniques and models","Yes, skin cancer diagnosis (one of the case studies)","Adaptation","No, single models used for each task","Exploring the concept of explainable artificial intelligence in healthcare and its importance in readdressing obstacles presented by black box AI models","Yes, various Explainable AI techniques and models used to achieve feature extraction and interpretability","Skin cancer (one of the case studies)","Not specified in the text but mentioned as 'various datasets' for each task","Not specified in the text but mentioned as 'large number of images' used for training and testing Explainable AI models","No (class imbalance not explicitly stated)","Yes, data collection and preprocessing discussed as part of implementing Explainable AI in healthcare settings","Quantitative measures: diagnostic accuracy, transparency, interpretability levels","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for Explainable AI in healthcare settings","Quantitative measures: diagnostic accuracy, transparency, interpretability levels","Explainable AI enhances diagnostic accuracy and provides transparent insights into AI predictions (case studies on retinopathy, skin cancer, ICU mortality prediction diagnosis)","Yes, comparison with state-of-the-art methods demonstrated the importance of Explainable AI in healthcare settings","No (tested on various datasets for each task)","Not explicitly stated","Explainable AI Case Studies in Healthcare"
"Customized ResNet152 model","Yes, common inflammatory skin diseases detection and classification (eczema, psoriasis, actinic keratosis, severe acne)","Adaptation","No, single models used for each task","Automated system to classify four common inflammatory skin diseases using deep learning and web application","Yes, deep features extracted by customized ResNet152 model for disease classification","Not applicable (skin diseases)","SD-260 dataset (5433 images) and Dermnet dataset","5433","No (class imbalance not explicitly stated)","Yes, image preprocessing step included in deep learning model development","Accuracy results: better than 89%","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin disease classification and detection","Accuracy results: better than 89%","Customized ResNet152 model achieved accuracy results of better than 89% on SD-260 dataset and Dermnet dataset","Yes, comparison with state-of-the-art methods demonstrated the superiority of proposed method","No (tested on SD-260 dataset and Dermnet dataset)","Not explicitly stated","Design a System to Automatically Detect Common Skin Diseases Using Deep Learning and Web Application"
"Machine learning (ML) and deep learning (DL) models","Yes, skin cancer detection among other types of cancers","Adaptation","No, single models used for each type of cancer","Comprehensive analysis of recent advancements in cancer detection using ML and DL models","Yes, various feature extraction techniques (e.g. GLCM) used with CNN and SVM models","Multiple types: brain, lung, skin, breast cancers","Not specified but mentioned as 'various datasets' for each type of cancer","Not specified in the text but mentioned as 'large number of images' used for training and testing ML and DL models","No (class imbalance not explicitly stated)","Yes, preprocessing steps included in proposed methods","Accuracy as performance evaluation metric","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art models for each type of cancer detection","Accuracy","DL techniques achieved highest accuracy of 100%, while ML techniques achieved 99.89% for various types of cancers","Yes, comparative analysis between best performing and worst performing models presented","No (tested on various datasets for each type of cancer)","Challenges in classification efficiency identified: need for continued advancements in ML and DL-based approaches","A comprehensive analysis of recent advancements in cancer detection using machine learning and deep learning models for improved diagnostics"
"DenseNet201-based architecture","Yes, Monkeypox detection from skin images","Adaptation","No, single model used for each task","Monkeypox detection using deep neural networks","Yes, DenseNet201-based architecture extracts features for Monkeypox detection","Monkeypox","Dataset comprising skin images of three diseases: Monkeypox, Chickenpox, Measles, and Normal cases","Not specified in the text but mentioned as 'large number of images' used for training and testing DNN models","No (class imbalance not explicitly stated)","Yes, skin refinement step included in proposed method","Quantitative measures: Accuracy, F1-Score, Area Under Curve (AUC) for two-class and four-class scenarios","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with previous studies demonstrated superior performance of proposed model in terms of F1-Score metric","Quantitative measures: Accuracy, F1-Score, Area Under Curve (AUC) for two-class and four-class scenarios","DenseNet201-based architecture achieved best performance with Accuracy = 97.63%, F1-Score = 90.51%, AUC = 94.27% in two-class scenario; and Accuracy = 95.18%, F1-Score = 89.61%, AUC = 92.06% for four-class scenario","Yes, comparison with previous studies demonstrated superior performance of proposed model","No (tested on dataset comprising skin images of three diseases: Monkeypox, Chickenpox, Measles, and Normal cases)","Not explicitly stated","Monkeypox detection using deep neural networks"
"Machine learning (ML) model for skin disease diagnosis","Yes, skin lesion diagnosis in primary care","Adaptation","No, single ML model used for multiple diseases","Prospective validation of an image analysis ML model for screening 44 skin diseases","Yes, deep features extracted by ML model from images for disease diagnosis","Not specified in the text (multiple types of skin diseases)","Real-life dataset collected from patients visiting GPs in central Catalonia, Spain","100 consecutive patients with a skin problem","No (class imbalance not explicitly stated)","Yes, anonymized images uploaded to ML application for analysis","Diagnostic accuracy study: comparison of GPs', dermatologists', and ML model's diagnostic accuracy","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with GPs' and dermatologists' diagnostic accuracy in real-life setting","Diagnostic accuracy, sensitivity, specificity, balanced Top-1 accuracy, Top-3 accuracy, Top-5 accuracy","ML model's Top-5 accuracy (89%) was comparable to the dermatologist Top-3 accuracy (90%); ML model's sensitivity in benign tumour pathology group (87% and 96%) is higher than that of clinicians","Yes, comparison with existing prospective studies conducted under real-life conditions","No (tested on real-life dataset collected from patients visiting GPs)","ML model's overall diagnostic accuracy in this study is lower than that of both GPs and dermatologists; need for external testing in real-life conditions to validate data","Exploring the potential of artificial intelligence in improving skin lesion diagnosis in primary care"
"Deep Belief Network (DBN)","No, not a skin-related task","New architecture","Yes, combines biophilia color design and IoT technology with DBN for intelligent building lighting system","Design of green intelligent buildings using deep learning techniques (DBN) and IoT technology","No, not a feature extraction task","Not applicable","Not specified in the text but mentioned as 'children's medical building space' and 'green building lighting system'","Not specified in the text","No (class imbalance not explicitly stated)","Yes, preprocessing step included for IoT data collection and processing","Questionnaire Survey method to evaluate practicability and preference of users","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with traditional lighting systems for children's medical buildings","Illuminance error and user preference scores from Questionnaire Survey","Proposed intelligent dimming lighting system based on IoT technology achieved small illuminance errors (not specified in the text)","Yes, comparison with traditional lighting systems demonstrated the effectiveness of proposed method for green intelligent buildings","No (tested on a specific children's medical building space and green building lighting system)","Not explicitly stated","Design strategy of green intelligent building using deep belief network"
"CNN-Based Skin Disease Detection System","Yes, skin disease detection and classification","Adaptation","No, single CNN model used for each task","Design and analysis of a comprehensive system for detecting and classifying skin diseases using deep learning techniques","Yes, CNN extracts features from images to detect and classify skin diseases","Various types (cancerous: basal cell carcinoma, squamous cell carcinoma, melanoma; non-cancerous: acne, vitiligo, eczema)","Not specified in the text but mentioned as 'openly available image pre-processing mechanisms and classification algorithms'","Not specified in the text","No (class imbalance not explicitly stated)","Yes, image preprocessing techniques used to prepare images for CNN model","Various evaluation metrics: accuracy, precision, recall, F1 score, etc.","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin disease detection and classification","Various evaluation metrics: accuracy, precision, recall, F1 score, etc.","Not specified in the text but mentioned as 'appropriate results' using CNN model","Yes, comparison with state-of-the-art methods demonstrated the effectiveness of proposed method","No (tested on openly available datasets)","Not explicitly stated","Design and Analysis of CNN-Based Skin Disease Detection System with Preliminary Diagnosis"
"Various computational tools and methods (machine learning, artificial intelligence, deep neural networks)","Yes, skin lesion detection","Adaptation","No, single models used for each task","Computational tools for drug discovery of anticancer therapy and cancer diagnosis","Yes, deep features extracted by neural networks for skin lesion detection","Various types of cancers (not specified)","Not specified in the text but mentioned as 'large number of data sets' used for training and testing models","Not specified in the text but mentioned as 'complex experimental data sets'","No (class imbalance not explicitly stated)","Yes, image analysis methods included in computational tools","Quantitative measures: accuracy, precision, recall, F1 score","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for cancer diagnosis and treatment planning","Quantitative measures: accuracy, precision, recall, F1 score","Trained deep neural networks achieved high accuracy in detecting malignant skin lesions (rivaling well-trained dermatologists)","Yes, comparison with state-of-the-art methods demonstrated the effectiveness of computational tools for cancer diagnosis and treatment planning","No (tested on various datasets but not specified which ones)","Not explicitly stated","Computational Tools for Drug Discovery of Anticancer Therapy"
"Explainable deep learning model with advanced layers (Global Average Pooling, Batch Normalization, Dropout, and dense layers with ReLU and Swish activations)","Yes, high precision early melanoma detection using dermoscopic images","Adaptation","No, single model used for each task","Automated Diagnostic Systems for early skin cancer detection using explainable deep learning approaches","Yes, advanced layers in proposed model improve feature extraction and image analysis capabilities","Melanoma (early-stage)","Two different dermatology datasets (not specified which ones)","Not specified in the text but mentioned as 'large number of images' used for training and testing proposed model","No (class imbalance not explicitly stated)","Yes, preprocessing steps included in proposed method to improve image quality and enhance feature extraction","Quantitative measures: accuracy, precision, recall, F1 score, AUC-ROC curve","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for early melanoma detection and explainable AI techniques","Quantitative measures: accuracy, precision, recall, F1 score, AUC-ROC curve","Proposed model achieved accuracies of 95.23% and 96.48% on two different datasets for early melanoma detection","Yes, proposed method demonstrated strong performance across other metrics compared to state-of-the-art methods","No (tested on two unspecified dermatology datasets)","Not explicitly stated","Explainable deep learning approaches for high precision early melanoma detection using dermoscopic images"
"JuryFusionNet (CNN ensemble using Condorcet’s Jury Theorem)","Yes, monkeypox detection from skin lesion images","Adaptation","Yes, combines multiple CNN models and uses majority voting with CDJT","Enhanced monkeypox detection using JuryFusionNet","Yes, deep features extracted by four base models (DenseNet169, DenseNet201, MobileNet, ResNet50V2) enhanced by squeeze and excitation block","Monkeypox (Mpox)","MSID dataset (770 images with 4 classes: chickenpox, measles, Mpox, normal skin), MSLD dataset (3192 samples classified as Mpox or non-Mpox)","Not specified in the text but mentioned as 'large number of images' used for training and testing","No (class imbalance not explicitly stated)","Yes, transfer learning with four base models using pre-trained weights","Quantitative measures: accuracy rates on MSID and MSLD datasets","Yes, used for all four base models to extract deep features from skin lesion images","No (not mentioned as part of the proposed method)","Yes, comparison with standard CNN models and prior ensemble methods demonstrated superior effectiveness of JuryFusionNet","Accuracy rates on MSID and MSLD datasets","JuryFusionNet achieved accuracy rate of 91.55% on the MSID dataset and 100% on the MSLD dataset, outperforming various pre-trained models and traditional ensemble methods","Yes, JuryFusionNet surpassed standard CNN models by 1.94–5.19% and improved upon prior ensemble methods by 0.65–2.59%","No (tested on MSID and MSLD datasets)","Not explicitly stated","JuryFusionNet: a Condorcet’s jury theorem-based CNN ensemble for enhanced monkeypox detection from skin lesion images"
"nnUNetv2 framework with Hounsfield Units (HU) windowing and transformer-based 'Segment Anything Model' (MedSAM)","No, head and neck cancer reconstruction","Adaptation","Yes, combination of nnUNetv2 and MedSAM models for segmentation task","Automatic soft-tissue flap segmentation from CT scans in head and neck cancer patients","Yes, deep features extracted by nnUNetv2 framework with HU windowing for segmentation task","Head and Neck Cancer (HNC)","CT scans of 148 HNC patients undergoing post-operative radiotherapy (poRT) from various institutions","Not specified in the text but mentioned as 'large number of images' used for training and testing models","No (class imbalance not explicitly stated)","Yes, HU windowing step included in nnUNetv2 framework to mimic radiological assessment","Dice Similarity Coefficient (DSC) and Hausdorff Distance 95th percentile (HD95) metrics for evaluation of segmentation performance","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods demonstrated superiority of nnUNet-windowing model","Dice Similarity Coefficient (DSC) and Hausdorff Distance 95th percentile (HD95) metrics for evaluation of segmentation performance","nnUNet-windowing model achieved mean DSCs of 0.69 and HD95 of 25.6 mm using 5-fold cross-validation","Yes, comparison with state-of-the-art methods demonstrated superiority of nnUNet-windowing model in segmentation task","No (tested on CT scans from various institutions)","Rare situations such as pedicled flaps, laryngeal primaries and resected bone without bone reconstruction may require fine-tuning of the network","Auto-Segmentation via deep-learning approaches for the assessment of flap volume after reconstructive surgery or radiotherapy in head and neck cancer"
"Weakly Supervised Graph Transformers with transfer learning","Yes, basal cell carcinoma classification in preoperative biopsies","Adaptation","No, single models used for each task","Enhancing basal cell carcinoma classification via transfer learning with weakly supervised graph transformers","Yes, features extracted using a pretrained simCLR model trained on BCC excisions and processed by Vision Transformer","Basal Cell Carcinoma (BCC)","BCCC dataset (514 WSIs of punch biopsies) and COBRA dataset (3,588 WSIs)","Not specified in the text but mentioned as 'large number of images' used for training and testing models","No (class imbalance not explicitly stated)","Yes, patches extracted from WSIs and features formed into graphs for spatial information","Quantitative measures: accuracy, AUC-ROC, mean accuracy improvement over model trained from scratch","Yes, fine-tuned pre-trained models used to improve performance on small datasets","No (not mentioned as part of the proposed method)","Yes, comparison with non-fine-tuned pretrained model and model trained from scratch","Quantitative measures: accuracy, AUC-ROC, mean accuracy improvement over model trained from scratch","Fine-tuned model achieved accuracies of 91.7%, 82.1%, and 75.3% for two, three, and five-class classification on BCCC dataset","Yes, fine-tuned model outperformed non-fine-tuned pretrained model and model trained from scratch with significant improvements in accuracy and AUC-ROC values","No (tested on internal validation set)","Not explicitly stated","Enhancing basal cell carcinoma classification in preoperative biopsies via transfer learning with weakly supervised graph transformers"
"Deep learning model (AlexNet) for quantifying pathologic features of SSc","Yes, systemic sclerosis skin analysis and fibrosis scoring","Adaptation","No, single deep learning model used for each task","Quantification of dermal pathological parameters in patients with SSc using AI applied to biopsies","Yes, deep features extracted by AlexNet for fibrosis scoring and analysis of histologic parameters","Systemic sclerosis (SSc)","Clinical trial data from belumosudil treatment in patients with SSc","Not specified in the text but mentioned as 'serial biopsies' taken at week 0, 24 and 52","No (class imbalance not explicitly stated)","Yes, histologic analyses of stained sections included in proposed method","Quantitative measures: Spearman correlation between Fibrosis Score and mRSS, odds ratios for associations between Fibrosis Score and histologic parameters","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with traditional methods such as modified Rodnan skin score (mRSS) for SSc analysis","Quantitative measures: Spearman correlation between Fibrosis Score and mRSS, odds ratios for associations between Fibrosis Score and histologic parameters","Deep learning model achieved significant correlations with fibrosis scoring and histologic parameter changes in patients treated with belumosudil","Yes, comparison demonstrated the potential of AI applied to SSc biopsies as a novel outcome measure for systemic sclerosis analysis","No (tested on clinical trial data from belumosudil treatment in patients with SSc)","Small sample size and early study termination limited the generalizability of results","Neural network analysis as a novel skin outcome in a trial of belumosudil in patients with systemic sclerosis"
"NoxiScore, a deep learning-based software solution for automated and quantitative analysis of nucleus-related features in histological sections","Yes, evaluation of skin tissue damage after oxidative stress or UV exposure","Adaptation","No, single models used for each task","Evaluation of the efficacy and safety of dermato-cosmetic products using ex vivo human skin model","Yes, deep features extracted by NoxiScore pipeline to assess nuclear morphotypes in relation to tissue damage","Not applicable (study focused on skin injury and UV protection)","Ex vivo human skin samples from multiple donors","Not specified in the text but mentioned as 'large number of images' used for training and testing NoxiScore model","No (class imbalance not explicitly stated)","Yes, hematoxylin-eosin or hematoxylin-eosin saffron staining performed to assess skin structure before morphometric parameter computation","Quantitative measures: histometric analysis of human skin biopsies from multiple donors","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with commercial sun cream and mosquito repellent products","Quantitative measures: histometric analysis of human skin biopsies from multiple donors","Application of sunscreen provided efficient protection against UV effects in ex vivo skin model, while concurrent application of insect repellent with sunscreen significantly decreased the UVB protective effect of the sunscreen.","Yes, study demonstrated potential toxicity of combining real-life sunscreen and insect repellent products","No (tested on ex vivo human skin samples from multiple donors)","Not explicitly stated","Computational histology reveals that concomitant application of insect repellent with sunscreen impairs UV protection in an ex vivo human skin model"
"Extracorporeal photopheresis (ECP)","Yes, treatment of cutaneous T-cell lymphoma and other skin diseases","Adaptation","No, single method used for ECP","To identify novel mechanisms of ECP regardless of the patient’s background situation","Yes, lipid mediators and proteins extracted from blood plasma before and after treatment with ECP","Cutaneous T-cell lymphoma","Not specified in the text but mentioned as 'blood plasma of patients' used for analysis","Not applicable (text does not mention images)","No (class imbalance not explicitly stated)","No (not relevant to ECP treatment)","Proteome profiling and lipidomics analysis of blood plasma before and after treatment","Not applicable","No (not mentioned as part of the study)","Yes, comparison with other treatments for cutaneous T-cell lymphoma and skin diseases","Proteome profiling and lipidomics analysis results: upregulation of anti-inflammatory fatty acids and oxylipins, downregulation of pro-inflammatory sphingosine-1-phosphate (S1P)","ECP-induced changes in lipid mediators may contribute to the remarkable anti-inflammatory effects of the treatment","Yes, comparison with other treatments for cutaneous T-cell lymphoma and skin diseases demonstrated the superiority of ECP","No (tested on blood plasma samples from patients)","Not explicitly stated","Extracorporeal photopheresis induces the release of anti-inflammatory fatty acids and oxylipins and suppresses pro-inflammatory sphingosine-1-phosphate"
"Explainable Cubic Attention-Based Autoencoder (ECAbA)","Yes, skin cancer classification","Adaptation","No, single model used for each task","Proposed a Explainable Cubic Attention-based Autoencoder (ECAbA) model for skin cancer classification","Yes, using Cubic Attention-based Autoencoder (CAbA) with 5 3D convolutional layers and attention modules","Skin Cancer","HAM10000 dataset","Not specified in the text but mentioned as 'large number of images' used for training and testing ECAbA model","Yes, after data augmentation module transformed imbalanced HAM10000 dataset into a refined and balanced form","Yes, using data augmentation module to transform imbalanced HAM10000 dataset","Using three explainable models: LIME, Grad-CAM, and Kernel SHAP for making predictions of CAbA model explainable and reliable","Not applicable","Yes, using data augmentation module to transform imbalanced HAM10000 dataset into a refined and balanced form","No (compared with state-of-the-art methods for skin cancer classification)","Using three explainable models: LIME, Grad-CAM, and Kernel SHAP for making predictions of CAbA model explainable and reliable","ECAbA model can assist in the adoption of AI approaches among medical practitioners by providing explanations of predicted images using explainer modules.","Yes (compared with state-of-the-art methods for skin cancer classification)","No (tested on HAM10000 dataset)","Not explicitly stated","Explainable Cubic Attention-Based Autoencoder for Skin Cancer Classification"
"Ensemble of Bayesian fully convolutional networks (FCNs)","Yes, skin lesion segmentation","Adaptation","No, single models used for each task but ensemble is proposed to handle annotators' disagreements and improve confidence calibration","Handling annotators' disagreements when training a deep model for medical image segmentation","Yes, Bayesian FCNs are used for feature extraction and segmentation","Skin lesions (not specified as melanoma or other types of skin cancer)","ISIC Archive, PH2, DermoFit datasets","Not specified in the text but mentioned as 'large number of images' used for training and testing proposed method","No (class imbalance not explicitly stated)","Yes, pre-processing step included in proposed method to handle contradictory annotations and improve confidence calibration","Quantitative measures: performance on ISIC Archive dataset and cross-dataset evaluation on PH2 and DermoFit datasets","Not applicable","No (not mentioned as part of the proposed method)","Yes, comparison with state-of-the-art methods for skin lesion segmentation demonstrated superior performance of proposed approach","Quantitative measures: not specified in text but implied to be related to accuracy and confidence calibration","Proposed method demonstrates 'superior performance' on ISIC Archive dataset and explores generalization on PH2 and DermoFit datasets","Yes, comparison with state-of-the-art methods demonstrated superior performance of proposed approach","No (tested on multiple datasets but not explicitly stated as testing different datasets)","Not explicitly stated","D-LEMA: Deep Learning Ensembles from Multiple Annotations -- Application to Skin Lesion Segmentation"
