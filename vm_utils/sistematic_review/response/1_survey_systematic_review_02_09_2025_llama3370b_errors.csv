"Document Title","Authors","Publication Year","Title: Skin","Abstract: Skin","First Removal","Abstract: Traditional ML","Second Removal","Duplication Status","Third Removal","Accepted or not","Proposed Model","Tasks (Objectives)","Used Databases"," Proposed Methodology"," Evaluation Metrics and Results","Abstract","DOI","Author Keywords","Article Citation Count","PDF Link"
"Skin lesion detection using adaptive regularized kernel based fuzzy algorithm","Tamije Selvy P.; Shabarish N.; Anitha M.","2019","1","1","0","0","0","Unique","0","","","","","","","Skin cancer is found to be the worst type of cancer which is generally difficult to predict in early stages. In recent days, it has been proved that Computer Aided Diagnosis (CAD) System provides best result in automatic diagnosis of lesions in skin. The purpose of this research paper is early and automatic diagnosis of lesions in skin. Preprocessing, Segmentation by Adaptive Regularized Kernel Based Fuzzy and feature extraction is done in order to achieve a rapid and reliable diagnosis. This proposed work is implemented on 232 images obtained from International Skin Imaging Collaboration (ISIC) archive. © IJSTR 2019.","","Adaptive Regularized Kernel Based Fuzzy; Computer Aided Diagnosis; Melanoma; Region of Interest; Skin Cancer","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077341582&partnerID=40&md5=f5192b42cef65464ec50527c9c1ed4c9"
"Supervised Versus Unsupervised Deep Learning Based Methods for Skin Lesion Segmentation in Dermoscopy Images","Ali A.-R.; Li J.; Trappenberg T.","2019","1","1","0","0","0","Unique","0","","","","","","","Image segmentation is considered a crucial step in automatic dermoscopic image analysis as it affects the accuracy of subsequent steps. The huge progress in deep learning has recently revolutionized the image recognition and computer vision domains. In this paper, we compare a supervised deep learning based approach with an unsupervised deep learning based approach for the task of skin lesion segmentation in dermoscopy images. Results show that, by using the default parameter settings and network configurations proposed in the original approaches, although the unsupervised approach could detect fine structures of skin lesions in some occasions, the supervised approach shows much higher accuracy in terms of Dice coefficient and Jaccard index compared to the unsupervised approach, resulting in 77.7% vs. 40% and 67.2% vs. 30.4%, respectively. With a proposed modification to the unsupervised approach, the Dice and Jaccard values improved to 54.3% and 44%, respectively. © 2019, Springer Nature Switzerland AG.","10.1007/978-3-030-18305-9_32","Deep learning; Dermoscopy; Melanoma","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066139954&doi=10.1007%2f978-3-030-18305-9_32&partnerID=40&md5=aefc97e95e0d3ee7237a336babc33931"
"U-net based segmentation and multiple feature extraction of dermascopic images for efficient diagnosis of Melanoma","Roja Ramani D.; Siva Ranjani S.","2019","0","1","0","0","0","First occurrence","0","","","","","","","Skin cancer is found to be one of the most common types of deadly cancers among human beings in recent years. Computational-based techniques are developed to support the dermatologists for the early diagnosis of skin cancer. Computational analysis of the skin lesions in the dermascopic images is a challenging task due to the difficulties such as low-level of contrast between the lesion and surrounding skin regions, irregular and vague lesion borders, artifacts and poor imaging conditions. This paper presents a U-Net based segmentation and multiple feature extraction of the dermascopic images for the efficient diagnosis of skin cancer. The input dermascopic image is preprocessed to remove the noise and hair in the skin image. Fast Independent Component Analysis (FastICA) is applied to the skin images for obtaining the melanin and hemoglobin components. The U-net segmentation is applied to the dermascopic image to separate the cancer region from the background of the skin image. Different features such as vascular features, color features, texture features, RGB features, and depth features are extracted from the segmented image. RVM classification is applied to classify the normal and abnormal images. With the efficient segmentation and extraction of multiple features, our proposed work yields better performance than the existing segmentation and feature extraction techniques. © Springer Nature Switzerland AG 2019.","10.1007/978-3-030-04061-1_9","Independent component analysis; Melanoma; U-Net segmentation; Vascular features","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060257205&doi=10.1007%2f978-3-030-04061-1_9&partnerID=40&md5=a88642ff253e8f026b89af4dad0353be"
"A Bypass-Based U-Net for Medical Image Segmentation","Chen K.; Xu G.; Qian J.; Ren C.-X.","2019","0","1","0","0","0","Unique","0","","","","","","","U-Net has been one of the important deep learning models applied for biomedical image segmentation for a few years. In this paper, inspired by the way how fully convolutional network (FCN) makes dense predictions, we modify U-Net by adding a new bypass for the expansive path. Before combining the contracting path with the upsampled output, we connect with the feature maps from a deeper encoding convolutional layer for the decoding up-convolutional units, and sum up the information learned from both sides. Also, we have implemented this modification to recurrent residual convolutional neural network based on U-Net as well. The experimental results show that the proposed bypass-based U-Net can gain further context information, especially the details from the previous convolutional layer, and outperforms the original U-Net on the DRIVE dataset for retinal vessel segmentation and the ISBI 2018 challenge for skin lesion segmentation. © 2019, Springer Nature Switzerland AG.","10.1007/978-3-030-36189-1_13","Medical image segmentation; Retinal vessel segmentation; Skin lesion segmentation; U-Net","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077112169&doi=10.1007%2f978-3-030-36189-1_13&partnerID=40&md5=4c22d5ac14a48b18bb9877906729bdd1"
"A comparative study on skin cancer detection using machine learning models","Jayalakshmi D.; Dheeba J.","2019","1","1","0","0","0","Unique","0","","","","","","","The increasing case of malignant melanoma across the world compels the need for more focus on diagnosing it in early stage. A survey of the last five years shows the differences in the survival rate between the treated people of the advanced stage (15%) and the early stage (95%), and it shows the importance of the early detection of melanoma and early treatment. Non-invasive methods like dermoscopy are popular due to its accuracy but still, it is time-consuming and complex for interpretation. To overcome this, computer aided analysis methods were developed and it helped vastly to identify and analyze whether the affected lesion is melanoma or benign in the early stage. For computer Aided Diagnosis (CAD), a clear image without noise and artifacts are needed for accurate interpretation. Hence the importance of image processing plays an important role in these automated analyzing methods. This paper attempts to discuss and review about the techniques and steps involved in image processing and machine learning for skin cancer analysis. © 2019, Institute of Advanced Scientific Research, Inc.. All rights reserved.","","Computer Aided Diagnosis; Feature Extraction; Machine Learning Models; Malignant Melanoma; Pre-Processing; Skin cancer","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073353751&partnerID=40&md5=8c3cd67251dfae387e8eeec94a8a21e7"
"BIOIMAGING 2019 - 6th International Conference on Bioimaging, Proceedings; Part of 12th International Joint Conference on Biomedical Engineering Systems and Technologies, BIOSTEC 2019","","2019","0","1","0","0","0","Unique","0","","","","","","","The proceedings contain 20 papers. The topics discussed include: surgical phase recognition of short video shots based on temporal modeling of deep features; field of interest proposal for augmented mitotic cell count: comparison of two convolutional networks; quantification of stromule frequencies in microscope images of plastids combining ridge detection and geometric criteria; shape recognition in high-level image representations: data preparation and framework of recognition method; models of learning to classify x-ray images for the detection of pneumonia using neural networks; image segmentation using gradient-based histogram thresholding for skin lesion delineation; and enhanced deep learning for pathology image classification: a knowledge transfer based stepwise fine-tuning scheme.","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064710483&partnerID=40&md5=f2c7e13941b73caa3eba413b361bfe54"
"A Relation Hashing Network Embedded with Prior Features for Skin Lesion Classification","Zheng W.; Gou C.; Yan L.","2019","1","1","0","0","0","Unique","0","","","","","","","Deep neural networks have become an effective tool for solving end-to-end classification problems and are suitable for many diagnostic settings. However, the success of such deep models often depends on a large number of training samples with annotations. Moreover, deep networks do not leverage the power of domain knowledge which is usually essential for diagnostic decision. Here we propose a novel relation hashing network via meta-learning to address the problem of skin lesion classification with prior features. In particular, we present a deep relation network to capture and memorize the relation among different samples. To employ the prior domain knowledge, we construct the hybrid-prior feature representation via joint meta-learning based on handcrafted models and deep-learned features. In order to utilize the fast and efficient computation of representation learning, we further create a hashing hybrid-prior feature representation by incorporating deep hashing into hybrid-prior representation learning, and then integrating it into our proposed network. Final recognition is obtained from our hashing relation network by learning to compare among the hashing hybrid-prior features of samples. Experimental results on ISIC Skin 2017 dataset demonstrate that our hashing relation network can achieve the state-of-the-art performance for the task of skin lesion classification. © 2019, Springer Nature Switzerland AG.","10.1007/978-3-030-32692-0_14","Deep-hashing; Meta-learning; Prior feature; Skin lesion classification","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075675369&doi=10.1007%2f978-3-030-32692-0_14&partnerID=40&md5=6dcdc8466dd01191e2b055daf5a794cd"
"High- and Low-Level Feature Enhancement for Medical Image Segmentation","Wang H.; Wang G.; Xu Z.; Lei W.; Zhang S.","2019","0","1","0","0","0","Unique","0","","","","","","","The fully convolutional networks (FCNs) have achieved state-of-the-art performance in numerous medical image segmentation tasks. Most FCNs typically focus on fusing features in different levels to improve the learning ability to multi-scale features. In this paper, we explore an alternative direction to improve network performance by enhancing the encoding quality of high- and low-level features, so as to introduce two feature enhancement modules: (i) high-level feature enhancement module (HFE); (ii) low-level feature enhancement module (LFE). HFE utilizes attention mechanism to selectively aggregate the optimal feature information in high- and low-levels, enhancing the ability of high-level features to reconstruct accurate details. LFE aims to use global semantic information of high-level features to adaptively guide feature learning of bottom networks, so as to enhance the semantic consistency of high- and low-level features. We integrate HFE and LFE into a typical encoder-decoder network, and propose a novel medical image segmentation framework (HLF-Net). On two challenging datasets of skin lesion segmentation and spleen segmentation, we prove that the proposed modules and network can improve the performance considerably. © 2019, Springer Nature Switzerland AG.","10.1007/978-3-030-32692-0_70","Convolutional networks; Feature enhancement; Medical image; Segmentation","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075651659&doi=10.1007%2f978-3-030-32692-0_70&partnerID=40&md5=eb2a17befe5b6e3ecd01ab56f0b47a41"
"DSM: A Deep Supervised Multi-Scale Network Learning for Skin Cancer Segmentation","Zhang G.; Shen X.; Chen S.; Liang L.; Luo Y.; Yu J.; Lu J.","2019","1","1","0","0","0","First occurrence","0","","","","","","","The automatic segmentation of the skin lesion on dermoscopy images is an important step for diagnosing the melanoma. However, the skin lesion segmentation is still a challenging task due to the blur lesion border, low contrast between the skin cancer region and normal tissue background, and various sizes of cancer regions. In this paper, we propose a deep supervised multi-scale network (DSM-Network), which achieves satisfied skin cancer segmentation result by utilizing the side-output layers of the network to aggregate information from shallowdeep layers, and designing a multi-scale connection block to handle a variety of cancer sizes' changes. Moreover, a post-processing of the contour refinement strategy is adopted by a conditional random field (CRF) model to further improve the segmentation results. Extensive experiments on two public datasets: ISBI 2017 and PH2 have demonstrated that our designed DSM-Network has gained competitive performance compared with other state-of-The-Art methods. © 2013 IEEE.","10.1109/ACCESS.2019.2943628","conditional random field; deep supervised learning; dermoscopy image; multi-scale feature; Skin cancer","56","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077740206&doi=10.1109%2fACCESS.2019.2943628&partnerID=40&md5=23f942f019b5cc8ff5b894fdf6c383b2"
"Quality analysis of dermatoscopic images thresholding with malignant melanoma","Michalska M.; Hotra O.","2019","0","1","0","0","0","Unique","0","","","","","","","Malignant melanoma is one of the fastest-spreading skin cancer. The aim of the article is to segment human skin lesions with malignant melanoma from clinical dermatoscopic images and quality analysis images after segmentation. In this work the segmentation by thresholding with tree different threshold values was used. The quality analysis of the created binary images was carried out in Matlab software, based on statistics generated after image segmentation. The created segmentation algorithm allows the analysis of a single skin lesion, shows three areas of skin lesions based on their color. © 2019 SPIE.","10.1117/12.2536671","dermatoscopy; image quality; image thresholding; maligant melanoma","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075793634&doi=10.1117%2f12.2536671&partnerID=40&md5=dd766d8d817c3a37172b95409816b045"
"Neutrosophic multiple deep convolutional neural network for skin dermoscopic image classification","Guo Y.; Ashour A.S.","2019","1","1","0","0","0","Unique","0","","","","","","","Skin cancer is a fatal worldwide disease that has complicated types of different shapes, colors, patterns, and characteristics. Accurate and early diagnosis of skin lesions is a complicated task owing to the fuzzy characteristics of skin cancers. Lately, deep-learning models, including convolution neural networks (CNNs), have the ability to break through the analysis and classification processes in several medical applications. This chapter shows an automated computer-aided diagnosis (CAD) system for classifying skin lesions in dermoscopy images using deep learning networks. The proposed classification model seamlessly incorporates the proposed multiple deep convolution neural network (MDCNN) with a Neutrosophic Similarity Score (NSS) procedure to form a two-stage framework. In the proposed neutrosophic multiple deep convolution neural network (NMDCNN) model, the NSS is used to determine the reinforced training number for each epoch until all epochs are finished during the training process for each DCNN model. Furthermore, the incremental learning strategy and the maximum voting scheme are employed in the multiple deep convolution neural network to alleviate the final classification of the dermoscopic images into two classes: malignant or benign. The proposed framework is substantially assessed on the public International Skin Imaging Collaboration (ISIC) dataset. Evaluation metrics of the proposed NMDCNN proved the competency of the proposed model. © 2019 Elsevier Inc. All rights reserved.","10.1016/B978-0-12-818148-5.00013-8","Deep conventional neural network; Dermoscopy images; Neutrosophic reinforcement sample learning; Neutrosophic similarity score; Skin cancer","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148054699&doi=10.1016%2fB978-0-12-818148-5.00013-8&partnerID=40&md5=a4df5ab27d85c646f68625a6366f548f"
"Utilizing convolutional neural networks to detect skin cancer: A review of initial trials","Ladda M.; Champagne T.","2019","1","1","0","0","0","Unique","0","","","","","","","A convolutional neural network (CNN) is a type of deep, feed-forward artificial neural network able to detect, recognize, and classify visual imagery. Given the visual nature of dermatology, recent research has explored the ability of trained CNNs to detect skin cancers. The ability of CNNs to correctly categorize biopsy-confirmed images of skin lesions has been compared to that of dermatologists in several studies discussed herein. This article will review several studies that evaluated the ability of CNNs to detect skin cancer. Given the diagnostic accuracy that CNNs have demonstrated in studies to date, and the ease of which they could be incorporated into smartphones and digital dermatoscopes, CNNs have the potential to significantly improve the detection of skin cancer and potentially other dermatological diseases. Further research is needed regarding how CNNs could be effectively integrated into clinical practice. © 2019, University of Toronto. All rights reserved.","","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065044112&partnerID=40&md5=472fb2c481195ca44bce10100d44c719"
"Skin lesion boundary segmentation with fully automated deep extreme cut methods","Goyal M.; Ng J.; Oakley A.; Yap M.H.","2019","1","1","0","0","0","Unique","0","","","","","","","The skin is the largest organ in our body. There is a high prevalence of skin diseases and a scarcity of dermatologists, the experts in diagnosing and managing skin diseases, making CAD (Computer Aided Diagnosis) of skin disease an important field of research. Many patients present with a skin lesion of concern, to determine if it is benign or malignant. Lesion diagnosis is currently performed by dermatologists taking a history and examining the lesion and the entire body surface with the aid of a dermatoscope. Automatic lesion segmentation and evaluation of the symmetry or asymmetry of structures and colors with the help of computers may classify a lesion as likely benign or as likely malignant. We have explored a deep learning program called Deep Extreme Cut (DEXTR) and used the Faster-RCNN-InceptionV2 network to determine extreme points (left-most, right-most, top and bottom pixels). We used the ISIC challenge-2017 images for the training set and received Jaccard index of 82.2% on the ISIC testing set 2017 and 85.8% on the PH2 dataset. The proposed method outperformed the winner algorithm of the competition by 5.7% for the Jaccard index. © 2019 SPIE.","10.1117/12.2513015","Deep Extreme Cut; DeeplabV2; Faster-RCNN; Skin lesions segmentation","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068365860&doi=10.1117%2f12.2513015&partnerID=40&md5=54029a7f33da23edd17d308c7bd82968"
"Impact of Adversarial Examples on Deep Learning Models for Biomedical Image Segmentation","Ozbulak U.; Van Messem A.; De Neve W.","2019","0","1","0","0","0","First occurrence","0","","","","","","","Deep learning models, which are increasingly being used in the field of medical image analysis, come with a major security risk, namely, their vulnerability to adversarial examples. Adversarial examples are carefully crafted samples that force machine learning models to make mistakes during testing time. These malicious samples have been shown to be highly effective in misguiding classification tasks. However, research on the influence of adversarial examples on segmentation is significantly lacking. Given that a large portion of medical imaging problems are effectively segmentation problems, we analyze the impact of adversarial examples on deep learning-based image segmentation models. Specifically, we expose the vulnerability of these models to adversarial examples by proposing the Adaptive Segmentation Mask Attack (ASMA). This novel algorithm makes it possible to craft targeted adversarial examples that come with (1) high intersection-over-union rates between the target adversarial mask and the prediction and (2) with perturbation that is, for the most part, invisible to the bare eye. We lay out experimental and visual evidence by showing results obtained for the ISIC skin lesion segmentation challenge and the problem of glaucoma optic disc segmentation. An implementation of this algorithm and additional examples can be found at https://github.com/utkuozbulak/adaptive-segmentation-mask-attack. © 2019, Springer Nature Switzerland AG.","10.1007/978-3-030-32245-8_34","","46","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075672349&doi=10.1007%2f978-3-030-32245-8_34&partnerID=40&md5=12ca843c61a08172c7a11ce21f37697c"
"Convolutional neural network for diagnosing skin cancer","Ottom M.A.","2019","1","1","0","0","0","Unique","0","","","","","","","Diagnosis of melanoma (skin cancer disease) is a challenging task in medical science field due to the amount and nature of the data. Skin cancer datasets are usually comes in different format and shapes including medical images, hence, data require tremendous efforts for preprocessing before the auto-diagnostic task itself. In this work, deep learning (convolutional neural network) is used to build a computer model for predicting new cases of skin cancer. The first phase in this work is to prepare images data, this include images segmentation to find useful parts that are easier for analysis and to detect region of interest in digital images, reduce the amount of noise and image illumination, and to easily detect sharp edges (boundaries) of objects. Then, the proposed approach built a convolutional neural network model which consists of three convolution layers, three max pooling layers, and four fully connected layers. Testing the model produced promising results with accuracy of 0.74. The result encourages and motivates for future improvement and research on online diagnosing of melanoma in early stages. Therefore, a web application was built to utilize the model and provide online diagnosis of melanoma. © 2018 The Science and Information (SAI) Organization Limited.","10.14569/ijacsa.2019.0100746","Convolutional neural network CNN; Image preprocessing; Melanoma; Skin cancer","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070059271&doi=10.14569%2fijacsa.2019.0100746&partnerID=40&md5=3747c47e905d45a6e37f89ab0e8c2698"
"Deep neural network for fuzzy automatic melanoma diagnosis","Abbes W.; Sellami D.","2019","0","1","0","0","0","Unique","0","","","","","","","Melanoma is the most serious type of skin cancer. We consider in this paper diagnosing melanoma based on skin lesion images obtained by common optical cameras. Given the lower quality of such images, we should cope with the imprecision of image data. This paper proposes a CAD system for decision making about the skin lesion severity. We first define the fuzzy modeling of the Bag-of-Words (BoW) of the lesion. Indeed, features are extracted from the skin lesion image related to four criteria inspired by the ABCD rule (Asymmetry, Border, Color, and Differential structures). Based on Fuzzy C-Means (FCM), membership degrees are determined for each BoW. Then, a deep neural network classifier is used for decision making. Based on a public database of 206 lesion images, experimental results demonstrate that the fuzzification of feature modeling presents good results in term of sensitivity (90.1%) and of accuracy (87.5%). A comparative study illustrates that our approach offers the best accuracy and sensitivity. Copyright © 2019 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved","10.5220/0007697900470056","Bag of Words; CAD System; Deep Neural Network Classifier; Feature Extraction; Fuzzy C-Means; Melanoma","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068227292&doi=10.5220%2f0007697900470056&partnerID=40&md5=ad24fe1262a1837dcb9e1c18291f3092"
"Novel ABCD formula to diagnose and feature ranking of melanoma","Reshma M.; Priestly Shan B.","2019","0","1","0","0","0","Unique","0","","","","","","","A prototype of skin cancer detection system for melanoma diagnoses in early stages is very important. In this paper, a novel technique is proposed for Skin malignant growth identification based on feature parameters, color shading histogram, to improve the diagnosis method by optimizing the ABCD formula. Features are extracted like Shape, Statistical, GLCM texture, Color, Wavelet transform, Texture. Once the features are extracted we found the most prominent features by assigning a rank. We have calculated parameters such as sensitivity, specificity, accuracy for checking the imperceptibility and robustness of the proposed approach. Also, Correlation analysis is made between traditional and proposed TDS equation using Karl Pearson's method. © 2018 The Science and Information (SAI) Organization Limited.","10.14569/IJACSA.2019.0100111","Dermoscopy; Gray level co-occurrence matrix (GLCM); Karl Pearson's method; Melanoma; Wavelet transform","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062995239&doi=10.14569%2fIJACSA.2019.0100111&partnerID=40&md5=cc5769e0f6934036e7b334423a873ab7"
"Learning to segment skin lesions from noisy annotations","Mirikharaji Z.; Yan Y.; Hamarneh G.","2019","1","0","0","0","0","First occurrence","0","","","","","","","Deep convolutional neural networks have driven substantial advancements in the automatic understanding of images. Requiring a large collection of images and their associated annotations is one of the main bottlenecks limiting the adoption of deep networks. In the task of medical image segmentation, requiring pixel-level semantic annotations performed by human experts exacerbate this difficulty. This paper proposes a new framework to train a fully convolutional segmentation network from a large set of cheap unreliable annotations and a small set of expert-level clean annotations. We propose a spatially adaptive reweighting approach to treat clean and noisy pixel-level annotations commensurately in the loss function. We deploy a meta-learning approach to assign higher importance to pixels whose loss gradient direction is closer to those of clean data. Our experiments on training the network using segmentation ground truth corrupted with different levels of annotation noise show how spatial reweighting improves the robustness of deep networks to noisy annotations. © Springer Nature Switzerland AG 2019.","10.1007/978-3-030-33391-1_24","","62","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075689232&doi=10.1007%2f978-3-030-33391-1_24&partnerID=40&md5=bbe8359226440fd5d3b3f94dd8579d14"
"Fusion of Visual and Anamnestic Data for the Classification of Skin Lesions with Deep Learning","Bonechi S.; Bianchini M.; Bongini P.; Ciano G.; Giacomini G.; Rosai R.; Tognetti L.; Rossi A.; Andreini P.","2019","1","1","0","0","0","First occurrence","0","","","","","","","Early diagnosis of skin lesions is essential for the positive outcome of the disease, which can only be resolved with surgical treatment. In this manuscript, a deep learning method is proposed for the classification of cutaneous lesions based on their visual appearance and on the patient’s anamnestic data. These include age and gender of the patient and position of the lesion. The classifier discriminates between benign and malignant lesions, mimicking a typical procedure in dermatological diagnostics. Good preliminary results on the ISIC Dataset demonstrate the importance of the information fusion process, which significantly improves the classification accuracy. © 2019, Springer Nature Switzerland AG.","10.1007/978-3-030-30754-7_21","","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072865026&doi=10.1007%2f978-3-030-30754-7_21&partnerID=40&md5=67f80c1c05440ed59363335d52a32dd1"
"Malignant melanoma detection using multi layer perceptron with optimized network parameter selection by PSO","Mukherjee S.; Adhikari A.; Roy M.","2019","0","1","0","0","0","Unique","0","","","","","","","This paper optimizes a neural network classifier for detecting malignant melanoma, a type of skin cancer. A popular metaheuristic algorithm, Particle Swarm Optimization (PSO) is used for finding the optimal number of neuron in the hidden layers of multi-layer neural network (MLP). Using a total of 1875 color, texture and shape features extracted from 170 color images from MED-NODE dataset an accuracy of 85.9% is achieved with threefold cross-validation using two-layer neural network, which is 4.9% higher accuracy rate than previously reported result with the same dataset. © Springer Nature Singapore Pte Ltd. 2019.","10.1007/978-981-13-1540-4_11","ABCD rule; Gray-Level Co-Occurrence matrix; Gray-level run length matrix; Hidden layer neuron; Particle swam optimization","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054877894&doi=10.1007%2f978-981-13-1540-4_11&partnerID=40&md5=ed73151e7a64baa58e807624d405fb2d"
"A novel medical device for early detection of melanoma","Afifi S.; Gholamhosseini H.; Sinha R.; Lindén M.","2019","0","1","0","0","0","Unique","0","","","","","","","Melanoma is the deadliest form of skin cancer. Early detection of melanoma is vital, as it helps in decreasing the death rate as well as treatment costs. Dermatologists are using image-based diagnostic tools to assist them in decisionmaking and detecting melanoma at an early stage. We aim to develop a novel handheld medical scanning device dedicated to early detection of melanoma at the primary healthcare with low cost and high performance. However, developing this particular device is very challenging due to the complicated computations required by the embedded diagnosis system. In this paper, we propose a hardware-friendly design for implementing an embedded system by exploiting the recent hardware advances in reconfigurable computing. The developed embedded system achieved optimized implementation results for the hardware resource utilization, power consumption, detection speed and processing time with high classification accuracy rate using real data for melanoma detection. Consequently, the proposed embedded diagnosis system meets the critical embedded systems constraints, which is capable for integration towards a cost- and energy-efficient medical device for early detection of melanoma. © 2019 The authors and IOS Press. All rights reserved.","10.3233/978-1-61499-975-1-122","Diagnosis system; Embedded System; Medical device; Melanoma detection","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067129247&doi=10.3233%2f978-1-61499-975-1-122&partnerID=40&md5=ddfb5ce2c115768d7b809ef013bc4de0"
"Ensemble transductive learning for skin lesion segmentation","Cui Z.; Wu L.; Wang R.; Zheng W.-S.","2019","1","1","0","0","0","Unique","0","","","","","","","Automated segmentation of skin lesions from dermoscopy images is helpful for the diagnosis and treatment of skin cancers. However, due to small annotated training set and the large visual difference in skins and lesions between subjects, the generalization performance of segmentation models are often limited. Inspired by the transductive learning for image classification, we propose a transductive segmentation approach for skin lesion segmentation, by choosing some of the pixels in test images to participate the training of any segmentation model together with the training set. In this way, visual features in the test images can be effectively learned during model training. Comprehensive evaluations with different model structures and transductive learning strategies showed that the proposed transductive segmentation approach always improve the performance of the corresponding state-of-the-art segmentation models in skin lesion segmentation. © Springer Nature Switzerland AG 2019.","10.1007/978-3-030-31723-2_49","Medical image segmentation; Skin lesions; Transductive learning","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076965500&doi=10.1007%2f978-3-030-31723-2_49&partnerID=40&md5=6e2de539ec32a5ea619c30e84cc84a05"
"Selected technical issues of deep neural networks for image classification purposes","Grochowski M.; Kwasigroch A.; Mikołajczyk A.","2019","0","1","0","0","0","Unique","0","","","","","","","In recent years, deep learning and especially deep neural networks (DNN) have obtained amazing performance on a variety of problems, in particular in classification or pattern recognition. Among many kinds of DNNs, the convolutional neural networks (CNN) are most commonly used. However, due to their complexity, there are many problems related but not limited to optimizing network parameters, avoiding overfitting and ensuring good generalization abilities. Therefore, a number of methods have been proposed by the researchers to deal with these problems. In this paper, we present the results of applying different, recently developed methods to improve deep neural network training and operating. We decided to focus on the most popular CNN structures, namely on VGG based neural networks: VGG16, VGG11 and proposed by us VGG8. The tests were conducted on a real and very important problem of skin cancer detection. A publicly available dataset of skin lesions was used as a benchmark. We analyzed the influence of applying: dropout, batch normalization, model ensembling, and transfer learning. Moreover, the influence of the type of activation function was checked. In order to increase the objectivity of the results, each of the tested models was trained 6 times and their results were averaged. In addition, in order to mitigate the impact of the selection of learning, test and validation sets, k-fold validation was applied. © 2019 Polish Academy of Sciences. All rights reserved.","10.24425/bpas.2019.128485","Batch normalization; Deep learning; Deep neural network; Dropout; Image classification; Transfer learning","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066977291&doi=10.24425%2fbpas.2019.128485&partnerID=40&md5=f9281c0b9ae34569b06f64d282f8cf42"
"Step-wise integration of deep class-specific learning for dermoscopic image segmentation","Bi L.; Kim J.; Ahn E.; Kumar A.; Feng D.; Fulham M.","2019","0","1","0","0","0","Unique","0","","","","","","","The segmentation of abnormal regions on dermoscopic images is an important step for automated computer aided diagnosis (CAD) of skin lesions. Recent methods based on fully convolutional networks (FCN) have been very successful for dermoscopic image segmentation. However, they tend to overfit to the visual characteristics that are present in the dominant non-melanoma studies and therefore, perform poorly on the complex visual characteristics exhibited by melanoma studies, which usually consists of fuzzy boundaries and heterogeneous textures. In this paper, we propose a new method for automated skin lesion segmentation that overcomes these limitations via a novel deep class-specific learning approach which learns the important visual characteristics of the skin lesions of each individual class (melanoma vs. non-melanoma) on an individual basis. We also introduce a new probability-based, step-wise integration to combine complementary segmentation results derived from individual class-specific learning models. We achieved an average Dice coefficient of 85.66% on the ISBI 2017 Skin Lesion Challenge (SLC), 91.77% on the ISBI 2016 SLC and 92.10% on the PH2 datasets with corresponding Jaccard indices of 77.73%, 85.92% and 85.90%, respectively, for the same datasets. Our experiments on three well-established public benchmark datasets demonstrate that our method is more effective than other state-of-the-art methods for skin lesion segmentation. © 2018 Elsevier Ltd","10.1016/j.patcog.2018.08.001","Dermoscopic; Fully convolutional networks (FCN); Melanoma; Segmentation","176","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051363854&doi=10.1016%2fj.patcog.2018.08.001&partnerID=40&md5=80481debdcb791bb124023c3011b8370"
"Deep learning based skin lesion segmentation and classification of melanoma using support vector machine (SVM)","Seeja R.D.; Suresh A.","2019","1","1","0","0","0","Unique","0","","","","","","","Objective: The main objective of this study is to improve the classification performance of melanoma using deep learning based automatic skin lesion segmentation. It can be assist medical experts on early diagnosis of melanoma on dermoscopy images. Methods: First A Convolutional Neural Network (CNN) based U-net algorithm is used for segmentation process. Then extract color, texture and shape features from the segmented image using Local Binary Pattern ( LBP), Edge Histogram (EH), Histogram of Oriented Gradients (HOG) and Gabor method. Finally all the features extracted from these methods were fed into the Support Vector Machine (SVM), Random Forest (RF), K-Nearest Neighbor (KNN) and Naïve Bayes (NB) classifiers to diagnose the skin image which is either melanoma or benign lesions. Results: Experimental results show the effectiveness of the proposed method. The Dice co-efficiency value of 77.5% is achieved for image segmentation and SVM classifier produced 85.19% of accuracy. Conclusion: In deep learning environment, U-Net segmentation algorithm is found to be the best method for segmentation and it helps to improve the classification performance. © 2019, Asian Pacific Journal of Cancer Prevention.","10.31557/APJCP.2019.20.5.1555","Classification; Deep learning; Dermoscopy; Melanoma; Segmentation","136","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066949125&doi=10.31557%2fAPJCP.2019.20.5.1555&partnerID=40&md5=1f5419733a23c991de5f0e054f2d7ab5"
"The effect of color constancy algorithms on semantic segmentation of skin lesions","Ng J.H.; Goyal M.; Hewitt B.; Yap M.H.","2019","1","1","0","0","0","Unique","0","","","","","","","With the ever growing occurrences of skin cancer and limited healthcare settings, a reliable computer assisted diagnostic system is needed to assist the dermatologists for lesion diagnosis. Skin lesion segmentation on dermo- scopic images can be an efficient tool to determine the differences between benign and malignant skin lesions. The dermoscopic images in the public skin lesion datasets are collected from various sources around the world. The color of lesions in dermoscopic images can be strongly dependent on the light source. In this work, we provide a new insight on the effect of color constancy algorithms on skin lesion segmentation with deep learning algorithm. We pre-process the ISIC Challenge Segmentation 2017 dataset using different color constancy algorithms and study the effect on a popular semantic segmentation algorithm, i.e. Fully Convolutional Networks. We evaluate the results with two evaluation metrics, i.e. Dice Similarity Coefficient and Jaccard Similarity Index. Overall, our experiments showed improvements in semantic segmentation of skin lesions when pre-processed with color constancy algorithms. Further, we investigate the effect of these algorithms on different types of lesions (Naevi, Melanoma and Seborrhoeic Keratosis). We found pre-processing with color constancy algorithms improved the segmentation results on Naevi and Seborrhoeic Keratosis, but not Melanoma. Future work will seek to investigate an adaptive color constancy algorithm that could improve the segmentation results. © 2019 SPIE.","10.1117/12.2512702","Color constancy; fully convolutional network; semantic segmentation; skin lesions segmentation","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068412374&doi=10.1117%2f12.2512702&partnerID=40&md5=5ddd061bfa5f1e18a896994841210313"
"Skin melanoma assessment using Kapur’s entropy and level set—A study with bat algorithm","Rajinikanth V.; Satapathy S.C.; Dey N.; Fernandes S.L.; Manic K.S.","2019","1","1","0","0","0","Unique","0","","","","","","","Skin melanoma is considered as a deadliest form of skin malformation originates in human community. Due to its increasing incidence rates, it is necessary to build an accompanying procedure to assist the clinical detection and diagnosis process. Visual examination and the digital dermoscopy are the two common procedures widely adopted by the doctors to detect and verify skin melanoma. This paper proposes a soft-computing assisted tool to investigate the skin melanoma images. In this work, bat algorithm-assisted Kapur’s multithresholding is considered to preprocess the image, and the level set-based segmentation is adopted in the postprocessing stage to mine the skin melanoma section. The experimental investigation is implemented using the benchmark DERMIS dataset. The effectiveness of proposed technique is confirmed by measuring the familiar image similarity measures through a relative study among extracted skin melanoma with the ground truth. The experimental result verifies that the proposed technique is easy to implement and offers superior values of Jaccard (0.8805), Dice (0.9138), sensitivity (0.9927), specificity (0.9177), and accuracy (0.9628). © Springer Nature Singapore Pte Ltd. 2019.","10.1007/978-981-13-1921-1_19","Bat algorithm; Dermoscopy; Level set; Similarity estimation; Skin melanoma","43","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054797647&doi=10.1007%2f978-981-13-1921-1_19&partnerID=40&md5=947fb2ee12cf5b60b6ebe2cc82f365fd"
"An enhanced deep learning framework for skin lesions segmentation","Adegun A.; Viriri S.","2019","1","1","0","0","0","First occurrence","0","","","","","","","Reliable and accurate segmentation of skin lesions images is an essential step in analysing skin lesions for the clinical diagnosis and treatment of melanoma skin cancer. Skin cancer analysis and detection has been automated over the years using various computing techniques and algorithms. Machine learning techniques such as deep learning methods have also been recently applied in diagnosing the disease. Segmentation identifies the shape of the features and the region of interest for analysis. Inconsistency in the delicate arrangement of skin lesions, coupled with possible presence of noise and artefacts such as hairs, air or oil bubbles on skin lesions, weak edges, irregular and fuzzy borders, marks, dark corners, skin lines and blood vessels on skin lesions has made automation of skin lesions segmentation challenging. The proposed deep learning framework is composed of a deep convolutional neural network with an encoder-decoder type architecture that fully integrates a dice coefficient loss function and employs elastic transformation techniques for data augmentation. The multi-stage segmentation approach adopted in this work learns contextual information by extracting discriminative features at the encoder stage of the system and also captures the object boundaries of the skin lesions images at the decoder stage. This enable the system to effectively segment the challenging and inconsistent skin lesion images. This system is further improved with the combination of effective data augmentation technique and the dice loss function. The performance evaluation of the proposed model with evaluation metrics such as Dice Coefficient, Jaccard index, Accuracy and Sensitivity gives improved and promising results when compared with some existing state-of-the-arts techniques. © Springer Nature Switzerland AG 2019.","10.1007/978-3-030-28377-3_34","Data augmentation; Deep convolutional neural network; Deep learning; Dice loss function; Encoder-decoder; Melanoma; Skin lesion segmentation","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072870422&doi=10.1007%2f978-3-030-28377-3_34&partnerID=40&md5=3f8f451ce442fdaffab44715be7e0761"
"An Instrument for Accurate and Non-Invasive Screening of Skin Cancer Based on Multimodal Imaging","Diaz S.; Krohmer T.; Moreira A.; Godoy S.E.; Figueroa M.","2019","1","1","0","0","0","First occurrence","0","","","","","","","We present an instrument based on commodity embedded hardware, that implements an automatic procedure for early skin-cancer screening using dynamic thermal imaging. The procedure leverages image segmentation in the visible range and real-time multimodal registration to compute the temperature recovery curve (TRC) of suspicious skin lesions using thermal infrared video. The instrument implements two algorithms that infer the malignancy of the lesion from the computed TRCs. The first algorithm assumes that the TRCs are deterministic and infers the malignancy from the distance between the TRC of the suspicious lesion and its surrounding skin, which is assumed to be healthy tissue. The second algorithm models the TRC of the lesion as a random process and uses detection theory to statistically infer its malignancy from the eigenfunctions and corresponding eigenvalues of its covariance function. We built a prototype of the instrument using a Raspberry Pi 3 model B+ board, which acquires a visible-range image of the lesion at the beginning of the procedure and performs image segmentation in 62ms. Operating on a 400 × 400-pixel region-of-interest within the infrared video, the board performs frame-by-frame multimodal image registration and generates the TRCs in real time at more than 37 frames per second, thus eliminating the need to store video data for off-line processing. The statistical detection algorithm, which yields the best results, runs in 1.07s at the end of the procedure, and achieves a sensitivity of 98% and a specificity of 95% on a dataset of 116 volunteer subjects. © 2013 IEEE.","10.1109/ACCESS.2019.2956898","classification; detection algorithms; dynamic thermal imaging; embedded software; image segmentation; infrared imaging; multimodal registration; Skin cancer screening","25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077014085&doi=10.1109%2fACCESS.2019.2956898&partnerID=40&md5=77d4662396bb687220d005f476ca19cb"
"Skin Lesion Segmentation Based on Region-Edge Markov Random Field","Salih O.; Viriri S.; Adegun A.","2019","1","1","0","0","0","First occurrence","0","","","","","","","This paper presents a probabilistic model based on Markov Random Field (MRF) theory to achieve skin lesion segmentation. MRF theory plays a significant potential role in the image segmentation field. It has several models based on its theory such as region-based MRF model and edge-based MRF model to detect object, boundaries and other relevant information in an image. The proposed method aims to combine the advantages of these two models by computing the product of the regional likelihood function and edge likelihood function. Regional features and edge features are used to solve the maximum a posteriori (MAP) estimation problem to find the best estimation for better image segmentation. The algorithm starts from pre-processing obtained by convolution technique, and iteratively refines the segmentation by taking into account several metrics of region homogeneity under a probabilistic framework. The technical content is described in detail, and the algorithm was tested on the International Skin Imaging Collaboration (ISIC) database, showing its potential. The proposed method shows a significant improvement when compared with individual lesion segmentation methods in ISIC 2018 challenge with overall results achieved as Jaccard Index of $$76.40\%$$. © 2019, Springer Nature Switzerland AG.","10.1007/978-3-030-33723-0_33","Markov random field; Segmentation; Skin lesion","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076128960&doi=10.1007%2f978-3-030-33723-0_33&partnerID=40&md5=3c6b3989f42261c85de485f7a3837c2f"
"Design of Dmey Wavelet Gaussian Filter (DWGF) for De-noising of Skin Lesion Images","Arora G.; Dubey A.K.; Jaffery Z.A.","2019","1","1","0","0","0","First occurrence","0","","","","","","","Digital Image Processing initial step always starts with Image acquisition which is a start point for further analysis. Generally an analysis of skin lesion images is performed offline which increases the chances of having more disturbances in terms of noise, artifacts or air bubbles. Noise is one of the disturbing elements of this image acquisition which can lead to incorrect segmentation, analysis, or classification. In this paper, a new method Dmey Wavelet Gaussian Filter (DWGF) have been proposed for removing Gaussian type of noise based on Mean Square Error (MSE) and Peak Signal to Noise Ratio (PSNR) performance measures. Wavelet transformation filters, Low pass filters and proposed (DWGF) method have been tested on large data set of skin lesion images through quality measures in which low MSE (91.9083) and high PSNR (28.5313) proves to be better in DWGF. This method can be used for further analysis and detection of various skin diseases in Computer Aided Diagnostic System. © 2019, Springer Nature Singapore Pte Ltd.","10.1007/978-981-13-2414-7_44","Dmey filter; DWGF; Gaussian filter; MSE; PSNR","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057413530&doi=10.1007%2f978-981-13-2414-7_44&partnerID=40&md5=858d1c85da273181558e43c2c0e5d3d9"
"Towards the performance investigation of automatic melanoma diagnosis applications","Asif A.; Fatima I.; Anjum A.; Malik S.U.R.","2019","0","1","0","0","0","Unique","0","","","","","","","Melanoma is a type of skin cancer, one of the fatal diseases that appear as an abnormal growth of skin cells and the lesion part often looks like a mole on the skin. Early detection of melanoma from skin lesion by means of screening is an important step towards a reduction in mortality. For this purpose, numerous automatic melanoma diagnosis models based on image processing and machine learning techniques are available for computer-based applications (CBA) and smartphone-based applications (SBA). Since, the smartphones are available as most accessible and easiest methods with built-in camera option, SBA are preferred over CBA. In this paper, we explored the available literature and highlighted the challenges of SBA in terms of execution time due to the limited computing power of smartphones. To resolve this issue of storage of the smartphones, we proposed to develop an SBA that can seamlessly process the image data on the cloud instead of local hardware of the smartphone. Therefore, we designed a study to build a machine learning model of melanoma diagnosis to measure the time taken in preprocessing, segmentation, feature extraction, and classification on the cloud and compared the results with the processing time on the smartphone's local machine. The results showed there is a significant difference of p value < 0.001 on the average processing time taken on both environments. As the processing on the cloud is more efficient. The findings of the proposed research will be helpful for the developers to decide the processing platform while developing smartphone applications for automatic melanoma diagnosis. © 2018 The Science and Information (SAI) Organization Limited.","10.14569/IJACSA.2019.0100351","Cloud computing; Computer based systems; Melanoma diagnosis; Smartphones","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063727120&doi=10.14569%2fIJACSA.2019.0100351&partnerID=40&md5=1a239adfcecbe37046917f86f67a8374"
"Recurrent residual U-Net for medical image segmentation","Alom M.Z.; Yakopcic C.; Hasan M.; Taha T.M.; Asari V.K.","2019","0","1","0","0","0","Unique","0","","","","","","","Deep learning (DL)-based semantic segmentation methods have been providing state-of-the-art performance in the past few years. More specifically, these techniques have been successfully applied in medical image classification, segmentation, and detection tasks. One DL technique, U-Net, has become one of the most popular for these applications. We propose a recurrent U-Net model and a recurrent residual U-Net model, which are named RU-Net and R2U-Net, respectively. The proposed models utilize the power of U-Net, residual networks, and recurrent convolutional neural networks. There are several advantages to using these proposed architectures for segmentation tasks. First, a residual unit helps when training deep architectures. Second, feature accumulation with recurrent residual convolutional layers ensures better feature representation for segmentation tasks. Third, it allows us to design better U-Net architectures with the same number of network parameters with better performance for medical image segmentation. The proposed models are tested on three benchmark datasets, such as blood vessel segmentation in retinal images, skin cancer segmentation, and lung lesion segmentation. The experimental results show superior performance on segmentation tasks compared to equivalent models, including a variant of a fully connected convolutional neural network called SegNet, U-Net, and residual U-Net. © 2019 Society of Photo-Optical Instrumentation Engineers (SPIE).","10.1117/1.JMI.6.1.014006","convolutional neural networks; medical imaging; recurrent residual U-Net; recurrent U-Net; residual U-Net; semantic segmentation; U-Net","720","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064173188&doi=10.1117%2f1.JMI.6.1.014006&partnerID=40&md5=3affd9d3f9e8f99c3136c2ebb5f0bb05"
"Molecular imaging and validation of margins in surgically excised nonmelanoma skin cancer specimens","Liu Y.; Walker E.; Iyer S.R.; Biro M.; Kim I.; Zhou B.; Straight B.; Bogyo M.; Basilion J.P.; Popkin D.L.; Wilson D.L.","2019","1","1","0","0","0","Unique","0","","","","","","","In an effort to increase the efficiency and cure rate of nonmelanoma skin cancer (NMSC) excisions, we have developed a point-of-care method of imaging and evaluation of skin cancer margins. We evaluate the skin surgical specimens using a smart, near-infrared probe (6qcNIR) that fluoresces in the presence of cathepsin proteases overexpressed in NMSC. Imaging is done with an inverted, flying-spot fluorescence scanner that reduces scatter, giving a 70% improved step response as compared to a conventional imaging system. We develop a scheme for careful comparison of fluorescent signals to histological annotation, which involves image segmentation, fiducial-based registration, and nonrigid free-form deformation on fluorescence images, corresponding color images, ""bread-loafed"" tissue images, hematoxylin and eosin (H&E)-stained slides, and pathological annotations. From epidermal landmarks, spatial accuracy in the bulk of the sample is â1/4500 μm, which when extrapolated with a linear stretch model, suggests an error at the margin of â1/4100 μm, within clinical reporting standards. Cancer annotations on H&E slides are transformed and superimposed on the fluorescence images to generate the final results. Using this methodology, fluorescence cancer signals are generally found to correspond spatially with histological annotations. This method will allow us to accurately analyze molecular probes for imaging skin cancer margins. © The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License. Distribution or reproduction of this work in whole or in part requires full attribution of the original publication, including its DOI.","10.1117/1.JMI.6.1.016001","fluorescence imaging; histology validation; image processing; image registration; molecular imaging; skin cancer","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064149126&doi=10.1117%2f1.JMI.6.1.016001&partnerID=40&md5=ac86a20f0fcd0ed20cc5f5f4590c9079"
"Acral melanocytic lesion segmentation with a convolution neural network (U-Net)","Jaworek-Korjakowska J.","2019","0","1","0","0","0","Unique","0","","","","","","","Melanocytic lesions of acral sites (ALM) are common, with an estimated prevalence of 28-36% in the USA. While the majority of these lesions are benign, differentiation from acral melanoma (AM) is often challenging. Much research has been done in segmenting and classifying skin moles located in acral volar areas. However, methods published to date cannot be easily extended to new skin regions because of different appearance and properties. In this paper, we propose a deep learning (U-Net) architecture to segment acral melonacytic lesions which is a necessary initial step for skin lesion pattern recognition, furthermore it is a prerequisite step to provide an accurate classification and diagnosis. The U-Net is one of the most promising deep learning solution for image segmentation and is built upon fully convolutional network. On the independent validation dataset including 210 dermoscopy images our implemented method showed high segmentation accuracy. For the U-Net convolutional neural network, an average DSC of 0.92, accuracy 0.94, sensitivity 0.91, and specificity 0.92 has been achieved. ALM due to small size and similarity to other local structures create enormous difficulties during the segmentation and assessment process. The use of advanced segmentation methods like deep learning models especially convolutional neural networks have the potential to improve the accuracy of advanced medical area segmentation. © 2019 SPIE.","10.1117/12.2512804","Acral melanoma; Deep learning; Segmentation; Skin cancer; U-Net architecture","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068110576&doi=10.1117%2f12.2512804&partnerID=40&md5=7f07fc34acb0f7afdb1d6dade51db61b"
"Improved Inference via Deep Input Transfer","Taghanaki S.A.; Abhishek K.; Hamarneh G.","2019","0","1","0","0","0","First occurrence","0","","","","","","","Although numerous improvements have been made in the field of image segmentation using convolutional neural networks, the majority of these improvements rely on training with larger datasets, model architecture modifications, novel loss functions, and better optimizers. In this paper, we propose a new segmentation performance boosting paradigm that relies on optimally modifying the network’s input instead of the network itself. In particular, we leverage the gradients of a trained segmentation network with respect to the input to transfer it to a space where the segmentation accuracy improves. We test the proposed method on three publicly available medical image segmentation datasets: the ISIC 2017 Skin Lesion Segmentation dataset, the Shenzhen Chest X-Ray dataset, and the CVC-ColonDB dataset, for which our method achieves improvements of 5.8%, 0.5%, and 4.8% in the average Dice scores, respectively. © 2019, Springer Nature Switzerland AG.","10.1007/978-3-030-32226-7_91","Convolutional neural networks; Gradient-based image enhancement; Semantic image segmentation","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075828829&doi=10.1007%2f978-3-030-32226-7_91&partnerID=40&md5=ab68763982ba86ea0a8a384900f5aea1"
"Lesion classification using convolutional neural network","Sharma M.; Bhave A.","2019","0","1","0","0","0","Unique","0","","","","","","","Malignant melanoma is uncommon in India as compared to the Western nations. However, its growth in recent years has been significant. Early detection of malignant skin lesions can help in proper cure. All recent works on automated classification of skin lesions generate a set of features based on the lesion segment such as lesion diameter and texture. The lesions are then classified into malignant and benign classes based on these features. In our work, we use convolutional neural networks (CNNs) with LeNet architecture in order to automate the feature extraction and selection process. We classify skin lesions in binary class of malignant and benign using ISBI 2016 and PH2 data set with an accuracy of 75% and 97.91%, respectively. © Springer Nature Singapore Pte Ltd. 2019.","10.1007/978-981-13-3393-4_37","Convolutional neural network; Deep learning; Malignant melanoma; Skin lesion; Skin lesion classification","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062287201&doi=10.1007%2f978-981-13-3393-4_37&partnerID=40&md5=748262c6c07ff7ef6bd3f4961120c724"
"Segmentation of skin lesions in dermoscopy images using fuzzy classification of pixels and histogram thresholding","Garcia-Arroyo J.L.; Garcia-Zapirain B.","2019","1","1","0","0","0","Unique","0","","","","","","","Background and objective: To ensure proper functioning of a Computer Aided Diagnosis (CAD) system for melanoma detection in dermoscopy images, it is important to accurately detect the border of the lesion. This paper proposes a method developed by the authors to address this problem. Methods: The algorithm for segmentation of skin lesions in dermoscopy images is based on fuzzy classification of pixels and subsequent histogram thresholding. Results: This method participated in the 2016 and 2017 ISBI (International Symposium on Biomedical Imaging) Challenges, hosted by the ISIC (International Skin Imaging Collaboration). It was tested against two public databases containing 379 and 600 images respectively, and compared using the same defined metrics (Accuracy, Dice Coefficient, Jaccard Index, Sensitivity and Specificity) with the rest of participating state-of-the-art work, obtaining good results: (0.934, 0.869, 0.791, 0.870 and 0.978) and (0.884, 0.760, 0.665, 0.869 and 0.923) respectively, ranking 9th and 15th out of a total of 21 and 28 participants respectively using the Jaccard Index (which was the indicator used as a basis for ranking) and the 1st in the 2017 Challenge using the Sensitivity. Conclusion: The method has been proven to be robust and reliable. It's main contribution is the very design of the algorithm, highly innovative, which could also be used to deal with other segmentation problems of a similar nature. © 2018","10.1016/j.cmpb.2018.11.001","Border detection; Image processing; Machine learning; Pattern recognition","77","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056906784&doi=10.1016%2fj.cmpb.2018.11.001&partnerID=40&md5=b37d1f328272eec18a05836b0836e2f1"
"Manifold Exploring Data Augmentation with Geometric Transformations for Increased Performance and Robustness","Paschali M.; Simson W.; Roy A.G.; Göbl R.; Wachinger C.; Navab N.","2019","0","1","0","0","0","First occurrence","0","","","","","","","In this paper we propose a novel augmentation technique that improves not only the performance of deep neural networks on clean test data, but also significantly increases their robustness to random transformations, both affine and projective. Inspired by ManiFool, the augmentation is performed by a line-search manifold-exploration method that learns affine geometric transformations that lead to the misclassification on an image, while ensuring that it remains on the same manifold as the training data. This augmentation method populates any training dataset with images that lie on the border of the manifolds between two-classes and maximizes the variance the network is exposed to during training. Our method was thoroughly evaluated on the challenging tasks of fine-grained skin lesion classification from limited data, and breast tumor classification of mammograms. Compared with traditional augmentation methods, and with images synthesized by Generative Adversarial Networks our method not only achieves state-of-the-art performance but also significantly improves the network’s robustness. © 2019, Springer Nature Switzerland AG.","10.1007/978-3-030-20351-1_40","Breast tumor classification; Data augmentation; Deep learning; Manifold learning; Skin lesion classification","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066133575&doi=10.1007%2f978-3-030-20351-1_40&partnerID=40&md5=2e146b13fc946a5e7f6eff3bbad1751d"
"Classification of Vitiligo Based on Convolutional Neural Network","Liu J.; Yan J.; Chen J.; Sun G.; Luo W.","2019","0","1","0","0","0","First occurrence","0","","","","","","","Vitiligo is one of the most intractable skin disease in the world. According to incomplete statistics, there is about 0.5–2% incidence of vitiligo in the world, and the number is still growing, so the early diagnosis of vitiligo is very important. In recent years, deep learning has been successfully applied to medical image classification and has achieved outstanding performance, which helps achieve vitiligo intelligent diagnosis. In this paper, we propose a method base on probability-average value of three convolutional neural network (CNN) models which are same structures, and trained with three different color-space images (RGB, HSV, and YCrCb) for the same vitiligo dataset. The applied strategy is found to achieve the classification performance of 94.2% area under the roc curve (AUC), 87.8% accuracy, 91.9% precision, 90.9% sensitivity, 80.2% specificity which outperforms the individual networks. © 2019, Springer Nature Switzerland AG.","10.1007/978-3-030-24265-7_19","Classification; Color-space; Convolutional neural network; Probability-average; Vitiligo","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070242467&doi=10.1007%2f978-3-030-24265-7_19&partnerID=40&md5=0ee77eaf8fc36a460caa15ddb5bef35f"
"Artificial intelligence in mobile applications of dermatology: A systematic mapping study","Tintín V.; Caiza J.; Atencio H.; Caicedo F.","2019","0","1","0","0","0","Unique","0","","","","","","","Skin diseases are considered the fourth most common cause of human disease and are more common than it is thought. With the advancement of technology, new concepts have been incorporated into the field of mobile health and, specifically, into dermatology. On the other hand, some factors make access to medical care difficult which is why the use of mobile applications for medical care and diagnosis is very common today, but are these applications suitable? In this study, a systematic literature mapping is carried out of mobile applications that use techniques of artificial intelligence for the diagnosis of skin diseases. Its focus is mainly on the level of sensitivity, specificity and overall accuracy of said diagnoses in comparison to the accuracy of a dermatologist. Several applications of care and diagnosis of skin diseases were found. However, only 9 studies describe the techniques that use these applications for the classification of the disease; several of them with high levels of precision, and mainly those that utilize artificial neural networks and vector-support machine algorithms. Despite the research conducted in this field, these techniques are still in development and are available only for a number of limited diseases. Thus, we believe it is necessary to direct the research towards the field of dermatology and contribute to the minimization of the gap between doctor and patient. Copyright © 2019 for this paper by its authors.","","Artificial intelligence; Dermatology; Dermatology apps; Mobile applications; Skin care; Smartphone","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074653469&partnerID=40&md5=5416a3518bb05a1098274f594b83f751"
"Dermatological classification using deep learning of skin image and patient background knowledge","Sriwong K.; Bunrit S.; Kerdprasop K.; Kerdprasop N.","2019","1","1","0","0","0","Unique","0","","","","","","","Skin cancer is one of the most common human malignancies. It is a kind of skin diseases caused by abnormal growth of skin cells. Clinically, dermatological disease including skin cancer can be divided into many types. Treatment options for each type are varying depending on the prognosis of a disease. Type of skin disease or dermatological classification is an initial process of clinical screening. Traditional method of initial clinical screening requires a visual diagnosing by specialized expertise. In case the disease is classified as a type of skin cancers, it is a serious case of dermatological disease that should be treated promptly. Therefore, an automatic approach applied for this classification task is very useful. In this work, we propose an automatic method for skin disease classification using deep learning model of convolution neural network, or CNN. In order to increase the classification performance of CNN, we employ both image data and background knowledge of the patient in the modeling process. The experimental results performed on a public dataset show that the CNN model can classify skin diseases with 79.29% accuracy, while our proposed method to incorporate background knowledge of patient in the modeling phase can improve the accuracy up to 80.39%. © 2019 International Association of Computer Science and Information Technology.","10.18178/ijmlc.2019.9.6.884","Convolution neural network; Deep learning; Dermatological image classification; Skin cancer","30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077530229&doi=10.18178%2fijmlc.2019.9.6.884&partnerID=40&md5=449a8a68766dd9e5b7354de1762caa44"
"Measuring surface area of skin lesions with 2D and 3D algorithms","Mirzaalian Dastjerdi H.; Töpfer D.; Rupitsch S.J.; Maier A.","2019","1","1","0","0","0","Unique","0","","","","","","","Purpose. The treatment of skin lesions of various kinds is a common task in clinical routine. Apart from wound care, the assessment of treatment efficacy plays an important role. In this paper, we present a new approach to measure the skin lesion surface in two and three dimensions. Methods. For the 2D approach, a single photo containing a flexible paper ruler is taken. After semi-automatic segmentation of the lesion, evaluation is based on local scale estimation using the ruler. For the 3D approach, reconstruction is based on Structure from Motion. Roughly outlining the region of interest around the lesion is required for both methods. Results. The measurement evaluation was performed on 117 phantom images and five phantom videos for 2D and 3D approach, respectively. We found an absolute error of 0.99±1.18 cm2 and a relative error 9.89± 9.31% for 2D. These errors are <1 cm2 and <5% for five test phantoms in our 3D case. As expected, the error of 2D surface area measurement increased by approximately 10% for wounds on the bent surface compared to wounds on the flat surface. Using our method, the only user interaction is to roughly outline the region of interest around the lesion. Conclusions. We developed a new wound segmentation and surface area measurement technique for skin lesions even on a bent surface. The 2D technique provides the user with a fast, user-friendly segmentation and measurement tool with reasonable accuracy for home care assessment of treatment. For 3D only preliminary results could be provided. Measurements were only based on phantoms and have to be repeated with real clinical data. © 2019 Houman Mirzaalian Dastjerdi et al.","10.1155/2019/4035148","","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060815270&doi=10.1155%2f2019%2f4035148&partnerID=40&md5=5a6e15367d3c1f9676ec4dfb26b3f03e"
"32nd Canadian Conference on Artificial Intelligence, Canadian AI 2019","","2019","0","1","0","0","0","Unique","0","","","","","","","The proceedings contain 69 papers. The special focus in this conference is on Artificial Intelligence. The topics include: Automatically Learning a Human-Resource Ontology from Professional Social-Network Data; efficient Transformer-Based Sentence Encoding for Sentence Pair Modelling; instance Ranking and Numerosity Reduction Using Matrix Decomposition and Subspace Learning; hybrid Temporal Situation Calculus; 3D Depthwise Convolution: Reducing Model Parameters in 3D Vision Tasks; identifying Misaligned Spans in Parallel Corpora Using Change Point Detection; in Vino Veritas: Estimating Vineyard Grape Yield from Images Using Deep Learning; options in Multi-task Reinforcement Learning - Transfer via Reflection; the Invisible Power of Fairness. How Machine Learning Shapes Democracy; weakly Supervised, Data-Driven Acquisition of Rules for Open Information Extraction; maize Insects Classification Through Endoscopic Video Analysis; collaborative Clustering Approach Based on Dempster-Shafer Theory for Bag-of-Visual-Words Codebook Generation; memory-Efficient Backpropagation for Recurrent Neural Networks; a Behavior-Based Proactive User Authentication Model Utilizing Mobile Application Usage Patterns; sparseout: Controlling Sparsity in Deep Networks; crowd Prediction Under Uncertainty; optimized Random Walk with Restart for Recommendation Systems; inter and Intra Document Attention for Depression Risk Assessment; a Shallow Learning - Reduced Data Approach for Image Classification; multi-class Ensemble Learning of Imbalanced Bidding Fraud Data; measuring Human Emotion in Short Documents to Improve Social Robot and Agent Interactions; towards Causal Analysis of Protocol Violations; lexicographic Preference Trees with Hard Constraints; supervised Versus Unsupervised Deep Learning Based Methods for Skin Lesion Segmentation in Dermoscopy Images; lifted Temporal Maximum Expected Utility; automatic Generation of Video Game Character Images Using Augmented Structure-and-Style Networks; detecting Depression from Voice.","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066142191&partnerID=40&md5=b58f090ab5a084af076735517adf2ffc"
"Classification of Skin Lesions Based on Data Collaboration Under Imbalance Dataset","Ji W.; Cai L.; Chen M.; Wang N.","2019","1","1","0","0","0","Unique","0","","","","","","","Imbalance data is a common problem in machine learning task, which often impacts the accuracy of models. An effective way to solve it is to increase the number of minority class samples in the dataset. Many methods are put forward to solve the problem of imbalance data in machine learning. But these are all for low-dimensional data. For high-dimensional data, such as images, these methods are not well applicable. In this paper, an image generation method based on generative adversarial network is introduced to do pattern learning for samples of minority class in the dataset, so as to realize the expansion of data for minority class. And finally the classification networks for skin lesions are trained by data collaboration which consist of real images and generated images. The experimental results indicate that the accuracy of networks are further improved by the addition of generated images while alleviating the imbalance problem to some extent. © 2019, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","10.1007/978-3-030-30146-0_20","Data collaboration; Generative adversarial network; Imbalance data; Skin image classification","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077121043&doi=10.1007%2f978-3-030-30146-0_20&partnerID=40&md5=e631d41a5b3d871d961ffd69e708a11e"
"Skin Disease Diagnosis from Photographs Using Deep Learning","Goceri E.","2019","1","1","0","0","0","Unique","0","","","","","","","This work aims to study performance of different deep learning based approaches to classify skin diseases automatically from colored digital photographs. We applied recent network models, which are U-Net, Inception Version-3 (InceptionV3), Inception and Residual Network (InceptionResNetV2), VGGNet, and Residual Network (ResNet). Comparative evaluations of the results obtained by these network models indicated that automated diagnosis from digital photographs is possible with accuracy between 74% (by U-net) and 80% (by ResNet). Therefore, further studies are still required in this area to design and develop a new model by combining advantages of different network models and also to obtain higher accuracy. In addition, testing of the model should be performed with more data including more diversity to see reliability of the model. © Springer Nature Switzerland AG 2019.","10.1007/978-3-030-32040-9_25","Automated diagnosis; Classification; Color images; Deep learning; Skin disease","51","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073149296&doi=10.1007%2f978-3-030-32040-9_25&partnerID=40&md5=22407dfeb635bc66968103c38bdbae54"
"Deep Learning in Image Processing: Revolutionizing Diagnosis in the Field of Dermatology","Nayak R.; Hasija Y.","2019","0","1","0","0","0","Unique","0","","","","","","","The modern-day society is increasingly dependent on computer-aided tools and techniques. Digital imaging techniques have a tremendous impact on our day-to-day lives. Image processing is a vital component in the field of biological sciences and has the potential to drastically change the computer-human interface. Image processing refers to the conversion of an image into a digital form followed by enhancement of the image in order to extract useful information from it that are indiscernible by human ocular perceivers. Rapid advances in image processing, computerized reconstruction of an image and allied advancements in image analysis algorithms and the application of artificial intelligence has spurred a revolution in the field of medical and diagnostic imaging. Deep learning, a type of Artificial Neural Network (Machine Learning), is resurfacing as a powerful tool for its utilization in big healthcare data. The integration of deep learning techniques to image processing has the potential to add momentum to the dermatological imaging and promote early and accurate diagnosis of skin lesions. This review attempts to discuss the fundamentals of image processing, its importance, various clinical imaging modalities in use in the field of dermatology and application of deep learning algorithms in dermatological imaging, accentuating the inadequacies and future research prospects. © 2019, Springer Nature Singapore Pte Ltd.","10.1007/978-981-15-0108-1_27","Deep learning; Dermatological imaging; Image processing; Image segmentation","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075235218&doi=10.1007%2f978-981-15-0108-1_27&partnerID=40&md5=bbf592360bc7b8bca11f9b3c2fb7d8c0"
"1st MICCAI Workshop on Domain Adaptation and Representation Transfer, DART 2019, and the 1st International Workshop on Medical Image Learning with Less Labels and Imperfect Data, MIL3ID 2019, held in conjunction with 22nd International Conference on Medical Image Computing and Computer- Assisted Intervention, MICCAI 2019","","2019","0","1","0","0","0","Unique","0","","","","","","","The proceedings contain 28 papers. The special focus in this conference is on MICCAI Workshop on Domain Adaptation and Representation Transfer, and the International Workshop on Medical Image Learning with Less Labels and Imperfect Data, held in conjunction with International Conference on Medical Image Computing and Computer- Assisted Intervention. The topics include: Harmonization and targeted feature dropout for generalized segmentation: Application to multi-site traumatic brain injury images; improving pathological structure segmentation via transfer learning across diseases; generating virtual chromoendoscopic images and improving detectability and classification performance of endoscopic lesions; self-supervised learning of inverse problem solvers in medical imaging; weakly supervised segmentation of vertebral bodies with iterative slice-propagation; A cascade attention network for liver lesion classification in weakly-labeled multi-phase CT images; CT data curation for liver patients: Phase recognition in dynamic contrast-enhanced CT; active learning technique for multimodal brain tumor segmentation using limited labeled images; semi-supervised learning of fetal anatomy from ultrasound; Multi-modal segmentation with missing MR sequences using pre-trained fusion networks; temporal consistency objectives regularize the learning of disentangled representations; more unlabelled data or label more data? a study on semi-supervised laparoscopic image segmentation; few-shot learning with deep triplet networks for brain imaging modality recognition; a convolutional neural network method for boundary optimization enables few-shot learning for biomedical image segmentation; transfer learning from partial annotations for whole brain segmentation; learning to segment skin lesions from noisy annotations; a weakly supervised method for instance segmentation of biological cells; towards practical unsupervised anomaly detection on retinal images.","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075679187&partnerID=40&md5=3094bc893749cd1b353c0917132a993f"
"XiangyaDerm: A clinical image dataset of asian race for skin disease aided diagnosis","Xie B.; He X.; Zhao S.; Li Y.; Su J.; Zhao X.; Kuang Y.; Wang Y.; Chen X.","2019","1","1","0","0","0","Unique","0","","","","","","","Skin disease is a quite common disease of human beings, which has been found in all races and ages. It seriously affects people’s quality of life or even endangers people’s lives. In this paper, we propose a large-scale, Asian-dominated dataset of skin diseases with bounding box labels, namely XiangyaDerm. It contains 107,565 clinical images, covering 541 types of skin diseases. Each image in this dataset is labeled by professional doctors. As far as we know, this dataset is the largest clinical image dataset of Asian skin diseases used in Computer Aided Diagnosis (CAD) system worldwide. We compare the classification results of several advanced Convolutional Neural Networks (CNNs) on this dataset. InceptionResNetV2 is the best one for 80 skin disease classification whose Top-1 and Top-3 accuracies can reach 0.588 and 0.764, which proves the usefulness of the proposed benchmark dataset, and gives the baseline performance on it. The cross-test experiment with Derm101 shows us that the CNN model has a very different test effect on different ethnic datasets. Therefore, to build a skin disease CAD system with high performance and stability, we recommend to establish a specific dataset of skin diseases for different regions and races. © Springer Nature Switzerland AG 2019.","10.1007/978-3-030-33642-4_3","Clinical image dataset; Computer Aided Diagnosis; Skin disease","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076689538&doi=10.1007%2f978-3-030-33642-4_3&partnerID=40&md5=9d73b65aeb28e2bd70fc9cd13890c93e"
"Automated phenotyping of epicuticular waxes of grapevine berries using light separation and convolutional neural networks","Barré P.; Herzog K.; Höfle R.; Hullin M.B.; Töpfer R.; Steinhage V.","2019","0","1","0","0","0","Unique","0","","","","","","","The epicuticular wax represents the outer layer of the grape berry skin and is known as trait that is significantly correlated to resilience towards Botrytis bunch rot. Traditionally this trait is classified using the OIV descriptor 227 (berry bloom) in a time consuming way resulting in subjective and error-prone phenotypic data. In the present study an objective, fast and sensor-based approach was developed to monitor epicuticular waxes. From the technical point-of-view, it is known that the measurement of different illumination components conveys important information about observed object surfaces. A Light-Separation-Lab is proposed in order to capture illumination-separated images of grapevine berries for phenotyping the distribution of epicuticular waxes (berry bloom). For image analysis, an efficient convolutional neural network approach is used to derive the uniformity and intactness of waxes on berries. Method validation over six grapevine cultivars shows accuracies up to 97.3%. In addition, electrical impedance of the cuticle and its epicuticular waxes (described as an indicator for the thickness of berry skin and its permeability) was correlated to the detected proportion of waxes with r = 0.76. This novel, fast and non-invasive phenotyping approach facilitates enlarged screenings within grapevine breeding material and genetic repositories regarding berry bloom characteristics and its impact on resilience towards Botrytis bunch rot. © 2018 Elsevier B.V.","10.1016/j.compag.2018.11.012","Berry bloom; Botrytis cinerea; Convolutional Neural Networks (CNN); Direct and global illumination; Vitis vinifera","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057837256&doi=10.1016%2fj.compag.2018.11.012&partnerID=40&md5=cc609e533b66cbc3327f2379859b5f02"
"Biomarker localization by combining CNN classifier and generative adversarial network","Zhang R.; Tan S.; Wang R.; Manivannan S.; Chen J.; Lin H.; Zheng W.-S.","2019","0","1","0","0","0","First occurrence","0","","","","","","","This paper proposes a novel deep neural network architecture to effectively localize potential biomarkers in medical images, when only the image-level labels are available during model training. The proposed architecture combines a CNN classifier and a generative adversarial network (GAN) in a novel way, such that the CNN classifier and the discriminator in the GAN can effectively help the encoder-decoder in the GAN to remove biomarkers. Biomarkers in abnormal images can then be easily localized and segmented by subtracting the output of the encoder-decoder from its original input. The proposed approach was evaluated on diabetic retinopathy images with real biomarkers and on skin images with simulated biomarkers, showing state-of-the-art performance in localizing biomarkers even if biomarkers are irregularly scattered and are of various sizes in images. © 2019, Springer Nature Switzerland AG.","10.1007/978-3-030-32239-7_24","Biomarker localization; Encoder-decoder; Generative adversarial networks","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075639922&doi=10.1007%2f978-3-030-32239-7_24&partnerID=40&md5=0f5e9821c97854e8af5836212fbd2828"
"The Landscape of Research on Skin Detectors: Coherent Taxonomy, Open Challenges, Motivations, Recommendations and Statistical Analysis, Future Directions","Chyad M.A.; Alsattar H.A.; Zaidan B.B.; Zaidan A.A.; Al Shafeey G.A.","2019","1","1","0","0","0","Unique","0","","","","","","","This paper review and analysis the literature on skin detector (SD), in order to establish the coherent taxonomy and figure out the gap on this pivotal research area. An extensive search is conducted to identify articles that deal with skin detection, skin segmentation, skin tone detector, and skin recognition issues, related techniques are reviewed comprehensively and a coherent taxonomy of these articles is established. ScienceDirect, IEEE Xplore, and Web of Science databases are checked for articles on skin detector. A total of 2803 papers are collected from 2007 to February 2018. The set comprised 173 articles. The largest portion of the papers (n = 158/173) = 91 % belong to Development and Design, that is aimed to develop an approach for skin classifier into skin and non-skin. A sum total of (n = 5/173)= 3 % of the papers belong to Evaluation and Framework, (n=10/173)= 6 % papers was categorized as Comparative Study. This paper discusses the open challenges, motivations and recommendations of the related works. Furthermore, state-of-the-art is a step to demonstrate the novelty of the presented study by conducted a statistical analysis for previous studies such as (Dataset, Color spaces, features, image type, and Classification techniques) as a future direction for other researchers who are interested in SD. © 2013 IEEE.","10.1109/ACCESS.2019.2924989","deep learning; detection; recognition; segmentation; skin classification; Skin detector; skin tone","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071091071&doi=10.1109%2fACCESS.2019.2924989&partnerID=40&md5=5f914da299f6a7a9b067ba832aa176fd"
"Whole-section tumor micro-architecture analysis by a two-dimensional phasor-based approach applied to polarization-dependent second harmonic imaging","Scodellaro R.; Bouzin M.; Mingozzi F.; D'Alfonso L.; Granucci F.; Collini M.; Chirico G.; Sironi L.","2019","0","1","0","0","0","Unique","0","","","","","","","Second Harmonic Generation (SHG) microscopy has gained much interest in the histopathology field since it allows label-free imaging of tissues simultaneously providing information on their morphology and on the collagen microarchitecture, thereby highlighting the onset of pathologies and diseases. A wide request of image analysis tools is growing, with the aim to increase the reliability of the analysis of the huge amount of acquired data and to assist pathologists in a user-independent way during their diagnosis. In this light, we exploit here a set of phasor-parameters that, coupled to a 2-dimensional phasor-based approach (μMAPPS, Microscopic Multiparametric Analysis by Phasor projection of Polarization-dependent SHG signal) and a clustering algorithm, allow to automatically recover different collagen microarchitectures in the tissues extracellular matrix. The collagen fibrils microscopic parameters (orientation and anisotropy) are analyzed at a mesoscopic level by quantifying their local spatial heterogeneity in histopathology sections (few mm in size) from two cancer xenografts in mice, in order to maximally discriminate different collagen organizations, allowing in this case to identify the tumor area with respect to the surrounding skin tissue. We show that the “fibril entropy” parameter, which describes the tissue order on a selected spatial scale, is the most effective in enlightening the tumor edges, opening the possibility of their automatic segmentation. Our method, therefore, combined with tissue morphology information, has the potential to become a support to standard histopathology in diseases diagnosis. Copyright © 2019 Scodellaro, Bouzin, Mingozzi, D'Alfonso, Granucci, Collini, Chirico and Sironi. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.","10.3389/fonc.2019.00527","Cancer; Collagen; Label-free imaging; Phasor approach; Second harmonic generation; Two-photon microscopy","19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068999268&doi=10.3389%2ffonc.2019.00527&partnerID=40&md5=9ce1a76a4dd0f87334809aa5692fb442"
"Computational intelligence CSA-based approach for machine-driven calculation of outline curves of cutaneous melanoma","Galvez A.; Iglesias A.","2018","0","1","0","0","0","First occurrence","0","","","","","","","This paper addresses the problem of obtaining automatically a good approximation of the outline curve of skin lesions from dermoscopy images. This problem appears as a critical step in machine-driven segmentation of dermoscopy imges for semi-automatic early diagnosis of cutaneous melanoma. Given a set of feature points selected by a specialist, the method applies a powerful nature-inspired metaheuristic optimization method called cuckoo search algorithm (CSA) to obtain the free-form parametric Ber curve that fits the points better in the least-squares sense. Two illustrative examples of a benign and a malignant skin lesions (a naevus and a melanoma, respectively) are used to evaluate the performance of the method. Our experimental results show that the method performs very well and can be applied as a intermediate step of semi-automatic image segmentation for early diagnosis of cutaneous melanoma. © 2018 IEEE.","10.1109/CW.2018.00055","Artificial intelligence for cognitive health; Computational intelligence; Cuckoo search algorithm; Cutaneous melanoma; Machine-driven segmentation; Outline curves","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061430957&doi=10.1109%2fCW.2018.00055&partnerID=40&md5=534fafc9878cfbb356cd2636cd08c14a"
"Second-harmonic generation imaging analysis can help distinguish sarcoidosis from tuberculoid leprosy","Utino F.L.; Garcia M.; Velho P.E.N.F.; Da Costa França A.F.E.; Stelini R.F.; Pelegati V.B.; Cesar C.L.; De Souza E.M.; Cintra M.L.; Damiani G.V.","2018","0","1","0","0","0","Unique","0","","","","","","","Sarcoidosis and tuberculoid leprosy (TL) are prototypes of granulomatous inflammation in dermatology, which embody one of the histopathology limitations in distinguishing some diseases. Recent advances in the use of nonlinear optical microscopy in skin have enabled techniques, such as second-harmonic generation (SHG), to become powerful tools to study the physical and biochemical properties of skin. We use SHG images to analyze the collagen network, to distinguish differences between sarcoidosis and TL granulomas. SHG images obtained from skin biopsies of 33 patients with TL and 24 with sarcoidosis retrospectively were analyzed using first-order statistics (FOS) and second-order statistics, such as gray-level co-occurrence matrix (GLCM). Among the four parameters evaluated (optical density, entropy, contrast, and second angular moment), only contrast demonstrated statistical significance, being higher in sarcoidosis (p = 0.02; 4908.31 versus 2822.17). The results may indicate insufficient differentiating power for most tested FOS and GLCM parameters in classifying sarcoidosis and TL granulomas, when used individually. But in combination with histopathology (H&E and complementary stains, such as silver and fast acid stains), SHG analysis, like contrast, can contribute to distinguishing between these diseases. This study can provide a way to evaluate collagen distribution in granulomatous diseases. © 2018 SPIE. All rights reserved.","10.1117/1.JBO.23.12.126001","granulomatous diseases; sarcoidosis; second-harmonic generation; tuberculoid leprosy.","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058264703&doi=10.1117%2f1.JBO.23.12.126001&partnerID=40&md5=e67f3c86e004a8aca260cb09c425c5b5"
"Segmentation of lesions in skin image based on salient object detection with deeply supervised learning","Ji W.; Cai L.; Chen W.; Chen M.; Chai G.","2018","1","1","0","0","0","Unique","0","","","","","","","In this paper, a binary segmentation method HCDS based on salient object detection is proposed to solve the segmentation of lesions in skin images. The original U-Net model encounters some problems in its application to skin image segmentation, one of which is the non-pathological region information remained in the segmentation results. Our HCDS method improves its basic structure by adding a hybrid convolution module to the direct connection between the down-sampling and up-sampling. It deepens the abstract understanding of the input features in shallow layers and further eliminate the information interference of the non-pathological regions. Besides, the method employs a deeply supervised structure in each stage of up-sampling to learn from the output feature and ground truth. Finally, the HCDS integrates the multi-path outputs to obtain the best result. The experimental results show that the proposed method HCDS can effectively segment the lesion regions from the skin images. Our evaluation metrics about the HCDS are obviously superior to the original U-Net's. © 2018 IEEE.","10.1109/CompComm.2018.8780745","Deep learning; Image segmentation; Medical image processing; Salient object detection","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070807830&doi=10.1109%2fCompComm.2018.8780745&partnerID=40&md5=69cef5cb3d11c76aca4ba63f0e643267"
"Characterizing the stratum corneum structure, barrier function, and chemical content of human skin with coherent Raman scattering imaging","Osseiran S.; Cruz J.D.; Jeong S.; Wang H.; Fthenakis C.; Evans C.L.","2018","1","1","0","0","0","Unique","0","","","","","","","The most superficial layer of the epidermis, the stratum corneum, plays a crucial role in retaining hydration; if its structure or composition is compromised, dry skin may result as a consequence of poor water retention. Dry skin is typically treated with topical application of humectant agents that attract water into the skin. Corneometry, the industry standard for measuring skin hydration, works by assessing the bulk electrical properties of skin. However, this technique samples a large volume of tissue and thus does not resolve the biochemical changes that occur at the cellular level that may underlie mechanisms of dry skin. These limitations can be addressed using coherent Raman scattering (CRS) microscopy to probe the intrinsic vibrational modes of chemical groups such as lipids and water. In the present study, ex vivo human skin explants undergoing dehydration and humectant-induced rehydration were measured via CRS imaging and corneometry. Corneometry data and chemically specific images were obtained from the stratum corneum of each patient sample at each timepoint. The resulting data was statistically analyzed using linear mixed effect model regression analysis. The cellular imaging data revealed water loss in the stratum corneum during dehydration that was correlated with corneometer readings. Interestingly, the imaging data and corneometer readings show differences under the experimental rehydration conditions. The rehydration results suggest that hydration restored by the humectant agents may not be retained by the corneocytes in the ex vivo model system. Given the complementary nature of corneometry, a bulk assessment tool, and CRS microscopy, a modality with subcellular resolution implemented here in an en-face tissue imaging setup, these techniques can be used to measure uptake and efficacy of topical compounds in order to better understand their mode of action and improve therapeutic applications. © 2018 Optical Society of America.","10.1364/BOE.9.006425","","45","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057833695&doi=10.1364%2fBOE.9.006425&partnerID=40&md5=e1d9d987f29bc7f303c2680fca058969"
"IFNγ-activated dermal lymphatic vessels inhibit cytotoxic T cells in melanoma and inflamed skin","Lane R.S.; Femel J.; Breazeale A.P.; Loo C.P.; Thibault G.; Kaempf A.; Mori M.; Tsujikawa T.; Chang Y.H.; Lund A.W.","2018","1","1","0","0","0","Unique","0","","","","","","","Mechanisms of immune suppression in peripheral tissues counteract protective immunity to prevent immunopathology and are coopted by tumors for immune evasion. While lymphatic vessels facilitate T cell priming, they also exert immune suppressive effects in lymph nodes at steady-state. Therefore, we hypothesized that peripheral lymphatic vessels acquire suppressive mechanisms to limit local effector CD8                             +                              T cell accumulation in murine skin. We demonstrate that nonhematopoietic PD-L1 is largely expressed by lymphatic and blood endothelial cells and limits CD8                             +                              T cell accumulation in tumor microenvironments. IFNγ produced by tissue-infiltrating, antigen-specific CD8                             +                              T cells, which are in close proximity to tumor-associated lymphatic vessels, is sufficient to induce lymphatic vessel PD-L1 expression. Disruption of IFNγ-dependent crosstalk through lymphatic-specific loss of IFNγR boosts T cell accumulation in infected and malignant skin leading to increased viral pathology and tumor control, respectively. Consequently, we identify IFNγR as an immunological switch in lymphatic vessels that balances protective immunity and immunopathology leading to adaptive immune resistance in melanoma.                          © 2018 Lane et al.","10.1084/jem.20180654","","133","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057354722&doi=10.1084%2fjem.20180654&partnerID=40&md5=03c178062017130ef4f03f7817a9357d"
"Segmenting skin images for cancer detection","Abdel Kader R.; El Hajj Chehade W.; Al-Zaart A.","2018","1","1","0","0","0","First occurrence","0","","","","","","","The analysis of medical images for skin cancer detection is rising. A fundamental step in image analysis is segmentation. One of the segmentation techniques is thresholding, which is based on finding the optimal threshold value that partitions the image into multiple classes. Otsu's method, a known thresholding technique searches iteratively for the optimal threshold. It assumes that an image has a Gaussian distribution, which does not always apply to the data in skin cancer images. Skin cancer images usually have a lognormal distribution. We, therefore, propose a Lognormal variant of the Otsu's sequential method to find the optimal threshold. The sequential search tries all 255 possible values of the threshold, which is time consuming. We therefore propose an iterative Lognormal method, which we found by computing the derivative of Otsu's optimization formula using a Lognormal distribution. We applied our method on 20 skin cancer images, and we showed that it yields threshold values and segmented images better than the traditional Otsu's-Gaussian method. Our proposed method uses on average only 6.5 iterations, which saves time and CPU power, compared to the sequential search, which uses 255 iterations. We conclude that Otsu-Lognormal segmentation is more suitable for skin cancer images. © 2018 IEEE.","10.1109/CSCI46756.2018.00080","Between class-variance; Image segmentation; Lognormal distribution; Skin cancer; Thresholding","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078530753&doi=10.1109%2fCSCI46756.2018.00080&partnerID=40&md5=babe4bee8380a5fb7331ffbd38619eec"
"Skin disorder diagnosis assisted by lesion color adaptation","Petrellis N.","2018","1","1","0","0","0","First occurrence","0","","","","","","","A technique that counterbalances the variations in the color features of skin disorder lesions is tested in the framework of a skin disease diagnosis application. This application attempts to recognize a skin disorder by photographs displaying a body part with normal skin and lesion. These color feature variations are caused by different lighting condition or different settings used during the analysis of the photograph. Although the color features of the lesions depend on the stage of the disease, the color of the patient, etc, a significant accuracy improvement can be achieved if a simple color adaptation proposed in this paper is also taken into account. A sensitivity improvement of up to 150% can be measured (e.g., from 45% to 68% in Papillomas) in most of the skin disorders that have been tested. The Skin Disease application that employs the proposed color adaptation technique can be implemented on any low cost smart phone. It can serve as a diagnosis assistant for dermatologists or a tool for remote monitoring of skin disorders. An important advantage of the Skin Disease application is that it allows the end user to customize the disorder recognition rules or extend the supported set of diseases. © 2018 Copyright is held by the owner/author. Publication rights licensed to ACM.","10.1145/3291533.3291565","Classification; Color adaptation; Histograms; Image processing; Image Segmentation; Lesions; Skin disorders; Smart phone app","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060848055&doi=10.1145%2f3291533.3291565&partnerID=40&md5=8a6fc9329120b4dc8d2efbfbd45109f8"
"Identification of Melanoma in Dermoscopy Images Using Image Processing Algorithms","Asha Gnana Priya H.; Anitha J.; Poonima Jacinth J.","2018","0","1","0","0","0","First occurrence","0","","","","","","","Skin cancer is the most common of all human cancers and is always misunderstood with other kind of skin diseases, so accurate early detection of skin cancer is essential. The main objective of this paper is to segment the lesion and identify melanoma from dermoscopy images. A total of 170 dermoscopy images are used in this research. Firstly, the input images are enhanced for better processing then, the lesion portion is segmented from the enhanced image by two methods 1.Otsu thresholding 2.Morphological operations. The descriptive features are extracted from the segmented lesion. The extracted feature values are used to compute the Total Dermatascopy Score (TDS), which is used to find the presence or absence of melanoma in dermoscopy images. Classification accuracy is calculated to assess the performance of the proposed algorithm. © 2018 IEEE.","10.1109/ICCPCCT.2018.8574277","Dermoscopy; Feature Extraction; Melanoma; Segmentation; Skin cancer; Total Dermatoscopy Score(TDS)","25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060006701&doi=10.1109%2fICCPCCT.2018.8574277&partnerID=40&md5=f3067c8008e659b8533ea96b1129cc33"
"Deep Learning for Two-Step Classification of Malignant Pigmented Skin Lesions","Kaymak S.; Esmaili P.; Serener A.","2018","1","1","0","0","0","Unique","0","","","","","","","Skin cancer is one of the most common types of cancer. Its early detection drastically improves outcomes and saves human lives. Well known skin cancer types are melanoma, basal cell carcinoma and squamous cell carcinoma. Melanoma is melanocytic malignant while basal cell carcinoma and squamous cell carcinoma are non-melanocytic malignant. Even though the diagnosis of these cancer types is done by a skin biopsy, automatic detection of skin cancer using computerized methods may lead to a faster and a more accurate diagnosis. The majority of automated skin cancer detection methods proposed by researchers so far concentrated only on melanocytic malignant type melanoma. Non-melanocytic malignant skin lesions could not be investigated in detail due to the lack of available datasets with different lesion classes. In this paper, an automatic detection of malignant pigmented skin lesions is investigated. For this, the two-step skin lesion diagnostic procedure of the dermatologists is followed. Using a deep learning model, the skin lesion is first classified as melanocytic or non-melanocytic and then malignant types are detected using other deep learning models. The performance evaluations show that melanocytic and non-melanocytic skin lesions are detected with the highest accuracy. They also show that melanocytic malignant skin lesions can be classified with a higher accuracy than non-melanocytic malignant skin lesions. © 2018 IEEE.","10.1109/NEUREL.2018.8587019","Deep learning; dermoscopic skin images; malignant skin lesions; skin cancer; two-step diagnostic","44","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060954153&doi=10.1109%2fNEUREL.2018.8587019&partnerID=40&md5=667ae77d6a5a07d8158d9d87f6135172"
"Advances in deep learning techniques for medical image analysis","Niyaz U.; Sambyal A.S.; Devanand","2018","0","1","0","0","0","Unique","0","","","","","","","Deep learning is contributing to the high level of services to the healthcare sector. As the digital medical data is increasing exponentially with time, early detection and prediction of diseases are becoming more efficient because of the deep learning techniques which reduce the fatality rate to a great extent. The main focus of this paper is to provide the comprehensive review of deep learning in the domain of medical image processing and analysis. We have demonstrated the use of new deep learning architectures in oncology for the prediction of different types of cancer like the brain, lung, skin, etc. The state-of-the-art architectures effectively carry out analysis of 2D and 3D medical images to make the diagnosis of patients faster and more accurate. The use of popular approaches in machine learning such as ensemble and transfer learning with fine-tuning of parameters improve the performance of the deep neural networks in medical image analysis. The existing deep networks urge the new image classification network called Capsule Network (CapsNet) to make the classification and detection comparatively better. The equivariance characteristics of CapsNet make it more influential as it discourages the effect of any structural invariance of an input image on the network. © 2018 IEEE.","10.1109/PDGC.2018.8745790","3D CNN; cancer; capsule network; convolutional neural network; deep learning; ensemble learning; transfer learning","30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069527514&doi=10.1109%2fPDGC.2018.8745790&partnerID=40&md5=c6e8ffc0128470adcbcbc7c692f7751f"
"A New Clustering-based Thresholding Method for Human Skin Segmentation Using HSV Color Space","Feitosa R.D.F.; Da Silva Soares A.; Pereyra L.C.","2018","1","1","0","0","0","Unique","0","","","","","","","Skin detection based on color can be applied in eHealth systems for preventive healthcare and computer-aided diagnosis. These algorithms could be incorporated in acquisition and preprocessing steps of the applications that assist with skincare, as prevention and detection of melanoma. In this paper we present the results of a study that investigated the reduction of the color spectrum in the HSV system for sample-based skin detection of individuals of different ages and ethnicities. The proposed HSV filter reduced the color spectrum by 97.4648% so as to select candidates for human skin tones. It achieved low sensitivity (54.6333%) and high specificity (92.6390%) in human skin detection in color digital images when compared to the performance of other algorithms proposed in the literature. Different from other filters described in the literature which propose a single interval for human skin in the HSV system, this model presents and discusses 13 intervals in the possible spectrum which present a well-defined variation in terms of tone. © 2018 IEEE.","10.1109/ISCC.2018.8538604","clustering; color segmentation; HSV; skin detection; thresholding","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059217372&doi=10.1109%2fISCC.2018.8538604&partnerID=40&md5=6ed91a7cea10b2f37373c0966f707b33"
"An Automated Classification Framework for Pressure Ulcer Tissues Based on 3D Convolutional Neural Network","Elmogy M.; Garcia-Zapirain B.; Elmaghraby A.S.; El-Baz A.","2018","0","1","0","0","0","Unique","0","","","","","","","Pressure ulcer (PU) is a clinical pathology of localized deterioration to the underlying tissues as well as to the skin, which is generated by friction and pressure. A trustworthy diagnosis of PU, which is supported by accurate assessment, is critical to have effective therapy and save the patient's life. In this paper, we propose an automatic classification framework to segment and classify various tissues to help in diagnosis and treatment of PU. The proposed framework consists of two main stages, which are region of interest (ROI) extraction and tissue segmentation stages. The main idea is to extract various models and features from PU RGB images and supply them to multi-path 3D convolution neural network (CNN) to segment slough, necrotic eschar, and granulation tissues to help in assessing the status of PU. ROI is extracted by supplying three different color models to the CNN, which are RGB, HSV, and YCbCr. Then, the PU tissues are classified by providing four various models to the 3D CNN. These models are the original RGB image, the smoothed image with a pre-selected Gaussian kernel, and the 1                             st                             -order models of prior and current visual appearance. The framework was trained and tested on 100 color RGB PU images. The classification accuracy was evaluated using the area under the curve (AUC), the percentage area distance (PAD), and Dice similarity coefficient (DSC). The obtained preliminary results have AUC of 96%, PAD of 10%, and DSC of 93%. These experimental results are promising and can lead to an accurate assessment of the PU status.                          © 2018 IEEE.","10.1109/ICPR.2018.8546081","","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059763731&doi=10.1109%2fICPR.2018.8546081&partnerID=40&md5=8ea415a7022e9a1f9ae0328ec7dc7857"
"Skin Lesion Segmentation via Dense Connected Deconvolutional Network","Li H.; He X.; Yu Z.; Zhou F.; Cheng J.-Z.; Huang L.; Wang T.; Lei B.","2018","1","1","0","0","0","Unique","0","","","","","","","Dermoscopy imaging analysis is a routine procedure for diagnosis and treatment of skin lesions. Segmentation is the very first step to demarcate skin lesions for further quantitative analysis. However, it is a challenging task due to various changes from different viewpoints and scales of skin lesions. To handle these challenges, we devise a new dense deconvolutional network (DDN) for skin lesion segmentation based on encoding module and decoding module. Our devised network consists of convolution unit, dense deconvolutionallayer (DDL) and chained residual pooling block. DDL is adopted to restore the high resolution of the original input by upsampling, while the chained residual pooling is utilized to fuse multilevel features. Also, the hierarchical supervision is added to capture low level detailed boundary information. The DDN is trained in an end-to-end manner and free of prior knowledge and complicated post-processing procedures. With fusing the local and global contextual information, the high-resolution prediction output is obtained. The validation on the public ISBI 2016 and 2017 skin lesion challenge dataset demonstrates the effectiveness of our proposed method. © 2018 IEEE.","10.1109/ICPR.2018.8545136","Chained residual pooling; Dense deconvolutionallayer; Dermoscopy image; Skin lesion segmentation","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059754648&doi=10.1109%2fICPR.2018.8545136&partnerID=40&md5=6a5653921aedaca1e68990c313f7aafb"
"Hair detection and lesion segmentation in dermoscopic images using domain knowledge","Pathan S.; Prabhu K.G.; Siddalingaswamy P.C.","2018","0","1","0","0","0","First occurrence","0","","","","","","","Automated segmentation and dermoscopic hair detection are one of the significant challenges in computer-aided diagnosis (CAD) of melanocytic lesions. Additionally, due to the presence of artifacts and variation in skin texture and smooth lesion boundaries, the accuracy of such methods gets hampered. The objective of this research is to develop an automated hair detection and lesion segmentation algorithm using lesion-specific properties to improve the accuracy. The aforementioned objective is achieved in two ways. Firstly, a novel hair detection algorithm is designed by considering the properties of dermoscopic hair. Second, a novel chroma-based geometric deformable model is used to effectively differentiate the lesion from the surrounding skin. The speed function incorporates the chrominance properties of the lesion to stop evolution at the lesion boundary. Automatic initialization of the initial contour and chrominance-based speed function aids in providing robust and flexible segmentation. The proposed approach is tested on 200 images from PH2 and 900 images from ISBI 2016 datasets. Average accuracy, sensitivity, specificity, and overlap scores of 93.4, 87.6, 95.3, and 11.52% respectively are obtained for the PH2 dataset. Similarly, the proposed method resulted in average accuracy, sensitivity, specificity, and overlap scores of 94.6, 82.4, 97.2, and 7.20% respectively for the ISBI 2016 dataset. Statistical and quantitative analyses prove the reliability of the algorithm for incorporation in CAD systems. [Figure not available: see fulltext.]. © 2018, International Federation for Medical and Biological Engineering.","10.1007/s11517-018-1837-9","Color; Dermoscopy; Hair shafts; Lesion segmentation; Melanoma; Skin; Texture","32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055127649&doi=10.1007%2fs11517-018-1837-9&partnerID=40&md5=d43719abf99d3cc1239e8be02907486b"
"New Compact Deep Learning Model for Skin Cancer Recognition","Ly P.; Bein D.; Verma A.","2018","1","1","0","0","0","First occurrence","0","","","","","","","Deep learning neural networks have made significant progress in image analysis and have been used for skin cancer recognition. Early detection and proper treatments for malignant skin cancer cases are vital to ensure high survival rate in patients. We present a novel deep learning based convolutional neural network (CNN) model for generating compatible models on mobile platforms such as Android and iOS. The proposed model was tested on the grand challenge PHDB melanoma dataset. The best performing proposed model excels in the following ways: (1) it outperforms the baseline model in terms of accuracy by 1%; (2) it consists of 60% fewer parameters compared to the base model and thereby it is more efficient on mobile platforms. Furthermore, the model is more compact and retains high accuracy without the need to be downsized; (3) in conjunction with advanced regularization techniques such as dropout and data augmentation, the proposed CNN model excelled when implemented on state-of-the-art frameworks such as Keras and TensorFlow. Additionally, we were able to successfully deploy it on the iOS and Android mobile systems. The proposed model could also be lucrative towards other datasets for image classification on mobile platform. © 2018 IEEE.","10.1109/UEMCON.2018.8796628","CNN; Deep Learning; Melanoma; Mobile Systems; PHDB; Skin Cancer","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071582796&doi=10.1109%2fUEMCON.2018.8796628&partnerID=40&md5=e5831d19675e70751960cb554238c2f0"
"Learning based segmentation of skin lesion from dermoscopic images","Ammar M.; Khawaja S.G.; Atif A.; Akram M.U.; Sakeena M.","2018","1","1","0","0","0","First occurrence","0","","","","","","","Segmentation is the pre-requisite process in most of the computer aided diagnosis systems for medical imaging. Presence of different artifacts makes segmentation of skin lesion very difficult. Abnormal growth of artifacts can appear as false positives and can degrade the performance of the diagnosis systems. It can be avoided only when false structures are removed while extracting the lesion. To address this issue, this paper proposes deep leaning for skin lesion segmentation. Within this framework, automated skin lesion segmentation is proposed which achieves high accuracy segmentation of skin lesion. Our proposed architecture is 31 layers deep with same filter size. The validity of the proposed techniques is tested on two publically available databases of PH2 and ISIC 2017. Experimental results show the efficiency of the proposed approaches. The proposed method gives Dice Coefficient of 92.3% for PH2 Dataset while Dice Coefficient of 85.5% for ISIC 2017 Dataset. © 2018 IEEE.","10.1109/HealthCom.2018.8531156","Automatic segmentation; Convolution Neural Network; Deep Learning; Dermoscopy; Dice Coefficient; Melanoma","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058319271&doi=10.1109%2fHealthCom.2018.8531156&partnerID=40&md5=4b394b2fe389ae0d7390ce1bd177fa0a"
"Multimodal skin lesion classification using deep learning","Yap J.; Yolland W.; Tschandl P.","2018","1","1","0","0","0","Unique","0","","","","","","","While convolutional neural networks (CNNs) have successfully been applied for skin lesion classification, previous studies have generally considered only a single clinical/macroscopic image and output a binary decision. In this work, we have presented a method which combines multiple imaging modalities together with patient metadata to improve the performance of automated skin lesion diagnosis. We evaluated our method on a binary classification task for comparison with previous studies as well as a five class classification task representative of a real-world clinical scenario. We showed that our multimodal classifier outperforms a baseline classifier that only uses a single macroscopic image in both binary melanoma detection (AUC 0.866 vs 0.784) and in multiclass classification (mAP 0.729 vs 0.598). In addition, we have quantitatively showed the automated diagnosis of skin lesions using dermatoscopic images obtains a higher performance when compared to using macroscopic images. We performed experiments on a new data set of 2917 cases where each case contains a dermatoscopic image, macroscopic image and patient metadata. © 2018 The Authors. Experimental Dermatology Published by John Wiley & Sons Ltd","10.1111/exd.13777","deep learning; dermatology; dermatoscopy; feature fusion; multimodal","251","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053925211&doi=10.1111%2fexd.13777&partnerID=40&md5=3b0a55f6a88e8d351c2bf9d0a11670d8"
"Principles of skin cancer detection in image processing: Challenges and techniques","Omar Adil Dheyab A.; Rahmatullah B.; Hashim C.M.","2018","1","1","0","0","0","Unique","0","","","","","","","Skin cancer is most common and widespread type of cancer. Fortunately, its early diagnosis assists to prevent and cure several cases and increase the possibilities of reducing its dangerous effect. However, proper detection of skin cancer especially malignant melanoma in its early stages is still challenging. Image processing is a good choice for skin cancer early detection. Image processing techniques for skin cancer detection commonly include several stages such as pre-processing to enhance images, segment the interest regions to extract significant features, and finally perform classification process. This paper introduces the principles of skin cancer detection in image processing and addresses the challenges of each stage and the common techniques used in analysis.. © 2018, Indian Journal of Public Health Research and Development. All rights reserved.","10.5958/0976-5506.2018.01674.1","Classification; Feature extraction; Segmentation; Skin cancer","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058174134&doi=10.5958%2f0976-5506.2018.01674.1&partnerID=40&md5=e7a208a9050257d726d80ac8c42c2b44"
"Segmentation of Both Diseased and Healthy Skin from Clinical Photographs in a Primary Care Setting","Codella N.C.F.; Anderson D.; Philips T.; Porto A.; Massey K.; Snowdon J.; Feris R.; Smith J.","2018","1","1","0","0","0","Unique","0","","","","","","","This work presents the first segmentation study of both diseased and healthy skin in standard camera photographs from a clinical environment. Challenges arise from varied lighting conditions, skin types, backgrounds, and pathological states. For study, 400 clinical photographs (with skin segmentation masks) representing various pathological states of skin are retrospectively collected from a primary care network. 100 images are used for training and fine-tuning, and 300 are used for evaluation. This distribution between training and test partitions is chosen to reflect the difficulty in amassing large quantities of labeled data in this domain. A deep learning approach is used, and 3 public segmentation datasets of healthy skin are collected to study the potential benefits of pretraining. Two variants of U-Net are evaluated: U-Net and Dense Residual U-Net. We find that Dense Residual U-Nets have a 7.8% improvement in Jaccard, compared to classical U-Net architectures (0.55 vs. 0.51 Jaccard), for direct transfer, where fine-tuning data is not utilized. However, U-Net outperforms Dense Residual U-Net for both direct training (0.83 vs. 0.80) and fine-tuning (0.89 vs. 0.88). The stark performance improvement with fine-tuning compared to direct transfer and direct training emphasizes both the need for adequate representative data of diseased skin, and the utility of other publicly available data sources for this task. © 2018 IEEE.","10.1109/EMBC.2018.8512980","","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056647561&doi=10.1109%2fEMBC.2018.8512980&partnerID=40&md5=37f901a2379533efd772b5b18dc47c82"
"Research on Skin Cancer Cell Detection Using Image Processing","Jana E.; Subban R.; Saraswathi S.","2018","1","1","0","0","0","First occurrence","0","","","","","","","Out of the three basic types of skin cancer, namely, Basal Cell Carcinoma (BCC), Squamous Cell Carcinoma (SCC) and Melanoma, Melanoma is the most dangerous in which survival rate is very low. Early detection of Melanoma can potentially improve survival rate. The skin cancer detection technology is broadly divided into four basic components, viz., image preprocessing which includes hair removal, de-noise, sharpening, resize of the given skin image, segmentation which is used for segmenting out the region of interest from the given image. Different methods can be used for segmentation. Some commonly used segmentation algorithms are k-means, threshold in histogram etc., features extraction from the segmented image and classification of the image from the features set extracted from segmented image. Different classification algorithms can be used for this purpose. The recent skin cancer detection technology uses machine learning and deep learning based algorithms for classification. The most commonly used classification algorithms are support vector machine (SVM), feed forward artificial neural network, deep convolutional neural network. This paper provides a study and analysis on In this paper, an extensive literature survey of current technology is made for skin cancer detection and an accurate comparison among state of the art algorithm for the same. © 2017 IEEE.","10.1109/ICCIC.2017.8524554","Artificial Neural Network (ANN); Image Segmentation; Melanoma Skin Cancer; Skin Cancer; Support Vector Machine (SVM)","53","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057994452&doi=10.1109%2fICCIC.2017.8524554&partnerID=40&md5=e2f93bfe34da4781b0d78d202e9b7d60"
"Fast Skin Lesion Segmentation via Fully Convolutional Network with Residual Architecture and CRF","Luo W.; Yang M.","2018","1","1","0","0","0","First occurrence","0","","","","","","","Melanoma is known to be the most fatal form of skin cancers. In order to achieve automated diagnosis of such disease, a system is needed to accurately locate suspicious skin lesions using images captured by standard digital cameras. Recently, there exists a trend for the use of Fully Convolutional Net-work(FCN) to perform image segmentation task. In this paper, we propose a FCN-based processing pipeline that incorporates a deep neural net and a graphical model, to attain a segmentation mask of lesion region from normal skin. Our method extends the residual network by adding a transposed convolution layer to yield a FCN architecture. We demonstrate that the noisy outcome from FCN can be refined by a fully connected Conditional Random Field(CRF). Our model enjoys three major advantages over existing algorithms: Simpler process pipeline, state-of-art accuracy in terms of segmentation sensitivity(95.6%) and fast inference time. © 2018 IEEE.","10.1109/ICPR.2018.8545571","Conditional Random Field; Fully Convolutional Network; Image Segmentation; Melanoma; Transposed Convolution","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059764483&doi=10.1109%2fICPR.2018.8545571&partnerID=40&md5=2969825c5d265a291c3c72c7680a3862"
"Automated Detection of Facial Disorders (ADFD): a novel approach based-on digital photographs","Goceri E.; Gunay M.","2018","0","1","0","0","0","Unique","0","","","","","","","Abnormal regions on a face are often indicative of facial dermatological diseases, such as rosacea, eczema, allergy, burn injury, facial rash and acne. Identification and quantitative evaluation of these facial disorders is often subjective and currently done by expert dermatologists. However, with the advances in image processing techniques, it is now possible to consistently identify, classify and objectively quantify facial skin disorders using digital photographs. Furthermore, digital photographs can be used to assess progression of the diseases by applying time-series analysis on infected (abnormal) facial regions of the photograph. In this paper, we propose a novel real-time approach for detection and segmentation of abnormal facial regions. Experimental results showed that the proposed method is efficient for segmentation of abnormal regions, which were caused by facial fever or disease, from digital photographs in terms of accuracy and required processing time. © 2017, © 2017 Informa UK Limited, trading as Taylor & Francis Group.","10.1080/21681163.2017.1317292","facial disorders; Facial fever; image segmentation; level sets","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031395465&doi=10.1080%2f21681163.2017.1317292&partnerID=40&md5=9be9f3aecbdc3c4efbd523d8a24535ec"
"A review on smartphone skin cancer diagnosis apps in evaluation and benchmarking: coherent taxonomy, open issues and recommendation pathway solution","Zaidan A.A.; Zaidan B.B.; Albahri O.S.; Alsalem M.A.; Albahri A.S.; Yas Q.M.; Hashim M.","2018","1","1","0","0","0","First occurrence","0","","","","","","","This research aims to review the attempts of researchers in response to the new and disruptive technology of skin cancer applications in terms of evaluation and benchmarking, in order to identify the research landscape from the literature into a cohesive taxonomy. An extensive search was conducted for articles dealing with ‘skin cancer’, ‘apps’ and ‘smartphone’ or ‘mHealth’ in different variations to find all the relevant articles in three main databases, namely, “Web of Science”, “Science Direct”, and “IEEE explore”. These databases are considered wide enough to cover medical and technical literature. The final classification scheme outcome of the dataset contained 110 articles that were classified into four classes: development and design; analytical; evaluative and comparative; and review and survey studies. Afterwards, another filtering process was achieved based on the evaluation criteria error rate within the dataset, time complicity and reliability, which are used in skin cancer applications. The final classification scheme outcome of the dataset contained 89 articles distributed in mapping and crossover with four sections concluded from 110 articles. Development and design studies, analytical studies, evaluative and comparative studies and articles of reviews and surveys comprised of 48.3146%, 22.4719%, 16.8539% (15), and 12.3595% (11) of the reviewed articles, respectively. The basic features of this evolving approach were identified in these aspects. We also determined open issues in terms of evaluation and benchmarking that hamper the utility of this technology. Furthermore, with the exception of the 89 papers reviewed, the new recommendation pathway solution was described in order to improve the measurement process for smartphone-based skin cancer diagnosis applications. © 2018, IUPESM and Springer-Verlag GmbH Germany, part of Springer Nature.","10.1007/s12553-018-0223-9","Mobile health; Real-time apps; Skin cancer diagnosis, evaluation and benchmarking, smartphone","82","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052206797&doi=10.1007%2fs12553-018-0223-9&partnerID=40&md5=2ae673fb60ac157328673d6d0cb31ad1"
"Hardware Implementation of Hybrid Classifier to Detect Cancer Cells","Gowda M.N.; Rasheed A.I.","2018","0","1","0","0","0","First occurrence","0","","","","","","","Convolutional Neural Network and Support Vector Machine are the common machine learning algorithms for classification. Both the classification techniques are fused to develop a hybrid classifier. The hardware implementation of hybrid classifier can improve the performance of the system and reduce the power consumption for real time applications. The main aim of this study is early detection of cancer cell using hybrid classifier implemented on a low cost handheld device. Leukemia and melanoma are the blood and skin cancer respectively. Both are dangerous form of cancers, many deaths have occurred due to leukemia and melanoma. In this paper, a hardware design is proposed to implement hybrid classifier on FPGA. The proposed system is implemented on Zync SoC FPGA platform and it gives the high performance, low power consumption and low hardware utilization. © 2017 IEEE.","10.1109/INDICON.2017.8487787","Convolutional Neural Networks (CNN); FPGA; Support Vector Machine (SVM)","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056391291&doi=10.1109%2fINDICON.2017.8487787&partnerID=40&md5=2a37ad70d71cd883cc9160e369958544"
"Skin Cancer Segmentation with Entropy PAL MCET using Gaussian Distribution","Zreika N.A.; El Zaart A.; El Chakik A.; El Arwadi T.","2018","1","1","0","0","0","First occurrence","0","","","","","","","Skin cancer is the most common cancer diagnosis and it is the most preventable cancer. Diagnosis of skin cancer would be improved if an accurate skin image segmentation is available. The process of image segmentation is a fundamental step in many applications of image processing, yet current methods and techniques for image segmentation necessitate particular domain knowledge to define well the region of the cancer. To estimate an optimal threshold for skin cancer images, thresholding is used as the principal approach of segmentation. We propose a new method for skin cancer segmentation using a Minimum Cross Entropy Thresholding (MCET) method. We applied this method on bimodal skin cancer images and obtained promising experimental results. The resulting segmented skin cancer images yielded better estimation of the optimal threshold than does the same MCET method with Poisson distribution. © 2018 IEEE.","10.1109/iCATccT44854.2018.9001993","Bi modal technique; Computer-Aided Diagnosis; Gaussian distribution; Image Segmentation; Melanoma; Minimum Cross Entropy; Skin cancer; Threshold","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081404111&doi=10.1109%2fiCATccT44854.2018.9001993&partnerID=40&md5=42569da2e246c24d258402685ad63eee"
"Identification of skin tumours using statistical and histogram based features","Thamizhvani T.R.; Hemalatha R.J.; Babu B.; Josephin Arockia Dhivya A.; Joseph J.E.; Chandrasekaran R.","2018","1","1","0","0","0","Unique","0","","","","","","","Introduction: Skin tumour is uncontrolled growth of cells in skin. Skin tumour is becoming predominant in different parts of the world. Basal carcinoma, squamous carcinoma and melanoma are the skin cancer types common in India. The rate of survival depends on the cancer stages, if diagnosed early it can be treated completely. Statistical and histogram features can be defined as part of image processing algorithm used to identify the type of skin tumours based on the probabilistic occurrence and intensity of pixel values respectively. Aim: The aim was to illustrate easy identification process of skin tumours from dermal images using statistical and histogram features. Materials and Methods: Dermal images were obtained from the PH2 database for identification of two different types of skin tumours such as melanocytic nevi and malignant melanoma. Colour Histogram was used to differentiate the two categories. Pre-processing and segmentation was performed for extraction of statistical and histogram based features from the lesion. From the extracted features, mean and standard deviation values were calculated for proper identification of skin tumours. Further to improve the accuracy of the identification, neural network classifiers were used which defines more enhanced efficiency in detection of skin tumours. Results: Colour histogram was used to differentiate the two categories of skin tumours. Malignant melanoma possesses high peaks of channel pixels at both extremities of the histogram. Histogram and statistical based features derived from the lesion describes that malignant melanoma has higher values of mean and standard deviation of features derived from segmented lesions. Neural network classifiers were used for further accuracy of identification which distinguishes the two different categories of skin tumours. Conclusion: Colour histogram, statistical and histogram based features were derived for differentiation and identification of two categories of skin tumours. Thus, a simple and effective technique for description of skin tumours was determined. © 2018, Journal of Clinical and Diagnostic Research. All rights reserved.","10.7860/JCDR/2018/36258.12040","Colour histogram; Malignant melanoma; Neural networks","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052733842&doi=10.7860%2fJCDR%2f2018%2f36258.12040&partnerID=40&md5=3c27c078cfcdbf63c4fc30bc3001dd32"
"Machine learning aided tumor diagnosis","Zhao K.; Yang M.; Zhu J.; Wang Z.; Shen W.","2018","0","1","0","0","0","Unique","0","","","","","","","In recent years, the application of high-quality digital slides in pathological diagnosis has changed the traditional reading methods. As a result, a large number of quantitative analysis algorithms come into being. Among them, the machine deep learning algorithm has outperformed other algorithms in the analysis of large data, showing great potential in the analysis of pathological sections. The process of pathological image analysis based on machine learning consists of feature extraction and classification to determine the nature, grading and prognosis of tumors, which can improve the objectivity and accuracy of pathological diagnosis. At present, those fields in which machine learning aided pathological image analysis presents as a relatively mature diagnostic tool include the diagnosis and prognosis of breast cancer, the determination of the nature of skin cancer, the diagnosis and prognosis of lung cancer, and the grading of prostate cancer and cervical intraepithelial neoplasia. In this paper, the research progresses in these fields are reviewed and discussed. © 2018 by TUMOR All rights reserved.","10.3781/j.issn.1000-7431.2018.55.217","Artificial intelligence; Diagnosis; Neoplasms; Pathology; Prognosis","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055926561&doi=10.3781%2fj.issn.1000-7431.2018.55.217&partnerID=40&md5=abf835dc35630bff339142db90fda481"
"Automatic histologically-closer classification of skin lesions","Rebouças Filho P.P.; Peixoto S.A.; Medeiros da Nóbrega R.V.; Hemanth D.J.; Medeiros A.G.; Sangaiah A.K.; de Albuquerque V.H.C.","2018","1","1","0","0","0","Unique","0","","","","","","","According to the American Cancer Society, melanoma is one of the most common types of cancer in the world. In 2017, approximately 87,110 new cases of skin cancer were diagnosed in the United States alone. A dermatoscope is a tool that captures lesion images with high resolution and is one of the main clinical tools to diagnose, evaluate and monitor this disease. This paper presents a new approach to classify melanoma automatically using structural co-occurrence matrix (SCM) of main frequencies extracted from dermoscopy images. The main advantage of this approach consists in transform the SCM in an adaptive feature extractor improving his power of discrimination using only the image as parameter. The images were collected from the International Skin Imaging Collaboration (ISIC) 2016, 2017 and Pedro Hispano Hospital (PH2) datasets. Specificity (Spe), sensitivity (Sen), positive predictive value, F Score, Harmonic Mean, accuracy (Acc) and area under the curve (AUC) were used to verify the efficiency of the SCM. The results show that the SCM in the frequency domain work automatically, where it obtained better results in comparison with local binary patterns, gray-level co-occurrence matrix and invariant moments of Hu as well as compared with recent works with the same datasets. The results of the proposed approach were: Spe 95.23%, 92.15% and 99.4%, Sen 94.57%, 89.9% and 99.2%, Acc 94.5%, 89.93% and 99%, and AUC 92%, 90% and 99% in ISIC 2016, 2017 and PH2 datasets, respectively. © 2018 Elsevier Ltd","10.1016/j.compmedimag.2018.05.004","Image classification; Machine learning; Melanoma; Structural co-occurrence matrix","45","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048624238&doi=10.1016%2fj.compmedimag.2018.05.004&partnerID=40&md5=811aa6a730757e79ac3803551ba0f064"
"Evaluation of Levenberg-Marquardt neural networks and stacked autoencoders clustering for skin lesion analysis, screening and follow-up","Rundo F.; Conoci S.; Banna G.L.; Ortis A.; Stanco F.; Battiato S.","2018","1","1","0","0","0","Unique","0","","","","","","","Traditional methods for early detection of melanoma rely on the visual analysis of the skin lesions performed by a dermatologist. The analysis is based on the so-called ABCDE (Asymmetry, Border irregularity, Colour variegation, Diameter, Evolution) criteria, although confirmation is obtained through biopsy performed by a pathologist. The proposed method exploits an automatic pipeline based on morphological analysis and evaluation of skin lesion dermoscopy images. Preliminary segmentation and pre-processing of dermoscopy image by SC-cellular neural networks is performed, in order to obtain ad-hoc grey-level skin lesion image that is further exploited to extract analytic innovative hand-crafted image features for oncological risks assessment. In the end, a pre-trained Levenberg-Marquardt neural network is used to perform ad-hoc clustering of such features in order to achieve an efficient nevus discrimination (benign against melanoma), as well as a numerical array to be used for follow-up rate definition and assessment. Moreover, the authors further evaluated a combination of stacked autoencoders in lieu of the Levenberg-Marquardt neural network for the clustering step. © The Institution of Engineering and Technology 2018.","10.1049/iet-cvi.2018.5195","","29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053451652&doi=10.1049%2fiet-cvi.2018.5195&partnerID=40&md5=128284df3f10043a265eb9040c639c5f"
"Diagnosis of skin diseases using Convolutional Neural Networks","Rathod J.; Wazhmode V.; Sodha A.; Bhavathankar P.","2018","1","1","0","0","0","Unique","0","","","","","","","Dermatology is one of the most unpredictable and difficult terrains to diagnose due its complexity. In the field of dermatology, many a times extensive tests are to be carried out so as to decide upon the skin condition the patient may be facing. The time may vary from practitioner to practitioner. This is also based on the experience of that person too. So, there is a need of a system which can diagnose the skin diseases without any of these constraints. We propose an automated image based system for recognition of skin diseases using machine learning classification. This system will utilize computational technique to analyze, process, and relegate the image data predicated on various features of the images. Skin images are filtered to remove unwanted noise and also process it for enhancement of the image. Feature extraction using complex techniques such as Convolutional Neural Network (CNN), classify the image based on the algorithm of softmax classifier and obtain the diagnosis report as an output. This system will give more accuracy and will generate results faster than the traditional method, making this application an efficient and dependable system for dermatological disease detection. Furthermore, this can also be used as a reliable real time teaching tool for medical students in the dermatology stream. © 2018 IEEE.","10.1109/ICECA.2018.8474593","Artificial Intelligence; Automated Disease Diagnosis; Computational Intelligence; Computer Vision; Convolutional Neural Network; Deep Learning; Dermatology; Image Processing; Machine Learning; Neural Network","111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060845364&doi=10.1109%2fICECA.2018.8474593&partnerID=40&md5=e540a72df45e190264117179d041a559"
"Robust Feature Spaces from Pre-Trained Deep Network Layers for Skin Lesion Classification","Pereira Dos Santos F.; Antonelli Ponti M.","2018","1","1","0","0","0","First occurrence","0","","","","","","","The incidence of skin cancer in the world population is a public health concern, and the first diagnosis takes into account the appearance of lesions on skin. In this context, automated methods to aid the screening for malign lesions can be an important tool. However, the efficiency of developed methods depends directly on the quality of the generated feature space which may vary when considering different image datasets and sources. We present a detailed study of feature spaces obtained from deep convolutional networks (CNNs), using the benchmark PH2 dataset, considering three CNN architectures, as well as investigating different layers, impact of dimensionality reduction, use of colour quantisation and noise addition. Our results show that, features have discriminative capability comparable to competing methods with balanced accuracy 94%, and 95% with noise injection. Additionally, we present a study of fine-tuning and generalisation across image quantisation and noise levels, contributing to the discussion of learning features from deep networks and offering a guideline for future works. © 2018 IEEE.","10.1109/SIBGRAPI.2018.00031","","24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062222641&doi=10.1109%2fSIBGRAPI.2018.00031&partnerID=40&md5=ee589583351008ea133a81305163a60b"
"Skin lesion segmentation in dermoscopy images via deep full resolution convolutional networks","Al-masni M.A.; Al-antari M.A.; Choi M.-T.; Han S.-M.; Kim T.-S.","2018","1","1","0","0","0","Unique","0","","","","","","","Background and objective: Automatic segmentation of skin lesions in dermoscopy images is still a challenging task due to the large shape variations and indistinct boundaries of the lesions. Accurate segmentation of skin lesions is a key prerequisite step for any computer-aided diagnostic system to recognize skin melanoma. Methods: In this paper, we propose a novel segmentation methodology via full resolution convolutional networks (FrCN). The proposed FrCN method directly learns the full resolution features of each individual pixel of the input data without the need for pre- or post-processing operations such as artifact removal, low contrast adjustment, or further enhancement of the segmented skin lesion boundaries. We evaluated the proposed method using two publicly available databases, the IEEE International Symposium on Biomedical Imaging (ISBI) 2017 Challenge and PH2 datasets. To evaluate the proposed method, we compared the segmentation performance with the latest deep learning segmentation approaches such as the fully convolutional network (FCN), U-Net, and SegNet. Results: Our results showed that the proposed FrCN method segmented the skin lesions with an average Jaccard index of 77.11% and an overall segmentation accuracy of 94.03% for the ISBI 2017 test dataset and 84.79% and 95.08%, respectively, for the PH2 dataset. In comparison to FCN, U-Net, and SegNet, the proposed FrCN outperformed them by 4.94%, 15.47%, and 7.48% for the Jaccard index and 1.31%, 3.89%, and 2.27% for the segmentation accuracy, respectively. Furthermore, the proposed FrCN achieved a segmentation accuracy of 95.62% for some representative clinical benign cases, 90.78% for the melanoma cases, and 91.29% for the seborrheic keratosis cases in the ISBI 2017 test dataset, exhibiting better performance than those of FCN, U-Net, and SegNet. Conclusions: We conclude that using the full spatial resolutions of the input image could enable to learn better specific and prominent features, leading to an improvement in the segmentation performance. © 2018 Elsevier B.V.","10.1016/j.cmpb.2018.05.027","Deep learning; Dermoscopy; Full resolution convolutional network (FrCN); Melanoma; Skin lesion segmentation","404","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047600387&doi=10.1016%2fj.cmpb.2018.05.027&partnerID=40&md5=18812c13cc0b21ec98c5062d3b4aad2c"
"Adaptive activation functions for skin lesion classification using deep neural networks","Namozov A.; Ergashev D.; Cho Y.I.","2018","1","1","0","0","0","First occurrence","0","","","","","","","Skin cancer is considered one of the most common human malignancies, and melanoma is the deadliest form of this disease. Early detection can influence the outcome of the disease and improve the chance of surviving. The tremendous improvement of deep learning algorithms in image recognition tasks promises a great success for medical image analysis, in particular, skin lesion classification for melanoma diagnosis. Activation functions play an important role in the performance of deep neural networks for image recognition problems as well as medical image classification. In this paper, we show that a deep neural network model with adaptive piecewise linear units can achieve excellent results in skin disease recognition. Experimental results show that a convolutional neural network model with adaptive piecewise linear units outperforms the same network with different activation functions in the skin lesion classification task. All experiments are performed using the data provided in International Skin Imaging Collaboration (ISIC) 2018 Skin Lesion Analysis towards Melanoma Detection. © 2018 IEEE.","10.1109/SCIS-ISIS.2018.00048","Activation Functions; Convolutional Neural Networks; Deep learning; Skin Cancer","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067113394&doi=10.1109%2fSCIS-ISIS.2018.00048&partnerID=40&md5=ef22394ed5769d43d9e58069ae6d5051"
"The Effect of the Training Set Size in a Skin Disorder Classification Application","Petrellis N.","2018","1","1","0","0","0","Unique","0","","","","","","","An image processing technique for skin disorder classification is presented in this paper. A few photographs displaying the same skin disorder are statistically processed in order to define the range of the extracted features. These range limits form a Disease Signature. When a new photograph is analyzed a feature value is compared with the limits defined in each signature in order to select the most likely disease. The proposed method can be implemented on any low cost smart phone since the estimation of the employed features does not require complicated operations. The system is extendible since the Disease Signatures can be defined or customized by a user that is not necessarily qualified in computer science e.g., a dermatologist. Seven skin disorders are supported in the present version and the system is initially trained with a very small set of 3 to 5 photographs per disease. Then, an extended training set of 8 photographs is used, with an up to 2.66 times accuracy improvement. © 2018 IEEE.","10.1109/TSP.2018.8441474","histograms; image processing; kin disorders; lesions; mobile apps; skin infections","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053523466&doi=10.1109%2fTSP.2018.8441474&partnerID=40&md5=5945d84efdb667da881434d70590d8a4"
"Rethinking Skin Lesion Segmentation in a Convolutional Classifier","Burdick J.; Marques O.; Weinthal J.; Furht B.","2018","1","1","0","0","0","First occurrence","0","","","","","","","Melanoma is a fatal form of skin cancer when left undiagnosed. Computer-aided diagnosis systems powered by convolutional neural networks (CNNs) can improve diagnostic accuracy and save lives. CNNs have been successfully used in both skin lesion segmentation and classification. For reasons heretofore unclear, previous works have found image segmentation to be, conflictingly, both detrimental and beneficial to skin lesion classification. We investigate the effect of expanding the segmentation border to include pixels surrounding the target lesion. Ostensibly, segmenting a target skin lesion will remove inessential information, non-lesion skin, and artifacts to aid in classification. Our results indicate that segmentation border enlargement produces, to a certain degree, better results across all metrics of interest when using a convolutional based classifier built using the transfer learning paradigm. Consequently, preprocessing methods which produce borders larger than the actual lesion can potentially improve classifier performance, more than both perfect segmentation, using dermatologist created ground truth masks, and no segmentation altogether. © 2017, Society for Imaging Informatics in Medicine.","10.1007/s10278-017-0026-y","Convolutional neural networks; Deep learning; Machine learning; Medical decision support systems; Medical image analysis; Skin lesions","60","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031745245&doi=10.1007%2fs10278-017-0026-y&partnerID=40&md5=730309f20f68889563c32692481eb057"
"A Novel Approach for Automatic Identification of Psoriasis Affected Skin Area.","Arunkumar T.R.; Jayanna H.S.","2018","1","1","0","0","0","Unique","0","","","","","","","The paper presents the detection of psoriasis affected skin. Thecolor feature of the skin from RGB model, where the skin color is defined as redness, greenness, and blueness are analyzed. An algorithm is developed to differentiate affected area from non affected area. The color histogram analysis is carried out for more than fifty samples to analyse erythema in order to differentiate affected skin from non affected skin. Today dermatologists visually analyse the patients for the line of treatment which is biased by various external factors. The proposed model for diagnosis is not subjective where the decisions are based on various external factors such as emotions, part of the day and vary from dermatologist to dermatologist which may have a great impact on the treatment of the disorder. The algorithm is objective and minimizes the deviation in the line of treatment as it is not affected by intra and inter diagnosis by dermatologists. The RGB histogram is analyzed and a model is built based on mean and standard deviation to differentiate healthy skin and psoriasis disorder affected skin. © 2017 IEEE.","10.1109/ICECIT.2017.8453316","Erythema; Histogram; Mean and Standard Deviation; Texture","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054033952&doi=10.1109%2fICECIT.2017.8453316&partnerID=40&md5=a5cf60d1717068286275e9eca78c74bd"
"Improving Skin Lesion Segmentation with Generative Adversarial Networks","Bolelli F.; Pollastri F.; Paredes R.; Grana C.","2018","1","0","0","0","0","First occurrence","0","","","","","","","This paper proposes a novel strategy that employs Generative Adversarial Networks (GANs) to augment data in the image segmentation field, and a Convolutional-Deconvolutional Neural Network (CDNN) to automatically generate lesion segmentation mask from dermoscopic images. Training the CDNN with our GAN generated data effectively improves the state-of-the-art. © 2018 IEEE.","10.1109/CBMS.2018.00086","Convolutional Deconvolutional Neural Networks; Generative Adversarial Networks; Skin Lesion Segmentation","28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050970405&doi=10.1109%2fCBMS.2018.00086&partnerID=40&md5=52f63e23f34087624ed7d22158c75269"
"Skin lesion segmentation method for dermoscopy images using artificial bee colony algorithm","Aljanabi M.; Özok Y.E.; Rahebi J.; Abdullah A.S.","2018","1","0","0","0","0","Unique","0","","","","","","","The occurrence rates of melanoma are rising rapidly, which are resulting in higher death rates. However, if the melanoma is diagnosed in Phase I, the survival rates increase. The segmentation of the melanoma is one of the largest tasks to undertake and achieve when considering both beneath and over the segmentation. In this work, a new approach based on the artificial bee colony (ABC) algorithm is proposed for the detection of melanoma from digital images. This method is simple, fast, flexible, and requires fewer parameters compared with other algorithms. The proposed approach is applied on the PH2, ISBI 2016 challenge, the ISBI 2017 challenge, and Dermis datasets. These bases contained images are affected by different abnormalities. The formation of the databases consists of images collected from different sources; they are bases with different types of resolution, lighting, etc., so in the first step, the noise was removed from the images by using morphological filtering. In the next step, the ABC algorithm is used to find the optimum threshold value for the melanoma detection. The proposed approach achieved good results in the conditions of high specificity. The experimental results suggest that the proposed method accomplished higher performance compared to the ground truth images supported by a Dermatologist. For the melanoma detection, the method achieved an average accuracy and Jaccard's coefficient in the range of 95.24-97.61%, and 83.56-85.25% in these four databases. To show the robustness of this work, the results were compared to existing methods in the literature for melanoma detection. High values for estimation performance confirmed that the proposed melanoma detection is better than other algorithms, which demonstrates the highly differential power of the newly introduced features. © 2018 by the authors.","10.3390/sym10080347","Artificial bee colony (ABC); Dermoscopy; Heuristic method; Image segmentation; Skin melanoma","47","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052491100&doi=10.3390%2fsym10080347&partnerID=40&md5=0b0fe6c3c8e9c01fbf01c984a252a2cd"
"Analyzing Skin Lesions in Dermoscopy Images Using Convolutional Neural Networks","Singh V.; Nwogu I.","2018","1","1","0","0","0","First occurrence","0","","","","","","","In this paper, we discuss the problem of automatic skin lesion analysis, specifically melanoma detection and semantic segmentation. We accomplish this by using deep learning techniques to perform classification on publicly available dermoscopic images. Skin cancer, of which melanoma is a type, is the most prevalent form of cancer in the US and more than four million cases are diagnosed in the US every year. In this work, we present our efforts towards an accessible, deep learning-based system that can be used for skin lesion classification, thus leading to an improved melanoma screening system. For classification, a deep convolutional neural network architecture is first implemented over the raw images. In addition, hand-coded features such as 166-D color histogram distribution, edge histogram and Multiscale Color local binary patterns are extracted from the images and presented to a random forest classifier. The average of the outputs from the two mentioned classifiers is taken as the final classification result. The classification task achieves an accuracy of 80.3%, AUC score of 0.69 and a precision score of 0.81. For segmentation, we implement a convolutional-deconvolutional architecture and the segmentation model achieves a Dice coefficient of 73.5%. © 2018 IEEE.","10.1109/SMC.2018.00684","Classification algorithms; Convolutional Neural Networks (CNN); Dermatology; Learning systems","24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062242434&doi=10.1109%2fSMC.2018.00684&partnerID=40&md5=1800826cfb4e523946773014626bf5f1"
"A survey on automated melanoma detection","Okur E.; Turkan M.","2018","0","1","0","0","0","Unique","0","","","","","","","Skin cancer is defined as the rapid growth of skin cells due to DNA damage that cannot be repaired. Melanoma is one of the deadliest types of skin cancer, which originates from melanocytes. While other skin cancer types have limited spreading capabilities, the danger of melanoma comes from its ability to spread (metastasize) rapidly. Fortunately, it can be detected by visual inspection of the skin surface, and it is 100% curable if identified in the early stages. However, detection by “subjective visual inspection” creates an important problem, due to investigators’ different levels of experiences and education. Dermoscopy (dermatoscopy) has significantly increased the diagnostic accuracy of melanoma since late 90’s. In addition, several systems have been proposed in order to assist investigators or to perform an automatic melanoma detection. This survey focuses on the algorithms for automated melanoma detection in dermoscopic images through an extensive analysis of the stages in methodologies proposed in the literature, and by examining related concepts and describing possible future directions through open problems in this domain of research. © 2018 Elsevier Ltd","10.1016/j.engappai.2018.04.028","Automated detection; Dermoscopy; Image processing; Machine learning; Melanoma detection; Skin cancer","84","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047056100&doi=10.1016%2fj.engappai.2018.04.028&partnerID=40&md5=2aa4b6307bfeb335ec29140934e9f095"
"Deep Ensemble Learning for Skin Lesion Classification from Dermoscopic Images","Shahin A.H.; Kamal A.; Elattar M.A.","2018","1","1","0","0","0","Unique","0","","","","","","","Skin cancer is one of the leading causes of death globally. Early diagnosis of skin lesion significantly increases the prevalence of recovery. Automatic classification of the skin lesion is a challenging task to provide clinicians with the ability to differentiate between different kind of lesion categories and recommend the suitable treatment. Recently, Deep Convolutional Neural Networks have achieved tremendous success in many machine learning applications and have shown an outstanding performance in various computer-assisted diagnosis applications. Our goal is to develop an automated framework that efficiently performs a reliable automatic lesion classification to seven skin lesion types. In this work, we propose a deep neural network-based framework that follows an ensemble approach by combining ResNet-50 and Inception V3 architectures to classify the seven different skin lesion types. Experimental validation results have achieved accurate classification with an assuring validation accuracy up to 0.899. © 2018 IEEE.","10.1109/CIBEC.2018.8641815","deep learning; deep neural networks; diagnosis; melanoma; skin lesions","113","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063203458&doi=10.1109%2fCIBEC.2018.8641815&partnerID=40&md5=7f537c450ddd95dfdacaaa0786ae037d"
"Skin Cancer Classification using Deep Learning and Transfer Learning","Hosny K.M.; Kassem M.A.; Foaud M.M.","2018","1","1","0","0","0","First occurrence","0","","","","","","","Skin cancer, specially melanoma is one of most deadly diseases. In the color images of skin, there is a high similarity between different skin lesion like melanoma and nevus, which increase the difficulty of the detection and diagnosis. A reliable automated system for skin lesion classification is essential for early detection to save effort, time and human life. In this paper, an automated skin lesion classification method is proposed. In this method, a pre-trained deep learning network and transfer learning are utilized. In addition to fine-tuning and data augmentation, the transfer learning is applied to AlexNet by replacing the last layer by a softmax to classify three different lesions (melanoma, common nevus and atypical nevus). The proposed model is trained and tested using the ph2 dataset. The well-known quantative measures, accuracy, sensitivity, specificity, and precision are used in evaluating the performance of the proposed method where the obtained values of these measures are 98.61%, 98.33%, 98.93%, and 97.73%, respectively. The performance of the proposed method is compared with the existing methods where the classification rate of the proposed method outperformed the performance of the existing methods. © 2018 IEEE.","10.1109/CIBEC.2018.8641762","","232","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063229823&doi=10.1109%2fCIBEC.2018.8641762&partnerID=40&md5=d2734153e6628bd362b79d36893aff7b"
"Deep Convolutional Pixel-wise Labeling for Skin Lesion Image Segmentation","Youssef A.; Bloisi D.D.; Muscio M.; Pennisi A.; Nardi D.; Facchiano A.","2018","1","1","0","0","0","First occurrence","0","","","","","","","Melanoma is one of the deadliest form of cancer with an increasing incidence rate. The development of automatic diagnostic tools for the early detection of skin cancer lesions in dermoscopic images can help to reduce melanoma-induced mortality. In this paper, we present an automatic method for skin lesion image segmentation based on a deep learning algorithm for pixel-wise labeling. Experimental results have been obtained by testing two network architectures on publicly available data and, in order to show that the used approach is not data set related, we have used the ISIC database for training the network and the PH2 database for testing. The results show that the proposed approach achieves a very accurate segmentation even in presence of hair and air/oil bubbles. An additional contribution of this work is the development of a semi-automatic GUI for data annotation that can be used to generate more test images. © 2018 IEEE.","10.1109/MeMeA.2018.8438669","Deep Learning Image Processing; Dermoscopy Images; Melanoma Detection; Skin Lesion Segmentation","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053153323&doi=10.1109%2fMeMeA.2018.8438669&partnerID=40&md5=4fc411e66fcae18e1d4a272b613a2669"
"An Automatic Segmentation of Skin Lesion from Dermoscopy Images using Watershed Segmentation","Chakkaravarthy A.P.; Chandrasekar A.","2018","1","1","0","0","0","First occurrence","0","","","","","","","Among all cancers, there is a deadly disease that affects the outer layer of the body which skin cancer. There are many rules for analysis and detection of skin lesion which are provided in literature reviews. In the proposed research work, the main task is to identify the malignant lesion at the initial stage. In the initial pre-processing, the noise is isolated and a purely digital image for segmentation and Edge detection is prepared. The Sobel Operator filters the extracted cancer region as foreground region and the remaining part of the image as background regions. Finally, the desired diagnosis is extracted from the Gradient magnitude based on Watershed Transformation. Watershed segmentation segments or separates the adjacent different colors in RGB image. The proposed simulation measures the accurate diagnosis between Threshold image, gradient Image and Watershed Image and confirms the best-offered values of accuracy up to 90.46%, sensitivity up to 98.36% and specificity up to 82.95%. © 2018 IEEE.","10.1109/RTECC.2018.8625662","Gaussian Filter; Gradient Magnitude; Salt and Pepper Noise; Sobel Operator; Watershed Segmentation","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062542446&doi=10.1109%2fRTECC.2018.8625662&partnerID=40&md5=44ed7cc66a9e5cf9ea2c17c635d952c2"
"Classification of Skin Lesion by Interference of Segmentation and Convolotion Neural Network","Rehman M.U.; Khan S.H.; Danish Rizvi S.M.; Abbas Z.; Zafar A.","2018","1","1","0","0","0","First occurrence","0","","","","","","","Classification of skin lesions plays a crucial role in diagnosing various, local and gene related, medical conditions in the field of dermoscopy. Estimation of these biomarkers are used to provide some insight, while detecting cancerous cells and classifying the lesion as either benign or malignant. This paper presents groundwork for detection of skin lesions with cancerous inclination by segmentation and subsequent application of Convolution Neural Network on dermoscopy images. Images included in ISIC-2016 were used as dataset. Images with skin lesions were segmented based on individual channel intensity thresholding. The resultant images were fed into CNN for feature extraction. The extracted features were then used for classification by an ANN classifier. Previously, several approaches have been used for subject diagnostic with varying degree of success. However, room is still available for exploring other techniques for improving proportion of successfully detected malignant lesions. As compared to a previous best of 97%, methodology presented in this paper yielded an accuracy of 98.32%. © 2018 IEEE.","10.1109/ICEI18.2018.8448814","accuracy; artificial neural network (ANN); convolutional neural network (CNN); ReLU; segmentation; sensitivity; skin lesion; specificity","54","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054004678&doi=10.1109%2fICEI18.2018.8448814&partnerID=40&md5=2f9698ab9adfcdce135f06ae1f56a6f9"
"An Enhanced Hybrid Model for Skin Diagnosis Using Deep Convolution Neural Network","Shoieb D.A.; Youssef S.M.","2018","1","1","0","0","0","Unique","0","","","","","","","Melanoma is the deadliest form of skin cancer. Unfortunately, Skin cancer can't be identified by visual examination. So, there is a call for an automated model which assists dermatologists in early diagnosis of skin cancer and help remote patient to save their life by remote diagnosis. This paper introduces an enhanced expert computer-aided model for skin diagnosis using deep learning. The proposed region of interest (ROI) segmentation is done by integrating both color and texture properties for the skin in both spatial and frequency domains. Then, the convolution neural network (CNN) is used for extracting all the possible discriminating features. Experiments have been conducted on various large datasets to demonstrate the efficiency of the proposed model. The experimental results show an outstanding performance in the terms of sensitivity, specificity and accuracy compared with others in literature. © 2018 IEEE.","10.1109/CIBEC.2018.8641806","computer-aided diagnosis; Convolution neural networks; deep learning; discriminating features","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063212654&doi=10.1109%2fCIBEC.2018.8641806&partnerID=40&md5=9d2ad66adc1bf3c0a15d99818a9ec9fd"
"Tissue classification and segmentation of pressure injuries using convolutional neural networks","Zahia S.; Sierra-Sosa D.; Garcia-Zapirain B.; Elmaghraby A.","2018","0","1","0","0","0","Unique","0","","","","","","","Background and Objectives: This paper presents a new approach for automatic tissue classification in pressure injuries. These wounds are localized skin damages which need frequent diagnosis and treatment. Therefore, a reliable and accurate systems for segmentation and tissue type identification are needed in order to achieve better treatment results. Methods: Our proposed system is based on a Convolutional Neural Network (CNN) devoted to performing optimized segmentation of the different tissue types present in pressure injuries (granulation, slough, and necrotic tissues). A preprocessing step removes the flash light and creates a set of 5x5 sub-images which are used as input for the CNN network. The network output will classify every sub-image of the validation set into one of the three classes studied. Results: The metrics used to evaluate our approach show an overall average classification accuracy of 92.01%, an average total weighted Dice Similarity Coefficient of 91.38%, and an average precision per class of 97.31% for granulation tissue, 96.59% for necrotic tissue, and 77.90% for slough tissue. Conclusions: Our system has been proven to make recognition of complicated structures in biomedical images feasible. © 2018 Elsevier B.V.","10.1016/j.cmpb.2018.02.018","Convolutional neural networks; Deep learning; Image segmentation; Pressure injuries; Tissue type classification","74","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043369305&doi=10.1016%2fj.cmpb.2018.02.018&partnerID=40&md5=aab242960976e1122e2b5ddd9e25baca"
"Significant Bit Contribution in Robust Feature Extraction for Dermoscopic Image Classification","Das R.; Ghosh S.; Khatua S.; Sen A.; Thepade S.; Banerjee M.","2018","0","1","0","0","0","First occurrence","0","","","","","","","Augmented episodes of melanoma, a curable skin cancer variety of antagonistic nature have stimulated the advancements in designing systems for computer aided diagnosis of the disease. Clinical diagnosis includes primary vetting of the symptoms followed by a biopsy and necessary medical examinations. However, computer based classification of the clinical images of dermoscopy have the potential to diminish the exertion of the dermatologist by offering a computer aided opinion independent of medical know-how. Assorted methods have been proposed in recent times including the deep learning techniques for computer based melanoma recognition. But, most of the techniques have enhanced feature dimension which has added to the computational complexity of the entire system. In this work, the authors have attempted to design robust light-weight feature extraction techniques from high level bit planes of dermoscopic images. The noisy lower bit planes are ignored for lack of significant feature information. The proposed method of feature extraction is tested with three different classifiers for specificity and sensitivity outputs of the dermoscopic images. The results of classification have outclassed the performance of state-of-the-art feature extraction techniques. © 2018 IEEE.","10.1109/ICRIEECE44171.2018.9008865","Binarization; Bit Plane; Classification; Dermoscopy; Medical Imaging; Melanoma; uLBP","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081977075&doi=10.1109%2fICRIEECE44171.2018.9008865&partnerID=40&md5=5fc9a1e27862c1d019cedfa95e2b5553"
"A study on melanoma skin cancer detection techniques","Amulya P.M.; Jayakumar T.V.","2018","1","1","0","0","0","First occurrence","0","","","","","","","The incidence of melanoma has been increasing for many decades. Skin cancer is the one of the most hazardous form of the cancers found in humans. An early detection of this skin cancer can save the victim. The advancements in technology in nowadays can make possible to detection of skin cancer early. As per the literature the lesion characteristic such as shape, color, structure etc are the important diagnostic parameters. In this paper we review the various techniques for early stage melanoma skin cancer detection. © 2017 IEEE.","10.1109/ISS1.2017.8389278","Classification; Lesion; Melanoma; Segmentation","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050017403&doi=10.1109%2fISS1.2017.8389278&partnerID=40&md5=627d542d01caefa4995a6614d6e42116"
"Melanoma recognition in dermoscopy images via deep residual network","Hang L.; Zhen Y.; Dong N.; Baiying L.; Tianfu W.","2018","0","1","0","0","0","Unique","0","","","","","","","Malignant melanoma is one of the most common and deadly skin cancers. Clinically, dermoscopy is a routine method for early diagnosis of malignant melanoma. However, human's visual examinations are laborious, time-consuming, and highly dependent on dermatologist' s clinical experience. Therefore, it is important to design an algorithm for recognizing melanoma automatically in dermoscopy images. This study proposed a novel framework for the evaluation of dermoscopy images, using deep learning to generate more discriminative features with limited training data. Specifically, we first extracted the intermediate convolutional features of each skin lesion image using a very deep residual neural network including 152 network layers (i. e. Res-152) which was pre-trained on a large natural image dataset, and the final deep representation was obtained by averaging the spatial feature maps into single feature vector, then, the support vector machine (SVM) was used to classify the melanoma. By using the proposed method 248 melanoma images and 1031 nonmelanoma images in published ISBI 2016 challenge datasets of skin lesion images were evaluated, obtaining accuracy rate of 84.96% and AUC of 84. 18%. In addition, in order to demonstrate the effect of neural network depth on the classification results, we compared the different depth of the model framework. Our approach, which could solve large variations in melanoma and small differences between melanoma and nonmelanoma with the limited training data, can produce more discriminative representations than existing studies using hand-crafted features (i. e. the BoF models based on densely sampled SIFT (DSIFT) descriptors) or only to extract features from the fully connected layers. © 2018 Society of China University Journals in Natural Sciences. Allm rights reserved.","10.3969/j.issn.0258-8021.2018.03.003","Deep learning; Dermoscopy image; Melanoma recognition; Residual network","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051014334&doi=10.3969%2fj.issn.0258-8021.2018.03.003&partnerID=40&md5=94795ebed3e7062151ae290200100b23"
"Segmentation and Measurement of Chronic Wounds for Bioprinting","Gholami P.; Ahmadi-Pajouh M.A.; Abolftahi N.; Hamarneh G.; Kayvanrad M.","2018","0","1","0","0","0","Unique","0","","","","","","","Objective: to provide a proof-of-concept tool for segmenting chronic wounds and transmitting the results as instructions and coordinates to a bioprinter robot and thus facilitate the treatment of chronic wounds. Methods: several segmentation methods used for measuring wound geometry, including edge-detection and morphological operations, region-growing, Livewire, active contours, and texture segmentation, were compared on 26 images from 15 subjects. Ground-truth wound delineations were generated by a dermatologist. The wound coordinates were converted into G-code understandable by the bioprinting robot. Due to its desirable properties, alginate hydrogel was synthesized by dissolving 16% (w/v) sodium-alginate and 4% (w/v) gelatin in deionized water and used for cell encapsulation. Results: Livewire achieved the best performance, with minimal user interaction: 97.08%, 99.68% 96.67%, 96.22, 98.15, and 32.26, mean values, respectively, for accuracy, sensitivity, specificity, Jaccard index, Dice similarity coefficient, and Hausdorff distance. The bioprinter robot was able to print skin cells on the surface of skin with a 95.56% similarity between the bioprinted patch's dimensions and the desired wound geometry. Conclusion: we have designed a novel approach for the healing of chronic wounds, based on semiautomatic segmentation of wound images, improving clinicians' control of the bioprinting process through more accurate coordinates. Significance: this study is the first to perform wound bioprinting based on image segmentation. It also compares several segmentation methods used for this purpose to determine the best. © 2013 IEEE.","10.1109/JBHI.2017.2743526","Aliginate-gel; bio-ink; Bioprinting; chronic wound; image segmentation","30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028500550&doi=10.1109%2fJBHI.2017.2743526&partnerID=40&md5=162943cd2c9f1418d4b782b80bf6df3b"
"A Novel Algorithm for Hand Tracking with Particle Filter and Improved GVF Snake; [基于粒子滤波与改进GVF Snake的人手跟踪算法]","Sun Y.; Wu A.; Dong N.; Shao Y.","2018","0","1","0","0","0","Unique","0","","","","","","","To implement the hand tracking and contour tracking accurately and quickly in complex background, a novel algorithm for hand tracking with particle filter and skin color adaptive gradient vector flow snake (GVF snake) model is proposed. This algorithm especially applies to the extraction of deep concave region of hand contour, and overcomes the problem that particle filter can not obtain accurate information. Firstly, the hand region obtained by the particle filter is grayscale enhanced by skin color, weakening the background gradient information. And then the GVF snake model, with adaptive gradient vector flow field and adaptive external guidance force improved by skin color, is introduced to extract the real contour and modify the systematic observation and system state of particle filter. In this case, it can reduce the possibility of degradation of particles and realize hand tracking more accurately. The experimental results show that the proposed algorithm extracts more accurate contour of hand and improves real-time performance of human tracking by 13% and the root mean square error is reduced by 48%, under the conditions of complexity, moving background and even a wide range of occlusion. © 2018, Shanghai Jiao Tong University Press. All right reserved.","10.16183/j.cnki.jsjtu.2018.07.007","Adaptiveness; Gradient vector flow snake (GVF snake) model; Hand contour; Hand tracking; Particle filter","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055549121&doi=10.16183%2fj.cnki.jsjtu.2018.07.007&partnerID=40&md5=fd264bfe91d49886258aee61e4194c08"
"Adaptive active contours based on variable kernel with constant initialisation","Munir A.; Soomro S.; Lee C.H.; Choi K.N.","2018","0","1","0","0","0","Unique","0","","","","","","","In this paper, a novel method of active contours based on the formulation of partial differential equation (PDE) is proposed for image segmentation. The evolution equation incorporates a force term that pushes the contour towards object boundary, a regularisation term which takes into account the smoothness of the level set function and an edge term which helps to stop the contour at required boundaries. The proposed method integrates an image convolved by a variable kernel into an energy formulation, where the width of the kernel varies in each iteration. Therefore, it takes local region information when the width of the kernel is small while for the larger width of the kernel, the proposed method considers global region information across the regions. Due to the use of both local and global image information, the method easily detects objects in the complex background and also segments the objects where intensity changes within the object. Moreover, the proposed method totally eliminates the need of the contour initialisation by using constant initialisation scheme. Experimental results on real and medical images prove the robustness of the proposed method. Finally, the authors validate their method on PH2 database for skin lesion segmentation. © The Institution of Engineering and Technology 2018.","10.1049/iet-ipr.2017.0481","","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048639280&doi=10.1049%2fiet-ipr.2017.0481&partnerID=40&md5=1c1b408b5d96e1fe2d7f892d3c2aeab5"
"Data augmentation for improving deep learning in image classification problem","Mikołajczyk A.; Grochowski M.","2018","0","1","0","0","0","First occurrence","0","","","","","","","These days deep learning is the fastest-growing field in the field of Machine Learning (ML) and Deep Neural Networks (DNN). Among many of DNN structures, the Convolutional Neural Networks (CNN) are currently the main tool used for the image analysis and classification purposes. Although great achievements and perspectives, deep neural networks and accompanying learning algorithms have some relevant challenges to tackle. In this paper, we have focused on the most frequently mentioned problem in the field of machine learning, that is the lack of sufficient amount of the training data or uneven class balance within the datasets. One of the ways of dealing with this problem is so called data augmentation. In the paper we have compared and analyzed multiple methods of data augmentation in the task of image classification, starting from classical image transformations like rotating, cropping, zooming, histogram based methods and finishing at Style Transfer and Generative Adversarial Networks, along with the representative examples. Next, we presented our own method of data augmentation based on image style transfer. The method allows to generate the new images of high perceptual quality that combine the content of a base image with the appearance of another ones. The newly created images can be used to pre-train the given neural network in order to improve the training process efficiency. Proposed method is validated on the three medical case studies: skin melanomas diagnosis, histopathological images and breast magnetic resonance imaging (MRI) scans analysis, utilizing the image classification in order to provide a diagnose. In such kind of problems the data deficiency is one of the most relevant issues. Finally, we discuss the advantages and disadvantages of the methods being analyzed. © 2018 IEEE.","10.1109/IIPHDW.2018.8388338","data augmentation; deep learning; Machine learning; medical imaging; style transfer","1442","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050025181&doi=10.1109%2fIIPHDW.2018.8388338&partnerID=40&md5=9f3e4d6b58e06bafcce8660fcd6e616f"
"A review of image processing techniques common in human and plant disease diagnosis","Petrellis N.","2018","0","1","0","0","0","Unique","0","","","","","","","Image processing has been extensively used in various (human, animal, plant) disease diagnosis approaches, assisting experts to select the right treatment. It has been applied to both images captured from cameras of visible light and from equipment that captures information in invisible wavelengths (magnetic/ultrasonic sensors, microscopes, etc.). In most of the referenced diagnosis applications, the image is enhanced by various filtering methods and segmentation follows isolating the regions of interest. Classification of the input image is performed at the final stage. The disease diagnosis approaches based on these steps and the common methods are described. The features extracted from a plant/skin disease diagnosis framework developed by the author are used here to demonstrate various techniques adopted in the literature. The various metrics along with the available experimental conditions and results presented in the referenced approaches are also discussed. The accuracy achieved in the diagnosis methods that are based on image processing is often higher than 90%. The motivation for this review is to highlight the most common and efficient methods that have been employed in various disease diagnosis approaches and suggest how they can be used in similar or different applications. © 2018 by the author.","10.3390/sym10070270","Classification; Disease diagnosis; Image filtering; Image processing; Plant disease; Segmentation","32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050380768&doi=10.3390%2fsym10070270&partnerID=40&md5=f5e3ab9a936bd97a7d7b1ff1d3fa86d5"
"Vi-da: Vitiligo diagnostic assistance mobile application","Nugraha G.A.; Nurhudatiana A.; Bahana R.","2018","0","1","0","0","0","Unique","0","","","","","","","Vitiligo is a skin disorder in which white patches of depigmentation appear on different parts of the body. Usually, patients come to hospitals or clinics to have their vitiligo conditions assessed. This can be very tiring to the patients, as vitiligo treatments usually take a relatively long period of time, which can range from months to years. To address this challenge, we present in this paper a prototype of an Android-based mobile application called Vi-DA, which stands for Vitiligo Diagnostic Assistance. Vi-DA consists of three subsystems, which are user sign-up subsystem, camera and image analysis subsystem, and progress report subsystem. The mobile application was developed in Java programming language and uses MySQL as the database system. Vi-DA adopts a vitiligo segmentation algorithm to segment input image into normal skin area, vitiligo skin area, and non-skin area. Results showed that Vi-DA gave comparable results to the previous system implemented in Matlab. User acceptance testing results also showed that all respondents agreed on the usefulness of the system and agreed to use Vi-DA again in the future. Vi-DA benefits both dermatologists and patients as not only a computer-aided diagnosis (CAD) tool but also as a smart application that can be used for self-assessment at home. © Published under licence by IOP Publishing Ltd.","10.1088/1742-6596/978/1/012003","","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045144773&doi=10.1088%2f1742-6596%2f978%2f1%2f012003&partnerID=40&md5=31b50b40e406bc218f5123424378836a"
"A study of lesion skin segmentation, features selection and classification approaches","Filali Y.; Ennouni A.; Sabri M.A.; Aarab A.","2018","1","1","0","0","0","First occurrence","0","","","","","","","Among the most dangerous cancer in the world is skin cancer. If not diagnosed in early stages it might be hard to cure. The aim of this work is to present a study of skin segmentation, features selection and classification approaches. In the segmentation stage, we will present the result of the use of a pre-processing based on a multiscale decomposition model where geometrical component is used to get a good segmentation. The features are firstly extracted using the texture component and color of the lesion, and then we will present a comparative study of some features selection approaches that select the relevant ones. In feature classification we will compare between the most and good classifiers used in literature. © 2018 IEEE.","10.1109/ISACV.2018.8354069","features classification; features extraction; KNN; machine-learning; PDE multi-scale decomposition; Segmentation; Skin cancer; SVM","30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050920372&doi=10.1109%2fISACV.2018.8354069&partnerID=40&md5=6d5449c598d8f58073931d889fbc7638"
"Deep residual neural networks for automated Basal Cell Carcinoma detection","Putten E.V.; Kambod A.; Kambod M.","2018","0","1","0","0","0","First occurrence","0","","","","","","","Despite being the most common cancer around the world, five year survival rates of skin cancer are above 95%, as long as they are detected and treated before they have spread. The key to prolonged survival is early detection, making an automated analysis tool indispensable. Current machine learning analyses of Basal Cell Carcinoma (BCC) dermoscopy images have failed to create a model viable for use in clinical applications. In this paper, we demonstrate a sensitivity and specificity that could make neural networks a realistic tool for dermatologists. Our algorithm follows a three step process: first, the original image is preprocessed and fed into the segmentation model; second, a black and white lesion map is produced to extract the minimum area of the image; third, the classification model is introduced for classifying whether an input image is BCC or not. By building upon melanoma research performed by He, et al., we reached an overall weighted sensitivity and specificity of 96% and 89%, respectively. We demonstrated that deep residual neural networks (> 100 layers), carefully optimized, can surpass the limitations of depth one sees with more common convolutional neural networks. © 2018 IEEE.","10.1109/BHI.2018.8333437","","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050881342&doi=10.1109%2fBHI.2018.8333437&partnerID=40&md5=5c4eb35cd67d5c26fa1075081538fdda"
"Construction of adaptive pulse coupled neural network for abnormality detection in medical images","Upadhyay P.K.; Chandra S.","2018","0","1","0","0","0","Unique","0","","","","","","","In this article, we propose a customized pulse coupled neural network for image segmentation to detect the different classes of skin lesions by minimizing the number of pixels as image harmonics. In addition, we have used a distribution similar to primary visual cortex for internal activation function. This helps in transforming the visual behavior of the cortex. The developed neural synchrony of adaptive pulse coupled neural network helps in classifying the lesion patterns in dermoscopy images. We evaluate our proposed approach on 240 gold standard dermofit images of lesions. Our results have shown significant improvement in the accuracy and efficiency when compared with existing methods. © 2018, © 2018 Taylor & Francis.","10.1080/08839514.2018.1481818","","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048372680&doi=10.1080%2f08839514.2018.1481818&partnerID=40&md5=110d8ed8f5ddfedd17b74dac80d19ef2"
"Machine learning–based diagnosis of melanoma using macro images","Gautam D.; Ahmed M.; Meena Y.K.; Ul Haq A.","2018","0","1","0","0","0","Unique","0","","","","","","","Cancer bears a poisoning threat to human society. Melanoma, the skin cancer, originates from skin layers and penetrates deep into subcutaneous layers. There exists an extensive research in melanoma diagnosis using dermatoscopic images captured through a dermatoscope. While designing a diagnostic model for general handheld imaging systems is an emerging trend, this article proposes a computer-aided decision support system for macro images captured by a general-purpose camera. General imaging conditions are adversely affected by nonuniform illumination, which further affects the extraction of relevant information. To mitigate it, we process an image to define a smooth illumination surface using the multistage illumination compensation approach, and the infected region is extracted using the proposed multimode segmentation method. The lesion information is numerated as a feature set comprising geometry, photometry, border series, and texture measures. The redundancy in feature set is reduced using information theory methods, and a classification boundary is modeled to distinguish benign and malignant samples using support vector machine, random forest, neural network, and fast discriminative mixed-membership–based naive Bayesian classifiers. Moreover, the experimental outcome is supported by hypothesis testing and boxplot representation for classification losses. The simulation results prove the significance of the proposed model that shows an improved performance as compared with competing arts. Copyright © 2017 John Wiley & Sons, Ltd.","10.1002/cnm.2953","benign and malignant melanoma; computer-aided decision support system; feature selection; information theory; machine learning; texture","35","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042181700&doi=10.1002%2fcnm.2953&partnerID=40&md5=34d005abd4032ef2b6c53d73efe50971"
"Enriched dermoscopic-structure-based cad system for melanoma diagnosis","López-Labraca J.; Fernández-Torres M.Á.; González-Díaz I.; Díaz-De-María F.; Pizarro Á.","2018","0","1","0","0","0","First occurrence","0","","","","","","","Computer-Aided Diagnosis (CAD) systems for melanoma detection have received a lot of attention during the last decades because of the utmost importance of detecting this type of skin cancer in its early stages. However, despite of the many research efforts devoted to this matter, these systems are not used yet in everyday clinical practice. Very likely, this is due to two main reasons: 1) the accuracy of the systems is not high enough; and 2) they simply provide a parallel diagnosis that actually does not help to the doctors (as long as there is no way to interpret it). In this paper, we propose a novel approach that aims to provide the doctor with an enriched diagnosis. Specifically, we rely on a dermoscopic-structure-based soft segmentation to design a set of structure-specific classifiers. Each individual structure-specific classifier is trained to distinguish benign lesions from melanomas just paying attention to one type of dermoscopic structure. Then, the outputs of the individual classifiers are combined by a means of the Bayesian method that, besides the final diagnosis, provide the doctor with additional valuable information, such as the opinions of the individual structure-specific experts and the uncertainty of the diagnosis. The results in terms of the features selected for the structure-specific classifiers are consistent with the expert insights. Furthermore, regarding the automatic melanoma diagnosis problem, the proposed method has been assessed on two different datasets, and the experimental results revealed that the proposed system clearly outperforms other methods in two datasets and compares well with the official submissions of the ISBI 2016 challenge on melanoma detection. Moreover, the system performance is equivalent to that of a well-known dermoscopy expert and its combination with the human diagnosis surpasses the human performance. © 2017, Springer Science+Business Media New York.","10.1007/s11042-017-4879-3","Bayesian fusion; Computer-aided diagnosis; Dermoscopic structures; Enriched diagnosis; Melanoma diagnosis","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020743290&doi=10.1007%2fs11042-017-4879-3&partnerID=40&md5=ef7b639789f8bb696423a48ddfc2d2b4"
"Building a qualified annotation dataset for skin lesion analysis trough gamification","Balducci F.; Buono P.","2018","1","0","0","0","0","Unique","0","","","","","","","The deep learning approach has increased the quality of automatic medical diagnoses at the cost of building qualified datasets to train and test such supervised machine learning methods. Image annotation is one of the main activity of dermatologists and the quality of annotation depends on the physician experience and on the number of studied cases: manual annotations are very useful to extract features like contours, intersections and shapes that can be used in the processes of lesion segmentation and classification made by automatic agents. This paper proposes the design of an interactive multimedia platform that enhance the annotation process of medical images, in the domain of dermatology, adopting gamification and “games with a purpose” (GWAP) strategies in order to improve the engagement and the production of qualified datasets also fostering their sharing and practical evaluation. A special attention is given to the design choices, theories and assumptions as well as the implementation and technological details. © 2018 Association for Computing Machinery.","10.1145/3206505.3206555","Annotation; Dermatology; Gamification; GWAP; Machine learning","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048873504&doi=10.1145%2f3206505.3206555&partnerID=40&md5=8bd86469e80417a3ee8bf9695f33aa4d"
"Segmentation of melanoma skin lesions using anisotropic diffusion and adaptive thresholding","Khan A.H.; Latif G.; Awang Iskandar D.N.F.; Alghazo J.; Butt M.","2018","1","1","0","0","0","First occurrence","0","","","","","","","Segmentation is the first and most important task in the diagnosis of skin cancer using computer-aided systems and due to complex structure of skin lesions, the automated process may lead to a completely different diagnosis. In this paper, a novel segmentation method of skin lesions is proposed which is both effective and simple to implement. Smoothing of skin lesions in original image plays a pivotal role to secure an accurate segmented image. Anisotropic Diffusion Filter (ADF) is used in the initial stage to smooth images with preserved edges. Adaptive thresholding is then applied to segment the skin lesion of the image by binarizing it. The morphological operations are applied for further enhancement and final segmented image is obtained by applying proposed boundary conditions in which objects are selected on basis of distance. The proposed technique is tested on over 300 images and averaged results are compared with existing methods like L-SRM, Otsu-R, Otsu-RGB and TDLS. The proposed method achieved an average accuracy of 96.6%. Visual results for selected images also depicted better performance of proposed method even in the presence of bad illumination and rough skin lesions in the image. © 2018 Association for Computing Machinery.","10.1145/3208955.3208961","Adaptive thresholding; Anisotropic diffusion; Melanoma skin lesions; Segmentation; Skin cancer","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055575386&doi=10.1145%2f3208955.3208961&partnerID=40&md5=ed1ee413cadcb113863818ad7702a18e"
"Skin lesion analysis toward melanoma detection: A challenge at the 2017 International symposium on biomedical imaging (ISBI), hosted by the international skin imaging collaboration (ISIC)","Codella N.C.F.; Gutman D.; Celebi M.E.; Helba B.; Marchetti M.A.; Dusza S.W.; Kalloo A.; Liopyris K.; Mishra N.; Kittler H.; Halpern A.","2018","1","1","0","0","0","First occurrence","0","","","","","","","This article describes the design, implementation, and results of the latest installment of the dermoscopic image analysis benchmark challenge. The goal is to support research and development of algorithms for automated diagnosis of melanoma, the most lethal skin cancer. The challenge was divided into 3 tasks: lesion segmentation, feature detection, and disease classification. Participation involved 593 registrations, 81 pre-submissions, 46 finalized submissions (including a 4-page manuscript), and approximately 50 attendees, making this the largest standardized and comparative study in this field to date. While the official challenge duration and ranking of participants has concluded, the dataset snapshots remain available for further research and development. © 2018 IEEE.","10.1109/ISBI.2018.8363547","Challenge; Dataset; Deep learning; Dermatology; Dermoscopy; Melanoma; Skin cancer","1671","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048103617&doi=10.1109%2fISBI.2018.8363547&partnerID=40&md5=da7c17cd6c9ac36af58e97774e2b5bdc"
"A multi-task framework with feature passing module for skin lesion classification and segmentation","Chen S.; Wang Z.; Shi J.; Liu B.; Yu N.","2018","1","1","0","0","0","First occurrence","0","","","","","","","Skin lesion classification and segmentation are highly correlated tasks. However, their relationship is not fully utilized in previous methods. In this paper, we propose a multi-task deep convolutional neural network architecture to solve the skin lesion classification and segmentation problem simultaneously. To take full advantage of features from different tasks and thus get richer knowledge about the sample, we design a feature passing module to pass messages between segmentation branch and classification branch. Since feature passing module is not always helpful and can be related with individual samples, gate functions are used for controlling messages transmission. Therefore, features from one task are learned and selectively passed to the other task, and vice versa, which effectively improves the performance of both tasks. We have evaluated the proposed method on ISBI-2017 challenge dataset, and the experimental results demonstrate the superiority and effectiveness of the proposed method, compared to our base model and other state-of-art methods. © 2018 IEEE.","10.1109/ISBI.2018.8363769","Convolutional neural networks; Feature passing; Multi-task; Skin lesion","52","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048120387&doi=10.1109%2fISBI.2018.8363769&partnerID=40&md5=72abe7a99bf6d78077b045f168469b2a"
"Apply lightweight deep learning on internet of things for low-cost and easy-To-Access skin cancer detection","Sahu P.; Yu D.; Qin H.","2018","1","1","0","0","0","Unique","0","","","","","","","Melanoma is the most dangerous form of skin cancer that often resembles moles. Dermatologists often recommend regular skin examination to identify and eliminate Melanoma in its early stages. To facilitate this process, we propose a hand-held computer (smart-phone, Raspberry Pi) based assistant that classifies with the dermatologist-level accuracy skin lesion images into malignant and benign and works in a standalone mobile device without requiring network connectivity. In this paper, we propose and implement a hybrid approach based on advanced deep learning model and domain-specific knowledge and features that dermatologists use for the inspection purpose to improve the accuracy of classification between benign and malignant skin lesions. Here, domain-specific features include the texture of the lesion boundary, the symmetry of the mole, and the boundary characteristics of the region of interest. We also obtain standard deep features from a pre-Trained network optimized for mobile devices called Google's MobileNet. The experiments conducted on ISIC 2017 skin cancer classification challenge demonstrate the effectiveness and complementary nature of these hybrid features over the standard deep features. We performed experiments with the training, testing and validation data splits provided in the competition. Our method achieved area of 0.805 under the receiver operating characteristic curve. Our ultimate goal is to extend the trained model in a commercial hand-held mobile and sensor device such as Raspberry Pi and democratize the access to preventive health care. © 2018 SPIE.","10.1117/12.2293350","Deep learning; Internet of things; Melanoma; Polar Harmonic Transform; Raspberry Pi; Skin cancer; Transfer learning","25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047757954&doi=10.1117%2f12.2293350&partnerID=40&md5=c0c150ee801a79e0a6b0950f13e49573"
"SLSDeep: Skin lesion segmentation based on dilated residual and pyramid pooling networks","Sarker M.M.K.; Rashwan H.A.; Akram F.; Banu S.F.; Saleh A.; Singh V.K.; Chowdhury F.U.H.; Abdulwahab S.; Romani S.; Radeva P.; Puig D.","2018","1","1","0","0","0","Unique","0","","","","","","","Skin lesion segmentation (SLS) in dermoscopic images is a crucial task for automated diagnosis of melanoma. In this paper, we present a robust deep learning SLS model represented as an encoder-decoder network. The encoder network is constructed by dilated residual layers, in turn, a pyramid pooling network followed by three convolution layers is used for the decoder. Unlike the traditional methods employing a cross-entropy loss, we formulated a new loss function by combining both Negative Log Likelihood (NLL) and End Point Error (EPE) to accurately segment the boundaries of melanoma regions. The robustness of the proposed model was evaluated on two public databases: ISBI 2016 and 2017 for skin lesion analysis towards melanoma detection challenge. The proposed model outperforms the state-of-the-art methods in terms of the segmentation accuracy. Moreover, it is capable of segmenting about 100 images of a 384 × 384 size per second on a recent GPU. © Springer Nature Switzerland AG 2018.","10.1007/978-3-030-00934-2_3","Deep learning; Dilated residual networks; Pyramid pooling; Skin lesion segmentation melanoma","128","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054092998&doi=10.1007%2f978-3-030-00934-2_3&partnerID=40&md5=ea8c3e11769038d5c17b5a435f50a20b"
"Skin lesion images segmentation: A survey of the state-of-the-art","Adeyinka A.A.; Viriri S.","2018","1","1","0","0","0","Unique","0","","","","","","","This paper presents a detailed and robust survey of the state-of-the-art algorithms and techniques for performing skin lesion segmentation. The approach used is the comparative analysis of the existing methods for skin lesion analysis, critical review of the performance evaluation of some recently developed algorithms for skin lesion images segmentation, and the study of current evaluating metrics used for performance analysis. The study highlights merits and demerits of the algorithms examined, observing the strength and weakness of each algorithm. An inference can thus be made from the analysis about the best performing algorithms. It is observed that the advancement of technology and availability of a large and voluminous data set for training the machine learning algorithms encourage the application of machine learning techniques such as deep learning for performing skin lesion images segmentation. This work shows that most deep learning techniques out-perform some existing state-of-the arts algorithm for skin lesion images segmentation. © Springer Nature Switzerland AG 2018.","10.1007/978-3-030-05918-7_29","Deep learning; Evaluation metrics; Segmentation; Skin lesion","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059084464&doi=10.1007%2f978-3-030-05918-7_29&partnerID=40&md5=e987b98372335a008f73347c96c1cb92"
"Multi-Channel-ResNet: An integration framework towards skin lesion analysis","Guo S.; Yang Z.","2018","1","1","0","0","0","Unique","0","","","","","","","This paper proposes a feasible framework towards skin lesion analysis, named Multi-Channel-ResNet. The basic idea is to assemble multiple residual neural networks (ResNets), in which the training data has been pretreated with different methods. For different situations with practical applications, we put forward two training methods. Our method performs better than a single ResNet or a simple ensemble of ResNets. The validity of the framework is verified on two data sets: dermoscopic images and skin surface photos. For dermoscopic images, we completed the third part of a public competition, called “ISIC 2017: Skin Lesion Analysis Towards Melanoma Detection”. The metric is the mean value of the area under the curve (AUC) for the melanoma and seborrheic keratosis classifications. Our framework achieves a result of 0.917 on the test set, which is 0.046 higher than a single ResNet. For skin surface photos, we collected images of four diseases, including eczema, heatrash, subitum, and varicella. The framework achieves 82.4% accuracy on the test set, which is 3% higher than the baseline. This implies that the proposed framework is applicable in practice and achieves excellent performance. © 2018","10.1016/j.imu.2018.06.006","Deep convolutional neural network; Medical image classification; Model ensemble; Multi-Channel-ResNet; Skin diseases","57","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049298662&doi=10.1016%2fj.imu.2018.06.006&partnerID=40&md5=ee717def0c4faee8c4351eed566c2d86"
"Multi-scale Fully Convolutional DenseNets for Automated Skin Lesion Segmentation in Dermoscopy Images","Zeng G.; Zheng G.","2018","1","1","0","0","0","Unique","0","","","","","","","This paper addresses the problem of automated skin lesion segmentation in dermoscopy images. We propose a novel Multi-Scale Fully Convolutional DenseNets (MSFCDN) for skin lesion segmentation. The MSFCDN adopts fully convolutional architecture, which after training, can perform semantic segmentation of an image with arbitrary size. We conduct extensive experiments on ISBI 2017 “Skin Lesion Analysis Towards Melanoma Detection” Challenge dataset. Our method achieves an average Dice coefficient of 86.9% and an average accuracy of 95.3% for skin lesion segmentation. © 2018, Springer International Publishing AG, part of Springer Nature.","10.1007/978-3-319-93000-8_58","Deep learning; Dense convolutional networks; Skin lesion segmentation","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049454555&doi=10.1007%2f978-3-319-93000-8_58&partnerID=40&md5=68c1a3bb6de9ad175902540adc1f9612"
"Social group optimization supported segmentation and evaluation of skin melanoma images","Dey N.; Rajinikanth V.; Ashour A.S.; Tavares J.M.R.S.","2018","1","1","0","0","0","Unique","0","","","","","","","The segmentation of medical images by computational methods has been claimed by the medical community, which has promoted the development of several algorithms regarding different tissues, organs and imaging modalities. Nowadays, skin melanoma is one of the most common serious malignancies in the human community. Consequently, automated and robust approaches have become an emerging need for accurate and fast clinical detection and diagnosis of skin cancer. Digital dermatoscopy is a clinically accepted device to register and to investigate suspicious regions in the skin. During the skin melanoma examination, mining the suspicious regions from dermoscopy images is generally demanded in order to make a clear diagnosis about skin diseases, mainly based on features of the region under analysis like border symmetry and regularity. Predominantly, the successful estimation of the skin cancer depends on the used computational techniques of image segmentation and analysis. In the current work, a social group optimization (SGO) supported automated tool was developed to examine skin melanoma in dermoscopy images. The proposed tool has two main steps, mainly the image pre-processing step using the Otsu/Kapur based thresholding technique and the image post-processing step using the level set/active contour based segmentation technique. The experimental work was conducted using three well-known dermoscopy image datasets. Similarity metrics were used to evaluate the clinical significance of the proposed tool such as Jaccard's coefficient, Dice's coefficient, false positive/negative rate, accuracy, sensitivity and specificity. The experimental findings suggest that the proposed tool achieved superior performance relatively to the ground truth images provided by a skin cancer physician. Generally, the proposed SGO based Kapur's thresholding technique combined with the level set based segmentation technique is very effective for identifying melanoma dermoscopy digital images with high sensitivity, specificity and accuracy. © 2018 by the authors.","10.3390/sym10020051","Active contour; Kapur; Level set; Otsu; Skin melanoma; Social group optimization (SGO)","137","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042553220&doi=10.3390%2fsym10020051&partnerID=40&md5=21af815f1537da124b591e214ecc3838"
"Imaging techniques to extract information: New born baby's skin birthmark","Rasel M.A.; Hasan M.; Azad A.S.; Akther S.","2018","1","1","0","0","0","Unique","0","","","","","","","Birthmark on human skin can be used for digital identification specially for new born baby, because their skin usually scars, tattoo, and others unexpected lesion free. The available methods to extract skin birthmark information take long time and depend on clinical process. Computer based Imaging program can be the solution to minimize time delay and reduce the complexity. Extracting information of skin birthmark is critical and complex process because of skin tone variation and shape of different organs. Different types of imaging operation such as edge detection for shape analysis, morphological operation for getting clear view, and mathematical image enhancing operations are applied for the extracting process to visualize the identifying information of new born baby. By comparing with other approaches, the successfulness of this new technique has been demonstrated for the forensic study where the average success rate is 94.75%. © 2017 IEEE.","10.1109/R10-HTC.2017.8288901","Edge Detection; Image acquisition; Image segmentation; Mathematical Morphology; MATLAB; Object Tracking; Thresholding","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047556509&doi=10.1109%2fR10-HTC.2017.8288901&partnerID=40&md5=d7bb670a62ea9df2b88ad68fcf227784"
"Melanoma skin cancer detection using image processing","Garg N.; Sharma V.; Kaur P.","2018","1","1","0","0","0","Unique","0","","","","","","","Scientists have been trying to implement conventional ways across the world especially in developing and developed countries to cure the deadliest form of skin cancer in human which is known as Melanoma. But efforts are always blockaded by various challenges like high cost of sustaining traditional telemedicine and less availability of experts. There are broadly three types of skin cancer: basal cell cancer, squamous cell cancer, and melanoma. Greater than 90% of the cases are caused by exposure to ultraviolet radiation from the sun. It is important to detect cancer at the initial stage; only an expert dermatologist can classify which one is melanoma and which one is non-melanoma. A short time ago, there has been high implementation of techniques such as dermoscopy or epiluminescence light microscopy (ELM) in helping diagnosis. Using ELM is not affordable and objective, thus researchers motivated in automation diagnosis. This paper is intended to take a digital image, followed by preprocessing of the image to filter the extra noise present in the image. After this, skin lesion is subjected to segmentation and feature extraction with the implementation ABCD rule which will test the skin lesion on various parameters like asymmetry, border irregularity, color, and diameter of the lesion. © 2018, Springer Nature Singapore Pte Ltd.","10.1007/978-981-10-6614-6_12","ABCD rule; Feature extraction; Melanoma; Segmentation","28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031428751&doi=10.1007%2f978-981-10-6614-6_12&partnerID=40&md5=450ffb0a1ff7566ad66719b7236bdf0c"
"Skin lesion analysis towards melanoma detection using deep learning network","Li Y.; Shen L.","2018","1","1","0","0","0","Unique","0","","","","","","","Skin lesions are a severe disease globally. Early detection of melanoma in dermoscopy images significantly increases the survival rate. However, the accurate recognition of melanoma is extremely challenging due to the following reasons: low contrast between lesions and skin, visual similarity between melanoma and non-melanoma lesions, etc. Hence, reliable automatic detection of skin tumors is very useful to increase the accuracy and efficiency of pathologists. In this paper, we proposed two deep learning methods to address three main tasks emerging in the area of skin lesion image processing, i.e., lesion segmentation (task 1), lesion dermoscopic feature extraction (task 2) and lesion classification (task 3). A deep learning framework consisting of two fully convolutional residual networks (FCRN) is proposed to simultaneously produce the segmentation result and the coarse classification result. A lesion index calculation unit (LICU) is developed to refine the coarse classification results by calculating the distance heat-map. A straight-forward CNN is proposed for the dermoscopic feature extraction task. The proposed deep learning frameworks were evaluated on the ISIC 2017 dataset. Experimental results show the promising accuracies of our frameworks, i.e., 0.753 for task 1, 0.848 for task 2 and 0.912 for task 3 were achieved. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/s18020556","Deep convolutional network; Fully-convolutional residual network; Melanoma recognition; Skin lesion classification","517","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041966080&doi=10.3390%2fs18020556&partnerID=40&md5=ad96fc18bce0a634de60d661b12e8a4e"
"Optical design improvement for noncontact skin cancer diagnostic device","Plorina E.V.; Bliznuks D.; Derjabo A.; Lihachev A.; Lihacova I.; Oshina I.; Lange M.","2018","1","1","0","0","0","Unique","0","","","","","","","Multispectral diffuse reflectance imaging and autofluorescence photo-bleaching imaging are methods that have been investigated for use in skin disorder diagnostics. In response to the ever-increasing incidence of skin cancer in light skinned populations a new device has been designed incorporating both of these methods. The aim of the study was to create a device that is most efficient in terms of hardware and software parameters for the screening of malignant and benign skin lesions. A set of 525 nm, 630 nm and 980 nm LEDs were used to illuminate the skin area at three wavelengths [1] and a set of 405 nm LEDs were used to induce the skin autofluorescence [2]. For a more homogenous illumination of investigated skin area the optimal placement for LEDs in a cylindrical case was found. The requisite spacing from the camera lens was taken into account to produce a focused RGB image. The geometrical shape of the device allows to capture images of skin that are illuminated solely by the diodes without interference from sunlight or other nearby light sources. Polarizing filters were used to decrease glare effects, therefore preventing image overexposure of very reflective skin areas. 515 nm long pass filter was used to enable the 405 nm excitation while capturing autofluorescence images of the skin. Further improvements to the quality of the diagnostic data can be achieved using reference images to track homogeneity of the intensity and then applying a compensating algorithm on the subsequent screening images. These and other design considerations serve to realize the full potential of the diagnostic method. Results of clinical approbation to assess the efficacy of the new device to diagnose malignant skin lesions will be demonstrated. © 2018 SPIE.","10.1117/12.2307125","autofluorescence; Diffuse reflectance; skin cancer","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049209149&doi=10.1117%2f12.2307125&partnerID=40&md5=1b9986c01b2e3ce600d55d753188d8e4"
"Detection of melanoma skin disease by extracting high level features for skin lesions","Yadav V.; Kaushik V.D.","2018","1","1","0","0","0","Unique","0","","","","","","","Melanoma is a very dangerous type of skin cancer as compared to others. It can be cured, when diagnosed in its early stage. The detection and diagnosis of skin cancer is difficult using earlier conventional methods. The accurate detection and diagnosis of melanoma is possible using suitable image processing techniques. High level features, measures asymmetry of skin lesion images. These features can be used to diagnose lesions as skin cancer (melanoma). This paper presents large set of low level features for analysing skin lesions. The best classification is obtained by combining the low level feature set with the high level feature set. The result shows that this method can be used and further developed as a tool for detection and classification of skin cancer (melanoma). Copyright © 2018 Inderscience Enterprises Ltd.","10.1504/IJAIP.2018.095493","Feature descriptor; Feature extraction; Melanoma; Radial search; Skin lesion","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054958626&doi=10.1504%2fIJAIP.2018.095493&partnerID=40&md5=2ffa66b4499db2480bfc8ed66a0f7f6d"
"Partial order label decomposition approaches for melanoma diagnosis","Sánchez-Monedero J.; Pérez-Ortiz M.; Sáez A.; Gutiérrez P.A.; Hervás-Martínez C.","2018","0","1","0","0","0","Unique","0","","","","","","","Melanoma is a type of cancer that develops from the pigment-containing cells known as melanocytes. Usually occurring on the skin, early detection and diagnosis is strongly related to survival rates. Melanoma recognition is a challenging task that nowadays is performed by well trained dermatologists who may produce varying diagnosis due to the task complexity. This motivates the development of automated diagnosis tools, in spite of the inherent difficulties (intra-class variation, visual similarity between melanoma and non-melanoma lesions, among others). In the present work, we propose a system combining image analysis and machine learning to detect melanoma presence and severity. The severity is assessed in terms of melanoma thickness, which is measured by the Breslow index. Previous works mainly focus on the binary problem of detecting the presence of the melanoma. However, the system proposed in this paper goes a step further by also considering the stage of the lesion in the classification task. To do so, we extract 100 features that consider the shape, colour, pigment network and texture of the benign and malignant lesions. The problem is tackled as a five-class classification problem, where the first class represents benign lesions, and the remaining four classes represent the different stages of the melanoma (via the Breslow index). Based on the problem definition, we identify the learning setting as a partial order problem, in which the patterns belonging to the different melanoma stages present an order relationship, but where there is no order arrangement with respect to the benign lesions. Under this assumption about the class topology, we design several proposals to exploit this structure and improve data preprocessing. In this sense, we experimentally demonstrate that those proposals exploiting the partial order assumption achieve better performance than 12 baseline nominal and ordinal classifiers (including a deep learning model) which do not consider this partial order. To deal with class imbalance, we additionally propose specific over-sampling techniques that consider the structure of the problem for the creation of synthetic patterns. The experimental study is carried out with clinician-curated images from the Interactive Atlas of Dermoscopy, which eases reproducibility of experiments. Concerning the results obtained, in spite of having augmented the complexity of the classification problem with more classes, the performance of our proposals in the binary problem is similar to the one reported in the literature. © 2017 Elsevier B.V.","10.1016/j.asoc.2017.11.042","Computer vision; Machine learning; Melanoma; Ordinal classification; Partial order; Skin cancer","19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039720658&doi=10.1016%2fj.asoc.2017.11.042&partnerID=40&md5=940866f5f70d345d0805e716b15a3225"
"Molecular imaging and validation of non-melanoma skin cancer margins","Liu Y.; Walker E.; Kim I.; Biro M.; Iyer S.R.; Zhou B.; Bogyo M.; Basilion J.P.; Popkin D.; Wilson D.","2018","1","1","0","0","0","Unique","0","","","","","","","We have developed a point-of-care imaging method for non-melanoma skin cancer surgery whereby excised tissues are imaged with a smart near infrared quenched protease probe (6qcNIR) that fluoresces in the presence of overexpressed cathepsin proteases in basal cell carcinoma (BCC) and squamous cell carcinoma (SCC), and determine if margins are clear of cancer. Here we report our imaging system and our method to validate the detection of skin cancer. We imaged skin samples with an inverted, flying spot fluorescence scanner (LI-COR Odyssey CLx). Scatter in Odyssey system was greatly reduced giving an 80% improvement in the step response as compared to a previously used macroscopic imaging system with imaging of a fluorescence phantom. We developed a validation scheme for careful comparison of fluorescent cancer signal to histology annotation, involving image segmentation, fiducial based registration and non-rigid free-form deformation, using our LI-COR fluorescence images, corresponding color images, bread-loafed tissue images, H&E slides and pathologist annotation. Spatial accuracy in the bulk of the sample was â1/4500 μm. Extrapolated with a linear stretch model suggests an error at the margin of <100 μm. Cancer annotations on H&E slides were transformed and superimposed on the probe fluorescence to generate the final result. In general, the fluorescence cancer signal corresponded with histological annotation. © 2018 SPIE.","10.1117/12.2293847","Fluorescence imaging; Histology validation; Image registration; Near infrared probe; non-melanoma skin cancer","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047727312&doi=10.1117%2f12.2293847&partnerID=40&md5=1a48cff62160cc748e2103c910e7ccdd"
"Skin lesion segmentation using enhanced unified Markov random field","Salih O.; Viriri S.","2018","1","1","0","0","0","Unique","0","","","","","","","Markov Random Field (MRF) theory has a significant potential role in image segmentation field. It uses (pixels, regions, edges)-based on MRF models to detect objects, boundaries and other relevant information in an image. This paper proposes an extension of Unified Markov Random Field (UMRF) model to include edge-based features. Firstly, the proposed technique employs the likelihood function to combine the advantages of the pixel-based, region-based and edge-based MRF model, by computing the product of the pixel likelihood function, regional likelihood function and edge likelihood function. Secondly, the region-based macro texture features are extracted using the UMRF model. Then the edge-based features are extracted using the maximum gradient method to recover any significant lost information. A principled probabilistic inference is implemented to integrate various types of likelihood information and spatial constraints by iteratively updating the posterior probability of the proposed model. The segmentation process is completed when the iterations converge. The proposed enhanced UMRF technique which combines pixel-based, region-based and edge-based features achieved a higher skin lesion segmentation accuracy than MRF model which combines pixel-based and region-based only. © Springer Nature Switzerland AG 2018.","10.1007/978-3-030-05918-7_30","Markov Random Field; Segmentation; Skin lesion; Unified Markov Random Field","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059105166&doi=10.1007%2f978-3-030-05918-7_30&partnerID=40&md5=9fda1b984e023dca6c2587e86fa6336b"
"Semi-supervised Skin Lesion Segmentation via Transformation Consistent Self-ensembling Model","Li X.; Yu L.; Chen H.; Fu C.-W.; Heng P.-A.","2018","1","1","0","0","0","Unique","0","","","","","","","Automatic skin lesion segmentation on dermoscopic images is an essential component in computer-aided diagnosis of melanoma. Recently, many fully supervised deep learning based methods have been proposed for automatic skin lesion segmentation. However, these approaches require massive pixel-wise annotation from experienced dermatologists, which is very costly and time-consuming. In this paper, we present a novel semi-supervised method for skin lesion segmentation, where the network is optimized by the weighted combination of a common supervised loss for labeled inputs only and a regularization loss for both labeled and unlabeled data. To utilize the unlabeled data, our method encourages the consistent predictions of the network-in-training for the same input under different regularizations. Aiming for the semi-supervised segmentation problem, we enhance the effect of regularization for pixel-level predictions by introducing a transformation, including rotation and flipping, consistent scheme in our self-ensembling model. With only 300 labeled training samples, our method sets a new record on the benchmark of the International Skin Imaging Collaboration (ISIC) 2017 skin lesion segmentation challenge. Such a result clearly surpasses fully-supervised state-of-the-arts that are trained with 2000 labeled data. © 2018. The copyright of this document resides with its authors.","","","28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084017407&partnerID=40&md5=9c83587be527ca08edfe164d8854d53a"
"Pigmented skin lesion segmentation based on random forest and full convolutional neural networks","Yang T.; Peng S.; Hu P.; Huang L.","2018","1","1","0","0","0","Unique","0","","","","","","","Segmentation of pigmented lesions is often affected by factors such as hair around the skin lesions, artificial markings, etc., and the complexity of the lesion itself, such as lesions and skin boundaries is not clear, the internal color of lesions is variable, etc., resulting in segmentation difficulties. Aiming at the problem that the segmentation method of pigmented skin lesions using only random forests is not accurate, a segmentation method for pigmented skin lesion using a combination of random forest and fully convolutional neural networks (FCN) is proposed. This method firstly classifies and recognizes skin lesion images based on random forests to obtain a probability distribution of the lesions and the background. Then, the other probability distribution is obtained using FCN based on an improved loss function. Finally, the classification results of random forest and FCN are fused into the final image segmentation results. The experimental results show that the combination of random forest and FCN yields better performances than using random forest alone, in particular, can increase the sensitivity by about 20%. © 2018 Copyright SPIE.","10.1117/12.2503941","full convolutional neural network; pigmented lesion segmentation; Random forest","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057279732&doi=10.1117%2f12.2503941&partnerID=40&md5=a874ef53b46b989666dbb42705efae26"
"The impact of replacing complex hand-crafted features with standard features for melanoma classification using both hand-crafted and deep features","Devassy B.M.; Yildirim-Yayilgan S.; Hardeberg J.Y.","2018","0","1","0","0","0","First occurrence","0","","","","","","","Melanoma is the deadliest form of skin cancer and it is the most rapidly spreading cancer in the world. An earlier detection of this kind of cancer is curable; hence, earlier detection of melanoma is pre-eminent. Because of this fact, a lot of research is being done in this area especially in automatic detection of melanoma. In this paper, we are proposing an automatic melanoma detection system which utilizes a combination of deep and hand-crafted features. We analyzed the impact of using a simpler and standard hand-crafted feature, in place of complex usual hand-crafted features e.g. shape, texture, diameter, or some custom features. We used a convolutional neural network (CNN) known as deep residual network (ResNet) to extract the deep features and utilized the scale invariant feature descriptor (SIFT) as the hand-crafted feature. The experiments revealed that combining SIFT did not improve the accuracy of the system however, we obtained higher accuracy than state-of-the-art methods with our deep only solution. © Springer Nature Switzerland AG 2019.","10.1007/978-3-030-01054-6_10","Melanoma detection; ResNet; SIFT","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057074503&doi=10.1007%2f978-3-030-01054-6_10&partnerID=40&md5=d3085f1b39a0073fd6ee5073ffabedfd"
"Macroscopic Pigmented Skin Lesion Prescreening","Bernart E.; Flores E.S.; Scharcanski J.","2018","1","1","0","0","0","Unique","0","","","","","","","Melanoma is one of the deadliest types of pigmented skin lesions, and if identified in the earlier stages can increase the patient survival rate. The use of digital cameras as an alternative to other devices, such as dermatoscope, is gaining space in skin lesion prescreening with e-health systems used in the macroscopic diagnose of pigmented skin lesion images. The traditional framework used to classify macroscopic pigmented skin lesion (MPSL) images consists of a preprocessing step to remove hair and shading effects, followed by the lesion area detection and segmentation. Next, techniques are used to extract a set of features from the obtained region, and these attributes make it possible to distinguish between malignant and benign cases. Usually, the features are extracted from data labeled by a specialist, and are used to train a machine learning algorithm, which is then used to suggest a diagnosis for an undiagnosed skin lesion image. In this work, we present a review of some of the most recent advances in MPSL segmentation and classification. © 2019 Elsevier Inc. All rights reserved.","10.1016/B978-0-12-801238-3.99956-2","Classification; Macroscopy; Melanocytic lesion; Segmentation","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011456217&doi=10.1016%2fB978-0-12-801238-3.99956-2&partnerID=40&md5=0e6989a5a4290c4b780e16cf9cfb9442"
"A structure-aware convolutional neural network for skin lesion classification","Thandiackal K.; Goksel O.","2018","1","1","0","0","0","Unique","0","","","","","","","Neural networks have emerged as a successful tool to solve end-to-end classification problems, potentially applicable in many diagnostic settings once trained with a sufficient number of existing annotations. Nevertheless, in such training it is often nontrivial to enter already available domain knowledge. We herein propose a simple approach of inputing any such information as additional layers to a network. This may then yield better performance by allowing for networks with fewer parameters that can be tuned with fewer annotations and with better generalization capabilities. This can also allow for interpretability of a deep network, by quantifying attribution to such additional inputs. We study this approach for the task of skin lesion classification, where we focus on prior knowledge in the form of pigment networks as they are known visual indicators of certain skin lesions, e.g. melanoma. We used a public dataset of dermoscopic images, where a low number of feature segmentations and a high number of classifications are provided in disjoint datasets. By including information from learned pigment network segmentations, the recall for malignant melanoma was seen to increase from 0.213 to 0.4. To help interpret the results, we also quantified the “attention” to pigment networks paid by the deep classifier both location- and channel-wise. © Springer Nature Switzerland AG 2018.","10.1007/978-3-030-01201-4_34","Attention; Deep learning; Dermoscopy; Interpretability","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054864394&doi=10.1007%2f978-3-030-01201-4_34&partnerID=40&md5=7aafe96a9cb9e5796206e13a47129093"
"Genetic programming for feature selection and feature construction in skin cancer image classification","Ain Q.U.; Xue B.; Al-Sahaf H.; Zhang M.","2018","1","1","0","0","0","Unique","0","","","","","","","The incidence of skin cancer, particularly, malignant melanoma, continues to increase worldwide. If such a cancer is not treated at an early stage, it can be fatal. A computer system based on image processing and computer vision techniques, having good diagnostic ability, can provide a quantitative evaluation of these skin cancer cites called skin lesions. The size of a medical image is usually large and therefore requires reduction in dimensionality before being processed by a classification algorithm. Feature selection and construction are effective techniques in reducing the dimensionality while improving classification performance. This work develops a novel genetic programming (GP) based two-stage approach to feature selection and feature construction for skin cancer image classification. Local binary pattern is used to extract gray and colour features from the dermoscopy images. The results of our proposed method have shown that the GP selected and constructed features have promising ability to improve the performance of commonly used classification algorithms. In comparison with using the full set of available features, the GP selected and constructed features have shown significantly better or comparable performance in most cases. Furthermore, the analysis of the evolved feature sets demonstrates the insights of skin cancer properties and validates the feature selection ability of GP to distinguish between benign and malignant cancer images. © Springer Nature Switzerland AG 2018.","10.1007/978-3-319-97304-3_56","Dimensionality reduction; Feature construction; Feature selection; Genetic programming; Image classification","25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051988902&doi=10.1007%2f978-3-319-97304-3_56&partnerID=40&md5=20d1b90cb1422fdcfa32e1e7c4c3302d"
"Deeply supervised rotation equivariant network for lesion segmentation in dermoscopy images","Li X.; Yu L.; Fu C.-W.; Heng P.-A.","2018","0","1","0","0","0","Unique","0","","","","","","","Automatic lesion segmentation in dermoscopy images is an essential step for computer-aided diagnosis of melanoma. The dermoscopy images exhibits rotational and reflectional symmetry, however, this geometric property has not been encoded in the state-of-the-art convolutional neural networks based skin lesion segmentation methods. In this paper, we present a deeply supervised rotation equivariant network for skin lesion segmentation by extending the recent group rotation equivariant network. Specifically, we propose the G-upsampling and G-projection operations to adapt the rotation equivariant classification network for our skin lesion segmentation problem. To further increase the performance, we integrate the deep supervision scheme into our proposed rotation equivariant segmentation architecture. The whole framework is equivariant to input transformations, including rotation and reflection, which improves the network efficiency and thus contributes to the segmentation performance. We extensively evaluate our method on the ISIC 2017 skin lesion challenge dataset. The experimental results show that our rotation equivariant networks consistently excel the regular counterparts with the same model complexity under different experimental settings. Our best model also outperforms the state-of-the-art challenging methods, which further demonstrate the effectiveness of our proposed deeply supervised rotation equivariant segmentation network. © Springer Nature Switzerland AG 2018.","10.1007/978-3-030-01201-4_25","","23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054823433&doi=10.1007%2f978-3-030-01201-4_25&partnerID=40&md5=2eced0201bc209f38bec84879960057f"
"Detection and classification of pigment network in dermoscopic color images as one of the 7-point checklist criteria","Jaworek-Korjakowska J.; Kłeczek P.; Tadeusiewicz R.","2018","0","1","0","0","0","Unique","0","","","","","","","Malignant melanoma, which is a dangerous proliferation of melanocytes, is commonly diagnosed in all people, regardless of age, gender, or race. In the last several years an increasing melanoma incidence and mortality rate has been observed worldwide and it is rising faster than other forms of cancer. In this paper we present a new approach to the detection and classification of pigment network, one of the major feature in a widely used diagnostic algorithm 7-point checklist. Accurate assessment of pigment network is clinically important due to a significantly different occurrence in benign and malignant skin lesions. We describe a complex algorithm containing following steps: image enhancement, lesion segmentation, pigment network detection as well as classification. The algorithm has been tested on 300 dermoscopic images and achieved 91% sensitivity and classification accuracy of 85%. Compared to state-of-the-art, we obtain improved classification accuracy. © 2018, Springer International Publishing AG.","10.1007/978-3-319-66905-2_15","","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028712054&doi=10.1007%2f978-3-319-66905-2_15&partnerID=40&md5=74522c64594a348502776d386ecf2ee7"
"A deep learning approach to vascular structure segmentation in dermoscopy colour images","Jaworek-Korjakowska J.","2018","0","1","0","0","0","Unique","0","","","","","","","Background. Atypical vascular pattern is one of the most important features by differentiating between benign and malignant pigmented skin lesions. Detection and analysis of vascular structures is a necessary initial step for skin mole assessment; it is a prerequisite step to provide an accurate outcome for the widely used 7-point checklist diagnostic algorithm. Methods. In this research we present a fully automated machine learning approach for segmenting vascular structures in dermoscopy colour images. The U-Net architecture is based on convolutional networks and designed for fast and precise segmentation of images. After preprocessing the images are randomly divided into 146516 patches of 64 × 64 pixels each. Results. On the independent validation dataset including 74 images our implemented method showed high segmentation accuracy. For the U-Net convolutional neural network, an average DSC of 0.84, sensitivity 0.85, and specificity 0.81 has been achieved. Conclusion. Vascular structures due to small size and similarity to other local structures create enormous difficulties during the segmentation and assessment process. The use of advanced segmentation methods like deep learning, especially convolutional neural networks, has the potential to improve the accuracy of advanced local structure detection. Copyright © 2018 Joanna Jaworek-Korjakowska. This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.","10.1155/2018/5049390","","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062858736&doi=10.1155%2f2018%2f5049390&partnerID=40&md5=adddb2d849d6717c68735556fedba172"
"Star Shape Prior in Fully Convolutional Networks for Skin Lesion Segmentation","Mirikharaji Z.; Hamarneh G.","2018","1","1","0","0","0","Unique","0","","","","","","","Semantic segmentation is an important preliminary step towards automatic medical image interpretation. Recently deep convolutional neural networks have become the first choice for the task of pixel-wise class prediction. While incorporating prior knowledge about the structure of target objects has proven effective in traditional energy-based segmentation approaches, there has not been a clear way for encoding prior knowledge into deep learning frameworks. In this work, we propose a new loss term that encodes the star shape prior into the loss function of an end-to-end trainable fully convolutional network (FCN) framework. We penalize non-star shape segments in FCN prediction maps to guarantee a global structure in segmentation results. Our experiments demonstrate the advantage of regularizing FCN parameters by the star shape prior and our results on the ISBI 2017 skin segmentation challenge data set achieve the first rank in the segmentation task among 21 participating teams. © 2018, Springer Nature Switzerland AG.","10.1007/978-3-030-00937-3_84","","115","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053836914&doi=10.1007%2f978-3-030-00937-3_84&partnerID=40&md5=2f2bdc77b2bd6d151679cde621294612"
"Generating highly realistic images of skin lesions with GANs","Baur C.; Albarqouni S.; Navab N.","2018","1","1","0","0","0","Unique","0","","","","","","","As many other machine learning driven medical image analysis tasks, skin image analysis suffers from a chronic lack of labeled data and skewed class distributions, which poses problems for the training of robust and well-generalizing models. The ability to synthesize realistic looking images of skin lesions could act as a reliever for the aforementioned problems. Generative Adversarial Networks (GANs) have been successfully used to synthesize realistically looking medical images, however limited to low resolution, whereas machine learning models for challenging tasks such as skin lesion segmentation or classification benefit from much higher resolution data. In this work, we successfully synthesize realistically looking images of skin lesions with GANs at such high resolution. Therefore, we utilize the concept of progressive growing, which we both quantitatively and qualitatively compare to other GAN architectures such as the DCGAN and the LAPGAN. Our results show that with the help of progressive growing, we can synthesize highly realistic dermoscopic images of skin lesions that even expert dermatologists find hard to distinguish from real ones. © Springer Nature Switzerland AG 2018.","10.1007/978-3-030-01201-4_28","","63","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054877487&doi=10.1007%2f978-3-030-01201-4_28&partnerID=40&md5=48a56befb4260f0b7b32903dd41ad5dd"
"Workshop on Bildverarbeitung fur die Medizin, 2018","","2018","0","1","0","0","0","Unique","0","","","","","","","The proceedings contain 96 papers. The special focus in this conference is on Bildverarbeitung fur die Medizin. The topics include: First approaches towards automatic detection of microaneurysms in OCTA images; Automatic malignancy estimation for pulmonary nodules from CT images; Amplitude of brain signals classify hunger status based on machine learning in resting-state fMRI; assessment of segmentation dependence in macroscopic lung cavity extraction; percutaneous pelvis fixation using the camera-augmented C-arm: First successes in ex vivo deployment; augmented reality im operationssaal; efficient labeling of optical coherence tomography angiography data using eye tracking; leveraging open source software to close translational gaps in medical image computing; 3D-CNNs for deep binary descriptor learning in medical volume data; reinventing bone surgery: From planning to execution of a hard-tissue cut; detecting and measuring surface area of skin lesions; deep hashing for large-scale medical image retrieval; physiological parameter estimation from multispectral images unleashed; probabilistic appearance models for medical image analysis; Robust multi-scale anatomical landmark detection in incomplete 3D-CT data; Exploring sparsity in CNNs for medical image segmentation BRIEFnet; Fast MRI whole brain segmentation with fully convolutional neural networks; patient surface model and internal anatomical landmarks embedding; Comparison of self-similarity measures for multi-modal non-rigid registration of 3D-PLI brain images; two-step trajectory visualization for robot-assisted spine radiofrequency ablations; from mechanistic to data-driven models for surgical planning, guidance and simulation; unsupervised pathology detection in medical images using learning-based methods; Classification of lobular and ductal breast carcinomas by texture analysis in DCE-MRI data; towards full-body X-ray images; patches in magnetic particle imaging.","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138866846&partnerID=40&md5=1c43269c5c642064b9484cba12ffd2cf"
"A review of denoising medical images using machine learning approaches","Kaur P.; Singh G.; Kaur P.","2018","0","1","0","0","0","Unique","0","","","","","","","Background: This paper attempts to identify suitable Machine Learning (ML) approach for image denoising of radiology based medical application. The Identification of ML approach is based on (i) Review of ML approach for denoising (ii) Review of suitable Medical Denoising approach. Discussion: The review focuses on six application of radiology: Medical Ultrasound (US) for fetus development, US Computer Aided Diagnosis (CAD) and detection for breast, skin lesions, brain tumor MRI diagnosis, X-Ray for chest analysis, Breast cancer using MRI imaging. This survey identifies the ML approach with better accuracy for medical diagnosis by radiologists. The image denoising approaches further includes basic filtering techniques, wavelet medical denoising, curvelet and optimization techniques. In most of the applications, the machine learning performance is better than the conventional image denoising techniques. For fast and computational results the radiologists are using the machine learning methods on MRI, US, X-Ray and Skin lesion images. The characteristics and contributions of different ML approaches are considered in this paper. Conclusion: The problem faced by the researchers during image denoising techniques and machine learning applications for clinical settings have also been discussed. © 2018 Bentham Science Publishers.","10.2174/1573405613666170428154156","Classifiers; Curvelets; Data mining methods; Filtering techniques; Image denoising; Ultrasound; Wavelets","86","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053254430&doi=10.2174%2f1573405613666170428154156&partnerID=40&md5=b9be3f444c684ee77edbaa813acfc041"
"A multiresolution convolutional neural network with partial label training for annotating reflectance confocal microscopy images of skin","Bozkurt A.; Kose K.; Alessi-Fox C.; Gill M.; Dy J.; Brooks D.; Rajadhyaksha M.","2018","1","1","0","0","0","Unique","0","","","","","","","We describe a new multiresolution “nested encoder-decoder” convolutional network architecture and use it to annotate morphological patterns in reflectance confocal microscopy (RCM) images of human skin for aiding cancer diagnosis. Skin cancers are the most common types of cancers, melanoma being the most deadly among them. RCM is an effective, non-invasive pre-screening tool for skin cancer diagnosis, with the required cellular resolution. However, images are complex, low-contrast, and highly variable, so that it requires months to years of expert-level training for clinicians to be able to make accurate assessments. In this paper we address classifying 4 key clinically important structural/textural patterns in RCM images. The occurrence and morphology of these patterns are used by clinicians for diagnosis of melanomas. The large size of RCM images, the large variance of pattern size, the large scale range over which patterns appear, the class imbalance in collected images, and the lack of fully-labelled images all make this a challenging problem to address, even with automated machine learning tools. We designed a novel nested U-net architecture to cope with these challenges, and a selective loss function to handle partial labeling. Trained and tested on 56 melanoma-suspicious, partially labelled, 12k × 12k pixel images, our network automatically annotated RCM images for these diagnostic patterns with high sensitivity and specificity, providing consistent labels for unlabelled sections of the test images. We believe that providing such annotation in a fast manner will aid clinicians in achieving diagnostic accuracy, and perhaps more important, dramatically facilitate clinical training, thus enabling much more rapid adoption of RCM into widespread clinical use process. In addition our adaptation of U-net architecture provides an intrinsically multiresolution deep network that may be useful in other challenging biomedical image analysis applications. © Springer Nature Switzerland AG 2018.","10.1007/978-3-030-00934-2_33","Melanoma; Reflectance confocal microscopy; Segmentation","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054068516&doi=10.1007%2f978-3-030-00934-2_33&partnerID=40&md5=7bd30ec693abeda69325172f22d4bfb2"
"Classification for dermoscopy images using convolutional neural networks based on region average pooling","Yang J.; Xie F.; Fan H.; Jiang Z.; Liu J.","2018","0","1","0","0","0","First occurrence","0","","","","","","","In this paper, a novel melanoma classification method based on convolutional neural networks is proposed for dermoscopy images. First a region average pooling (RAPooling) method is introduced which makes feature extraction can focus on the region of interest. Then an end-to-end classification framework combining with segmentation information is designed, which uses the segmented lesion region to guide the classification by RAPooling. Finally, a linear classifier RankOpt based on the area under the ROC curve is used to optimize and obtain the final classification result. The proposed method integrates segmentation information into the classification task, and in addition, by the optimization of RankOpt, a better classification performance for imbalanced dermoscopy image dataset is obtained. Experiments are conducted on ISBI 2017 skin lesion analysis towards melanoma detection challenge dataset, and comparisons with the other state-of-the-art methods demonstrate the effectiveness of our method. © 2013 IEEE.","10.1109/ACCESS.2018.2877587","Convolutional neural networks; Dermoscopy images; Melanoma detection; Region average pooling","74","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055703863&doi=10.1109%2fACCESS.2018.2877587&partnerID=40&md5=43944936cb4789d2d62f699cf5591810"
"Convolutional neural-adaptive networks for melanoma recognition","Bakkouri I.; Afdel K.","2018","0","1","0","0","0","Unique","0","","","","","","","Designing appropriate features for melanoma recognition tasks is an active field of research. Current deep Convolutional Neural Network (CNN) based recognition methods for medical images need collection of large volumes of labeled data in order to train a new CNN. However, this approach implies very long calculation times and high computational costs. Inspired by transfer learning, we are interested in studying efficacy of lower convolutional weights adaptation process for addressing the challenge of small training data sizes in the dermoscopic domain. It is a convenient deep adaptation network in terms of overfitting prevention, convergence speed and high performance achievement. We evaluated our methodology on the publicly dermoscopic dataset such as the International Skin Imaging Collaboration (ISIC) database using 5-fold cross-validation. In comparison with the current state-of-the-art methods, the experiments show that our proposed system provides efficient results, achieving an average area under the receiver operating characteristic curve (AUC) of 96.66%. © Springer International Publishing AG, part of Springer Nature 2018.","10.1007/978-3-319-94211-7_49","CNN; Dermoscopy; Melanoma recognition; Weights adaptation","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049681480&doi=10.1007%2f978-3-319-94211-7_49&partnerID=40&md5=804d76b4fccf0e03e1378f12a63b83be"
"Automatic detection of eczema using image processing","Srivastava S.; Singh A.; Gupta R.","2018","0","1","0","0","0","Unique","0","","","","","","","Eczema is the most common form of skin disease in humans. Skin diseases like eczema, if not detected and controlled early, may lead to severe health and financial consequences for patients. Most of the skin disease is curable at initial stages with the improvement in technology. Also, an early detection of skin disease can prevent the progression of the disease and save the patient’s life. Early measurement of disease harshness, combined with a recommendation for skin protection and use of appropriate medication, can prevent the disease from worsening. At present, diagnosis can be costly and time-consuming. In this paper, a method for early detection of eczema is presented using modern image processing and algorithms. Techniques such as preprocessing, segmentation, feature extraction, filtering, edge detection, etc. are part of image processing and are used to identify the part affected by disease. Simulation suggests that the proposed system can successfully detect the regions affected by eczema. An attempt has been made to detect eczema-affected region with the help of proposed algorithm. © Springer International Publishing AG, part of Springer Nature 2018.","10.1007/978-3-319-75626-4_13","Automatic detection; Eczema; Image processing; Morphology","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090256947&doi=10.1007%2f978-3-319-75626-4_13&partnerID=40&md5=582de77130e5fc7bc68659065c3f8ea5"
"6th International Conference on Mining Intelligence and Knowledge Exploration, MIKE 2018","","2018","0","1","0","0","0","Unique","0","","","","","","","The proceedings contain 33 papers. The special focus in this conference is on Mining Intelligence and Knowledge Exploration. The topics include: Categorical modeling method of intelligent WorkFlow; classification of dengue serotypes using protein sequence based on rule extraction from neural network; orienting social event streams as data stories; software driven optimal design for maintenance man hour; modeling trajectory data as a directed graph; connected cars traffic flow balancing based on classification and calibration; identification and control of a car speed dynamics using artificial intelligence; industry 4.0, intelligent visual assisted picking approach; Detection and mapping of a toxic cloud using UAVs and emergent techniques; Meaningful clusterings of recurrent neural network activations for NLP; convolutional neural networks for multi-class intrusion detection system; wraudit: A tool to transparently monitor web resources’ integrity; using stigmergy to incorporate the time into artificial neural networks; modeling sustainability reporting with ternary attractor neural networks; analysing a periodical and multi-dimensional time series; stock price forecasting over adaptive timescale using supervised learning and receptive fields; Periodically diluted BEGNN model of corruption perception; neural machine translation with recurrent highway networks; a comparative study of methods used in the analysis and prediction of financial data; skin lesion images segmentation: A survey of the state-of-the-art; automatic extraction of structured information from drug descriptions; skin lesion segmentation using enhanced unified Markov random field; texture classification using deep convolutional neural network with ensemble learning; a novel decision tree approach for the handling of time series; reference metadata extraction from Korean research papers.","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059099483&partnerID=40&md5=323f1fb1c409772098d812c063577fab"
"Hybrid two-stage active contour method with region and edge information for intensity inhomogeneous image segmentation","Soomro S.; Munir A.; Choi K.N.","2018","0","1","0","0","0","Unique","0","","","","","","","This paper presents a novel two-stage image segmentation method using an edge scaled energy functional based on local and global information for intensity inhomogeneous image segmentation. In the first stage, we integrate global intensity term with a geodesic edge term, which produces a preliminary rough segmentation result. Thereafter, by taking final contour of the first stage as initial contour, we begin second stage segmentation process by integrating local intensity term with geodesic edge term to get final segmentation result. Due to the suitable initialization from the first stage, the second stage precisely achieves desirable segmentation result for inhomogeneous image segmentation. Two stage segmentation technique not only increases the accuracy but also eliminates the problem of initial contour existed in traditional local segmentation methods. The energy function of the proposed method uses both global and local terms incorporated with compacted geodesic edge term in an additive fashion which uses image gradient information to delineate obscured boundaries of objects inside an image. A Gaussian kernel is adapted for the regularization of the level set function and to avoid an expensive re-initialization. The experiments were carried out on synthetic and real images. Quantitative validations were performed on Multimodal Brain Tumor Image Segmentation Benchmark (BRATS) 2015 and PH 2 skin lesion database. The visual and quantitative comparisons will demonstrate the efficiency of the proposed method. © 2018 Soomro et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","10.1371/journal.pone.0191827","","50","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041202985&doi=10.1371%2fjournal.pone.0191827&partnerID=40&md5=0dd45e4732dc2f44650903f2a37242b4"
"Pre-trained convolutional neural network for classification of tanning leather image","Winiarti S.; Prahara A.; Murinto; Ismi D.P.","2018","0","1","0","0","0","Unique","0","","","","","","","Leather craft products, such as belt, gloves, shoes, bag, and wallet are mainly originated from cow, crocodile, lizard, goat, sheep, buffalo, and stingray skin. Before the skins are used as leather craft materials, they go through a tanning process. With the rapid development of leather craft industry, an automation system for leather tanning factories is important to achieve large scale production in order to meet the demand of leather craft materials. The challenges in automatic leather grading system based on type and quality of leather are the skin color and texture after tanning process will have a large variety within the same skin category and have high similarity with the other skin categories. Furthermore, skin from different part of animal body may have different color and texture. Therefore, a leather classification method on tanning leather image is proposed. The method uses pre-trained deep convolution neural network (CNN) to extract rich features from tanning leather image and Support Vector Machine (SVM) to classify the features into several types of leather. Performance evaluation shows that the proposed method can classify various types of leather with good accuracy and superior to other state-of-the-art leather classification method in terms of accuracy and computational time. © 2015 The Science and Information (SAI) Organization Limited.","10.14569/IJACSA.2018.090129","Convolution neural network (CNN); Deep learning; Leather classification; Support vector machine (SVM); Tanning leather","30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049503625&doi=10.14569%2fIJACSA.2018.090129&partnerID=40&md5=bf482eb7846551f89e509742d40d91ba"
"Webly supervised learning for skin lesion classification","Navarro F.; Conjeti S.; Tombari F.; Navab N.","2018","1","1","0","0","0","Unique","0","","","","","","","Within medical imaging, manual curation of sufficient well-labeled samples is cost, time and scale-prohibitive. To improve the representativeness of the training dataset, for the first time, we present an approach to utilize large amounts of freely available web data through web-crawling. To handle noise and weak nature of web annotations, we propose a two-step transfer learning based training process with a robust loss function, termed as Webly Supervised Learning (WSL) to train deep models for the task. We also leverage search by image to improve the search specificity of our web-crawling and reduce cross-domain noise. Within WSL, we explicitly model the noise structure between classes and incorporate it to selectively distill knowledge from the web data during model training. To demonstrate improved performance due to WSL, we benchmarked on a publicly available 10-class fine-grained skin lesion classification dataset and report a significant improvement of top-1 classification accuracy from 71.25% to 80.53% due to the incorporation of web-supervision. © Springer Nature Switzerland AG 2018.","10.1007/978-3-030-00934-2_45","","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054070905&doi=10.1007%2f978-3-030-00934-2_45&partnerID=40&md5=3fa559c040b3de611a6f805e5150d063"
"Visualizing convolutional neural networks to improve decision support for skin lesion classification","Van Molle P.; De Strooper M.; Verbelen T.; Vankeirsbilck B.; Simoens P.; Dhoedt B.","2018","1","0","0","0","0","Unique","0","","","","","","","Because of their state-of-the-art performance in computer vision, CNNs are becoming increasingly popular in a variety of fields, including medicine. However, as neural networks are black box function approximators, it is difficult, if not impossible, for a medical expert to reason about their output. This could potentially result in the expert distrusting the network when he or she does not agree with its output. In such a case, explaining why the CNN makes a certain decision becomes valuable information. In this paper, we try to open the black box of the CNN by inspecting and visualizing the learned feature maps, in the field of dermatology. We show that, to some extent, CNNs focus on features similar to those used by dermatologists to make a diagnosis. However, more research is required for fully explaining their output. © Springer Nature Switzerland AG 2018.","10.1007/978-3-030-02628-8_13","Deep learning; Dermatology; Skin lesions; Visualization","49","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056478318&doi=10.1007%2f978-3-030-02628-8_13&partnerID=40&md5=5df81d36e9b654eb05f3b017b02950aa"
"Embedded healthcare system based on bioimpedance analysis for identification and classification of skin diseases in Indian context","Patil P.M.; Kamat D.K.","2018","1","1","0","0","0","Unique","0","","","","","","","This chapter contributes toward real-time data collection, data management, system design, and analysis related to an embedded U-healthcare system for various skin diseases. The application domains of the developed system include diagnostic services, decision-support systems, and U-healthcare systems in real-world healthcare applications. The chapter explains a system developed for noninvasive identification and classification of skin diseases in the Indian context. The chapter describes the global scenario of skin diseases as well as in developing countries such as India. There are various challenges faced by dermatologists in the identification and classification of skin diseases. These are described with reference to state-of-the-art dermatological practices such as visual inspection, histopathological examination of a biopsy, and dermoscopy. The limitations of these subjective methods are discussed. The need to devise a noninvasive, reliable, simple, safe, and objective technique is described with reference to bioimpedance measurement. The chapter further describes a system developed for the measurement of human skin impedance. Skin impedance is measured with the help of a developed skin electrode. The requirements, specifications, and limitations of the developed skin electrode are described. The generation of a database of Indian skin diseases is described. The impedance of diseased and normal skin is measured with the help of the developed system and various impedance indices have been computed for an individual subject. The need of impedance indices for identification and classification of skin diseases is described. The identification of skin diseases requires discrimination between diseased and normal skin, which is explained with the help of the Wilcoxon signed rank test. The role of the Statistical Package for the Social Sciences (SPSS) is explained for computing the probability of similarity between diseased and normal skin. The possibility of the classification of skin diseases is described with the help of box and whisker plots and statistical measures of central tendency. The classification of skin diseases using a modular fuzzy hypersphere neural network has been explained. The performance of the proposed system for classification of skin diseases is explained with the help of confusion matrix and timing analysis. © 2019 Elsevier Inc. All rights reserved.","10.1016/B978-0-12-815370-3.00011-6","Bioimpedance; Data management; Embedded healthcare system; Impedance indices; Noninvasive measurements; Real-time data collection; Skin diseases","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088142685&doi=10.1016%2fB978-0-12-815370-3.00011-6&partnerID=40&md5=71131cce05bdc805c5cc8e43b14af488"
"Data augmentation for skin lesion analysis","Perez F.; Vasconcelos C.; Avila S.; Valle E.","2018","1","1","0","0","0","Unique","0","","","","","","","Deep learning models show remarkable results in automated skin lesion analysis. However, these models demand considerable amounts of data, while the availability of annotated skin lesion images is often limited. Data augmentation can expand the training dataset by transforming input images. In this work, we investigate the impact of 13 data augmentation scenarios for melanoma classification trained on three CNNs (Inception-v4, ResNet, and DenseNet). Scenarios include traditional color and geometric transforms, and more unusual augmentations such as elastic transforms, random erasing and a novel augmentation that mixes different lesions. We also explore the use of data augmentation at test-time and the impact of data augmentation on various dataset sizes. Our results confirm the importance of data augmentation in both training and testing and show that it can lead to more performance gains than obtaining new images. The best scenario results in an AUC of 0.882 for melanoma classification without using external data, outperforming the top-ranked submission (0.874) for the ISIC Challenge 2017, which was trained with additional data. © Springer Nature Switzerland AG 2018.","10.1007/978-3-030-01201-4_33","Data augmentation; Deep learning; Skin lesion analysis","167","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054813602&doi=10.1007%2f978-3-030-01201-4_33&partnerID=40&md5=ca8e55df52bc750d1d10e039a5974eda"
"Comprehensive insights into evaluation and benchmarking of real-time skin detectors: Review, open issues & challenges, and recommended solutions","Yas Q.M.; Zaidan A.A.; Zaidan B.B.; Rahmatullah B.; Abdul Karim H.","2018","1","1","0","0","0","Unique","0","","","","","","","Evaluation and benchmarking of real-time skin detectors remain challenging because of multiple evaluation attributes that must be considered. Numerous evaluation and benchmarking techniques have been proposed, but they exhibit several limitations. Fixing multiple attributes based on benchmarking approaches by using other attributes limits reliable real-time skin detection. This paper presents comprehensive insights into the evaluation and benchmarking of real-time skin detectors on the basis of two critical directions. Current evaluation criteria highlight conflicting issues and benchmarking techniques to identify weak points, and possible solutions are discussed. The findings are as follows: (1) open issues and challenges to evaluation and benchmarking are emphasized; and (2) decision making using multiple criteria such as reliability, time complexity, and error rate within a dataset is used for evaluating and benchmarking real-time skin detectors to come up with solutions for future directions. © 2017 Elsevier Ltd","10.1016/j.measurement.2017.09.027","Evaluation and benchmarking; Multi-criteria analysis; Multi-criterion decision making; Skin detector","64","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030544821&doi=10.1016%2fj.measurement.2017.09.027&partnerID=40&md5=2b31ff96b3f340c71219cdc6eaf02b07"
"Evaluation of scaly levels in psoriasis using multispectral polarized imaging","Van Tien T.; Phuc N.H.; Nhien L.Q.; Trang T.T.T.; Hieu D.S.; Cat P.N.K.; Mien P.T.H.; Linh H.Q.","2018","0","1","0","0","0","Unique","0","","","","","","","Psoriasis is a chronic inflammatory skin condition characterised by the changes of skin cell’slife cycle. These skin patches are typically red, itch, and scale. Psoriasis area severity index (PASI) is currently the gold standard score for the assessment and management of psoriasis level. However, using PASI is sometimes subjective as it is possible to derive two different severity scores with the same lesion. In this research, we developed the multispectral polarized imaging system to capture the image of psoriasis and used image processing method for evaluating the scaly levels. Based on that, the algorithm has been developed to directly and automatically segment scale from the skin surface and the redness regions. This system will be able to diagnose of psoriasis skin disease more quickly and exactly according to PASI index. © Springer Nature Singapore Pte Ltd. 2018.","10.1007/978-981-10-4361-1_16","Multispectral polarized imaging; Psoriasis; Scaling segment","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030867086&doi=10.1007%2f978-981-10-4361-1_16&partnerID=40&md5=e95b84346e57c2f00821ae1bb9b83f5c"
"Soft computing approach based segmentation and analysis of skin cancer","DIvya G.; Uniyal D.; Sivakumar R.; Sundaravadivu K.","2017","1","1","0","0","0","First occurrence","0","","","","","","","Skin melanoma is one of the common and most important cancer among human beings. In recent years, a numerous procedures have been proposed to detect and analyze skin cancer. The initial screening of the skin cancer is carried out visually by a doctor. Later, the suspicious regions are recorded using a digital dermatoscope. In the proposed research work, extraction of the cancerous region from the dermoscopy image is performed using the Firefly Algorithm (FA) based Tsallis function and the Active Contour Segmentation (ACS) procedures existing in the literature. In this work, the well known skin cancer database, DERMQUEST is considered for the analysis. The efficiency of the proposed approach is confirmed using some well known image quality measures. The simulation result of this work confirms that, the proposed approach offers better values of precision, sensitivity, specificity, and accuracy. © 2017 IEEE.","10.1109/ICCCI.2017.8117799","accuracy; active contour; segmentation; skin cancer; thresholding","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041436574&doi=10.1109%2fICCCI.2017.8117799&partnerID=40&md5=893919f9726cc50e1302db409c64fbae"
"Wavelet-based statistical classification of skin images acquired with reflectance confocal microscopy","Halimi A.; Batatia H.; Digabel J.L.; Josse G.; Tourneret J.Y.","2017","1","1","0","0","0","Unique","0","","","","","","","Detecting skin lentigo in reflectance confocal microscopy images is an important and challenging problem. This imaging modality has not yet been widely investigated for this problem and there are a few automatic processing techniques. They are mostly based on machine learning approaches and rely on numerous classical image features that lead to high computational costs given the very large resolution of these images. This paper presents a detection method with very low computational complexity that is able to identify the skin depth at which the lentigo can be detected. The proposed method performs multiresolution decomposition of the image obtained at each skin depth. The distribution of image pixels at a given depth can be approximated accurately by a generalized Gaussian distribution whose parameters depend on the decomposition scale, resulting in a very-low-dimension parameter space. SVM classifiers are then investigated to classify the scale parameter of this distribution allowing real-time detection of lentigo. The method is applied to 45 healthy and lentigo patients from a clinical study, where sensitivity of 81.4% and specificity of 83.3% are achieved. Our results show that lentigo is identifiable at depths between 50µm and 60µm, corresponding to the average location of the the dermoepidermal junction. This result is in agreement with the clinical practices that characterize the lentigo by assessing the disorganization of the dermoepidermal junction. © 2017 Optical Society of America.","10.1364/BOE.8.005450","","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037334355&doi=10.1364%2fBOE.8.005450&partnerID=40&md5=54d222d7de03ca2ee7eba12dad636a10"
"Deep learning for skin lesion segmentation","Mishra R.; Daescu O.","2017","1","1","0","0","0","First occurrence","0","","","","","","","Melanomas are the most aggressive form of skin cancer. Due to observer bias, computerized analysis of dermoscopy images has become an important research area. One of the most important steps in dermoscopy image analysis is the automated detection of lesion areas in the dermoscopy images. In this paper, we present a deep learning method for automatic skin lesion segmentation. We use a subset of the International Skin Imaging Collaboration (ISIC) Archive dataset, which contains dermoscopic images paired with their corresponding lesion binary masks, provided by IEEE International Symposium on Biomedical Imaging (ISBI) 2017 challenge for Skin Lesion Analysis Towards Melanoma Detection, and compare against the benchmark results submitted by other participants. The experimental results show that our proposed method can outperform the submissions in terms of segmentation accuracy. © 2017 IEEE.","10.1109/BIBM.2017.8217826","Convolutional neural network; Deep Learning; Melonama; Skin Lesion Segmentation","46","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046035884&doi=10.1109%2fBIBM.2017.8217826&partnerID=40&md5=ce33afc92aed930a8cae77a95a802659"
"Bagged textural and color features for melanoma skin cancer detection in dermoscopic and standard images","Alfed N.; Khelifi F.","2017","1","1","0","0","0","Unique","0","","","","","","","Early detection of malignant melanoma skin cancer is crucial for treating the disease and saving lives. Many computerized techniques have been reported in the literature to diagnose and classify the disease with satisfactory skin cancer detection performance. However, reducing the false detection rate is still challenging and preoccupying because false positives trigger the alarm and require intervention by an expert pathologist for further examination and screening. In this paper, an automatic skin cancer diagnosis system that combines different textural and color features is proposed. New textural and color features are used in a bag-of-features approach for efficient and accurate detection. We particularly claim that the Histogram of Gradients (HG) and the Histogram of Lines (HL) are more suitable for the analysis and classification of dermoscopic and standard skin images than the conventional Histogram of Oriented Gradient (HOG) and the Histogram of Oriented Lines (HOL), respectively. The HG and HL are bagged separately using a codebook for each and then combined with other bagged color vector angles and Zernike moments to exploit the color information. The overall system has been assessed through intensive experiments using different classifiers on a dermoscopic image dataset and another standard dataset. Experimental results have shown the superiority of the proposed system over state-of-the-art techniques. © 2017 Elsevier Ltd","10.1016/j.eswa.2017.08.010","Dermoscopic images; Malignant melanoma; Skin cancer diagnosis; Standard skin images; Textural and color features","81","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028927276&doi=10.1016%2fj.eswa.2017.08.010&partnerID=40&md5=4d6e164361247c35123b391b9d41dda3"
"Otsu's multi-thresholding and active contour snake model to segment dermoscopy images","Rajinikanth V.; MadhavaRaja N.S.; Satapathy S.C.; Fernandes S.L.","2017","0","1","0","0","0","Unique","0","","","","","","","Melanoma is one of the deadliest form of skin cancer widely which affects human beings. Due to its growing occurrence rates, it is essential to develop an assisting methodology to support the present clinical detection procedures. Digital dermatoscopy is a clinically proven process to record and analyse the suspicious regions of skin. Extracting the uncertain region from dermoscopy image is generally preferred to have a clear idea about skin infections. The success of skin infection forecast relies primarily on the chosen image segmentation and analysing tool. In this paper, heuristic algorithm assisted multi-thresholding and Active Contour Snake Model (ACSM) based segmentation is proposed to extract the cancerous section from the image dataset. The experimental results obtained with ACSM are then validated with the segmentation results of Localized Active Contour (LAC) and Regularized Level Set (RLS) approaches. The results confirm that proposed approach offers better values of image similarity index and statistical measures compared with the alternatives. Copyright © 2017 American Scientific Publishers.","10.1166/jmihi.2017.2265","Active Contour Snake Model; Dermoscopy Image; Otsu's Function; Skin Melanoma; Statistical Measures","75","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032938321&doi=10.1166%2fjmihi.2017.2265&partnerID=40&md5=2230dbef2453ac34fd7d7d42a60ec240"
"Segmentation of skin lesions using an improved FLICM method","Kanaani S.; Helfroush M.S.; Danyali H.; Kazemi M.A.","2017","1","1","0","0","0","Unique","0","","","","","","","In this paper a modified fuzzy approach is introduced to diagnose the skin damages in dermoscopy images. In this method, firstly the level of brightness on images is arranged by colored contrast modification; afterward, the edge of area is achieved by applying FLICM algorithm, which is modified by concept of complex Gaussian model approximation and FCM. Efficiency of this method is evaluated on real dermoscopy images which are taken from skin damages with different color and size. The presented parameter evaluation and their results are compared with the newest method of level set partitioning. Increasing amount of partitioning sensitivity in comparison with reliable methods, demonstrate the efficiency of the proposed method and its application in cad systems. © 2017 IEEE.","10.1109/ICCKE.2017.8167919","Dermoscopy; FLICM; fuzzy segmentation","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046438968&doi=10.1109%2fICCKE.2017.8167919&partnerID=40&md5=01a141ce50c9ba16075b3917ce51a739"
"Comparison of computer systems and ranking criteria for automatic melanoma detection in dermoscopic images","Møllersen K.; Zortea M.; Schopf T.R.; Kirchesch H.; Godtliebsen F.","2017","0","1","0","0","0","Unique","0","","","","","","","Melanoma is the deadliest form of skin cancer, and early detection is crucial for patient survival. Computer systems can assist in melanoma detection, but are not widespread in clinical practice. In 2016, an open challenge in classification of dermoscopic images of skin lesions was announced. A training set of 900 images with corresponding class labels and semi-automatic/manual segmentation masks was released for the challenge. An independent test set of 379 images, of which 75 were of melanomas, was used to rank the participants. This article demonstrates the impact of ranking criteria, segmentation method and classifier, and highlights the clinical perspective. We compare five different measures for diagnostic accuracy by analysing the resulting ranking of the computer systems in the challenge. Choice of performance measure had great impact on the ranking. Systems that were ranked among the top three for one measure, dropped to the bottom half when changing performance measure. Nevus Doctor, a computer system previously developed by the authors, was used to participate in the challenge, and investigate the impact of segmentation and classifier. The diagnostic accuracy when using an automatic versus the semi-automatic/manual segmentation is investigated. The unexpected small impact of segmentation method suggests that improvements of the automatic segmentation method w.r.t. resemblance to semi-automatic/manual segmentation will not improve diagnostic accuracy substantially. A small set of similar classification algorithms are used to investigate the impact of classifier on the diagnostic accuracy. The variability in diagnostic accuracy for different classifier algorithms was larger than the variability for segmentation methods, and suggests a focus for future investigations. From a clinical perspective, the misclassification of a melanoma as benign has far greater cost than the misclassification of a benign lesion. For computer systems to have clinical impact, their performance should be ranked by a high-sensitivity measure. © 2017 Møllersen et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","10.1371/journal.pone.0190112","","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038932051&doi=10.1371%2fjournal.pone.0190112&partnerID=40&md5=d994e3a3ad37417838e21f367bc4949b"
"Classification of malignant melanoma and Benign Skin Lesion by using back propagation neural network and ABCD rule","Rajesh A.","2017","1","1","0","0","0","Unique","0","","","","","","","Human Cancer is a standout amongest the most unsafe illnesses which is for the most part brought about by hereditary insecurity of various sub-atomic modifications. Among many types of human disease, skin tumour is the most widely recognized one. To recognize skin tumour at an early stage we will think about and break down them through different methods named as segmentation and feature extraction. Here, we center threatening melanoma skin disease, (because of the high grouping of Melanoma-Hier we offer our skin, in the dermis layer of the skin) location. In this, We utilized our ABCD govern dermoscopy innovation for harmful melanoma skin malignancy location. In this framework distinctive stride for melanoma skin injury portrayal i.e, to begin with, the Image Acquisition Technique, pre-processing, segmentation, characterize a component for skin Feature Selection decides sore portrayal, grouping strategies. In the Feature extraction by advanced picture preparing technique incorporates, Asymmetry recognition, Border Detection, Colour, and Diameter detection and furthermore we utilized LBP for extract the texture based features. Here we proposed the Back Propagation Neural Network to classify the benign or malignant stage. © 2017 IEEE.","10.1109/ICEICE.2017.8191916","","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047200935&doi=10.1109%2fICEICE.2017.8191916&partnerID=40&md5=b448796e9861896e0fd8e82051d22576"
"Texture based skin lesion abruptness quantification to detect malignancy","Erol R.; Bayraktar M.; Kockara S.; Kaya S.; Halic T.","2017","1","1","0","0","0","First occurrence","0","","","","","","","Background: Abruptness of pigment patterns at the periphery of a skin lesion is one of the most important dermoscopic features for detection of malignancy. In current clinical setting, abrupt cutoff of a skin lesion determined by an examination of a dermatologist. This process is subjective, nonquantitative, and error-prone. We present an improved computational model to quantitatively measure abruptness of a skin lesion over our previous method. To achieve this, we quantitatively analyze the texture features of a region within the lesion boundary. This region is bounded by an interior border line of the lesion boundary which is determined using level set propagation (LSP) method. This method provides a fast border contraction without a need for extensive boolean operations. Then, we build feature vectors of homogeneity, standard deviation of pixel values, and mean of the pixel values of the region between the contracted border and the original border. These vectors are then classified using neural networks (NN) and SVM classifiers. Results: As lower homogeneity indicates sharp cutoffs, suggesting melanoma, we carried out our experiments on two dermoscopy image datasets, which consist of 800 benign and 200 malignant melanoma cases. LSP method helped produce better results than Kaya et al., 2016 study. By using texture homogeneity at the periphery of a lesion border determined by LSP, as a classification results, we obtained 87% f1-score and 78% specificity; that we obtained better results than in the previous study. We also compared the performances of two different NN classifiers and support vector machine classifier. The best results obtained using combination of RGB color spaces with the fully-connected multi-hidden layer NN. Conclusions: Computational results also show that skin lesion abrupt cutoff is a reliable indicator of malignancy. Results show that computational model of texture homogeneity along the periphery of skin lesion borders based on LSP is an effective way of quantitatively measuring abrupt cutoff of a lesion. © 2017 The Author(s).","10.1186/s12859-017-1892-5","Abrupt cutoff; Contour contraction; Level set; Pigmented lesions; Skin lesion","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039709241&doi=10.1186%2fs12859-017-1892-5&partnerID=40&md5=1e9f2adc0a4c1e3b5e5443cf5f46b144"
"Automatic skin lesion analysis towards melanoma detection","Thao L.T.; Quang N.H.","2017","1","1","0","0","0","First occurrence","0","","","","","","","Deep learning methods for image analysis have shown impressive performance in recent years. In this paper, we present deep learning based approaches to solve two problems in skin lesion analysis using a dermoscopic image containing skin tumor. In the first problem, we use a fully convolutional-deconvolutional architecture to automatically segment skin tumor from the surrounding skin. In the second problem, we use a simple convolutional neural network and VGG-16 architecture using transfer learning to address the two different tasks in skin tumor classification. The proposed models are trained and evaluated on standard benchmark datasets from the International Skin Imaging Collaboration (ISIC) 2017 Challenge, which consists of 2000 training samples and 600 testing samples. The result shows that the proposed methods achieve promising performances. In the first problem, the average value of Jaccard index for lesion segmentation using fully convolutional-deconvolutional architecture is 0.507. In the second problem, the values of area under the receiver operating characteristic curve (AUC) on two different lesion classifications using VGG16 with transfer learning are 0.763 and 0.869, respectively; the average value of AUC in two tasks is 0.816. © 2017 IEEE.","10.1109/IESYS.2017.8233570","convolutional neural networks; deep learning; skin lesions; transfer learning","62","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049261839&doi=10.1109%2fIESYS.2017.8233570&partnerID=40&md5=ec0b3f010b5cd6771aa71fa0481bf339"
"Automatic Skin Lesion Segmentation Using Deep Fully Convolutional Networks with Jaccard Distance","Yuan Y.; Chao M.; Lo Y.-C.","2017","1","1","0","0","0","First occurrence","0","","","","","","","Automatic skin lesion segmentation in dermoscopic images is a challenging task due to the low contrast between lesion and the surrounding skin, the irregular and fuzzy lesion borders, the existence of various artifacts, and various imaging acquisition conditions. In this paper, we present a fully automatic method for skin lesion segmentation by leveraging 19-layer deep convolutional neural networks that is trained end-to-end and does not rely on prior knowledge of the data. We propose a set of strategies to ensure effective and efficient learning with limited training data. Furthermore, we design a novel loss function based on Jaccard distance to eliminate the need of sample re-weighting, a typical procedure when using cross entropy as the loss function for image segmentation due to the strong imbalance between the number of foreground and background pixels. We evaluated the effectiveness, efficiency, as well as the generalization capability of the proposed framework on two publicly available databases. One is from ISBI 2016 skin lesion analysis towards melanoma detection challenge, and the other is the PH2 database. Experimental results showed that the proposed method outperformed other state-of-the-art algorithms on these two databases. Our method is general enough and only needs minimum pre- and post-processing, which allows its adoption in a variety of medical image segmentation tasks. © 1982-2012 IEEE.","10.1109/TMI.2017.2695227","Deep learning; dermoscopy; fully convolutional neural networks; image segmentation; jaccard distance; melanoma","570","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027980102&doi=10.1109%2fTMI.2017.2695227&partnerID=40&md5=9a387f4da29843912d3c1fdf3dd378d7"
"Design and implementation of high speed Gabor filter with variable thresholding process for disease detection","Radhakrishnan K.; Sri D.; Dhanalakshmi R.; Elakkiya M.; Gayathiri G.","2017","0","1","0","0","0","First occurrence","0","","","","","","","In current scenario, there are number of skin related diseases such as tonsillitis, tumors, skin cancers, etc... which can be detected at an early stage and can be cured. For this a new idea is proposed which aims at designing a Gabor filter that makes accurate detection of diseases. We use an efficient pipelined architecture for input. Image segmentation for the detection of diseases is done using Gabor filter that in turn uses shift-add CORDIC algorithm for making the designing of Gabor filter easier. In addition to this algorithm, we use a new algorithm called Variable Thresholding algorithm that sets a threshold value during the decision making period. The algorithm is named variable because, the threshold value can be varied depending upon the diseases we are going to detect. All these algorithms are written in VHDL Language in MODELSIM software, which makes the designing and decision making process more effective. This technique is also implemented on FPGA/CPLD kit that shows us the presence of disease manually through lighting of LED's. Thus the decision of disease is made more accurate and faster through this design. © 2017 IEEE.","10.1109/SSPS.2017.8071634","","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039922876&doi=10.1109%2fSSPS.2017.8071634&partnerID=40&md5=79ff01c9b32cfd17ba2536e26af4bafc"
"Development of a quantitative assessment method of pigmentary skin disease using ultraviolet optical imaging","Lee O.; Park S.; Kim J.; Oh C.","2017","1","1","0","0","0","Unique","0","","","","","","","Background/Purpose: The visual scoring method has been used as a subjective evaluation of pigmentary skin disorders. Severity of pigmentary skin disease, especially melasma, is evaluated using a visual scoring method, the MASI (melasma area severity index). This study differentiates between epidermal and dermal pigmented disease. The study was undertaken to determine methods to quantitatively measure the severity of pigmentary skin disorders under ultraviolet illumination. Methods: The optical imaging system consists of illumination (white LED, UV-A lamp) and image acquisition (DSLR camera, air cooling CMOS CCD camera). Each camera is equipped with a polarizing filter to remove glare. To analyze images of visible and UV light, images are divided into frontal, cheek, and chin regions of melasma patients. Each image must undergo image processing. To reduce the curvature error in facial contours, a gradient mask is used. Results: The new method of segmentation of front and lateral facial images is more objective for face-area-measurement than the MASI score. Image analysis of darkness and homogeneity is adequate to quantify the conventional MASI score. Under visible light, active lesion margins appear in both epidermal and dermal melanin, whereas melanin is found in the epidermis under UV light. Conclusion: This study objectively analyzes severity of melasma and attempts to develop new methods of image analysis with ultraviolet optical imaging equipment. Based on the results of this study, our optical imaging system could be used as a valuable tool to assess the severity of pigmentary skin disease. © 2017 John Wiley & Sons A/S. Published by John Wiley & Sons Ltd","10.1111/srt.12372","gradient mask; image analysis; optical imaging system; pigmentary skin disease; segmentation; ultraviolet","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019578920&doi=10.1111%2fsrt.12372&partnerID=40&md5=628e705398f046c2ec2102601af68e69"
"Saliency-Based Lesion Segmentation Via Background Detection in Dermoscopic Images","Ahn E.; Kim J.; Bi L.; Kumar A.; Li C.; Fulham M.; Feng D.D.","2017","0","1","0","0","0","First occurrence","0","","","","","","","The segmentation of skin lesions in dermoscopic images is a fundamental step in automated computer-aided diagnosis of melanoma. Conventional segmentation methods, however, have difficulties when the lesion borders are indistinct and when contrast between the lesion and the surrounding skin is low. They also perform poorly when there is a heterogeneous background or a lesion that touches the image boundaries; this then results in under- and oversegmentation of the skin lesion. We suggest that saliency detection using the reconstruction errors derived from a sparse representation model coupled with a novel background detection can more accurately discriminate the lesion from surrounding regions. We further propose a Bayesian framework that better delineates the shape and boundaries of the lesion. We also evaluated our approach on two public datasets comprising 1100 dermoscopic images and compared it to other conventional and state-of-the-art unsupervised (i.e., no training required) lesion segmentation methods, as well as the state-of-the-art unsupervised saliency detection methods. Our results show that our approach is more accurate and robust in segmenting lesions compared to other methods. We also discuss the general extension of our framework as a saliency optimization algorithm for lesion segmentation. © 2013 IEEE.","10.1109/JBHI.2017.2653179","Computer-aided diagnosis (CAD); dermoscopic image; lesion segmentation; saliency detection","140","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020617368&doi=10.1109%2fJBHI.2017.2653179&partnerID=40&md5=2904a5482a053f6eadb095202b369816"
"Skin lesion computational diagnosis of dermoscopic images: Ensemble models based on input feature manipulation","Oliveira R.B.; Pereira A.S.; Tavares J.M.R.S.","2017","1","1","0","0","0","Unique","0","","","","","","","Background and objectives: The number of deaths worldwide due to melanoma has risen in recent times, in part because melanoma is the most aggressive type of skin cancer. Computational systems have been developed to assist dermatologists in early diagnosis of skin cancer, or even to monitor skin lesions. However, there still remains a challenge to improve classifiers for the diagnosis of such skin lesions. The main objective of this article is to evaluate different ensemble classification models based on input feature manipulation to diagnose skin lesions. Methods: Input feature manipulation processes are based on feature subset selections from shape properties, colour variation and texture analysis to generate diversity for the ensemble models. Three subset selection models are presented here: (1) a subset selection model based on specific feature groups, (2) a correlation-based subset selection model, and (3) a subset selection model based on feature selection algorithms. Each ensemble classification model is generated using an optimum-path forest classifier and integrated with a majority voting strategy. The proposed models were applied on a set of 1104 dermoscopic images using a cross-validation procedure. Results: The best results were obtained by the first ensemble classification model that generates a feature subset ensemble based on specific feature groups. The skin lesion diagnosis computational system achieved 94.3% accuracy, 91.8% sensitivity and 96.7% specificity. Conclusions: The input feature manipulation process based on specific feature subsets generated the greatest diversity for the ensemble classification model with very promising results. © 2017 Elsevier B.V.","10.1016/j.cmpb.2017.07.009","Computational diagnosis; Ensemble of classifiers; Feature extraction; Feature selection; Image classification","51","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025691118&doi=10.1016%2fj.cmpb.2017.07.009&partnerID=40&md5=dcc80e1c826e9bfc2620313f1abe962a"
"An unsupervised Bayesian approach for the joint reconstruction and classification of cutaneous reflectance confocal microscopy images","Halimi A.; Batatia H.; Le Digabel J.; Josse G.; Tourneret J.-Y.","2017","0","1","0","0","0","Unique","0","","","","","","","This paper studies a new Bayesian algorithm for the joint reconstruction and classification of reflectance confocal microscopy (RCM) images, with application to the identification of human skin lentigo. The proposed Bayesian approach takes advantage of the distribution of the multiplicative speckle noise affecting the true reflectivity of these images and of appropriate priors for the unknown model parameters. A Markov chain Monte Carlo (MCMC) algorithm is proposed to jointly estimate the model parameters and the image of true reflectivity while classifying images according to the distribution of their reflectivity. Precisely, a Metropolis-within-Gibbs sampler is investigated to sample the posterior distribution of the Bayesian model associated with RCM images and to build estimators of its parameters, including labels indicating the class of each RCM image. The resulting algorithm is applied to synthetic data and to real images from a clinical study containing healthy and lentigo patients. © EURASIP 2017.","10.23919/EUSIPCO.2017.8081205","Bayesian algorithm; Classification; Metropolis-within-Gibbs sampler; Reflectance confocal microscopy","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041530553&doi=10.23919%2fEUSIPCO.2017.8081205&partnerID=40&md5=8451cfd500cd005acabc00a50c2f66f9"
"Automated lesion segmentation and dermoscopic feature segmentation for skin cancer analysis","Pour M.P.; Seker H.; Shao L.","2017","1","1","0","0","0","First occurrence","0","","","","","","","Segmentation is the first and most important task in computer-based diagnosis of skin cancer since other tasks are relied mainly on accurately segmented lesions. Recently, deep learning as a mainstream method in machine learning has shown promising results on semantic image segmentation. In this paper, we demonstrate applying deep convolutional networks to two main segmentation tasks in melanoma diagnosis, a lesion segmentation task followed by a lesion dermoscopic feature segmentation task. The proposed method is evaluated on a database from ISBI challenge 2016. By using a hybrid model, computation load for the second task decreases and masks provided by lesion segmentation have been used to enhance the results for the feature segmentation task as well. The results are close to the best results of ISBI challenge 2016. The proposed model yields quite promising results although it is based on very initial hybrid model without an aggressive fine-tuning that is heavily required in Deep Learning implementations. Therefore, there is a room for further improvements. © 2017 IEEE.","10.1109/EMBC.2017.8036906","","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032210054&doi=10.1109%2fEMBC.2017.8036906&partnerID=40&md5=3bbe088165811b660ca83a978f8d8188"
"A smart dermoscope design using artificial neural network","Turkeli S.; Oguz M.S.; Abay S.B.; Kumbasar T.; Atay H.T.; Kurt K.K.","2017","0","1","0","0","0","First occurrence","0","","","","","","","Melanoma is certainly the deadliest skin cancer. Clinicians try to detect melanoma at early stages in order to increase the successful treatment rate by using dermoscopes. We have designed a digital dermoscope that is both mobile and highly sensitive for automatic classification. We developed an accurate image processing software and a learning program that uses artificial neural network learning algorithm. A dataset of 200 images were used for training and 12 features were extracted. We considered common nevus, atypical nevus and melanoma as our diagnostic results. By doing that, we acquire three sensitivity and specifity values for each of the outputs. For the common nevus detection, SE = 100%, SP = 98.3%, for the atypical nevus detection, SE = 95%, SP = 97.5%, for the melanoma detection, SE = 92.5%, SP = 98.75%. © 2017 IEEE.","10.1109/IDAP.2017.8090211","Classification; Dermoscope; Feature selection; Melanoma; Nevus; Segmentation","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039912655&doi=10.1109%2fIDAP.2017.8090211&partnerID=40&md5=819a3590342305869f442b7ef707def0"
"Skin disease recognition using texture analysis","Islam M.N.; Gallardo-Alvarado J.; Abu M.; Salman N.A.; Rengan S.P.; Said S.","2017","1","1","0","0","0","First occurrence","0","","","","","","","This research describes skin disease recognition by using neural network which based on the texture analysis. There are many skin diseases which have a lot of similarities in their symptoms, such as Measles (rubeola), German measles (rubella), and Chickenpox etc. In general, these diseases have similarities in pattern of infection and symptoms such as redness and rash. Diagnosis and recognition of skin disease take a very long term process because it requires patient's history, physical examination and proper laboratory diagnostic tests. Not only that, it also requires large number of features clinical as well as histopathological for analysis and to provide further treatment. The disease diagnosis and recognition becomes difficult as the complexity and number of features of the disease increases. Hence, a computer aided diagnosis and recognition system is introduced. Computer algorithm which contains few steps that involves image processing, image feature extraction and classification of data have been implemented with the help of classifier such as artificial neural network (ANN). The ANN can learn patterns of symptoms of particular diseases and provides faster diagnosis and recognition than a human physician. Thus, the patients can do the treatment for the skin disease faced immediately based on the symptoms detected. © 2017 IEEE.","10.1109/ICSGRC.2017.8070584","Classification by NN; GLCM features; Segmentation; Skin disease","24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039941110&doi=10.1109%2fICSGRC.2017.8070584&partnerID=40&md5=c7d95061f32fb532800f8aa15d87d471"
"Hair segmentation using adaptive threshold from edge and branch length measures","Lee I.; Du X.; Anthony B.","2017","0","1","0","0","0","Unique","0","","","","","","","Background Non-invasive imaging techniques allow the monitoring of skin structure and diagnosis of skin diseases in clinical applications. However, hair in skin images hampers the imaging and classification of the skin structure of interest. Although many hair segmentation methods have been proposed for digital hair removal, a major challenge in hair segmentation remains in detecting hairs that are thin, overlapping, of similar contrast or color to underlying skin, or overlaid on highly-textured skin structure. Methods To solve the problem, we present an automatic hair segmentation method that uses edge density (ED) and mean branch length (MBL) to measure hair. First, hair is detected by the integration of top-hat transform and modified second-order Gaussian filter. Second, we employ a robust adaptive threshold of ED and MBL to generate a hair mask. Third, the hair mask is refined by k-NN classification of hair and skin pixels. Results The proposed algorithm was tested using two datasets of healthy skin images and lesion images respectively. These datasets were taken from different imaging platforms in various illumination levels and varying skin colors. We compared the hair detection and segmentation results from our algorithm and six other hair segmentation methods of state of the art. Our method exhibits high value of sensitivity: 75% and specificity: 95%, which indicates significantly higher accuracy and better balance between true positive and false positive detection than the other methods. © 2017","10.1016/j.compbiomed.2017.08.020","Adaptive threshold; Dermatology; Hair detection; Hair segmentation; Multiscale matched filter","25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028318238&doi=10.1016%2fj.compbiomed.2017.08.020&partnerID=40&md5=6a2ee5e57473e7b40ca35155acfbd012"
"Dermatological effect of UV rays owing to ozone layer depletion","Chakraborty S.; Mali K.; Chatterjee S.; Banerjee S.; Roy K.; Dutta N.; Bhaumik N.; Mazumdar S.","2017","0","1","0","0","0","Unique","0","","","","","","","In recent years, one of the major threat for the earth is the depletion of ozone layer that accelerates the incoming amount of various solar rays including the UV rays. It has an drastic effect on the health of different living organisms most prominently on the skin. There are several reasons for which ozone hole is being created and increased continuously. In recent days, an increasing awareness can be noticed and different countries are showing their concern on this issue. It is also one of the reasons for global warming and different climate changes that can indirectly. Besides various effects, one of the major threats caused by solar radiation is the skin cancers. In United Kingdom, higher temperature can be observed during the summer period along with some temperature events. This can cause serious issues that can be harmful for the total population. An ozone hole can be observed at the Antarctic region. A notable increase in UV-B has been reported in Punta Arenas, Chile which also known as the south most city. So, the rate of depletion of the ozone layer must be reduced. Moreover, skin related diseases should be detected early so that proper treatment can be given. In this work, effects of ozone hole are being studied on the skin. © 2017 IEEE.","10.1109/OPTRONIX.2017.8349975","environmental pollution; Ozone hole; skin disease detection; skin diseases","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050352838&doi=10.1109%2fOPTRONIX.2017.8349975&partnerID=40&md5=d89f7013383e1cf469942ba662c95db7"
"An integrated deep learning framework approach for nail disease identification","Nijhawan R.; Verma R.; Ayushi; Bhushan S.; Dua R.; Mittal A.","2017","0","1","0","0","0","Unique","0","","","","","","","Nail Diseases refer to some kind of deformity in the nail unit. Although the nail unit is a skin accessory, it has its own distinct class of diseases as these diseases have their own set of signs, symptoms, causes and effects that may or may not relate to other medical conditions. Recognizing nail diseases still remains an unexplored and a challenging endeavor in itself. This paper proposes a novel deep learning framework to detect and classify nail diseases from images. A distinct class of eleven diseases i.e. onychomycosis, subungulal hematoma, beau's lines, yellow nail syndrome, psoriasis, hyperpigmentation, koilonychias, paroncychia, pincer nails, leukonychia, and onychorrhexis. The framework uses a hybrid of Convolutional Neural Network (CNNs) for feature extraction. Due to the non-existence of a meticulous dataset, a new dataset was built for testing the enactment of our proposed framework. This work has been tested on our dataset and has also been compared with other state-of-the-art algorithms (SVM, ANN, KNN, and RF) that have been shown to have an excelled performance in the area of feature extraction. The results have shown a comparable performance, in terms of differentiating amongst the wide spectrum of nail diseases and are able to recognize them with an accuracy of 84.58%. © 2017 IEEE.","10.1109/SITIS.2017.42","Deep Convolutional Neural Networks; Deep Learning; Feature Extraction; Nail Diseases","61","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048901060&doi=10.1109%2fSITIS.2017.42&partnerID=40&md5=83594c6539dcc83cf1ba5f0d0e66f3f1"
"A statistical approach to combining multisource information in one-class classifiers","Simonson K.M.; Derek West R.; Hansen R.L.; LaBruyere T.E., III; Van Benthem M.H.","2017","0","1","0","0","0","Unique","0","","","","","","","A new method is introduced for combining information from multiple sources to support one-class classification. The contributing sources may represent measurements taken by different sensors of the same physical entity, repeated measurements by a single sensor, or numerous features computed from a single measured image or signal. The approach utilizes the theory of statistical hypothesis testing, and applies Fisher's technique for combining p-values, modified to handle nonindependent sources. Classifier outputs take the form of fused p-values, which may be used to gauge the consistency of unknown entities with one or more class hypotheses. The approach enables rigorous assessment of classification uncertainties, and allows for traceability of classifier decisions back to the constituent sources, both of which are important for high-consequence decision support. Application of the technique is illustrated in two challenge problems, one for skin segmentation and the other for terrain labeling. The method is seen to be particularly effective for relatively small training samples. © 2017 Wiley Periodicals, Inc.","10.1002/sam.11342","classification; dependent p-values; Fisher's combination method; gamma distribution; image segmentation; multisource fusion","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020298895&doi=10.1002%2fsam.11342&partnerID=40&md5=3efc789c7506a9160ddb9f1278a60478"
"In vivo skin moisturizing measurement by high-resolution 3 Tesla magnetic resonance imaging","Mesrar J.; Ognard J.; Garetier M.; Chechin D.; Misery L.; Ben Salem D.","2017","1","1","0","0","0","Unique","0","","","","","","","Background: Magnetic resonance imaging (MRI) is rarely used for the exploration of skin, even if studies have validated both feasibility of skin MRI and its interest for anatomical, physiological, and biochemical study of the skin. The purpose of this study is to explore moisturizing of the different skin layers using 3-T scan. Methods: An MRI of the heel's skin was performed using a 23 mm coil diameter on a 3T scan with a FFE (Fast Field Echo) 3D T1-weighted sequence and a TSE (Turbo Spin Echo) calculation T2-weighted sequence (pixels size of respectively 60 and 70 μm). This study was conducted on 35 healthy volunteers, who were scanned before applying moisturizer topic and 1 h after applying it. Region of interest in the stratum corneum, the epidermis and the dermis were generated on the T2 mapping. The thickness of each layer was measured. The T1 sequence allowed accurate cross-examination repositioning to ensure the comparability of the measurements. Results: Among the 35 cases, two were excluded from the analysis because of movement artifacts. Measurements before and after moisturizer topic application displayed a T2 increase of 48.94% (P < 0.0001) in the stratum corneum and of 5.45% (P < 0.0001) in the epidermis yet without significant difference in the dermis. There was no significant link between the thickness of the stratum corneum and the T2 increase. However, there was a strong correlation between the thickness of the stratum corneum and the thickness of the epidermis (P < 0.001; rhô=0.72). Conclusion: High-resolution MRI allows fine exploration of anatomical and physiological properties of the skin and can further be used to extend the studies of skin hydration. © 2016 John Wiley & Sons A/S. Published by John Wiley & Sons Ltd","10.1111/srt.12333","3 Tesla; microscopic coil; moisturizing measurement; skin imaging; T2 mapping","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995701619&doi=10.1111%2fsrt.12333&partnerID=40&md5=27e6662f893f73582acb420e09916dc7"
"Skin lesion segmentation using deep convolution networks guided by local unsupervised learning","Bozorgtabar B.; Sedai S.; Kanti Roy P.; Garnavi R.","2017","1","1","0","0","0","First occurrence","0","","","","","","","Automatic localization of skin lesions within dermoscopy images is a crucial step toward developing a decision support system for skin cancer detection. However, segmentation of the lesion image can be challenging, as these images possess various artifacts distorting the uniformity of the lesion area. Recently, deep convolution learning-based techniques have drawn great attention for pixel-wise image segmentation. These deep networks produce coarse segmentation, and convolutional filters and pooling layers result in segmentation of a skin lesion at a lower resolution than the original skin image. To overcome these drawbacks, we have proposed a superpixel-based fine-tuning strategy to effectively utilize the characteristics of the skin image pixels to accurately extract the border of the lesion. Our proposed approach not only learns a global map for skin lesions, but also acquires the local contextual information, such as lesion boundary. It can, therefore, accurately segment lesions within a given skin image, even in the presence of fuzzy boundaries and complex textures. To evaluate the performance of our proposed method, experiments have been conducted using the 2016 International Symposium on Biomedical Imaging dataset, and these experiments suggest the effectiveness of the proposed method. © 2017 IBM.","10.1147/JRD.2017.2708283","","48","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029503511&doi=10.1147%2fJRD.2017.2708283&partnerID=40&md5=9a928dded921854d5c6a056dee1b4776"
"Acne segmentation and classification using region growing and self-organizing map","Budhi G.S.; Adipranata R.; Gunawan A.","2017","0","1","0","0","0","Unique","0","","","","","","","Acne vulgaris is a common skin disease found in human of all ages and genders. Acnes have different types according to their severity. In this research, an application was developed to segment and process the classification an acne object in human's face. The process begins with the insertion of several seed points on a picture. Each of those seed points were developed further into a region that mask the whole acne using region growing method. Afterward, the regions were grouped together with other acne of similar features using self-organizing map. According to the experimental result, the region growing method gives a satisfying result to do segmentation on an acne object. But it should be pointed out that every different acne object requires different threshold to achieve an ideal result. Self-organizing map gives an undesirable result, as the input picture with different skin colors and lighting conditions affect the accuracy of the result. © 2017 IEEE.","10.1109/ICSIIT.2017.62","acne classification; Acne segmentation; region growing; self-organizing map","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049248557&doi=10.1109%2fICSIIT.2017.62&partnerID=40&md5=7c7c5680b622e78f96f41c9c5a230d7d"
"Skin lesion segmentation: U-Nets versus clustering","Lin B.S.; Michael K.; Kalra S.; Tizhoosh H.R.","2017","1","1","0","0","0","First occurrence","0","","","","","","","Many automatic skin lesion diagnosis systems use segmentation as a preprocessing step to diagnose skin conditions because skin lesion shape, border irregularity, and size can influence the likelihood of malignancy. This paper presents, examines and compares two different approaches to skin lesion segmentation. The first approach uses U-Nets and introduces a histogram equalization based preprocessing step. The second approach is a C-Means clustering based approach that is much simpler to implement and faster to execute. The Jaccard Index between the algorithm output and hand segmented images by dermatologists is used to evaluate the proposed algorithms. While many recently proposed deep neural networks to segment skin lesions require a significant amount of computational power for training (i.e., computer with GPUs), the main objective of this paper is to present methods that can be used with only a CPU. This severely limits, for example, the number of training instances that can be presented to the U-Net. Comparing the two proposed algorithms, U-Nets achieved a significantly higher Jaccard Index compared to the clustering approach. Moreover, using the histogram equalization for preprocessing step significantly improved the U-Net segmentation results. © 2017 IEEE.","10.1109/SSCI.2017.8280804","C-Means Clustering; Color Space; Histogram Equalization; Melanoma; Skin lesion Segmentation; U-Nets","88","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046162139&doi=10.1109%2fSSCI.2017.8280804&partnerID=40&md5=43e49a5122218a5c29b2f16fc9247540"
"Genetic programming for skin cancer detection in dermoscopic images","Ul Ain Q.; Xue B.; Al-Sahaf H.; Zhang M.","2017","1","1","0","0","0","First occurrence","0","","","","","","","Development of an effective skin cancer detection system can greatly assist the dermatologist while significantly increasing the survival rate of the patient. To deal with melanoma detection, knowledge of dermatology can be combined with computer vision techniques to evolve better solutions. Image classification can significantly help in diagnosing the disease by accurately identifying the morphological structures of skin lesions responsible for developing cancer. Genetic Programming (GP), an emerging Evolutionary Computation technique, has the potential to evolve better solutions for image classification problems compared to many existing methods. In this paper, GP has been utilized to automatically evolve a classifier for skin cancer detection and also analysed GP as a feature selection method. For combining knowledge of dermatology and computer vision techniques, GP has been given domain specific features provided by the dermatologists as well as Local Binary Pattern features extracted from the dermoscopic images. The results have shown that GP has significantly outperformed or achieved comparable performance compared to the existing methods for skin cancer detection. © 2017 IEEE.","10.1109/CEC.2017.7969598","","28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027841457&doi=10.1109%2fCEC.2017.7969598&partnerID=40&md5=008d7fcba66053492e5fbbcd2ba26882"
"Bag-of-features based classification of dermoscopic images","Chakraborty S.; Mali K.; Banerjee S.; Roy K.; Saha D.; Chatterjee S.; Dutta S.; Majumder S.","2017","0","1","0","0","0","Unique","0","","","","","","","Dermoscopy image analysis is one of the open challenge and important issue related to biomedical image analysis. Determination of different diseases of skin is necessary in medical practices. Automated techniques are proved to be useful in detection and classification process of different skin diseases. There are several automated computer guided tools and frameworks have been proposed for early detection and analysis of skin diseases. In this work a comprehensive study on dermoscopic image analysis using bag-of-features has been presented. Bag-of-features is one of the well-known classification method. It uses local description of images. In case of dermoscopy image analysis, color and texture plays a vital role. Color and texture descriptors have been also discussed. Future directions in dermoscopy image analysis based on bag-of-features model are also presented. © 2017 IEEE.","10.1109/OPTRONIX.2017.8349977","bag-of-features; dermoscopy image analysis; skin disease classification","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050353696&doi=10.1109%2fOPTRONIX.2017.8349977&partnerID=40&md5=9443439705c555b273f4da9e7dbd861f"
"Segmentation and classification of melanoma and benign skin lesions","Dalila F.; Zohra A.; Reda K.; Hocine C.","2017","1","0","0","0","0","Unique","0","","","","","","","The incidence ofmalignant melanoma has been increasing worldwide. An efficient non-invasive computer-aided diagnosis (CAD) is seen as a solution to make identification process faster, and accessible to a large population. Such automated system relies on three things: reliable lesion segmentation, pertinent features’ extraction and good lesion classifier. In this paper, we propose an automated system that uses an Ant colony based segmentation algorithm, takes into consideration three types of features to describe malignant lesion:geometrical properties, textureand relative colors from which pertinent ones are selected, and uses two classifiers K-Nearest Neighbor (KNN) and Artificial Neural Network (ANN). The objective of this paper is to test the efficiency of the proposed segmentation algorithm, extract most pertinent features that describe melanomas and compare the two classifiers. Our automated system is tested on 172 dermoscopic images where 88 are malignant melanomas and 84 benign lesions. The results of the proposed segmentation algorithm are encouraging as they gave promising results. 12 features seem to be sufficient to detect malignant melanoma. Moreover, ANN gives better results than KNN. © 2017 Elsevier GmbH","10.1016/j.ijleo.2017.04.084","Ant colony; Computer-aided diagnosis; Dermoscopy; Feature extraction; K-Nearest Neighbor; Melanoma; Neural network; Segmentation","86","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019369557&doi=10.1016%2fj.ijleo.2017.04.084&partnerID=40&md5=0b24dc363d55b8c3b90e29682a02f92b"
"Digital dermatology: Skin disease detection model using image processing","Ajith A.; Goel V.; Vazirani P.; Roja M.M.","2017","1","1","0","0","0","Unique","0","","","","","","","This paper proposes a skin disease detection method based on image processing techniques. This method is mobile based and hence very accessible even in remote areas and it is completely noninvasive to patient's skin. The patient provides an image of the infected area of the skin as an input to the prototype. Image processing techniques are performed on this image and the detected disease is displayed at the output. The proposed system is highly beneficial in rural areas where access to dermatologists is limited. © 2017 IEEE.","10.1109/ICCONS.2017.8250703","DCT; DWT; Image Processing; SVD","29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047466381&doi=10.1109%2fICCONS.2017.8250703&partnerID=40&md5=c80001e9e1aabf93634f11e468dd1c62"
"3rd International Conference on Pattern Analysis and Image Analysis, IPRIA 2017","","2017","0","1","0","0","0","Unique","0","","","","","","","The proceedings contain 47 papers. The topics discussed include: a new pansharpening method using multi resolution analysis framework and deep neural networks; hyperspectral anomaly detection using outlier removal from collaborative representation; nonlinear analysis of video images using deep recurrent auto-associative neural networks for facial understanding; shrinkage estimator based common spatial pattern for multi-class motor imagery classification by hybrid classifier; a Zernike moment based method for classification of Alzheimer's disease from structural MRI; CGACLC: improving genetic algorithm through clustering for designing of combinational logic circuits; reducing circular Hough transform parameters using morphological operations; evaluation of graph embedding approach for dimensionality reduction using different kernels; sentence-level sentiment analysis in Persian; accurate fall detection using 3-axis accelerometer sensor and MLF algorithm; combination of score level fusion methods in receiver operating characteristic space; skin lesion images classification using new color pigmented boundary descriptors; multi-modal data fusion using group-structured sparse canonical correlation analysis: a simulation study; license plate detection using adaptive morphological closing and local adaptive thresholding; and superpixel-based feature learning for joint sparse representation of hyperspectral images.","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027873630&partnerID=40&md5=26d47171960ad6234b24571de2cb78ba"
"Classification and detection of skin cancer using hybrid texture features","Bethanney Janney J.; Emalda Roslin S.","2017","1","1","0","0","0","Unique","0","","","","","","","Introduction and Aim: This paper depicts a novel image processing approach for skin cancer detection on dermatoscope images. The main objective of this work is to classify the skin lesion as malignant or benign using Hybrid texture features. Materials and Methods: The different stages of detection involve: a collection of data images, filtering the images for removing unwanted details and noise, segmenting the images using Region based segmentation. Two types of feature extraction methods have been used to perform classification. ABCD features and Gray Level Co-Occurrence Matrix (GLCM) features have been extracted at various angles as hybrid texture features. An Artificial Neural Network (ANN) has been used as a classifier to classify the skin lesion as malignant or benign. Results: Based on the hybrid texture features our proposed technique is able to better classify skin cancer images into Benign or Malignant with high precision. Conclusion: Hence the proposed method will enhance the effectiveness of early detection for skin cancer. In future, this method offers a chance for doctors, where the application can be prolonged to different forms of skin malignancy and other skin ailments.","","ANN classifier.; Hybrid texture features (ABCD features and GLCM features); Preprocessing; Region based segmentation","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027972962&partnerID=40&md5=4900b62a23256459c8c55d0683edcf12"
"Low quality dermal image classification using transfer learning","Elmahdy M.S.; Abdeldayem S.S.; Yassine I.A.","2017","0","1","0","0","0","First occurrence","0","","","","","","","In this study, we investigate three class skin lesion classification problem of a low quality and small size dataset using transfer learning using AlexNet deep Convolutional Neural Network (CNN). Our approach involves modifying the pre-trained AlexNet model; through replacing the decision layer to be compatible with our three class problem. In addition, we propose adding two dropout layers to overcome the over fitting problem. The fine tuning process of the complete network, based on stochastic gradient descent, is performed using skin lesion dataset. Furthermore, we investigated augmenting the original dataset through three flipping directions and sixteen rotation angles processes using a new methodology. The proposed algorithm has been compared with a hand crafted features, based on Local Binary Pattern (LBP) representation followed by Support Vector Machine (SVM) classifier. Increasing the dataset size has dramatically boosted the performance of classifiers achieving accuracy of 98.67% for the modified AlexNet compared to 96.8% using the LBP based system. © 2017 IEEE.","10.1109/BHI.2017.7897283","","25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018420575&doi=10.1109%2fBHI.2017.7897283&partnerID=40&md5=22dfe8a51fa655cfcecc3f9dbbe0b213"
"Investigating deep side layers for skin lesion segmentation","Bozorgtabar B.; Ge Z.; Chakravorty R.; Abedini M.; Demyanov S.; Garnavi R.","2017","1","1","0","0","0","First occurrence","0","","","","","","","Accurate skin lesion segmentation is an important yet challenging problem for medical image analysis. The skin lesion segmentation is subject to variety of challenges such as the significant pattern and colour diversity found within the lesions, presence of various artifacts, etc. In this paper, we present two fully convolutional networks with several side outputs to take advantage of discriminative capability of features learned at intermediate layers with varying resolutions and scales for the lesion segmentation. More specifically, we integrate fine and coarse prediction scores of the side-layers which allows our framework to not only output accurate probability map for the lesion, but also extract fine lesion boundary details such as the fuzzy border, which further improves the lesion segmentation. Quantitative evaluation is performed on the 2016 International Symposium on Biomedical Imaging (ISBI 2016) dataset, which shows our proposed approach compares favorably with state-of-the-art skin segmentation methods. © 2017 IEEE.","10.1109/ISBI.2017.7950514","Convolutional neural network; Fusion; Multi-layer net architectures; Skin lesion segmentation","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023181428&doi=10.1109%2fISBI.2017.7950514&partnerID=40&md5=d8c63a71c4a0072adcdcd8186c23300b"
"Automatic segmentation of dermoscopy images using saliency combined with Otsu threshold","Fan H.; Xie F.; Li Y.; Jiang Z.; Liu J.","2017","0","1","0","0","0","Unique","0","","","","","","","Segmentation is one of the crucial steps for the computer-aided diagnosis (CAD) of skin cancer with dermoscopy images. To accurately extract lesion borders from dermoscopy images, a novel automatic segmentation algorithm using saliency combined with Otsu threshold is proposed in this paper, which includes enhancement and segmentation stages. In the enhancement stage, prior information on healthy skin is extracted, and the color saliency map and brightness saliency map are constructed respectively. By fusing the two saliency maps, the final enhanced image is obtained. In the segmentation stage, according to the histogram distribution of the enhanced image, an optimization function is designed to adjust the traditional Otsu threshold method to obtain more accurate lesion borders. The proposed model is validated from enhancement effectiveness and segmentation accuracy. Experimental results demonstrate that our method is robust and performs better than other state-of-the-art methods. © 2017 Elsevier Ltd","10.1016/j.compbiomed.2017.03.025","Automatic segmentation; Computer-aided diagnosis; Dermoscopy images; Saliency; Threshold","136","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018357826&doi=10.1016%2fj.compbiomed.2017.03.025&partnerID=40&md5=f714e2f57ccb5d2dd0166c9844bb80b5"
"Adaptive thresholding for skin lesion segmentation using statistical parameters","Gupta A.; Issac A.; Dutta M.K.; Hsu H.-H.","2017","1","1","0","0","0","First occurrence","0","","","","","","","Melanoma is one of those skin cancers which can be fatal. So, the segmentation of lesions from the digital images becomes a crucial step in analysis and diagnosis of a skin cancer using image processing techniques. This work proposes a technique for automatic segmentation of lesion from the digital dermoscopic images using adaptive threshold making the process invariant and robust. The statistical features like standard deviation and mean are used to preprocess and segment the lesions completely in an automatic manner. The use of image processing techniques, such as average filtering for removal of hair and skin scales, mathematical morphology to reject the false positives have been successfully able to accurately segment the lesion from the images. The results are significant and indicate that the method has good accuracy. An average correlation of 90% and average overlapping score of 83% has been obtained. © 2017 IEEE.","10.1109/WAINA.2017.36","Dermoscopic image; Histogram analysis; Lesions; Medical imaging; Melanoma; Statistical parameters","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021418494&doi=10.1109%2fWAINA.2017.36&partnerID=40&md5=8be92caea128ee43b9456dfce82828d4"
"Skin melanoma segmentation using recurrent and convolutional neural networks","Attia M.; Hossny M.; Nahavandi S.; Yazdabadi A.","2017","1","1","0","0","0","First occurrence","0","","","","","","","Skin melanoma is one of the highly addressed health problems in many countries. Dermatologists diagnose melanoma by visual inspections of mole using clinical assessment tools such as ABCD. However, computer vision tools have been introduced to assist in quantitative analysis of skin lesions. Deep learning is one of the trending machine learning techniques that have been successfully utilized to solve many difficult computer vision tasks. We proposed using a hybrid method that utilizes two popular deep learning methods: convolutional and recurrent neural networks. The proposed method was trained using 900 images and tested on 375 images. Images were obtained from 'Skin Lesion Analysis Toward Melanoma Detection' challenge which was hosted by ISBI 2016 conference. We achieved segmentation average accuracy of 0.98 and Jaccard index of 0.93. Results were compared with other state-of-the-art methods, including winner of ISBI 2016 challenge for skin melanoma segmentation, along with the same evaluation criteria. © 2017 IEEE.","10.1109/ISBI.2017.7950522","Convolutional neural networks; Deep learning; Dermoscopy; Melanoma; Recurrent neural networks; Segmentation; Skin lesion","90","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023173036&doi=10.1109%2fISBI.2017.7950522&partnerID=40&md5=07655a000ce7335091ea4cbbe96c7068"
"Nonlinear Analysis of the Contour Boundary Irregularity of Skin Lesion Using Lyapunov Exponent and K-S Entropy","Khodadadi H.; Sedigh A.K.; Ataei M.; Motlagh M.R.J.; Hekmatnia A.","2017","1","1","0","0","0","First occurrence","0","","","","","","","Measuring the contour boundary irregularities of skin lesion is an important factor in early detection of malignant melanoma. On the other hand, cancer is usually recognized as a chaotic growth of cells. It is generally assumed that boundary irregularity associated with biomedical images may be due to the chaotic behavior of its originated system. Thus, chaotic indices can serve as some criteria for classifying dermoscopy images. In this paper, a new approach is presented for extraction of Lyapunov exponent and Kolmogorov–Sinai entropy in the skin lesion images. This method is based on chaotic time series analysis. Converting the region of interest of skin lesion to a time series, reconstruction of system phase space, estimation of the Lyapunov exponents and calculation of Kolmogorov–Sinai entropy are the steps of the proposed approach. The combination of the largest Lyapunov exponent and Kolmogorov–Sinai entropy is selected as a criterion for distinction between melanoma and mole categories. Experiments on a set of dermoscopy images yielded a sensitivity of 100% and a specificity of 92.5% providing superior diagnosis accuracy compared to other related similar works. © 2017, Taiwanese Society of Biomedical Engineering.","10.1007/s40846-017-0235-3","Computer aided diagnosis; Contour boundary irregularity; Kolmogorov–Sinai entropy; Lyapunov exponent; Melanoma detection; Phase space reconstruction","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018387100&doi=10.1007%2fs40846-017-0235-3&partnerID=40&md5=3923793a1f7c589a576b0443ccd184d5"
"Classification of the dermal-epidermal junction using in-vivo confocal microscopy","Robic J.; Perret B.; Nkengne A.; Couprie M.; Talbot H.","2017","0","1","0","0","0","Unique","0","","","","","","","Reflectance confocal microscopy (RCM) is a powerful tool to visualize the skin layers at cellular resolution. The dermal-epidermal junction (DEJ) is a thin complex 3D structure. It appears as a low-contrasted structure in confocal en-face sections, which is difficult to recognize visually, leading to uncertainty in the classification. In this article, we propose an automated method for segmenting the DEJ with reduced uncertainty. The proposed approach relies on a 3D Conditional Random Field to model the skin biological properties and impose regularization constraints. We improve the restitution of the epidermal and dermal labels while reducing the thickness of the uncertainty area in a coherent biological way from 16.9 μm (ground-truth) to 10.3 μm. © 2017 IEEE.","10.1109/ISBI.2017.7950513","Conditional Random Fields; Image segmentation; Reflectance confocal microscopy; Skin modeling","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023159517&doi=10.1109%2fISBI.2017.7950513&partnerID=40&md5=51e075ff7035262d618cc1e1119d5cf2"
"A simple weighted thresholding method for the segmentation of pigmented skin lesions in macroscopic images","Zortea M.; Flores E.; Scharcanski J.","2017","1","1","0","0","0","Unique","0","","","","","","","This work proposes a simple and yet effective thresholding method to segment pigmented skin lesions in macroscopic photographs automatically. Segmentation is one of the first steps in computer-aided diagnosis of skin cancers. Therefore, an accurate segmentation may play an important clinical role. We develop an algorithm that searches for a thin rectangular-shaped region near the image borders that is likely to contain mostly skin pixels. Segmentation is obtained by adapting Otsu's thresholding method by combining independent threshold estimates computed from histograms of different parts of a new intensity image designed to discriminate lesions from background skin. The proposed approach exploits the fact that the object of interest is approximately centered in the input photograph. A cross-diagonal sampling scheme helps to balance the size of the classes when the area of the lesion and the area of the surrounding skin are very different. A post-processing stage that includes morphological filtering and a weighted scheme to select the most salient object follows. The experimental results suggest that the method potentially can be used successfully to segment atypical nevi and melanomas in lesions with a highly heterogeneous background skin. The proposed algorithm is of interest for use in clinical settings as part of a CAD system. © 2016 Elsevier Ltd","10.1016/j.patcog.2016.10.031","Computer-aided diagnosis; Melanoma; Pigmented skin lesions; Segmentation; Thresholding","68","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007153920&doi=10.1016%2fj.patcog.2016.10.031&partnerID=40&md5=d041e431af23f997d215f9ff354e0f62"
"Survey of texture based feature extraction for skin disease detection","Kolkur S.; Kalbande D.R.","2017","1","1","0","0","0","Unique","0","","","","","","","Skin diseases are most common form of infections occurring in people of all ages. As the costs of dermatologists to monitor every patient is very high, there is a need for a computerized system to evaluate patient's risk of skin disease using images of their skin lesions. Many researchers have used different preprocessing, segmentation and classification techniques to determine whether a skin image suffers from diseases or not. Feature extraction is very important for predictive modeling applications. Feature extraction in image processing is a method of capturing visual content of images for indexing and retrieval. Primitive image features can be either general features, such as extraction of color, texture and shape or domain specific features. Texture based features are widely used in image analysis for medical diagnosis. This paper presents a comprehensive survey of texture based feature extraction for detection of skin diseases and proposes a system based on the findings. © 2016 IEEE.","10.1109/ICTBIG.2016.7892649","GLCM; Skin Diseases; Texture Features","37","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019072026&doi=10.1109%2fICTBIG.2016.7892649&partnerID=40&md5=ece66f79ba1a336bb96cfb1cee78ac5a"
"Deep neural network based diagnosis system for melanoma skin cancer; [Melanom Cilt Kanseri için Derin Sinir Aǧi Tabanli Tani Sistemi]","Basturk A.; Yuksei M.E.; Badem H.; Caliskan A.","2017","1","1","0","0","0","Unique","0","","","","","","","Melanoma is a serious cancer that causes many people to lose their lives. This disease can be diagnosed by a dermatologist as a result of interpretation of the dermoscopy images by the ABCD rule. In this study, a deep neural network (DNN) is used as a new method for diagnosis of melanoma skin cancer. This method is compared with the-state-art-methods in literature. According to the obtained results, DNN was more successful than the comparative methods. © 2017 IEEE.","10.1109/SIU.2017.7960563","ABCD rule; deep learning; deep neural network; melanoma","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026321493&doi=10.1109%2fSIU.2017.7960563&partnerID=40&md5=c37bb949609540159d92e97eb896fac5"
"Extraction of skin lesions from non-dermoscopic images for surgical excision of melanoma","Jafari M.H.; Nasr-Esfahani E.; Karimi N.; Soroushmehr S.M.R.; Samavi S.; Najarian K.","2017","1","1","0","0","0","First occurrence","0","","","","","","","Purpose: Computerized prescreening of suspicious moles and lesions for malignancy is of great importance for assessing the need and the priority of the removal surgery. Detection can be done by images captured by standard cameras, which are more preferable due to low cost and availability. One important step in computerized evaluation is accurate detection of lesion’s region, i.e., segmentation of an image into two regions as lesion and normal skin. Methods: In this paper, a new method based on deep neural networks is proposed for accurate extraction of a lesion region. The input image is preprocessed, and then, its patches are fed to a convolutional neural network. Local texture and global structure of the patches are processed in order to assign pixels to lesion or normal classes. A method for effective selection of training patches is proposed for more accurate detection of a lesion’s border. Results: Our results indicate that the proposed method could reach the accuracy of 98.7% and the sensitivity of 95.2% in segmentation of lesion regions over the dataset of clinical images. Conclusion: The experimental results of qualitative and quantitative evaluations demonstrate that our method can outperform other state-of-the-art algorithms exist in the literature. © 2017, CARS.","10.1007/s11548-017-1567-8","Convolutional neural network; Deep learning; Medical image segmentation; Melanoma excision; Skin cancer","78","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015983521&doi=10.1007%2fs11548-017-1567-8&partnerID=40&md5=102916f6be8a7db9e3121e4e64265b0d"
"Melanoma detection based on mahalanobis distance learning & constrained graph regularized nonnegative matrix factorization","Gu Y.; Zhou J.; Qian B.","2017","0","1","0","0","0","Unique","0","","","","","","","Melanoma is the most fatal form of all skin cancer types. An early screening of melanoma can greatly contribute to successful treatment, hence reliable early detection systems are highly demanded. In this paper, we propose a novel melanoma detection method based on Mahalanobis distance learning and constrained graph regularized nonnegative matrix factorization. The proposed method allows supervised learning for feature dimensionality reduction by incorporating both global geometry and local manifold, so as to enhance the discriminability of the classification performance. The proposed method is evaluated on PH2 Dermoscopy Image Dataset and Edinburgh Dermofit Image Library, with comparison against four alternative classification methods. Our method demonstrates the best performance, with 94:43% sensitivity and 81:01% specificity on PH2 dataset and 99:50% sensitivity and 93:68% specificity on Edinburgh Library. © 2017 IEEE.","10.1109/WACV.2017.94","","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020207437&doi=10.1109%2fWACV.2017.94&partnerID=40&md5=05c9c4125315f15a8296d55d1fa87cea"
"A mathematical analysis of the ABCD criteria for diagnosing malignant melanoma","Lee H.; Kwon K.","2017","0","1","0","0","0","Unique","0","","","","","","","The medical community currently employs the ABCD (asymmetry, border irregularity, color variegation, and diameter of the lesion) criteria in the early diagnosis of a malignant melanoma. Although many image segmentation and classification methods are used to analyze the ABCD criteria, it is rare to see a study containing mathematical justification of the parameters that are used to quantify the ABCD criteria. In this paper, we suggest new parameters to assess asymmetry, border irregularity, and color variegation, and explain the mathematical meaning of the parameters. The suggested parameters are then tested with 24 skin samples. The parameters suggested for the 24 skin samples are displayed in three-dimensional coordinates and are compared to those presented in other studies (Ercal et al 1994 IEEE Trans. Biomed. Eng. 41 837-45, Cheerla and Frazier 2014 Int. J. Innovative Res. Sci., Eng. Technol. 3 9164-83) in terms of Pearson correlation coefficient and classification accuracy in determining the malignancy of the lesions. © 2017 Institute of Physics and Engineering in Medicine.","10.1088/1361-6560/aa562f","ABCD criteria; mathematical quantification; melanoma","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013102435&doi=10.1088%2f1361-6560%2faa562f&partnerID=40&md5=2110f31ba2ba47f5c110f69c9fac93d2"
"Technique standards for skin lesion imaging a delphi consensus statement","Katragadda C.; Finnane A.; Soyer H.P.; Marghoob A.A.; Halpern A.; Malvehy J.; Kittler H.; Hofmann-Wellenhof R.; Da Silva D.; Abraham I.; Curiel-Lewandrowski C.","2017","1","1","0","0","0","Unique","0","","","","","","","IMPORTANCE Variability in the metrics for image acquisition at the total body, regional, close-up, and dermoscopic levels impacts the quality and generalizability of skin images. Consensus guidelines are indicated to achieve universal imaging standards in dermatology. OBJECTIVE To achieve consensus among members of the International Skin Imaging Collaboration (ISIC) on standards for image acquisition metrics using a hybrid Delphi method. EVIDENCE REVIEW Delphi study with 5 rounds of ratings and revisions until relative consensus was achieved. The initial set of statements was developed by a core group (CG) on the basis of a literature review and clinical experience followed by 2 rounds of rating and revisions. The consensus process was validated by an extended group (EG) of ISIC members through 2 rounds of scoring and revisions. In all rounds, respondents rated the draft recommendations on a 1 (strongly agree) to 5 (strongly disagree) scale, explained ratings of less than 5, and optionally provided comments. At any stage, a recommendation was retained if both mean and median rating was 4 or higher. RESULTS The initial set of 45 items (round 1) was expanded by the CG to 56 variants in round 2, subsequently reduced to 42 items scored by the EG in round 3, yielding an EG set of 33 recommendations (rounds 4 and 5): General recommendation (1 guideline), lighting (5), background color (3), field of view (3), image orientation (8), focus/depth of field (3), resolution (4), scale (3), color calibration (2), and image storage (1). CONCLUSIONS AND RELEVANCE This iterative process of ratings and comments yielded a strong consensus on standards for skin imaging in dermatology practice. Adoption of these methods for image standardization is likely to improve clinical practice, information exchange, electronic health record documentation, harmonization of clinical studies and database development, and clinical decision support. Feasibility and validity testing under real-world clinical conditions is indicated. © 2017 American Medical Association.","10.1001/jamadermatol.2016.3949","","40","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014680612&doi=10.1001%2fjamadermatol.2016.3949&partnerID=40&md5=1fbab5a602bb93e37cc24372d256a84a"
"Combined Raman and autofluorescence ex vivo diagnostics of skin cancer in near-infrared and visible regions","Bratchenko I.A.; Artemyev D.N.; Myakinin O.O.; Khristoforova Y.A.; Moryatov A.A.; Kozlov S.V.; Zakharov V.P.","2017","1","1","0","0","0","Unique","0","","","","","","","The differentiation of skin melanomas and basal cell carcinomas (BCCs) was demonstrated based on combined analysis of Raman and autofluorescence spectra stimulated by visible and NIR lasers. It was ex vivo tested on 39 melanomas and 40 BCCs. Six spectroscopic criteria utilizing information about alteration of melanin, porphyrins, flavins, lipids, and collagen content in tumor with a comparison to healthy skin were proposed. The measured correlation between the proposed criteria makes it possible to define weakly correlated criteria groups for discriminant analysis and principal components analysis application. It was shown that the accuracy of cancerous tissues classification reaches 97.3% for a combined 6-criteria multimodal algorithm, while the accuracy determined separately for each modality does not exceed 79%. The combined 6-D method is a rapid and reliable tool for malignant skin detection and classification. © 2017 Society of Photo-Optical Instrumentation Engineers (SPIE).","10.1117/1.JBO.22.2.027005","autofluorescence; basal cell carcinoma; melanoma; oncology; optical diagnostics; principal component analysis-discriminant analysis; Raman spectroscopy","64","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013167628&doi=10.1117%2f1.JBO.22.2.027005&partnerID=40&md5=f27b0f16902e3da17eb97acf684a6edb"
"Nuclei graph local features for basal cell carcinoma classification in whole slide images","Romo-Bucheli D.; Corredor G.; Garcia-Arteaga J.D.; Arias V.; Romero E.","2017","0","1","0","0","0","Unique","0","","","","","","","Evidence based medicine aims to provide a quantifiable framework to support cancer optimal treatment selection. Pathological examination is the main evidence used in medical management, yet the level of quantification is low and highly dependent on the examiner's expertise. This paper presents and evaluates a method to extract graph based topological features from skin tissue images to identify cancerous regions associated to basal cell carcinoma. These graph features constitute a quantitative measure of the architectural tissue organization. Results show that graph topological features extracted from a nuclei based distance graph, particularly those related to local density, have a high predictive value in the automated detection of basal cell carcinoma. The method was evaluated using a leave-one-out validation scheme in a set of 9 skin Whole Slide Images obtaining an average F-score of 0:72 in distinguishing basal cell carcinoma regions in skin tissue whole slide images. © 2017 SPIE.","10.1117/12.2257386","Digital histopathology; Graph theory; Image analysis; Machine learning","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014678529&doi=10.1117%2f12.2257386&partnerID=40&md5=af864ff189a1fa1ec71697ded6377822"
"New segmentation method for skin cancer lesions","Faisal Z.; El Abbadi N.K.","2017","1","1","0","0","0","Unique","0","","","","","","","Skin cancer lesioning one of the most skin lesions which cause death. Lesion segmentation is a very important step prior to detecting and classifying the skin cancer. In this study, we introduce a new method to extract the lesion from the surrounding of healthy skin. The proposed method starts with image preprocessing included image de-noising and removing the unwanted objects such as thin hair and air bubble by using the median filter, followed with edge detection using the Markov and Laplace filter. The current algorithm converts the color image to YUV color space and select the U channel for processing. Thick hair is removed from U channel by combining both morphological operation and median filter. Mathematical morphology such as close used to join narrow breaks regions in an object, fill the small holes and remove small objects. The final step is to find threshold based on Otsu's thresholding to separate the image to two regions one for lesion and the other for skin. The result image is binary image or can be color lesion with black background. The accuracy of the suggested method reaches up to 98%. The algorithm is tested with segmented images by an expert and give very promised results in many cases gives better results. Also hamming distance is imeasured and it was better value compared with other algorithms. © Medwell journals, 2017.","10.3923/jeasci.2017.5598.5602","Edges; Image processing; Morphological operation; Otsu's; Segmentation; YUV","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038403798&doi=10.3923%2fjeasci.2017.5598.5602&partnerID=40&md5=01843c36a5caf624a41d856990372a3a"
"Image processing, pattern recognition: An efficient block-based algorithm for hair removal in dermoscopic images","Zaqout I.S.","2017","0","1","0","0","0","Unique","0","","","","","","","Hair occlusion in dermoscopy images affects the diagnostic operation of the skin lesion. Segmentation and classification of skin lesions are two major steps of the diagnostic operation required by dermatologists. We propose a new algorithm for hair removal in dermoscopy images that includes two main stages: hair detection and inpainting. In hair detection, a morphological bottom-hat operation is implemented on Y-channel image of YIQ color space followed by a bina-rization operation. In inpainting, the repaired Y-channel is partitioned into 256 non-overlapped blocks and for each block, white pixels are replaced by locating the highest peak, using a histogram function and a morphological close operation. The proposed algorithm reports a true positive rate (sensitivity) of 97.36 %, a false positive rate (fall-out) of 4.25 %, and a true negative rate (specificity) of 95.75 %. The diagnostic accuracy achieved is recorded at a high level of 95.78 %. © 2018, Institution of Russian Academy of Sciences. All rights reserved.","10.18287/2412-6179-2017-41-4-521-527","Dermoscopy image; Hair detection; Hair removal; Inpainting; Melanoma; Skin lesion","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043324588&doi=10.18287%2f2412-6179-2017-41-4-521-527&partnerID=40&md5=009c28bf177e8b0ed35a9c82934a7884"
"A framework for detecting arsenic disease","Islam M.A.; Arefin M.S.","2017","0","1","0","0","0","First occurrence","0","","","","","","","Humans are exposed to arsenic (As) primarily from air, food and water. Anyone can develop arsenic toxicity as a result of arsenic exposure. Most of the reports of chronic as well as toxicity in human focus attention on skin manifestations because of its diagnostic specificity. A dermal manifestation such as hyperpigmentation is diagnostic of chronic arsenicosis. This paper focuses on designing and modelling a system that will collate Pigmented Skin Lesion (PSL), their analysis, corresponding observations and conclusions by medical experts using prototyping methodology. The system uses computational intelligence technique to analyse, process, and classify the image library data based on texture and morphological features of the images. A user in a remote location can use mobile data acquisition devices (such as smartphone) to generate images of PSL, supply such images as input to the proposed system, which in turns should intelligently be able to specify the arsenic poisoned hyperpigmentation status of the imaged PSL. The system has been evaluated with a set of images and found that the system can almost accurately detect arsenic. © 2016 IEEE.","10.1109/CEEICT.2016.7873149","Arsenic disease; automated diagnosis; medical imaging; skin disease","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016929982&doi=10.1109%2fCEEICT.2016.7873149&partnerID=40&md5=e1b7ac45484efaf542bc114e32f3854f"
"An integrated skin marking tool for use with optical coherence tomography (OCT)","Patalay R.; Craythorne E.; Mallipeddi R.; Coleman A.","2017","1","1","0","0","0","Unique","0","","","","","","","Optical coherence tomography (OCT) has been shown to provide clinically valuable images that can aid in the assessment of the pre-surgical margin in basal cell carcinoma (BCC). The accuracy and speed with which these images can be used to help delineate margins in the clinic are currently constrained by the need to suspend imaging whilst a pen is used to mark the skin. This constraint has been circumvented here by the design of a trigger-activated ink-loaded nib integrated with the OCT probe. The adapted OCT probe enables a mark to be placed on the skin precisely where a region of interest can be seen in the OCT images, accurately and reproducibly. The adapted probe is described and a comparison of its performance and early experience of its clinical use are reported here. Initial results indicate that the integrated skin marking probe makes margin delineation under OCT image-guidance faster, more accurate and more clinically acceptable. © 2017 SPIE.","10.1117/12.2250324","BCC; Mohs; optical coherence tomography; skin cancer; surgical margins","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019074762&doi=10.1117%2f12.2250324&partnerID=40&md5=4bec226bcf76e3d5f27249d2188ea78f"
"Melanoma Is Skin Deep: A 3D Reconstruction Technique for Computerized Dermoscopic Skin Lesion Classification","Satheesha T.Y.; Satyanarayana D.; Prasad M.N.G.; Dhruve K.D.","2017","1","1","0","0","0","Unique","0","","","","","","","Melanoma mortality rates are the highest amongst skin cancer patients. Melanoma is life threating when it grows beyond the dermis of the skin. Hence, depth is an important factor to diagnose melanoma. This paper introduces a non-invasive computerized dermoscopy system that considers the estimated depth of skin lesions for diagnosis. A 3-D skin lesion reconstruction technique using the estimated depth obtained from regular dermoscopic images is presented. On basis of the 3-D reconstruction, depth and 3-D shape features are extracted. In addition to 3-D features, regular color, texture, and 2-D shape features are also extracted. Feature extraction is critical to achieve accurate results. Apart from melanoma, in-situ melanoma the proposed system is designed to diagnose basal cell carcinoma, blue nevus, dermatofibroma, haemangioma, seborrhoeic keratosis, and normal mole lesions. For experimental evaluations, the PH2, ISIC: Melanoma Project, and ATLAS dermoscopy data sets is considered. Different feature set combinations is considered and performance is evaluated. Significant performance improvement is reported the post inclusion of estimated depth and 3-D features. The good classification scores of sensitivity = 96%, specificity = 97% on PH2 data set and sensitivity = 98%, specificity = 99% on the ATLAS data set is achieved. Experiments conducted to estimate tumor depth from 3-D lesion reconstruction is presented. Experimental results achieved prove that the proposed computerized dermoscopy system is efficient and can be used to diagnose varied skin lesion dermoscopy images. © 2013 IEEE.","10.1109/JTEHM.2017.2648797","3D features and tumor depth estimation; 3D lesion reconstruction; classification; Melanoma in-situ; skin lesions","109","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014894364&doi=10.1109%2fJTEHM.2017.2648797&partnerID=40&md5=4c23d4423c5e0fce1dbe96962dfae888"
"Dermoscopic image enhancement and hair artifact removal using Gabor wavelet","Jamil U.; Khalid S.; Akram M.U.","2017","0","1","0","0","0","First occurrence","0","","","","","","","Skin cancer is one of the most prevalent types of cancer in our world. Diagnosis of skin cancer needs specialized equipment, doctors and continuous monitoring. Patients living in remote areas normally cannot access such facilities. To overcome these barriers of access, Computer Aided Diagnostics, an emerging field in computer science, often called telemedicine, is being considered a promising approach. Image processing for Computer Aided Diagnostics has three key steps, i.e. Segmentation, Feature Extraction and Classification. In this research, preprocessing and hair artifact removal experiment was performed on dermatoscope images by using Morphological and Gabor wavelet-based techniques. It has been found that, in some cases, wavelet transformations provide better results as compared to other techniques like gel, water bubbles and dark hair around the surface affected by cancer, i.e. these artifacts are removed with less effort. Experiments also showed that images with Blue channel from RGB are better as compared to other grayscale conversion techniques. © 2016 IEEE.","10.1109/INTECH.2016.7845028","dermoscopy; hair Inpainting; hair segmentation; image enhancement; skin cancer","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015275217&doi=10.1109%2fINTECH.2016.7845028&partnerID=40&md5=568f90a73ad490e697e65724b5f9b16d"
"I3dermoscopyApp: Hacking Melanoma thanks to IoT technologies","Di Leo G.; Liguori C.; Pietrosanto A.; Sommella P.; Paciello V.","2017","0","1","0","0","0","Unique","0","","","","","","","The paper introduces I3DermoscopyApp, a new declination of the Internet of Things (IoT) paradigm, designed to allow the early detection of melanoma. Even though artificial intelligence programs cannot outperform the diagnostic accuracy of expert dermatologists yet, they reveal to be very useful in providing second opinions to physicians with short clinical experience, thus improving significantly their diagnostic performance. Following this trend, an original integration of mobile app technology and well-known image processing algorithms allows the automatic analysis of pigmented skin lesions to help physicians apply a diagnostic method (Seven Point Check List) based on dermoscopy. The web-based platform makes the physician able to: i) store digital images captured by smartphones featured with a dermatoscope; ii) measure morphological and chromatic parameters of the skin lesion; iii) make a diagnostic decision according to the Seven Point Checklist method. A detailed description of the adopted techniques, together with the first validation results are reported. © 2017 Proceedings of the Annual Hawaii International Conference on System Sciences. All rights reserved.","","","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038823793&partnerID=40&md5=323a0a1e919c0852db6808eb8ca3a61f"
"High-level features for automatic skin lesions neural network based classification","Abbes W.; Sellami D.","2017","1","1","0","0","0","Unique","0","","","","","","","Melanoma is the most dangerous form of skin cancer. It can be developed from pigmented cells of the skin and can grow and spread swiftly to other organs (metastasis). An early diagnosis increases the chance of cure. In the past three decades, the increase in the incidence of melanoma has given rise to more accurate methods of analysis. Feature extraction is a critical step in melanoma decision support systems. Early dermatoscopic rules (ABCD rule, 7-point checklist, Menzies method and CASH algorithm), used by experts are generally low level features. In this paper, we consider several dermatoscopic rules for automatic detection of melanoma in order to generate new high level features allowing semantic analysis. Such extracted features are based on shape characterization and color and texture features. A neural network classifier is used for decision making. Experimental results indicate that semantic analysis is a useful method for discrimination of melanocytic skin tumors with good accuracy. The proposed method yields a good sensitivity of 92% and a specificity of 95% on a database of 206 skin lesion images. A comparative study with recent previous works illustrates that our approach outperforms in terms of accuracy and specificity. © 2016 IEEE.","10.1109/IPAS.2016.7880148","color; detection; diagnosis; Feature extraction; high level features; melanoma; Semantic analysis; texture","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018542177&doi=10.1109%2fIPAS.2016.7880148&partnerID=40&md5=33f06cf76ba4816611095a24f6cf9189"
"Skin lesion segmentation using Gray Level Co-occurance Matrix","Hassan M.; Hossny M.; Nahavandi S.; Yazdabadi A.","2017","1","1","0","0","0","First occurrence","0","","","","","","","Skin lesions screening is an effective method for early detection of melanoma. Mostly, melanoma appears as hyper-pigmented area relative to the surrounding skin. Lesion segmentation is an indispensable step for skin lesions analysis. Automated segmentation is used to assist the dermatologist to isolate the suspicious lesion from the surrounding background. Iterative Otsu's method is state-of-art segmentation technique and it has acceptable accuracy. However, iterative methods suffer same drawback, they are time consuming and no guarantee for convergence to the best solution before the maximum iterations limit reached. This paper presents a novel segmentation algorithm using GLCM (Gray Level Co-occurrence Matrix). Segmentation masks extracted by proposed method are compared to human-expert extracted ground truth. The proposed method consists of three major stages, preprocessing, segmentation, and post processing. The proposed method achieved a specificity rate of 98.62%, precision of 96.25% and sensitivity of 80.8%. © 2016 IEEE.","10.1109/SMC.2016.7844341","Dermoscopic images; GLCM; Melanoma; Segmentation; Skin lesions","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015739459&doi=10.1109%2fSMC.2016.7844341&partnerID=40&md5=62ff07df0f7a964a43996039efe6e4b8"
"Automatic detection of blue-whitish veil as the primary dermoscopic feature","Jaworek-Korjakowska J.; Kłeczek P.; Grzegorzek M.; Shirahama K.","2017","0","1","0","0","0","Unique","0","","","","","","","Dermoscopy is one of the major imaging modalities used in the diagnosis of melanoma and other pigmented skin lesions. Owing to the difficulty and subjectivity of human interpretation, dermoscopy image analysis has become an important research area. One of the most important local structure that is likely to appear in malignant melanoma is the blue-whitish veil. In this article, we present an unsupervised approach to the blue-whitish veil detection in dermoscopy images of pigmented skin lesions based on the analysis of HSV color space. The method is tested on a set of 179 dermoscopy images and the detection error rate is lower than 15%. The results demonstrate that the presented method achieves both fast and accurate blue structure segmentation in dermoscopy images. © Springer International Publishing AG 2017.","10.1007/978-3-319-59063-9_58","","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020891903&doi=10.1007%2f978-3-319-59063-9_58&partnerID=40&md5=a310d0d10a1e6dbd787a8c498940c814"
"Bio-Inspired Feed-Forward System for Skin Lesion Analysis, Screening and Follow-Up","Rundo F.; Conoci S.; Banna G.L.; Stanco F.; Battiato S.","2017","1","1","0","0","0","Unique","0","","","","","","","Traditional methods for early detection of melanoma rely upon a dermatologist who visually analyzes skin lesion using the so called ABCDE (Asymmetry, Border irregularity, Color variegation, Diameter, Evolution) criteria even though conclusive confirmation is obtained through biopsy performed by pathologist. The proposed method shows a bio-inspired feed-forward automatic pipeline based on morphological analysis and evaluation of skin lesion dermoscopy image. Preliminary segmentation and pre-processing of dermoscopy image by SC-Cellular Neural Networks is performed in order to get ad-hoc gray-level skin lesion image in which we compute analytic innovative hand-crafted image features for oncological risks assessment. At the end, pre-trained Levenberg-Marquardt Neural Network is used to perform ad-hoc clustering of such hand-crafted image features in order to get an efficient nevus discrimination (benign against melanoma) as well as a numerical array to be used for follow-up rate definition and assessment. © 2017, Springer International Publishing AG.","10.1007/978-3-319-68548-9_37","","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032496747&doi=10.1007%2f978-3-319-68548-9_37&partnerID=40&md5=f93a9c828545f2604d9adb82abfdf702"
"Pigmented skin lesion segmentation based on sparse texture representations","Martinez C.E.; Albornoz E.M.","2017","1","1","0","0","0","Unique","0","","","","","","","Among the most dangerous cancers, there is the Melanoma that affects millions of people. As this is a type of malignant pigmented skin lesion and it can be recognized by medical experts, computer-aided diagnostic systems are developed in order to assist dermatologists in clinical routine. One of the more difficult tasks is to find the right segmentation of lesions whose precision is very important to distinguish benign from malignant cases. In this work, we propose a new method based on sparse representation. First, an alternative representation of the image is obtained from the texture information. A sparse non-negative dictionary is computed and every image is projected onto this space. The reconstruction is calculated using only the most active atoms, which allows to obtaining an enhanced version of the texture where the morphological post-processing can effectively extract the lesion area. The experiments were carried out on a publicly available database and performance was evaluated in terms of segmentation error, accuracy, and specificity. Results showed that this first approach performs better than methods reported in the literature on this same data. © 2017 SPIE.","10.1117/12.2256891","Pigmented skin lesions; Segmentation; Sparse representations; Texture","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014670856&doi=10.1117%2f12.2256891&partnerID=40&md5=f5d8a64fbb548b39a748372f4cad3022"
"An analysis of human dorsal hand skin texture using hyperspectral imaging technique for assessing the skin aging process","Calin M.A.; Parasca S.V.; Calin M.R.; Petrescu E.","2017","1","1","0","0","0","Unique","0","","","","","","","Skin texture has become an important issue in recent research with applications in the cosmetic industry and medicine. In this paper, we analyzed the dependence of skin texture features on wavelength as well as on different parameters (age and gender) of human participants using grey-level co-occurrence matrix and hyperspectral imaging technique for a more accurate quantitative assessment of the aging process. A total of 42 healthy participants (men and women; age range, 20-70 years) was enrolled in this study. A region of interest was selected from the hyperspectral images. The results were analyzed in terms of texture using the gray-level co-occurrence matrix which generated four features (homogeneity, contrast, entropy, and correlation). The results showed that most of these features displayed variations with wavelength (the exception was entropy), with higher variations in women. Only correlation in both sexes and contrast in men proved to vary statistically significant with age, making them the targeted variables in future attempts to characterize aging skin using the complex method of hyperspectral imaging. In conclusion, by using hyperspectral imaging some measure of the degree of damage or the aging process of the hand skin can be obtained, mainly in terms of correlation values. At the present time, reasonable explanations that can link the process of skin aging and the above mentioned features could not be found, but deeper investigations are on the way. © The Author(s) 2016.","10.1177/0003702816659667","Age; Gray-level co-occurrence matrix; Hyperspectral imaging; Skin texture features; Wavelength","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019780658&doi=10.1177%2f0003702816659667&partnerID=40&md5=37d1facb99d874cf8f0e8d90c1c34fa3"
"Skin lesion segmentation via deep RefineNet","He X.; Yu Z.; Wang T.; Lei B.","2017","1","1","0","0","0","Unique","0","","","","","","","Dermoscopy imaging has been a routine examination approach for skin lesion diagnosis. Accurate segmentation is the first step for automatic dermoscopy image assessment. The main challenges for skin lesion segmentation are numerous variations in viewpoint and scale of skin lesion region. To handle these challenges, we propose a novel skin lesion segmentation framework via a very deep residual neural network based on dermoscopic images. The deep residual neural network and generic multi-path Deep RefineNet are combined to improve the segmentation performance. The deep representation of all available layers is aggregated to form the global feature maps using skip connection. Also, the chained residual pooling is leveraged to capture diverse appearance features based on the context. Finally, we apply the conditional random field (CRF) to smooth segmentation maps. Our proposed method shows superiority over state-of-the-art approaches based on the public skin lesion challenge dataset. © Springer International Publishing AG 2017.","10.1007/978-3-319-67558-9_35","Conditional random field; Deep RefineNet; Deep residual network; Dermoscopy image; Skin lesion segmentation","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029815003&doi=10.1007%2f978-3-319-67558-9_35&partnerID=40&md5=3a36a7ba1f735b5ad743652735818062"
"A Swarm Optimization-Based Kmedoids Clustering Technique for Extracting Melanoma Cancer Features","Khatami A.; Mirghasemi S.; Khosravi A.; Lim C.P.; Asadi H.; Nahavandi S.","2017","0","1","0","0","0","Unique","0","","","","","","","Melanoma is a dangerous type of skin cancers. It is alarming to see the increase of this noxious disease in modern societies, however, it can be cured by surgical excision if it is detected early. In this paper, a swarm-based clustering technique for detecting melanoma is developed. Meaningful colour features from images are extracted, and a new objective function is introduced by applying an efficient and fast linear transformation to detect Melanoma. Specifically, the proposed technique consists of three main phases. The first phase is a pre-processing stage to organize data into proper attributes, while the subsequent two phases comprise iterative swarm optimisation procedures. The iterative swarm optimisation procedures involve a linear transformation to convert the existing colour components into a new colour space, formulation of the Kmedoids objective function, and error minimisation of the particle swarm optimisation (PSO) solutions. The Otsu threshold technique is utilised to provide binary images. The proposed technique is efficient and effective due to its linearity and simplicity. © 2017, Springer International Publishing AG.","10.1007/978-3-319-70093-9_32","Colour space; Kmedoids clustering; Melanoma skin cancer; Otsu threshold technique; PSO","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035125901&doi=10.1007%2f978-3-319-70093-9_32&partnerID=40&md5=dcdfd9eb413c6ad598e740b3b893d2ae"
"Studies on a formidable dot and globule related feature extraction technique for detection of melanoma from dermoscopic images","Chatterjee S.; Dey D.; Munshi S.","2017","0","1","0","0","0","Unique","0","","","","","","","Among the wide variety of skin abnormalities, malignant melanoma is the deadliest and causes a vast majority of deaths. Existence of dark dots/globules is a feature demarcating the melanocytic skin lesions from the others. In this reported research work, a methodical approach for the identification and segmentation of dark dots/globules from the dermoscopic images using mathematical morphology has been proposed and implemented. Different morphological gradient operations have been performed with varying size of the Structuring Element (SE) to identify the small circular structures present in the skin lesion area. In the segmentation stage the threshold value has been selected according to the range of intensity values present in those dot/globule regions. Subsequently, a number of dot/globule related features have been extracted for the classification of the dermoscopic images. Furthermore, it has been shown that the dot/globule related features have a significant effect on the classification of the melanoma, and has the potential for scoring even 100% sensitivity, provided it is used in conjunction with appropriately chosen classification algorithms. © 2017 Taylor & Francis Group.","10.1201/9781315400624-62","","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034831296&doi=10.1201%2f9781315400624-62&partnerID=40&md5=028008c66e57d7175f9557edd7b4728b"
"Aggregating deep convolutional features for melanoma recognition in dermoscopy images","Yu Z.; Jiang X.; Wang T.; Lei B.","2017","0","1","0","0","0","Unique","0","","","","","","","We present a novel framework for automated melanoma recognition in dermoscorpy images, which is a quite challenging task due to the high intra-class and low inter-class variations between melanoma and non-melanoma (benign). The proposed framework shares merits of deep learning method and local descriptors encoding strategy. Specifically, the deep representations of a dermoscopy image are first extracted using a very deep residual neural network pre-trained on ImageNet. Then these local deep descriptors are aggregated by fisher vector (FV) encoding to build a holistic image representation. Finally, the encoded representations are classified using SVM. In contrast to previous studies with complex preprocessing and feature engineering or directly using existing deep learning architectures with fine-tuning on the skin datasets, our solution is simpler, more compact and capable of producing more discriminative features. Extensive experiments performed on ISBI 2016 Skin lesion challenge dataset corroborate the effectiveness of the proposed method, outperforming state-of-the-art approaches in all evaluation metrics. © 2017, Springer International Publishing AG.","10.1007/978-3-319-67389-9_28","Dermoscopy image; Fisher vector; Melanoma recognition; Residual network","31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029692967&doi=10.1007%2f978-3-319-67389-9_28&partnerID=40&md5=0f73f6a3d913f370123f059b2ce32718"
"Advanced earlier melanoma detection algorithm using colour correlogram","Soumya R.S.; Neethu S.; Niju T.S.; Renjini A.; Aneesh R.P.","2017","0","1","0","0","0","First occurrence","0","","","","","","","Melanoma is a most dangerous form of skin cancer that develops from the pigment producing cells known as melanocytes. Melanoma skin cancers are also known as malignant melanoma. Recent studies show that the death rates of melanoma patients depend on the various stages of cancer, so early detection and treatment of melanoma implicate higher chances of cure. Now most of the existing skin lesion analysis system use ABCDE parameters for feature extraction. But these methods have lot of drawbacks. In this paper an advance earlier melanoma detection algorithm is proposed using colour correlogram and texture analysis. Bayesian classifier is used to detect the abnormal skin cells with colour correlogram and SFTA feature vectors. The system is successfully tested with the dermoscopic dataset and the experimental results show that the combination of colour correlogram and texture analysis give better results with an accuracy of 91.5%. © 2016 IEEE.","10.1109/CSN.2016.7824012","Bayesian classifier; Colour correlogram; Image segmentation; Melanoma; SFTA; Skin Cancer","27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014892673&doi=10.1109%2fCSN.2016.7824012&partnerID=40&md5=f415d3c60ac434e004039847f003604b"
"Automated epidermis segmentation in histopathological images of human skin stained with hematoxylin and eosin","Kłeczek P.; Dyduch G.; Jaworek-Korjakowska J.; Tadeusiewicz R.","2017","1","1","0","0","0","Unique","0","","","","","","","Background: Epidermis area is an important observation area for the diagnosis of inflammatory skin diseases and skin cancers. Therefore, in order to develop a computer-aided diagnosis system, segmentation of the epidermis area is usually an essential, initial step. This study presents an automated and robust method for epidermis segmentation in whole slide histopathological images of human skin, stained with hematoxylin and eosin. Methods: The proposed method performs epidermis segmentation based on the information about shape and distribution of transparent regions in a slide image and information about distribution and concentration of hematoxylin and eosin stains. It utilizes domain-specific knowledge of morphometric and biochemical properties of skin tissue elements to segment the relevant histopathological structures in human skin. Results: Experimental results on 88 skin histopathological images from three different sources show that the proposed method segments the epidermis with a mean sensitivity of 87 %, a mean specificity of 95% and a mean precision of 57%. It is robust to inter- and intra-image variations in both staining and illumination, and makes no assumptions about the type of skin disorder. The proposed method provides a superior performance compared to the existing techniques. © 2017 SPIE.","10.1117/12.2249018","2D histogram analysis; Color deconvolution; Eosin; Epidermis; Hematoxylin; Histopathology; Image analysis; Mathematical morphology; Segmentation","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020247639&doi=10.1117%2f12.2249018&partnerID=40&md5=129aa812c0aa29b8a09f65ae7b9e1eda"
"A marked poisson process driven latent shape model for 3d segmentation of reflectance confocal microscopy image stacks of human skin","Ghanta S.; Jordan M.I.; Kose K.; Brooks D.H.; Rajadhyaksha M.; Dy J.G.","2017","1","1","0","0","0","Unique","0","","","","","","","Segmenting objects of interest from 3D data sets is a common problem encountered in biological data. Small field of view and intrinsic biological variability combined with optically subtle changes of intensity, resolution, and low contrast in images make the task of segmentation difficult, especially for microscopy of unstained living or freshly excised thick tissues. Incorporating shape information in addition to the appearance of the object of interest can often help improve segmentation performance. However, the shapes of objects in tissue can be highly variable and design of a flexible shape model that encompasses these variations is challenging. To address such complex segmentation problems, we propose a unified probabilistic framework that can incorporate the uncertainty associated with complex shapes, variable appearance, and unknown locations. The driving application that inspired the development of this framework is a biologically important segmentation problem: the task of automatically detecting and segmenting the dermal-epidermal junction (DEJ) in 3D reflectance confocal microscopy (RCM) images of human skin. RCM imaging allows noninvasive observation of cellular, nuclear, and morphological detail. The DEJ is an important morphological feature as it is where disorder, disease, and cancer usually start. Detecting the DEJ is challenging, because it is a 2D surface in a 3D volume which has strong but highly variable number of irregularly spaced and variably shaped 'peaks and valleys.' In addition, RCM imaging resolution, contrast, and intensity vary with depth. Thus, a prior model needs to incorporate the intrinsic structure while allowing variability in essentially all its parameters. We propose a model which can incorporate objects of interest with complex shapes and variable appearance in an unsupervised setting by utilizing domain knowledge to build appropriate priors of the model. Our novel strategy to model this structure combines a spatial Poisson process with shape priors and performs inference using Gibbs sampling. Experimental results show that the proposed unsupervised model is able to automatically detect the DEJ with physiologically relevant accuracy in the range 10- $20 ~\mu m$. © 1992-2012 IEEE.","10.1109/TIP.2016.2615291","3D Bayesian model; dermis-epidermis; multiple object detection; poisson process; segmentation; shape model","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012083507&doi=10.1109%2fTIP.2016.2615291&partnerID=40&md5=0de6cae30dee60ce511a6d917b05e3a6"
"Multiregional Segmentation Modeling in Medical Ultrasonography: Extraction, Modeling and Quantification of Skin Layers and Hypertrophic Scars","Bryjova I.; Kubicek J.; Molnarova K.; Peter L.; Penhaker M.; Kuca K.","2017","1","1","0","0","0","First occurrence","0","","","","","","","In the clinical practice of the burns treatment, an autonomous modeling of the burns morphological structure is important for a correct diagnosis. Unfortunately, the geometrical parameters of burns and skin layers are subjectively estimated. This approach leads to the inaccurate assessment depending on the experience of an individual physician. In our research, we propose the analysis of multiregional segmentation method which is able to differentiate individual skin layers in the ultrasound image records. The segmentation method is represented by the mathematical model of skin layers while other structures are suppressed. Skin layers are consequently approximated by their skeleton with target of the layers distance measurement. The main applicable output of our research is the clinical SW SkinessMeter 1.0.0 serving for an autonomous modeling and quantification of the skin layers. © 2017, Springer International Publishing AG.","10.1007/978-3-319-67077-5_18","Burns; Hypertrophic scars; Multiregional segmentation; Skin layers; Ultrasound","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030843332&doi=10.1007%2f978-3-319-67077-5_18&partnerID=40&md5=867263ed626c74376485d341c20692bb"
"14th International Conference on Image Analysis and Recognition, ICIAR 2017","","2017","0","1","0","0","0","Unique","0","","","","","","","The proceedings contain 73 papers. The special focus in this conference is on Image Analysis and Recognition. The topics include: A weight-selection strategy on training deep neural networks for imbalanced classification; end-to-end deep learning for driver distraction recognition; deep CNN with graph Laplacian regularization for multi-label image annotation; transfer learning using convolutional neural networks for face anti spoofing; depth from defocus via active quasi-random point projections; discovery radiomics via a mixture of deep convnet sequencers for multi-parametric MRI prostate cancer classification; discovery radiomics for pathologically-proven computed tomography lung cancer prediction; left ventricle wall detection from ultrasound images using shape and appearance information; probabilistic segmentation of brain white matter lesions using texture-based classification; a machine learning-driven approach to computational physiological modeling of skin cancer; ejection fraction estimation using a wide convolutional neural network; fully deep convolutional neural networks for segmentation of the prostate gland in diffusion-weighted MR images; compensated row-column ultrasound imaging system using three dimensional random fields; curvelet-based Bayesian estimator for speckle suppression in ultrasound imaging; object boundary based denoising for depth images; a note on boosting algorithms for image denoising; scale and rotation invariant character segmentation from coins; image segmentation based on solving the flow in the mesh with the connections of limited capacities; exploiting semantic segmentation for robust camera motion classification; an event-based optical flow algorithm for dynamic vision sensors and hybrid multi-modal fusion for human action recognition.","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022210867&partnerID=40&md5=6f653446fff3bd997947a387c80e08f5"
"An intelligent despeckling method for swept source optical coherence tomography images of skin","Adabi S.; Mohebbikarkhoran H.; Mehregan D.; Conforto S.; Nasiriavanaki M.","2017","1","0","0","0","0","Unique","0","","","","","","","Optical Coherence Optical coherence tomography is a powerful high-resolution imaging method with a broad biomedical application. Nonetheless, OCT images suffer from a multiplicative artefacts so-called speckle, a result of coherent imaging of system. Digital filters become ubiquitous means for speckle reduction. Addressing the fact that there still a room for despeckling in OCT, we proposed an intelligent speckle reduction framework based on OCT tissue morphological, textural and optical features that through a trained network selects the winner filter in which adaptively suppress the speckle noise while preserve structural information of OCT signal. These parameters are calculated for different steps of the procedure to be used in designed Artificial Neural Network decider that select the best denoising technique for each segment of the image. Results of training shows the dominant filter is BM3D from the last category. © 2017 SPIE.","10.1117/12.2255565","Optical coherence tomography; Speckle reduction","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020270978&doi=10.1117%2f12.2255565&partnerID=40&md5=a8ebf9af507a5d1fadd4c12e38432982"
"Facial skin classification using convolutional neural networks","Alarifi J.S.; Goyal M.; Davison A.K.; Dancey D.; Khan R.; Yap M.H.","2017","1","1","0","0","0","Unique","0","","","","","","","Facial skin assessment is crucial for a number of fields including the make-up industry, dermatology and plastic surgery. This paper addresses skin classification techniques which use conventional machine learning and state-of-the-art Convolutional Neural Networks to classify three types of facial skin patches, namely normal, spots and wrinkles. This study aims to accomplish the pivotal work on the basis of these three classes to provide the collective facial skin quality score. In this work, we collected high quality face images of people from different ethnicities to create a derma dataset. Then, we outlined the skin patches of 100 × 100 resolution in the three pre-decided classes. With extensive parameter tuning, we ran a number of computer vision experiments using both traditional machine learning and deep learning techniques for this 3-class classification. Despite the limited dataset, GoogLeNet out-performs the Support Vector Machine approach with Accuracy of 0.899, F-Measure of 0.852 and Matthews Correlation Coefficient of 0.779. The result shows the potential use of deep learning for non-clinical skin images classification, which will be more promising with a larger dataset. © Springer International Publishing AG 2017.","10.1007/978-3-319-59876-5_53","Classification; CNNs; Facial skin; Skin quality assessment","24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022212534&doi=10.1007%2f978-3-319-59876-5_53&partnerID=40&md5=4395e2e9b3468df628e22633bcf5c612"
"Digital image preprocessing and hair artifact removal by using gabor wavelet","Jamil U.; Khalid S.; Akram M.U.","2016","0","1","0","0","0","First occurrence","0","","","","","","","Diagnosis of skin cancer needs specialized equipment, doctors and continuous monitoring to treat it well. Patients living in remote areas normally cannot access such facilities. To overcome these barriers of access. Computer Aided Diagnostics, an emerging field in computer science, often called telemedicine, is being considered a promising approach. In this research, preprocessing and hair artifact removal experiment was performed on dermatoscope images by using Morphological and Gabor wavelet-based techniques. It has been found that, in some cases, wavelet transformations provide better results as compared to other techniques like gel, water bubbles and dark hair around the surface affected by cancer, i.e. these artifacts are removed with less effort. © 2016 IEEE.","10.1109/ISOCC.2016.7799864","Dermoscopy; Hair inpainting; Hair segmentation; Illumination; Image enhancement; Melanoma; Skin cancer","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010303495&doi=10.1109%2fISOCC.2016.7799864&partnerID=40&md5=6a627ac43b3a9ffe4db74dd85b8e3af3"
"Huygens principle based UWB microwave imaging method for skin cancer detection","Ghavami N.; Tiberi G.; Ghavami M.; Dudley S.; Lane M.","2016","1","1","0","0","0","Unique","0","","","","","","","In recent years, Ultra Wideband (UWB) technology has emerged as a promising alternative for use in a wide range of applications. One of the potential applications of UWB is in healthcare and imaging, motivated by its non-ionizing signals, low cost, low complexity, and its ability to penetrate through mediums. Moreover, the large bandwidth covered by UWB signals permits the very high resolution required in imaging experiments. In this paper, a recently introduced UWB microwave imaging technique based on the Huygens principle (HP), has been applied to multilayered skin model with an inclusion representing a tumor. The methodology of HP permits the capture of contrast such that different material properties within the region of interest can be discriminated in the final image, and its simplicity removes the need to solve inverse problems when forward propagating the waves. Therefore the procedure can identify and localize significant scatterers inside a multilayered volume. Validation of the technique through simulations on multilayered cylindrical model of the skin with inclusion representing the tumor has been performed. © 2016 IEEE.","10.1109/CSNDSP.2016.7573969","","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991662198&doi=10.1109%2fCSNDSP.2016.7573969&partnerID=40&md5=3c9a4a8e16b62bbaad5d0fb506c60880"
"Improving skin lesion segmentation in dermoscopic images by thin artefacts removal methods","Majtner T.; Lidayová K.; Yildirim-Yayilgan S.; Hardeberg J.Y.","2016","1","1","0","0","0","First occurrence","0","","","","","","","In dermoscopic images, various thin artefacts naturally appear, most usually in the form of hairs. While trying to find the border of the skin lesion, these artefacts effect the lesion segmentation methods and also the subsequent classification. Currently, there is a lot of research focus in this area and various methods are presented both for skin lesion segmentation and thin artefacts removal. In this paper, we investigate into three different thin artefacts removal methods and compare their results using two different skin lesion segmentation methods. The segmentation results are compared with ground truth segmentation. In addition, we introduce our novel artefacts removal method, which combined with the Expectation Maximization image segmentation outperforms all the tested methods. © 2016 IEEE.","10.1109/EUVIP.2016.7764580","Chan-Vese segmentation; dermoscopic images; expectation-maximization segmentation; skin lesion segmentation; thin artefacts removal","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011294177&doi=10.1109%2fEUVIP.2016.7764580&partnerID=40&md5=debe1aa2ae0d758ecd089835eeb06653"
"Computer assisted diagnosis of basal cell carcinoma using Z-transform features","Noroozi N.; Zakerolhosseini A.","2016","0","1","0","0","0","Unique","0","","","","","","","Detection of basal cell carcinoma tumor is of great importance for decision making in the disease treatment procedure. Visual inspection of the histopathological slides for tumor detection is laborious, time consuming and prone to inter and intra observer variability. In this paper, we have proposed an automated method for discriminating basal cell carcinoma tumor from squamous cell carcinoma tumor in skin histopathological images using Z-transform features, which were not used previously in image classification tasks. For the first time, it is shown that how two or three Fourier transform features can be combined to form one Z-transform feature. Experiments have shown that the tumor classification results obtained by our method are in reasonable agreement with the gold standards provided by expert pathologists. © 2016 Elsevier Inc.","10.1016/j.jvcir.2016.06.014","Basal cell carcinoma; Fourier transform; Skin cancer; Squamous cell carcinoma; Z-transform","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976546780&doi=10.1016%2fj.jvcir.2016.06.014&partnerID=40&md5=5e3905b81586bef8e2bf3204bf368377"
"Multi-scale classification based lesion segmentation for dermoscopic images","Abedini M.; Codella N.; Chakravorty R.; Garnavi R.; Gutman D.; Helba B.; Smith J.R.","2016","0","1","0","0","0","Unique","0","","","","","","","This paper presents a robust segmentation method based on multi-scale classification to identify the lesion boundary in dermoscopic images. Our proposed method leverages a collection of classifiers which are trained at various resolutions to categorize each pixel as 'lesion' or 'surrounding skin'. In detection phase, trained classifiers are applied on new images. The classifier outputs are fused at pixel level to build probability maps which represent lesion saliency maps. In the next step, Otsu thresholding is applied to convert the saliency maps to binary masks, which determine the border of the lesions. We compared our proposed method with existing lesion segmentation methods proposed in the literature using two dermoscopy data sets (International Skin Imaging Collaboration and Pedro Hispano Hospital) which demonstrates the superiority of our method with Dice Coefficient of 0.91 and accuracy of 94%. © 2016 IEEE.","10.1109/EMBC.2016.7590960","","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009059939&doi=10.1109%2fEMBC.2016.7590960&partnerID=40&md5=b2fe52ab979c51b27502880d978c72d3"
"Comparison of different optical coherence tomography devices for diagnosis of non-melanoma skin cancer","Schuh S.; Kaestle R.; Sattler E.; Welzel J.","2016","1","1","0","0","0","Unique","0","","","","","","","Purpose: To compare the diagnostic imaging ability of three different optical coherence tomography (OCT) devices in non-melanoma skin cancer (NMSC). Methods: Thirty actinic keratoses (AKs) and 27 basal cell carcinomas (BCCs) of 29 patients were examined with three different OCT devices, VivoSight®, Callisto® and Skintell®. Results: Complete data sets were available for 16 BCCs and 10 AKs of 18 patients. All OCT devices were able to discriminate BCCs and AKs significantly from perilesional normal skin due to lower signal intensities as well as a thicker stratum corneum and epidermis in AKs. A significant decrease in the signal intensity and thickness of all skin layers was noted with Skintell® in contrast to VivoSight® and Callisto®. OCT comparisons revealed only slight differences between VivoSight® and Callisto®. Regarding BCC tumor thickness VivoSight® and Callisto® correlated well, histology did not correlate with the three OCT devices, whereas Skintell® showed no correlation with VivoSight®, Callisto® or histology. Conclusion: All tested OCT devices could identify BCCs and AKs objectively through standardized measurement of signal intensity and skin layer thickness. Due to their technical specifications (resolution, penetration depth), each of the OCT systems offers additional and special information on NMSC. © 2016 John Wiley & Sons A/S. Published by John Wiley & Sons Ltd","10.1111/srt.12277","actinic keratosis; basal cell carcinoma; non-melanoma skin cancer; OCT devices; optical coherence tomography; skin imaging","25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990180276&doi=10.1111%2fsrt.12277&partnerID=40&md5=db6c2950a3efe835c44df264661cfb85"
"Lesion border detection using deep learning","Sabouri P.; Gholamhosseini H.","2016","0","1","0","0","0","First occurrence","0","","","","","","","Computer aided diagnosis of medical images can result in (better) detection in addition to early diagnosis of many symptoms to assist health physicians and therefore reducing the mortality rate. Realization of an efficient mobile device for automatic diagnosis of melanoma would greatly enhance the applicability of medical image classification scheme and make it useful in clinical contexts. In this paper, a deep learning method using convolutional neural networks (CNN) is proposed for border detection of skin lesions based on clinical images. Prepossessing of clinical and dermoscopy images has been common and necessary in the lesion segmentation realm; however, the result of the study shows that CNN can be used with relatively much less prepossessing algorithm compared with previous methods. © 2016 IEEE.","10.1109/CEC.2016.7743955","Border detection; Convolutional neural networks; Deep learning; Lesion segmentation; Melanoma detection","36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008263004&doi=10.1109%2fCEC.2016.7743955&partnerID=40&md5=315400a65a91ec17d45a01e529016cb9"
"Sequential change of wound calculated by image analysis using a color patch method during a secondary intention healing","Yang S.; Park J.; Lee H.; Kim S.; Lee B.-U.; Chung K.-Y.; Oh B.","2016","0","1","0","0","0","Unique","0","","","","","","","Background Photographs of skin wounds have the most important information during the secondary intention healing (SIH). However, there is no standard method for handling those images and analyzing them efficiently and conveniently. Objective To investigate the sequential changes of SIH depending on the body sites using a color patch method Methods We performed retrospective reviews of 30 patients (11 facial and 19 non-facial areas) who underwent SIH for the restoration of skin defects and captured sequential photographs with a color patch which is specially designed for automatically calculating defect and scar sizes. Results Using a novel image analysis method with a color patch, skin defects were calculated more accurately (range of error rate: -3.39% ∼ + 3.05%). All patients had smaller scar size than the original defect size after SIH treatment (rates of decrease: 18.8% ∼ 86.1%), and facial area showed significantly higher decrease rate compared with the non-facial area such as scalp and extremities (67.05 ± 12.48 vs. 53.29 ± 18.11, P < 0.05). From the result of estimating the date corresponding to the half of the final decrement, all of the facial area showed improvements within two weeks (8.45 ± 3.91), and non-facial area needed 14.33 ± 9.78 days. Conclusion From the results of sequential changes of skin defects, SIH can be recommended as an alternative treatment method for restoration with more careful dressing for initial two weeks. © 2016 Yang et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","10.1371/journal.pone.0163092","","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991826489&doi=10.1371%2fjournal.pone.0163092&partnerID=40&md5=96a3cf4b459c0bd0614a2b019ba9e9a6"
"Hyperspectral imaging and spectral classification for assisting in vivo diagnosis of melanoma precursors: Preliminary results obtained from mice","Tsapras A.; Emmanouil T.; Emmanouil P.; Balas C.; Makris A.M.; Tsatsanis C.; Stathopoulos E.N.","2016","0","1","0","0","0","Unique","0","","","","","","","Dysplastic nevi are at high risk of converting to melanoma. Early detection of signs of skin dysplasias at their curable stage, is crucial. We present an integrated system combining a Hyperspectral Camera system (HyCam), with spectral classification algorithms, developed for the in vivo and objective discrimination between non dysplastic, dysplastic nevi and melanomas. A melanoma animal model was developed in order to monitor the process of melanoma development. Reference spectra were collected from normal skin areas, which were compared with the spectra obtained from the lesions using the Spectral Angle Mapper (SAM) algorithm. A pseoudocolor map was created with different colors representing various degrees of similarity between test and reference spectra. The system's predictions ware validated with biopsy/histology. Both sensitivity and specificity were found to be 77%, highlighting the potential of the method to improve diagnostic and screening accuracies. © 2016 IEEE.","10.1109/IST.2016.7738255","melanoma; nevi; spectral classification; Spectral Imaging","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85003794193&doi=10.1109%2fIST.2016.7738255&partnerID=40&md5=82add94906ddcf62c75be21fbfbd8921"
"Image-guided automatic triggering of a fractional CO2 laser in aesthetic procedures","Wilczyński S.; Koprowski R.; Wiernek B.K.; Błońska-Fajfrowska B.","2016","0","1","0","0","0","Unique","0","","","","","","","Background Laser procedures in dermatology and aesthetic medicine are associated with the need for manual laser triggering. This leads to pulse overlapping and side effects. Methods Automatic laser triggering based on image analysis can provide a secure fit to each successive doses of radiation. A fractional CO2 laser was used in the study. 500 images of the human skin of healthy subjects were acquired. Automatic triggering was initiated by an application together with a camera which tracks and analyses the skin in visible light. The tracking algorithm uses the methods of image analysis to overlap images. After locating the characteristic points in analysed adjacent areas, the correspondence of graphs is found. The point coordinates derived from the images are the vertices of graphs with respect to which isomorphism is sought. When the correspondence of graphs is found, it is possible to overlap the neighbouring parts of the image. Results The proposed method of laser triggering owing to the automatic image fitting method allows for 100% repeatability. To meet this requirement, there must be at least 13 graph vertices obtained from the image. For this number of vertices, the time of analysis of a single image is less than 0.5 s. Conclusions The proposed method, applied in practice, may help reduce the number of side effects during dermatological laser procedures resulting from laser pulse overlapping. In addition, it reduces treatment time and enables to propose new techniques of treatment through controlled, precise laser pulse overlapping. © 2016 Elsevier Ltd","10.1016/j.compbiomed.2016.06.012","Ablative lasers; Automatic laser triggering; CO<sub>2</sub> laser; Image processing","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976285862&doi=10.1016%2fj.compbiomed.2016.06.012&partnerID=40&md5=20e81eb30ec99c66a235f0c67549a56f"
"Dermatological Disease Detection Using Image Processing and Machine Learning","Kumar V.B.; Kumar S.S.; Saboo V.","2016","0","1","0","0","0","Unique","0","","","","","","","Dermatological diseases are the most prevalent diseases worldwide. Despite being common, its diagnosis is extremely difficult and requires extensive experience in the domain. In this research paper, we provide an approach to detect various kinds of these diseases. We use a dual stage approach which effectively combines Computer Vision and Machine Learning on clinically evaluated histopathological attributes to accurately identify the disease. In the first stage, the image of the skin disease is subject to various kinds of pre-processing techniques followed by feature extraction. The second stage involves the use of Machine learning algorithms to identify diseases based on the histopathological attributes observed on analysing of the skin. Upon training and testing for the six diseases, the system produced an accuracy of up to 95 percent. © 2016 IEEE.","10.1109/ICAIPR.2016.7585217","Automated Disease Diagnosis; Computational Intelligence; Computer Vision; Data Mining; Dermatology; Image Processing; Machine Learning","101","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995598514&doi=10.1109%2fICAIPR.2016.7585217&partnerID=40&md5=c7b12375947bc944e9fa60aed96bfdb8"
"Melanoma detection by analysis of clinical images using convolutional neural network","Nasr-Esfahani E.; Samavi S.; Karimi N.; Soroushmehr S.M.R.; Jafari M.H.; Ward K.; Najarian K.","2016","0","1","0","0","0","Unique","0","","","","","","","Melanoma, most threatening type of skin cancer, is on the rise. In this paper an implementation of a deep-learning system on a computer server, equipped with graphic processing unit (GPU), is proposed for detection of melanoma lesions. Clinical (non-dermoscopic) images are used in the proposed system, which could assist a dermatologist in early diagnosis of this type of skin cancer. In the proposed system, input clinical images, which could contain illumination and noise effects, are preprocessed in order to reduce such artifacts. Afterward, the enhanced images are fed to a pre-trained convolutional neural network (CNN) which is a member of deep learning models. The CNN classifier, which is trained by large number of training samples, distinguishes between melanoma and benign cases. Experimental results show that the proposed method is superior in terms of diagnostic accuracy in comparison with the state-of-the-art methods. © 2016 IEEE.","10.1109/EMBC.2016.7590963","","310","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009062852&doi=10.1109%2fEMBC.2016.7590963&partnerID=40&md5=c59b4095dde8011b7c90ff20d7785557"
"An intelligent system to diagnosis the skin disease","Kumar M.; Kumar R.","2016","1","1","0","0","0","Unique","0","","","","","","","Skin is the most sensitive part of the body therefore we need a special attention. This research is related to detect skin disease, such as acne, psoriasis etc. In general this type of disease can become more dangerous if it is not controlled at an earlier stage. This research will provide a facility to user for determining the skin disease based on symptoms. In this research the data processing of patients is using KNN (Neural Network) which has recently achieved very promising results in a wide range of areas such as computer vision, speech recognition and natural language processing. It aims to learn hierarchical representations of data by using KNN. In a skin disease detection system, images need to be automatically processed and analyzed. In this paper, we review the KNN algorithms applied to infected skin images of humans in terms of different research topics: skin image detection, image processing, and image recognition and image classification. © 2006-2016 Asian Research Publishing Network (ARPN).","","Active contour; Contrast; Dermatology; KNN; Mean value; ROI (Region of Interest)","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992143157&partnerID=40&md5=69c53820f3e33f258a3b6051927e49aa"
"Review of segmentation methods on malignant melanoma","Thompson F.; Jeyakumar M.K.","2016","0","1","0","0","0","First occurrence","0","","","","","","","Dermoscopy is a non-invasive, widely used diagnostic tool that aids the diagnosis of skin lesions and is proven to increase the accuracy of melanoma diagnosis. If the melanoma is diagnosed in an early stage, there is a high probability of being cured. In this regard, several imaging techniques have been explored to improve the diagnosis accuracy of skin lesions. The first step in these systems is skin lesion segmentation. The next essential step is feature extraction and pattern analysis procedures for better recognition. In this paper, a brief study has been carried out about the existing segmentation methods adopted by different scholars such as Adaptive thresholding, Thresholding based on type-2 fuzzy logic, Statistical region merging, Neuro fuzzy model, Geometric deformable models, Levelset model, Wavelet network model. The segmentation methods discussed here are thresholding, edge-based, and region-based. Color images when segmented directly, yields better differentiation between the lesions. These techniques are evaluated using Accuracy rate, sensitivity, specificity, Border error, Hammoude distance, Hausdorff distance, MSE, PSNR and elapsed time. © 2016 IEEE.","10.1109/ICCPCT.2016.7530350","dermoscopy; image segmentation; neuro fuzzy; region merging; thresholding; wavelet network","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992028227&doi=10.1109%2fICCPCT.2016.7530350&partnerID=40&md5=6be65d791a9e521f33ae8a94708ebc3d"
"Classification of dermoscopy patterns using deep convolutional neural networks","Demyanov S.; Chakravorty R.; Abedini M.; Halpern A.; Garnavi R.","2016","0","1","0","0","0","First occurrence","0","","","","","","","Detection of dermoscopic patterns, such as typical network and regular globules, is an important step in the skin lesion analysis. This is one of the steps, required to compute the ABCD-score, commonly used for lesion type classification. In this article, we investigate the possibility of automatically detect dermoscopic patterns using deep convolutional neural networks and other image classification algorithms. For the evaluation, we employ the dataset obtained through collaboration with the International Skin Imaging Collaboration (ISIC), including 211 lesions manually annotated by domain experts, generating over 2000 samples of each class (network and globules). Experimental results demonstrates that we can correctly classify 88% of network examples, and 83% of globules example. The best results are achieved by a convolutional neural network with 8 layers. © 2016 IEEE.","10.1109/ISBI.2016.7493284","Convolutional Networks; Deep Learning; Dermoscopy patterns; Image classification","80","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978420803&doi=10.1109%2fISBI.2016.7493284&partnerID=40&md5=144530666c5572ccbd2ba47f88c9bca6"
"Skin-pigmentation-disorder detection algorithm based on projective coordinates","Liu Y.; Lee S.-H.; Kwon S.-G.; Kwon K.-R.","2016","1","1","0","0","0","Unique","0","","","","","","","Our skin is the first line of defense from external environment. It covers whole body and protects the tissues and organs from various external assaults. Skin also keeps a stable internal environment for body's metabolism, like regulating temperature and saving necessary water. Furthermore the nerve of skin gives us tactile sensation, which makes us to better adapt to our living environment. When skin diseases occur, the partial functionality of skin cannot be accomplished. One of fatal diseases is skin cancer. With skin cancer progression, the color of skin will change on different stage. Paper proposes an algorithm to detect and quantize this kind of visual change. The program tries to assist people to diagnosis skin cancer, even self-exam. The proposed algorithm mainly contains three parts. Initially paper segments the skin area from images. Then two main components of skin color are retrieved by ICA. Finally paper estimates if there is pigmentation disorder through comparing the ratio of two main components, and a novel comparing model, projective coordinates is used in this process. © 2016 Elsevier GmbH. All rights reserved.","10.1016/j.ijleo.2016.04.013","GMM-EM clustering; Hemoglobin; Melanin; Projective HM coordinates; Skin disorder area detection","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964411164&doi=10.1016%2fj.ijleo.2016.04.013&partnerID=40&md5=364554636117c3df18c508a1d48752cc"
"Proposed threshold algorithm for accurate segmentation for skin lesion","Satheesha T.Y.; Sathyanarayana D.; Giri Prasad M.N.","2016","1","1","0","0","0","Unique","0","","","","","","","Automated diagnosis of skin cancer can be easily achieved only by effective segmentation of skin lesion. But this is a highly challenging task due to the presence of intensity variations in the images of skin lesions. The authors here, have presented a histogram analysis based fuzzy C mean threshold technique to overcome the drawbacks. This not only reduces the computational complexity but also unifies advantages of soft and hard threshold algorithms. Calculation of threshold values even the presence of abrupt intensity variations is simplified. Segmentation of skin lesions is easily achieved, in a more efficient way in the following algorithm. The experimental verification here is done on a large set of skin lesion images containing every possible artifacts which highly contributes to reversed segmentation outputs. This algorithm efficiency was measured based on a comparison with other prominent threshold methods. This approach has performed reasonably well and can be implemented in the expert skin cancer diagnostic systems. © 2017 by IGI Global. All rights reserved.","10.4018/978-1-5225-0549-5.ch009","","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013993718&doi=10.4018%2f978-1-5225-0549-5.ch009&partnerID=40&md5=d0ad5b9ad2090c95b0d71b81ced0da18"
"Computer-assisted image processing technique for tracking wound progress","Haider A.; Alhashim M.; Tavakolian K.; Fazel-Rezai R.","2016","0","1","0","0","0","Unique","0","","","","","","","The purpose of this study was to develop an algorithm to support the decisions of expert physicians in the management of wound healing. The goal was to work towards the development of an image processing algorithm for quantifying the progress of healing of skin wounds. For this algorithm development, multiple wound images were obtained from patients in clinical settings to monitor the status of wound healing after excision of skin lesions. Dermatologists applied Vaseline and novel experimental natural ointment (NENO) at two different spots on the same subject. The developed algorithm was evaluated for its compatibility to monitor the healing as well as a potential tool to compare the efficacy of Vaseline and NENO to heal the wound. Skin color was used as a feature to measure wound progress. Based on the temporal change of the skin color, decisions were made on whether the wound is healing or expanding. The proposed processing technique was able to detect the color change within the range of 10% to 90%. © 2016 IEEE.","10.1109/EIT.2016.7535333","","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984649603&doi=10.1109%2fEIT.2016.7535333&partnerID=40&md5=f7a38baf22a003baa8851fc53d52c99c"
"A comparative study of OTSU and entropy based segmentation approaches for lesion extraction","Tiwari R.; Sharma B.","2016","0","1","0","0","0","First occurrence","0","","","","","","","Skin cancer, melanoma has become a precarious issue in European continents. It can be easily cured if diagnosed and excised at very early stages. In this article we have focused our research on the lesion extraction from melanoma sample using entropy-based approaches. Various ideal and general entropy functions viz Havrda, Shannon, Renyi, Kapur, Vajda respectively are investigated for the evaluation of randomness measure at each possible threshold in gray range. The results retrieved shows an outperforming behavior of general entropy measure of Havrda function as compared to any other existing entropy functions.","10.1109/INVENTIVE.2016.7823182","Benign; Entropy; Malignant; Melanoma; Segmentation; Threshold selection","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011081881&doi=10.1109%2fINVENTIVE.2016.7823182&partnerID=40&md5=0a0d8fb73d22fb2b5a110c85273cfb99"
"A study on automatic segmentation and classification of skin lesions in dermoscopic images","Al-Mansour E.A.; Jaffar A.","2016","1","1","0","0","0","First occurrence","0","","","","","","","Malignant Melanoma is one of the rare and the deadliest form of skin cancer if left untreated. Death rate due to this cancer is three times more than all other skin-related malignancies combined. Incidence rates of melanoma have been increasing, especially among young adults, but survival rates are high if detected early. There is a need for an automated system to assess a patient's risk of melanoma using digital dermoscopy, that is, a skin imaging technique widely used for pigmented skin lesion inspection. Although many automated and semi-automated methods are available to diagnose skin cancer but each has its own limitations and there is no final, state-of-the art technique to date which is able to be implemented in real scenario. This survey paper is based on techniques used to segment the skin cancer, analysis of their merits and demerits and their applications on advanced imaging techniques. © 2017 by IGI Global. All rights reserved.","10.4018/978-1-5225-0549-5.ch020","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014033047&doi=10.4018%2f978-1-5225-0549-5.ch020&partnerID=40&md5=5c549704b89215ba6dd9c660cef16885"
"Reticular pattern detection in dermoscopy: An approach using curvelet transform","Machado M.; Pereira J.; Fonseca-Pinto R.","2016","0","1","0","0","0","Unique","0","","","","","","","Introduction: Dermoscopy is a non-invasive in vivo imaging technique, used in dermatology in feature identification, among pigmented melanocytic neoplasms, from suspicious skin lesions. Often, in the skin exam is possible to ascertain markers, whose identification and proper characterization is difficult, even when it is used a magnifying lens and a source of light. Dermoscopic images are thus a challenging source of a wide range of digital features, frequently with clinical correlation. Among these markers, one of particular interest to diagnosis in skin evaluation is the reticular pattern. Methods: This paper presents a novel approach (avoiding pre-processing, e.g. segmentation and filtering) for reticular pattern detection in dermoscopic images, using texture spectral analysis. The proposed methodology involves a Curvelet Transform procedure to identify features. Results: Feature extraction is applied to identify a set of discriminant characteristics in the reticular pattern, and it is also employed in the automatic classification task. The results obtained are encouraging, presenting Sensitivity and Specificity of 82.35% and 76.79%, respectively. Conclusions: These results highlight the use of automatic classification, in the context of artificial intelligence, within a computer-aided diagnosis strategy, as a strong tool to help the human decision making task in clinical practice. Moreover, the results were obtained using images from three different sources, without previous lesion segmentation, achieving to a rapid, robust and low complexity methodology. These properties boost the presented approach to be easily used in clinical practice as an aid to the diagnostic process. © 2016, Sociedade Brasileira de Engenharia Biomedica. All rights reserved.","10.1590/2446-4740.00315","Curvelet transform; Dermoscopy; Melanoma; Pattern recognition; Reticular pattern","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982299385&doi=10.1590%2f2446-4740.00315&partnerID=40&md5=bf0a9c2ffb5804665bc59a12cc64deef"
"Classification of malignant melanoma and benign skin lesions: Implementation of automatic ABCD rule","Kasmi R.; Mokrani K.","2016","1","0","0","0","0","Unique","0","","","","","","","The ABCD (asymmetry, border irregularity, colour and dermoscopic structure) rule of dermoscopy is a scoring method used by dermatologists to quantify dermoscopy findings and effectively separate melanoma from benign lesions. Automatic detection of the ABCD features and separation of benign lesions from melanoma could enable earlier detection of melanoma. In this study, automatic ABCD scoring of dermoscopy lesions is implemented. Pre-processing enables automatic detection of hair using Gabor filters and lesion boundaries using geodesic active contours. Algorithms are implemented to extract the characteristics of ABCD attributes. Methods used here combine existing methods with novel methods to detect colour asymmetry and dermoscopic structures. To classify lesions as melanoma or benign nevus, the total dermoscopy score is calculated. The experimental results, using 200 dermoscopic images, where 80 are malignant melanomas and 120 benign lesions, show that the algorithm achieves 91.25% sensitivity of 91.25 and 95.83% specificity. This is comparable to the 92.8% sensitivity and 90.3% specificity reported for human implementation of the ABCD rule. The experimental results show that the extracted features can be used to build a promising classifier for melanoma detection. © The Institution of Engineering and Technology 2016.","10.1049/iet-ipr.2015.0385","","228","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969668334&doi=10.1049%2fiet-ipr.2015.0385&partnerID=40&md5=41b6ec43f1681f7fa7e95a7f284fac80"
"Biologically inspired skin lesion segmentation using a geodesic active contour technique","Kasmi R.; Mokrani K.; Rader R.K.; Cole J.G.; Stoecker W.V.","2016","1","1","0","0","0","Unique","0","","","","","","","Background/Purpose: Computer-aided diagnosis of skin cancer requires accurate lesion segmentation, which must overcome noise such as hair, skin color variations, and ambient light variability. Methods: A biologically inspired geodesic active contour (GAC) technique is used for lesion segmentation. The algorithm presented here employs automatic contour initialization close to the actual lesion boundary, overcoming the 'sticking' at minimum local energy spots caused by noise artifacts such as hair. The border is significantly smoothed to mimic natural lesions. In addition, features that mimic biological parameters include spectral image subtraction and removal of peninsulas and inlets. Multiple boundary choices borders are created by parameter options used at different steps. These choices can allow future improvement over the basic default border. Results: The basic GAC algorithm was tested on 100 images (30 melanomas and 70 benign lesions), yielding a median XOR border error of 6.7%, comparable to the median inter-dermatologist XOR border error (7.4%), and lower than the gradient vector flow snake median XOR error of 14.2% on the same image set. On a difficult low-contrast border set of 1238 images, which included 350 non-melanocytic lesions, a median XOR error of 23.9% is obtained. Conclusion: GAC techniques show promise in attaining the goal of automatic skin lesion segmentation. © 2016 John Wiley & Sons Ltd.","10.1111/srt.12252","Automatic; Contour evolution; Dermoscopy; Detection; Geodesic active contour; Image analysis; Level set; Melanoma; Segmentation","36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942362082&doi=10.1111%2fsrt.12252&partnerID=40&md5=66ff82316f67c32409f4347f181ca6f0"
"Development and clinical validation of a novel photography-based skin pigmentation evaluation system: a comparison with the calculated consensus of dermatologists","Cho M.; Lee D.-H.; Kim Y.; Koh W.; Chung J.H.; Kim H.C.; Kim S.","2016","1","1","0","0","0","Unique","0","","","","","","","Objective: Various cosmetics, medicines, and light and laser treatments have been increasingly developed to improve pigmentary skin alterations such as melasma, actinic lentigo and dyschromia. To determine the efficacy of these modalities in view of the changes in pigmentation, an objective and reliable device that has a comparable performance to that of physicians is required. We developed a novel photography-based skin pigmentation evaluation system and validated its accuracy and reliability with a newly proposed method. Methods: A novel photography-based system was developed that integrates a consistent photography setting and image processing diagnostic algorithms. To automatically detect areas of pigmentation, the diagnostic algorithms were applied to photographs, which were obtained from 31 female patients. To validate its performance in comparison with the physicians’ evaluation, five dermatologists independently evaluated the area of pigmentation. The clinical consensus area of pigmentation (CCAP) was calculated based on the consensus of five dermatologists’ to exclude subjectivity or bias, and it was compared with the pigmentation area determined by the system. Results: Forty-four photographs with pigmented areas were evaluated by the system and the physicians. In contrast to the individual physician assessments, CCAP reduced the error that occurred due to subjectivity and bias, particularly for areas with indistinct pigmentation, and it was set as the gold standard. The results from the system showed a mean accuracy of 92.1% and a standard deviation of 4.6% in comparison with CCAP. Conclusion: This pigmentation evaluation system can reproduce the physicians’ consensus, suggesting that this system can support the dermatologists’ objective evaluation of pigmentation. © 2015 Society of Cosmetic Scientists and the Société Française de Cosmétologie","10.1111/ics.12303","evaluation device; melanogenesis; pigmentation; skin repair/acne/rosacea/dandruff/striae; UV/VIS/Fluo/CD spectroscopy","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978284996&doi=10.1111%2fics.12303&partnerID=40&md5=073b7ae9fa88f4358640b6aaddae029a"
"Automatic melanoma detection via multi-scale lesion-biased representation and joint reverse classification","Bi L.; Kim J.; Ahn E.; Feng D.; Fulham M.","2016","0","1","0","0","0","Unique","0","","","","","","","Dermoscopy image as a non-invasive diagnosis technique plays an important role for early diagnosis of malignant melanoma. Even for experienced dermatologists, however, diagnosis by human vision can be subjective, inaccurate and non-reproducible. This is attributed to the challenging image characteristics including varying lesion sizes and their shapes, fuzzy lesion boundaries, different skin color types and presence of hair. To aid in the image interpretation, automatic classification of dermoscopy images have been shown to be a valuable aid in the clinical decision making. Existing methods however have problems in representing and differentiating skin lesions due to high degree of similarities between melanoma and non-melanoma images and large variations inherited from skin lesion images. To overcome these limitations, this study proposes a new automatic melanoma detection method for dermoscopy images via multi-scale lesion-biased representation (MLR) and joint reverse classification (JRC). Our proposed MLR representation enable us to represent skin lesions using multiple closely related histograms derived from different rotations and scales while traditional methods can only represent skin lesion using a single-scale histogram. The MLR representation was then used with JRC for melanoma detection. The proposed JRC model allows us to use a set of closely related histograms to derive additional information for melanoma detection, where existing methods mainly rely on histogram itself. Our method was evaluated on a public dataset of dermoscopy images, and we demonstrate superior classification performance compared to the current state-of-the-art methods. © 2016 IEEE.","10.1109/ISBI.2016.7493447","Classification; Dermoscopy; Melanoma","69","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978399498&doi=10.1109%2fISBI.2016.7493447&partnerID=40&md5=aaa7185ce01e03fbcbdc00b047ec324b"
"A New fuzzy level set method for lesion border detection in dermoscopy images","Shojaedini S.V.","2016","0","1","0","0","0","First occurrence","0","","","","","","","Accurate segmentation plays a vital role in automated analysis of dermoscopy images. A new method based on fuzzy level set method is introduced here for lesion detection in dermoscopy images. In this method, a hypothesis testing framework is defined first to separate lesions from skin and artifacts. Then the boundary of lesion is estimated by a decision function based on the level set energy minimization method which is driven by fuzzy connectedness concept. Performance is evaluated on real dermoscopy images which are captured from various lesions with different sizes and colors. Parameters for performance evaluation are presented and obtained results are compared with some other state-of-the-art lesion detection methods. Increased true positive rate in parallel with simultaneous decrease in false positive rate, Hammoude distance and Hausdorff distance confirm the effectiveness of proposed method for skin cancer detection. © 2015, IUPESM and Springer-Verlag Berlin Heidelberg.","10.1007/s12553-015-0119-x","Dermoscopy images; Fuzzy connectedness; Hypothesis testing; Lesion detection; Level set","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977072775&doi=10.1007%2fs12553-015-0119-x&partnerID=40&md5=768b137092f24a288cda4e3e6127aa25"
"Digital image processing: Clinical applications and challenges in cosmetics","Iakovidis D.K.","2016","0","1","0","0","0","Unique","0","","","","","","","Digital image processing and analysis of medical images can effectively support medical diagnosis with valuable tools including automatic detection, recognition segmentation and measurement of visible entities of interest. This paper provides an overview of related clinical applications with focus on the analysis of skin disorders, extending to the limitedly explored field of cosmetics. Innovative applications and challenges are identified with respect to tissue quality and ageing measurement, as well as cosmetic recommendation systems. The impacts of research towards this direction could extend beyond the cosmetics industry. © 2015 IEEE.","10.1109/COMET.2015.7449660","Clinical applications; Cosmetics; Image analysis; Image processing; Measurement; Recommender systems; Skin","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965060875&doi=10.1109%2fCOMET.2015.7449660&partnerID=40&md5=5564ab10ad6323af778d9feb87573c8b"
"Quantitative and rapid estimations of human sub-surface skin mass using ultra-high-resolution spectral domain optical coherence tomography","Kuo W.-C.; Kuo Y.-M.; Wen S.-Y.","2016","1","1","0","0","0","Unique","0","","","","","","","Non-invasive and quantitative estimations for the delineation of sub-surface tumor margins could greatly aid in the early detection and monitoring of the morphological appearances of tumor growth, ensure complete tumor excision without the unnecessary sacrifice of healthy tissue, and facilitate post-operative follow-up for recurrence. In this study, a high-speed, non-invasive, and ultra-high-resolution spectral domain optical coherence tomography (UHR-SDOCT) imaging platform was developed for the quantitative measurement of human sub-surface skin mass. With a proposed robust, semi-automatic analysis, the system can rapidly quantify lesion area and shape regularity by an en-face-oriented algorithm. Various sizes of nylon sutures embedded in pork skin were used first as a phantom to verify the accuracy of our algorithm, and then in vivo, feasibility was proven using benign human angiomas and pigmented nevi. Clinically, this is the first step towards an automated skin lesion measurement system. © 2016 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim.","10.1002/jbio.201400153","Optical coherence tomography; Quantitative measurement; Skin lesions","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924235640&doi=10.1002%2fjbio.201400153&partnerID=40&md5=a80541a5df129db42878b692b2783be9"
"Automated segmentation of skin lesions using seed points and scale-invariant semantic mathematic model","Khan Z.F.","2016","1","1","0","0","0","First occurrence","0","","","","","","","A color image-based segmentation method for segmenting skin lesions is proposed in this paper. This proposed methodology mainly includes two parts: First, a combination of scale-invariant and semantic mathematic model is utilized to classify different pixels. Second, a strategy based on skeleton corner point’s extraction is proposed in order to extract the seed points for the skin lesion image. By this method, the skin slices are processed in series automatically. As a result, the lesions present in the skin can be segmented clearly and accurately. The proposed algorithm is trained and tested for 360 skin slices in order to evaluate the accuracy of segmentation. Overall accuracy of the proposed method is compared with existing conventional techniques. An average missing pixel rate of 3.02% and faulting pixel rate or 2.36% has been obtained for segmenting the skin lesion images. © Springer India 2016.","10.1007/978-81-322-2671-0_21","Color image segmentation; Seed points; Semantic mathematic model; Skin lesion","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955237353&doi=10.1007%2f978-81-322-2671-0_21&partnerID=40&md5=6b7837fa5879a48e904f7f31eabdff38"
"Line fitting based segmentation and its application to skin image analysis","Jeon J.-H.; Lee J.-Y.; Bae J.-S.; Kim J.-O.","2016","1","1","0","0","0","Unique","0","","","","","","","As mobile devices are recently equipped with advanced image sensors, it is expected that they would make it possible to diagnose one's skin condition conveniently anywhere and anytime. For this application it is necessary to classify the skin features from a skin image accurately. Although two conventional thresholding methods Otsu and Kapur perform well in a range of applications, we found that they are inappropriate for the specific skin analysis application of our interest. Otsu poorly works for non-bi-modal distributions while Kapur shows poor performance for long-tailed distributions. So, we propose a new line-fitting based thresholding method to detect pigments and pores from a skin image where the image histogram is simply modeled by two lines. Experimental results show that the proposed method finds better threshold which leads to the most visually plausible detection, compared to Otsu and Kapur. © 2015 IEEE.","10.1109/ICCE-Berlin.2015.7391333","line-fitting; pigments; pores; segmentation; skin image","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977650825&doi=10.1109%2fICCE-Berlin.2015.7391333&partnerID=40&md5=ca9b74812f2733974c6a4a55ac8f13c7"
"On the geometric modulation of skin lesion growth: A mathematical model for melanoma","Mendes A.I.; Nogueira C.; Pereira J.; Fonseca-Pinto R.","2016","1","1","0","0","0","Unique","0","","","","","","","Introduction: Early detection of suspicious skin lesions is critical to prevent skin malignancies, particularly the melanoma, which is the most dangerous form of human skin cancer. In the last decade, image processing techniques have been an increasingly important tool for early detection and mathematical models play a relevant role in mapping the progression of lesions. Methods: This work presents an algorithm to describe the evolution of the border of the skin lesion based on two main measurable markers: the symmetry and the geometric growth path of the lesion. The proposed methodology involves two dermoscopic images of the same melanocytic lesion obtained at different moments in time. By applying a mathematical model based on planar linear transformations, measurable parameters related to symmetry and growth are extracted. Results: With this information one may compare the actual evolution in the lesion with the outcomes from the geometric model. First, this method was tested on predefined images whose growth was controlled and the symmetry known which were used for validation. Then the methodology was tested in real dermoscopic melanoma images in which the parameters of the mathematical model revealed symmetry and growth rates consistent with a typical melanoma behavior. Conclusions: The method developed proved to show very accurate information about the target growth markers (variation on the growth along the border, the deformation and the symmetry of the lesion trough the time). All the results, validated by the expected phantom outputs, were similar to the ones on the real images. © 2016, Sociedade Brasileira de Engenharia Biomedica. All rights reserved.","10.1590/2446-4740.02815","Dermoscopy; Digital image skin processing; Linear transformations; Melanoma; Segmentation","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964067289&doi=10.1590%2f2446-4740.02815&partnerID=40&md5=495d17d16cf275c2a87d89fc016ecade"
"Statistical image segmentation for the detection of skin lesion borders in UV fluorescence excitation","Ortega-Martinez A.; Padilla-Martinez J.P.; Franco W.","2016","1","1","0","0","0","Unique","0","","","","","","","The skin contains several fluorescent molecules or fluorophores that serve as markers of structure, function and composition. UV fluorescence excitation photography is a simple and effective way to image specific intrinsic fluorophores, such as the one ascribed to tryptophan which emits at a wavelength of 345 nm upon excitation at 295 nm, and is a marker of cellular proliferation. Earlier, we built a clinical UV photography system to image cellular proliferation. In some samples, the naturally low intensity of the fluorescence can make it difficult to separate the fluorescence of cells in higher proliferation states from background fluorescence and other imaging artifacts-like electronic noise. In this work, we describe a statistical image segmentation method to separate the fluorescence of interest. Statistical image segmentation is based on image averaging, background subtraction and pixel statistics. This method allows to better quantify the intensity and surface distributions of fluorescence, which in turn simplify the detection of borders. Using this method we delineated the borders of highly-proliferative skin conditions and diseases, in particular, allergic contact dermatitis, psoriatic lesions and basal cell carcinoma. Segmented images clearly define lesion borders. UV fluorescence excitation photography along with statistical image segmentation may serve as a quick and simple diagnostic tool for clinicians. © 2016 SPIE.","10.1117/12.2208741","Fluorescence; Image histogram; Image processing; Imaging; Tryptophan; UV","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978476483&doi=10.1117%2f12.2208741&partnerID=40&md5=85a4c450d37c7cf228c32917939db7d1"
"Search for resolution invariant wavelet features of melanoma learned by a limited ANN classifier","Surówka G.","2016","0","1","0","0","0","Unique","0","","","","","","","This article addresses the Computer Aided Diagnosis (CAD) of melanoma pigmented skin cancer. We present back-propagated Artificial Neural Network (ANN) classifiers discriminating dermoscopic skin lesion images into two classes: malignant melanoma and dysplastic nevus. Features used for our classification experiments are derived from wavelet decomposition coefficients of the image. Our research objective is i) to select the most efficient topology of the hidden layers and the network learning algorithm for full-size and downgraded image resolutions and, ii) to search for resolution-invariant topologies and learning methods. The analyzed classifiers should be fit to work on ARM-based hand-held devices, hence we take into account only limited learning setups.","10.4467/20838476SI.16.015.6196","ANN; CAD; Melanoma; Wavelets","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027884972&doi=10.4467%2f20838476SI.16.015.6196&partnerID=40&md5=8fa0a49cf6d43025ee02fc0575cff735"
"Skin lesion segmentation in clinical images using deep learning","Jafari M.H.; Karimi N.; Nasr-Esfahani E.; Samavi S.; Soroushmehr S.M.R.; Ward K.; Najarian K.","2016","1","1","0","0","0","First occurrence","0","","","","","","","Melanoma is the most aggressive form of skin cancer and is on rise. There exists a research trend for computerized analysis of suspicious skin lesions for malignancy using images captured by digital cameras. Analysis of these images is usually challenging due to existence of disturbing factors such as illumination variations and light reflections from skin surface. One important stage in diagnosis of melanoma is segmentation of lesion region from normal skin. In this paper, a method for accurate extraction of lesion region is proposed that is based on deep learning approaches. The input image, after being preprocessed to reduce noisy artifacts, is applied to a deep convolutional neural network (CNN). The CNN combines local and global contextual information and outputs a label for each pixel, producing a segmentation mask that shows the lesion region. This mask will be further refined by some post processing operations. The experimental results show that our proposed method can outperform the existing state-of-the-art algorithms in terms of segmentation accuracy. © 2016 IEEE.","10.1109/ICPR.2016.7899656","Convolutional neural network; Deep learning; Medical image segmentation; Melanoma; Skin cancer","165","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019110482&doi=10.1109%2fICPR.2016.7899656&partnerID=40&md5=9b21dae81374bde68ea9862d4dbbdd5f"
"Optical coherence tomography of actinic keratoses and basal cell carcinomas – differentiation by quantification of signal intensity and layer thickness","Schuh S.; Kaestle R.; Sattler E.C.; Welzel J.","2016","0","1","0","0","0","Unique","0","","","","","","","Background: Previous studies have shown that actinic keratoses (AKs) and basal cell carcinomas (BCCs) can be diagnosed by optical coherence tomography (OCT) based on morphological characteristics. There is a lack of systematic studies that give standardized information on signal intensity and layer thickness of AKs and BCCs. Objective: The aim of this study was to find out if AKs and BCCs can be objectively diagnosed through standardized measurement of signal intensity and layer thickness and to use OCT as a non-invasive objective method for the diagnosis and evaluation of AKs and BCCs. Additionally, tumour and skin layer thickness were investigated in correlation with histology. Methods: In this experimental study, 301 lesions (188 BCCs and 113 AKs) of 125 patients were clinically as well as dermoscopically diagnosed and investigated with OCT before therapy. Normal perilesional skin served as control. Results: It is possible to differentiate BCCs and AKs from normal skin in OCT due to the decrease of local signal intensity in affected skin layers in relation to adjacent healthy skin. In AKs, a strong thickness increase of the stratum corneum and epidermis compared to normal skin were observed. For the distinction between AKs and BCCs, a drop of signal intensity in the dermis of AKs towards BCCs and a thicker epidermis of AKs in contrast to BCCs were registered. All results are statistically highly significant (P < 0.0001). Besides, a strong correlation of tumour and skin layer thickness of BCCs and AKs in OCT with histology was found. Conclusion: Through standardized measurement of signal intensity and layer thickness, BCCs and AKs can be objectively diagnosed and distinguished from each other with OCT. This will further improve the use of OCT as a non-invasive objective method for the diagnosis and treatment monitoring of these diseases. © 2016 European Academy of Dermatology and Venereology","10.1111/jdv.13569","","29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987875516&doi=10.1111%2fjdv.13569&partnerID=40&md5=ea8833f8608ac2cd098ca11a0f841ed8"
"Detection of melanoma using distinct features","Satheesha T.Y.; Satyanarayana D.; Giriprasad M.N.; Nagesh K.N.","2016","0","1","0","0","0","First occurrence","0","","","","","","","Melanoma is one of the deadliest cancer to be treated as well to detect in initial phase. Here we take the skin lesion by ROI and then we take out features of it then it needs to be segmented whether the particular image is cancerous or not. If it is cancerous then classify the extracted features and discuss about type of stages. A novel 3D reconstruction algorithm from 2D dermoscopic images is proposed. The detection of 3D image shape and RGB are to be carried out. In this paper we have proposed this work for 3D depth parameter which will enhance the classification rate. © 2016 IEEE.","10.1109/ICBDSC.2016.7460367","feature extraction; melanoma; preprocessing; segmentation","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973520181&doi=10.1109%2fICBDSC.2016.7460367&partnerID=40&md5=1c34aad27e76f446042a23e07f38da3a"
"Skin lesion classification using fourier descriptors of lesion borders; [Lezyon Kenarlarinin Fourier Tanimlayicilari Kullanilarak Cilt Lezyonlarinin Siniflandirilmasi]","Albay E.; Kamaşak M.","2016","1","0","0","0","0","Unique","0","","","","","","","Between cancer types, Melanom is the one of the most deadliest form. Although, dermoscopy increased rate of diagnosis of the disease, most of the time detection of the disease depends on experience of physicist. There is great effort to diagnosis of the disease using computerized techniques. In this paper, for that purpose, we propose new method that uses fourier descriptors. After the segmentation of dermoscopic images, they are classified using extracted fourier descriptors of lesion border. © 2015 IEEE.","10.1109/TIPTEKNO.2015.7374547","artificial neural networks; classification; dermoscopy; fourier descriptors; melanoma","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964255571&doi=10.1109%2fTIPTEKNO.2015.7374547&partnerID=40&md5=d391b00f8716dcaaa6d3191659219743"
"Recognition of images of finger skin with application of histogram, image filtration and K-NN classifier","Glowacz A.; Glowacz Z.","2016","1","1","0","0","0","Unique","0","","","","","","","In this paper, non-invasive method of recognition of finger skin was proposed. A plan of study of images of finger skin was proposed. Researches were carried out for three kinds of images: 60 h after injury, 160 h after injury, 450 h after injury. Proposed technique of recognition used methods of signal processing: extraction of magenta color, calculation of histogram, image filtration, calculation of perimeter, and K-NN classifier. A pattern creation process was conducted using 15 training images of finger skin. In the identification process 60 test images were used. The advantage of the presented method is analysis of the finger skin using a smartphone. The proposed approach will help to diagnose pathologies of human skin. © 2015 Nałęcz Institute of Biocybernetics and Biomedical Engineering of the Polish Academy of Sciences. Published by Elsevier Sp. z o.o. All rights reserved.","10.1016/j.bbe.2015.12.005","Finger skin; Histogram; Image filtration; K-NN classifier; Recognition","46","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957848982&doi=10.1016%2fj.bbe.2015.12.005&partnerID=40&md5=ec26dd5a45996ed2f05b8bb5e10e443f"
"Spectral-spatial classification combined with diffusion theory based inverse modeling of hyperspectral images","Paluchowski L.A.; Bjorgan A.; Nordgaard H.B.; Randeberg L.L.","2016","0","1","0","0","0","Unique","0","","","","","","","Hyperspectral imagery opens a new perspective for biomedical diagnostics and tissue characterization. High spectral resolution can give insight into optical properties of the skin tissue. However, at the same time the amount of collected data represents a challenge when it comes to decomposition into clusters and extraction of useful diagnostic information. In this study spectral-spatial classification and inverse diffusion modeling were employed to hyperspectral images obtained from a porcine burn model using a hyperspectral push-broom camera. The implemented method takes advantage of spatial and spectral information simultaneously, and provides information about the average optical properties within each cluster. The implemented algorithm allows mapping spectral and spatial heterogeneity of the burn injury as well as dynamic changes of spectral properties within the burn area. The combination of statistical and physics informed tools allowed for initial separation of different burn wounds and further detailed characterization of the injuries in short post-injury time. © 2016 SPIE.","10.1117/12.2212163","burn injuries; image classification; inverse skin model; optical properties; reflectance spectroscopy; tissue optics","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973333089&doi=10.1117%2f12.2212163&partnerID=40&md5=7cc6d9c391378d2298fe7c4a55173f35"
"Sparse coding based skin lesion segmentation using dynamic rule-based refinement","Bozorgtabar B.; Abedini M.; Garnavi R.","2016","1","1","0","0","0","First occurrence","0","","","","","","","This paper proposes an unsupervised skin lesion segmentation method for dermoscopy images by exploiting the contextual information of skin image at the superpixel level. In particular, a Laplacian sparse coding is presented to evaluate the probabilities of the skin image pixels to delineate lesion border. Moreover, a new rule-based smoothing strategy is proposed as the lesion segmentation refinement procedure. Finally, a multi-scale superpixel segmentation of the skin image is provided to handle size variation of the lesion in order to improve the accuracy of the detected border. Experiments conducted on two datasets show the superiority of our proposed method over several state-of-the-art skin segmentation methods. © Springer International Publishing AG 2016.","10.1007/978-3-319-47157-0_31","Dynamic rule-based refinement; Laplacian sparse coding; Superpixel-based segmentation","46","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992497945&doi=10.1007%2f978-3-319-47157-0_31&partnerID=40&md5=8efa96fdcbfe0270a3db62b1f065434e"
"Classification of melanoma presence and thickness based on computational image analysis","Sánchez-Monedero J.; Sáez A.; Pérez-Ortiz M.; Gutiérrez P.A.; Hervás-Martínez C.","2016","0","1","0","0","0","First occurrence","0","","","","","","","Melanoma is a type of cancer that occurs on the skin. Only in the US, 50,000–100,000 patients are yearly diagnosed with melanoma. Five year survival rate highly depends on early detection, varying between 99 % and 15 % depending on the melanoma stage. Melanoma is typically identified with a visual inspection and lately confirmed and classified by a biopsy. In this work, we propose a hybrid system combining features which describe melanoma images together with machine learning models that learn to distinguish melanoma lesions. Although previous works distinguish melanoma and non-melanoma images, those works focus only in the binary case. Opposed to this, we propose to consider finer classification levels within a five class learning problem. We evaluate the performance of several nominal and ordinal classifiers using four performance metrics to provide highlights of several aspects of classification performance, achieving promising results. © Springer International Publishing Switzerland 2016.","10.1007/978-3-319-32034-2_36","Computer vision; Dermoscopic image; Feature extraction; Imbalanced classification; Machine learning; Melanoma; Multi-class; Ordinal classification","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964047348&doi=10.1007%2f978-3-319-32034-2_36&partnerID=40&md5=b261632185eccb4789dc32a8ad8f5764"
"Computer Based Melanocytic and Nevus Image Enhancement and Segmentation","Jamil U.; Akram M.U.; Khalid S.; Abbas S.; Saleem K.","2016","0","1","0","0","0","Unique","0","","","","","","","Digital dermoscopy aids dermatologists in monitoring potentially cancerous skin lesions. Melanoma is the 5th common form of skin cancer that is rare but the most dangerous. Melanoma is curable if it is detected at an early stage. Automated segmentation of cancerous lesion from normal skin is the most critical yet tricky part in computerized lesion detection and classification. The effectiveness and accuracy of lesion classification are critically dependent on the quality of lesion segmentation. In this paper, we have proposed a novel approach that can automatically preprocess the image and then segment the lesion. The system filters unwanted artifacts including hairs, gel, bubbles, and specular reflection. A novel approach is presented using the concept of wavelets for detection and inpainting the hairs present in the cancer images. The contrast of lesion with the skin is enhanced using adaptive sigmoidal function that takes care of the localized intensity distribution within a given lesion's images. We then present a segmentation approach to precisely segment the lesion from the background. The proposed approach is tested on the European database of dermoscopic images. Results are compared with the competitors to demonstrate the superiority of the suggested approach. © 2016 Uzma Jamil et al.","10.1155/2016/2082589","","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991320470&doi=10.1155%2f2016%2f2082589&partnerID=40&md5=1fc66b095715f93210a3692ac255ef49"
"Melanoma-nevus discrimination based on image statistics in few spectral channels","Lorencs A.; Sinica-Sinavskis J.; Jakovels D.; Mednieks I.","2016","0","1","0","0","0","Unique","0","","","","","","","The purpose of this paper is to offer a method for discrimination of cutaneous melanoma from benign nevus, founded on analysis of skin lesion image. At the core of method is calculation of mean and standard deviation of pixel optical density values for a few narrow spectral bands. Calculated values are compared with discriminating thresholds derived from a set of images of benign nevi and melanomas with known diagnosis. Classification is done applying weighted majority rule to results of thresholding. Verification against the available multispectral images of 32 melanomas and 94 benign nevi has shown that the method using three spectral bands provided zero false negative and four false positive melanoma detections. The proposed classifier is characterized by high sensitivity and specificity concerning statistical point estimates whereas its possible technical implementation is fairly simple. The proposed method may be instrumental for designing low cost diagnostic equipment to be used in primary care that is important for early detection of cutaneous melanoma.","10.5755/j01.eie.22.2.12173","Biomedical optical imaging; Image classification; Melanoma detection; Multispectral imaging","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963815410&doi=10.5755%2fj01.eie.22.2.12173&partnerID=40&md5=d6c100f61bfc8638c8d4275b758f0c47"
"A benchmark for automatic visual classification of clinical skin disease images","Sun X.; Yang J.; Sun M.; Wang K.","2016","1","1","0","0","0","First occurrence","0","","","","","","","Skin disease is one of the most common human illnesses. It pervades all cultures, occurs at all ages, and affects between 30% and 70% of individuals, with even higher rates in at-risk. However, diagnosis of skin diseases by observing is a very difficult job for both doctors and patients, where an intelligent system can be helpful. In this paper, we mainly introduce a benchmark dataset for clinical skin diseases to address this problem. To the best of our knowledge, this dataset is currently the largest for visual recognition of skin diseases. It contains 6,584 images from 198 classes, varying according to scale, color, shape and structure. We hope that this benchmark dataset will encourage further research on visual skin disease classification. Moreover, the recent successes of many computer vision related tasks are due to the adoption of Convolutional Neural Networks(CNNs), we also perform extensive analyses on this dataset using the state of the art methods including CNNs. © Springer International Publishing AG 2016.","10.1007/978-3-319-46466-4_13","CNNs; Computer aided diagnosis; Hand-crafted features; Image classification; Skin disease image","127","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990036937&doi=10.1007%2f978-3-319-46466-4_13&partnerID=40&md5=1d2d4e6d12c5ea20767635c80b305d81"
"Automatic Classification of Specific Melanocytic Lesions Using Artificial Intelligence","Jaworek-Korjakowska J.; Kłeczek P.","2016","0","1","0","0","0","Unique","0","","","","","","","Background. Given its propensity to metastasize, and lack of effective therapies for most patients with advanced disease, early detection of melanoma is a clinical imperative. Different computer-aided diagnosis (CAD) systems have been proposed to increase the specificity and sensitivity of melanoma detection. Although such computer programs are developed for different diagnostic algorithms, to the best of our knowledge, a system to classify different melanocytic lesions has not been proposed yet. Method. In this research we present a new approach to the classification of melanocytic lesions. This work is focused not only on categorization of skin lesions as benign or malignant but also on specifying the exact type of a skin lesion including melanoma, Clark nevus, Spitz/Reed nevus, and blue nevus. The proposed automatic algorithm contains the following steps: image enhancement, lesion segmentation, feature extraction, and selection as well as classification. Results. The algorithm has been tested on 300 dermoscopic images and achieved accuracy of 92% indicating that the proposed approach classified most of the melanocytic lesions correctly. Conclusions. A proposed system can not only help to precisely diagnose the type of the skin mole but also decrease the amount of biopsies and reduce the morbidity related to skin lesion excision. © 2016 Joanna Jaworek-Korjakowska and Paweł Kłeczek.","10.1155/2016/8934242","","51","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958568480&doi=10.1155%2f2016%2f8934242&partnerID=40&md5=a28be8c6bcb2800acbd5da48be00a720"
"Breast cancer detection using RBF neural network","Kanojia M.G.; Abraham S.","2016","0","1","0","0","0","First occurrence","0","","","","","","","Breast cancer is the most frequently diagnosed non-skin cancer and the leading cause of cancer-deaths among women. With the advances in digital image processing techniques, it is envisaged that Computer aided diagnosis (CAD) systems can be devised to claim results at par with that of a histopathologist. The inherent assumption of this paper is that image-processing techniques and RBFN can be used to detect malignancy in histopathological images. The proposed work gives a wholesome, complete and automated detection of malignancy using both image processing techniques and RBFN. This is in contrast with other works, which either focus on image processing processes or classification based on online data, but not both. © 2016 IEEE.","10.1109/IC3I.2016.7917990","Image Processing; Neural Network; RBFN","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019992386&doi=10.1109%2fIC3I.2016.7917990&partnerID=40&md5=e6a230a8b1b5dbf8996ae7ede19fef09"
"Multigrid level-set segmentation of high-frequency 3D ultrasound images using the Hellinger distance","Sciolla B.; Delachartre P.; Cowell L.; Dambry T.; Guibert B.","2015","0","1","0","0","0","First occurrence","0","","","","","","","We propose a multigrid level-set segmentation algorithm for the segmentation of 3D high-frequency ultrasound images. Target applications include the quantitative analysis of lesions or normal structures within cutaneous and superficial subcutaneous tissues. The method is based on an a non-parametric region-based cost function, the Hellinger distance, which is related to the Bhattacharyya coefficient. The choice of this as a cost function allows the discrimination of different tissues using the statistics of the signal. Unlike other methods, it is also applicable when tissues are heterogenous. Moreover, the choice of a nonparametric method lends itself to a multigrid approach, which allows significant gains of speed, a critical property for 3D images. We show examples of segmentation of tumors and dermis in both realistic simulated images and clinical images from the Dermcup 25MHz skin probe (Atys Medical). © 2015 IEEE.","10.1109/ISPA.2015.7306052","","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978513169&doi=10.1109%2fISPA.2015.7306052&partnerID=40&md5=e42e1501ee5995138d0f346c0739bfba"
"Skin lesion segmentation using the D-S evidence theory based on the FCM using feature parameters","Trabelsi O.; Tlig L.; Sayadi M.; Fnaiech F.","2015","1","1","0","0","0","First occurrence","0","","","","","","","Lesion segmentation is an important step in diagnostic of skin lesion images. In this paper, to improve the segmentation of the skin color image (RGB), we apply the Fuzzy-C-Means method based on feature parameters in each color component (R, G and B) and we use the Dempster-Shafer evidence theory method to merge the results and to have the final segmentation result. In this work, the proposed technique was compared with the FCM based on feature applying in gray level skin image and the experiments show the performance of the proposed technique. © 2015 IEEE.","10.1109/SSD.2015.7348131","Color Segmentation; D-S evidence theory; Decision fusion; FCM; Feature parameters; Skin Segmentation","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962627907&doi=10.1109%2fSSD.2015.7348131&partnerID=40&md5=a55954c2ed47344538a05a6d3c29693e"
"Skin wound healing with chitosan thin films containing supported silver nanospheres","Ojeda-Martínez M.L.; Yáñez-Sánchez I.; Velásquez-Ordoñez C.; Martínez-Palomar M.M.; Álvarez-Rodríguez A.; Garcia-Sánchez M.A.; Rojas-González F.; Gálvez-Gastélum F.J.","2015","1","1","0","0","0","Unique","0","","","","","","","Dermal wound healing involves complex histo-molecular events aimed to repair the discontinuity of the epithelium. Employing nanometric silver particles provides an efficient antimicrobial effect for several dermal infections. The aim is to elucidate imminent advantages of silver nanoparticles, such as the possibility of modulating the epithelial cell repair process. Through the nanostructural implementation of chitosan thin films supporting silver nanoparticles, it was feasible to evaluate in vivo the efficacy and evolution of dermal recuperation after surgical damage. The characterization of chitosan silver nanoparticle films was performed by UV-visible spectra and Fourier transform infrared spectroscopy, X-ray diffraction, and high-resolution electron microscopy. An important dermal healing was accomplished in animals that were treated with chitosan films supporting silver nanoparticles, as confirmed by a histopathological analysis of the skin after 12 days of treatment. The developed chitosan thin film supporting an optimized amount of silver nanoparticles could be employed to treat diseases related to wound healing. © SAGE Publications.","10.1177/0883911515590495","Ag nanoparticles; cell proliferation; chitosan; collagen; extracellular matrix; fibroblast; reepithelialization; skin wound healing","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944049848&doi=10.1177%2f0883911515590495&partnerID=40&md5=2a0deb00430a1164f96f3398143b5df5"
"A combined segmentation approach for melanoma skin cancer diagnosis","Sujitha S.; Priya M.L.; Premaladha J.; Ravichandran K.S.","2015","1","1","0","0","0","First occurrence","0","","","","","","","This paper illustrates the methodology for melanoma diagnosis, a deadly skin cancer using computer aided image processing techniques. Here, the combination of Median filtering and Karhunen-Loeve transform are used in preprocessing part and also a combination of Active contours and Watershed Transformation algorithms are used in Segmentation process. When this combined method is applied on skin lesion images, the problems like over smoothing and over segmentation were solved. © 2015 IEEE.","10.1109/NCCCIS.2015.7295900","Active cont ours; image processing; Karhunen-Loeve transform; median filtering; Segmentation; Watershed transform","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961317234&doi=10.1109%2fNCCCIS.2015.7295900&partnerID=40&md5=3b3f4db3d941219c92be2a46688f2df3"
"Methodology for diagnosing of skin cancer on images of dermatologic spots by spectral analysis","Guerra-Rosas E.; Álvarez-Borrego J.","2015","1","1","0","0","0","Unique","0","","","","","","","In this paper a new methodology for the diagnosing of skin cancer on images of dermatologic spots using image processing is presented. Currently skin cancer is one of the most frequent diseases in humans. This methodology is based on Fourier spectral analysis by using filters such as the classic, inverse and k-law nonlinear. The sample images were obtained by a medical specialist and a new spectral technique is developed to obtain a quantitative measurement of the complex pattern found in cancerous skin spots. Finally a spectral index is calculated to obtain a range of spectral indices defined for skin cancer. Our results show a confidence level of 95.4%. © 2015 Optical Society of America.","10.1364/BOE.6.003876","","23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948740477&doi=10.1364%2fBOE.6.003876&partnerID=40&md5=fc4a48805d767dba92ffa95c3f86248d"
"Color and texture influence on computer-aided diagnosis of dermatological ulcers","Bedo M.V.N.; Santos L.F.D.; Oliveira W.D.; Blanco G.; Traina A.J.M.; Frade M.A.; Azevedo-Marques P.M.; Junior C.T.","2015","0","1","0","0","0","Unique","0","","","","","","","This study presents an analysis of classification techniques for Computer-Aided Diagnosis (CAD) regarding ulcerated lesions. We focus on determining influence of both color and texture in the automated image classification and its implication. To do so, we assayed a dataset of dermatological ulcers containing five variations in terms of tissue composition of lesion skin: granulation (red), fibrin (yellow), callous (white), necrotic (black), and a mix of the previous variations (mixed). Every image was previously labelled by experts regarding this red-yellow-black-white-mixed model. We employed specially designed color and texture extractors to represent the dataset images, namely: Color Layout, Color Structure, Scalable Color, Edge Histogram, Haralick, and Texture-Spectrum. The first three are color feature extractors and the last three are texture extractors. Following, we employed the Symmetrica Uncert Attribute Eval method to determine the features suitable for image classification. We tested a set of classifiers that follows distinct paradigms over the selected features, achieving an accuracy ratio of up to 77% in terms of images correctly classified, with the area under the receiver operating characteristic (ROC) curve up to 0.84. The classification performance and the selected features enabled us to determine that texture features were more predominant than color in the entire classification process. © 2015 IEEE.","10.1109/CBMS.2015.33","Computer-Aided Diagnosis; Dermatological Ulcers; Feature Selection; Image Classification","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944254368&doi=10.1109%2fCBMS.2015.33&partnerID=40&md5=868053a6c18882a4fd62f4c0480aea08"
"Adaptive segmentation based on multi-classification model for dermoscopy images","Xie F.; Wu Y.; Li Y.; Jiang Z.; Meng R.","2015","0","1","0","0","0","First occurrence","0","","","","","","","Segmentation accuracy of dermoscopy images is important in the computer-aided diagnosis of skin cancer and a wide variety of segmentation methods for dermoscopy images have been developed. Considering that each method has its strengths and weaknesses, a novel adaptive segmentation framework based on multi-classification model is proposed for dermoscopy images. Firstly, five patterns of images are summarized according to the factors influencing segmentation. Then the matching relation is established between each image pattern and its optimal segmentationmethod. Next, the given image is classified into one of the five patterns by the multi-classification model based on BP neural network. Finally, the optimal segmentation method for this image is selected according to the matching relation, and then the image is effectively segmented. Experiments show that the proposed method delivers better accuracy and more robust segmentation results compared with the other seven state-of-the-art methods. © 2015, Higher Education Press and Springer-Verlag Berlin Heidelberg.","10.1007/s11704-015-4391-8","adaptive segmentation; dermoscopy image; feature extraction; pattern classification","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942363968&doi=10.1007%2fs11704-015-4391-8&partnerID=40&md5=0deca245570332d2383b38c621f5b478"
"Characterizing sclerotic skin stiffness with Acoustic Radiation Force Impulse (ARFI) and Shear Wave Elasticity Imaging (SWEI)","Lee S.Y.; Cardones A.R.; Nightingale K.; Palmeri M.","2015","1","1","0","0","0","Unique","0","","","","","","","Sclerotic skin diseases are associated with inflammation and fibrosis in the dermis, and these changes in collagen content with disease progression make this pathology amenable to being characterized with Acoustic Radiation Force Impulse (ARFI) and Shear Wave Elasticity Imaging (SWEI) methods. We characterized skin stiffness in healthy individuals at repeated three month intervals and compared sclerotic to healthy skin stiffness. ARFI and SWEI were implemented using a Siemens 14L5 linear array on an ACUSON S2000™ scanner. A single dermatologist performed all imaging in twenty-two patients. Normal and sclerotic skin stiffnesses were characterized by (1) mean ARFI displacement magnitude, and (2) group shear wave speed estimated using a Radon sum of shear wave velocity data. Imaging was performed at different anatomic sites, including the upper and lower back, arm, forearm, abdomen, thigh and calf. Five repeat data acquisitions were performed in each anatomic location. ARFI displacement and SWEI shear wave speeds were reconstructed in 96% of all acquisitions when the region of interest was exclusively contained in the dermis. Overall, ARFI and SWEI metrics showed no significant difference between contralateral imaging locations across different anatomic sites in healthy skin (p < 0.05). Mean shear wave speeds were >200% greater in sclerotic lesions than in contralateral healthy skin in patients with graft-versus-host disease (GVHD) (p < 0.01), and 25% greater in patients with morphea. ARFI displacements exhibited greater variability than shear wave speed in characterizing sclerotic skin, showing a 61% decrease compared to healthy skin in GVHD patients (p < 0.05) and a 19% decrease in morphea patients (p < 0.05). ARFI and SWEI are able differentiate sclerotic skin lesions from healthy skin, and studies are underway to evaluate their utility in longitudinally-monitoring disease progression and response to therapy. Additional study details, data and conclusions can be found in the full-length manuscript describing this work [1]. © 2015 IEEE.","10.1109/ULTSYM.2015.0098","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961989784&doi=10.1109%2fULTSYM.2015.0098&partnerID=40&md5=6b92c1a6e60ddd5d1671e8fe9e3ef204"
"Melanoma recognition using extended set of descriptors and classifiers","Kruk M.; Świderski B.; Osowski S.; Kurek J.; Słowińska M.; Walecka I.","2015","0","1","0","0","0","First occurrence","0","","","","","","","The paper presents a novel method of melanoma recognition on the basis of dermoscopic images. We use color images of skin lesions, advanced image processing, and different classifiers to distinguish melanoma from the other non-melanoma lesions. Different families of descriptors are used for generation of the image diagnostic features for final pattern recognition. To increase the efficiency of the system, we apply different selection procedures to find the best set of features and different solutions of classifier. The numerical results concerning the accuracy of the proposed recognition system have confirmed good accuracy of the proposed method and high sensitivity in melanoma recognition. © 2015, Kruk et al.","10.1186/s13640-015-0099-9","Diagnostic features; Melanoma recognition; Random forest; SVM","43","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949985820&doi=10.1186%2fs13640-015-0099-9&partnerID=40&md5=780e8b4390afa972a11daf04eeb36dd2"
"Automated saliency-based lesion segmentation in dermoscopic images","Ahn E.; Bi L.; Jung Y.H.; Kim J.; Li C.; Fulham M.; Feng D.D.","2015","0","1","0","0","0","First occurrence","0","","","","","","","The segmentation of skin lesions in dermoscopic images is considered as one of the most important steps in computer-aided diagnosis (CAD) for automated melanoma diagnosis. Existing methods, however, have problems with over-segmentation and do not perform well when the contrast between the lesion and its surrounding skin is low. Hence, in this study, we propose a new automated saliency-based skin lesion segmentation (SSLS) that we designed to exploit the inherent properties of dermoscopic images, which have a focal central region and subtle contrast discrimination with the surrounding regions. The proposed method was evaluated on a public dataset of lesional dermoscopic images and was compared to established methods for lesion segmentation that included adaptive thresholding, Chan-based level set and seeded region growing. Our results show that SSLS outperformed the other methods in regard to accuracy and robustness, in particular, for difficult cases. © 2015 IEEE.","10.1109/EMBC.2015.7319025","","53","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953306575&doi=10.1109%2fEMBC.2015.7319025&partnerID=40&md5=60ad58d90dfe47d2fdf26c0ea0be3faa"
"Smartphone-based wound assessment system for patients with diabetes","Wang L.; Pedersen P.C.; Strong D.M.; Tulu B.; Agu E.; Ignotz R.","2015","0","1","0","0","0","Unique","0","","","","","","","Diabetic foot ulcers represent a significant health issue. Currently, clinicians and nurses mainly base their wound assessment on visual examination of wound size and healing status, while the patients themselves seldom have an opportunity to play an active role. Hence, a more quantitative and cost-effective examination method that enables the patients and their caregivers to take a more active role in daily wound care potentially can accelerate wound healing, save travel cost and reduce healthcare expenses. Considering the prevalence of smartphones with a high-resolution digital camera, assessing wounds by analyzing images of chronic foot ulcers is an attractive option. In this paper, we propose a novel wound image analysis system implemented solely on the Android smartphone. The wound image is captured by the camera on the smartphone with the assistance of an image capture box. After that, the smartphone performs wound segmentation by applying the accelerated mean-shift algorithm. Specifically, the outline of the foot is determined based on skin color, and the wound boundary is found using a simple connected region detection method. Within the wound boundary, the healing status is next assessed based on red-yellow-black color evaluation model. Moreover, the healing status is quantitatively assessed, based on trend analysis of time records for a given patient. Experimental results on wound images collected in UMASS - Memorial Health Center Wound Clinic (Worcester, MA) following an Institutional Review Board approved protocol show that our system can be efficiently used to analyze the wound healing status with promising accuracy. © 2014 IEEE.","10.1109/TBME.2014.2358632","Android-based smartphone; mean shift; patients with diabetes; wound analysis","104","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921442182&doi=10.1109%2fTBME.2014.2358632&partnerID=40&md5=26c67e00ddf41416ce541103bf814641"
"A web-based application for dermoscopic measurements and learning","Di Leo G.; Liguori C.; Paolillo A.; Sommella P.","2015","0","1","0","0","0","First occurrence","0","","","","","","","Image processing techniques have been long proposed for automatic analysis of skin lesions in the field of early detection of melanoma. Nevertheless, Computer Aided Systems are not yet able to outperform the diagnostic accuracy of expert dermatologists. They could instead reveal very useful in providing with a second opinion and improving the detection results from physicians with short clinical experience. The paper introduces an original web-based application for the automatic detection of dermoscopic structures within pigmented lesions and the support to novel dermatologists. It is able to receive and store digital images captured by digital cameras and smartphones equipped with dermoscopy, measure morphological and chromatic parameters, and take into account the measurement uncertainty to finally provide a clinical decision according to the diagnostic method 7-Point Checklist. © 2015 IEEE.","10.1109/MeMeA.2015.7145213","Biomedical image processing; distributed measurement systems; e-learning; uncertainty management","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939519857&doi=10.1109%2fMeMeA.2015.7145213&partnerID=40&md5=89c75700763c4f7358c50af65007c546"
"Efficient gabor filter using vedic mathematic for high speed convolution in skin cancer detection","Jain S.; Jagtap V.; Pise N.","2015","1","1","0","0","0","First occurrence","0","","","","","","","Normal moles are mostly small brown in color that are spots or growths on the skin that is by birth or emerge in the first few decades of life in almost everyone. Skin cancer most often appears as moles. Seldom people are aware about the skin cancer. If detected at early stages then it can be cured. We propose an improved design of Gabon filter which is combined with Vedic algorithm (Urdhva Triyagbhyam) to give faster convolution result. The exertion has proved the efficiency of Urdhva Triyagbhyam which is the Vedic method of multiplication that enables parallel generation of intermediary products that eliminates unwanted multiplication steps with zeros and scaled to higher bit. In this paper we employ the filter design appropriate for detecting the early stages of skin cancer using textural properties of skin. © 2015 IEEE.","10.1109/ICCUBEA.2015.160","Feature extraction; Gabor filter; Image segmentation; K-means; Mole; Skin cancer; Urdhva triyagbhyam; Vedic mathematics","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943237394&doi=10.1109%2fICCUBEA.2015.160&partnerID=40&md5=01ab838269c29fc0f6c7839538d3b5e0"
"Medical image analysis for cancer management in natural computing framework","Mitra S.; Uma Shankar B.","2015","0","1","0","0","0","Unique","0","","","","","","","Natural computing, through its repertoire of nature-inspired strategies, is playing a major role in the development of intelligent decision-making systems. The objective is to provide flexible, application-oriented solutions to current medical image analysis problems. It encompasses fuzzy sets, neural networks, genetic algorithms, rough sets, swarm intelligence, and a host of other paradigms, mimicking biological and physical processes from nature. Radiographic imaging modalities, like computed tomography (CT), positron emission tomography (PET), and magnetic resonance imaging (MRI), help in providing improved diagnosis, prognosis and treatment planning for cancer. This survey highlights the role of natural computing, in efficiently analyzing radiographic medical images, for improved tumor management. We also provide a categorization of the segmentation, feature extraction and selection methods, based on different natural computing technologies, with reference to the application-involving malignancy of the brain, breast, prostate, skin, lung, and liver. © 2015 Elsevier Inc. All rights reserved.","10.1016/j.ins.2015.02.015","Evolutionary algorithms biomedical imaging; Feature selection; Quantitative imaging; Radiomics; Segmentation","71","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926196742&doi=10.1016%2fj.ins.2015.02.015&partnerID=40&md5=56c546dc15180d169518a4ffe2ecd44c"
"A comparison of feature sets for an automated skin lesion analysis system for melanoma early detection and prevention","Abuzaghleh O.; Faezipour M.; Barkana B.D.","2015","1","1","0","0","0","First occurrence","0","","","","","","","One in five Americans will develop skin cancer in their lifetime, and on average, one American dies from skin cancer every hour. Melanoma spreads through metastasis, and can often be fatal. Statistical evidence has revealed that the majority of deaths resulting from skin cancer are as a result of melanoma. Further investigations have shown that the survival rates in patients depend on the stage of the cancer at the time it is first diagnosed; early detection and intervention of melanoma indicates higher chances of cure. Clinical diagnosis and prognosis of melanoma are challenging since the processes are prone to misdiagnosis and inaccuracies due to doctors' subjectivity. Malignant melanomas are asymmetrical, have irregular borders, notched edges, and color variations, so analyzing the shape, color, and texture of the skin lesion is important for melanoma early detection and prevention. This paper proposes the two major components of a noninvasive real-time automated skin lesion analysis system for melanoma early detection and prevention. The first component is a real-time alert to help users prevent skin burn caused by sunlight; a novel equation to compute the time for skin to burn is thereby introduced. The second component is an automated image analysis module which contains image acquisition, hair detection and exclusion, lesion segmentation, feature extraction, and classification. The proposed system uses PH2 Dermoscopy image database from Pedro Hispano Hospital for development and testing purposes. The image database contains a total of 200 dermoscopy images of lesions, including benign, atypical, and melanoma cases. A comparison of the performance of all feature sets is presented in this paper in order to determine what feature sets provide the best classification results. © 2015 IEEE.","10.1109/LISAT.2015.7160183","image segmentation; melanoma; skin cancer","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941248735&doi=10.1109%2fLISAT.2015.7160183&partnerID=40&md5=e2ecc29978ae654d2cd994cddb3e8e2d"
"Operative standards for cancer surgery","Nelson H.D.; Hunt K.K.","2015","0","1","0","0","0","Unique","0","","","","","","","Presented by the American College of Surgeons and the Alliance for Clinical Trials in Oncology, the first comprehensive, evidence-based examination of cancer surgery techniques as standards distills the well-defined protocols and techniques that are critical to achieve optimal outcomes in a cancer operation. This unique, one of a kind collaboration between the American College of Surgeons and the Alliance for Clinical Trials in Oncology focuses on best practices and state-of-the-art methodologies. Operative Standards for Cancer Surgery clearly describes the surgical activities that occur between skin incision and skin closure that directly affect cancer outcomes. © 2015 American College of Surgeons. All rights reserved.","","","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973110402&partnerID=40&md5=d0a8ccca59ae96e5f1d00ade062fa232"
"A new risk assessment methodology for dermoscopic skin lesion images","Vasconcelos M.J.M.; Rosado L.; Ferreira M.","2015","1","1","0","0","0","First occurrence","0","","","","","","","The incidence of melanoma has been increasing steadily over the past few decades throughout most of the world. The development of computer diagnosis systems that use dermoscopic images can be of great help for the diagnosis of melanoma. This paper presents an image processing and analysis methodology using supervised classification to independently assess the Asymmetry, Border, Color and Dermoscopic Structures score according to the ABCD rule, and the corresponding Total Dermatoscopy Score of a skin lesion using dermoscopic images. A dermoscopic image dataset was used to test the proposed approach, annotated by dermatology specialists according to the ABCD rule and being the confirmed malignant melanomas also identified. Accuracy rates of 74.0%, 78.3% and 53.5% were achieved for the estimation of the ABCD score of the Asymmetry, Border and Color criterion, as well as accuracy rates for the presence of the five Differential Structures of 72.4%, 68.5%, 74.0%, 74.0% and 85.8% for dots, globules, streaks homogeneous areas and pigment network. Moreover, sensitivity and specificity rates of 93.3% and 69.1% were achieved for the classification of the dermoscopic images as melanoma or non-melanoma. © 2015 IEEE.","10.1109/MeMeA.2015.7145268","Computer Aided Diagnosis Systems; Dermoscopic images; Image analysis; Melanoma","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939559681&doi=10.1109%2fMeMeA.2015.7145268&partnerID=40&md5=1ddba3c0d4e6880c572dc7b481ffcbf5"
"Automatic Kaposi's sarcoma detection using texture distinctiveness","Haseena S.; Renganayaki S.","2015","0","1","0","0","0","First occurrence","0","","","","","","","There is a growing emphasis on skin cancer diagnosis and Kaposi's sarcoma has recently received increasing attention. Kaposi's sarcoma is one form of skin cancer. The time and costs required for medical experts to screen all patients for Kaposi's sarcoma are prohibitively expensive. Dermatologists need an automatic diagnosis system to assess a patient's risk of Kaposi's sarcoma without using special or costly equipment. One challenge in implementing such a system is locating the skin lesion. We propose Texture Distinctiveness Lesion Segmentation Algorithm (TDS-KS) to automatically locate skin lesions from the photograph. TDS-KS algorithm consists of two main steps. First a set of representative texture distributions are learned from the input skin lesion image and texture distinctiveness metric is calculated for each distribution. Then a texture-based segmentation algorithm classifies regions the input image as normal skin or lesion based on the occurrence of representative texture distributions. The input images are taken from dermquest database which has images of different skin diseases. © 2015 IEEE.","10.1109/ICCPCT.2015.7159349","Kaposi's sarcoma; Segmentation; Skin Cancer; Texture","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945975477&doi=10.1109%2fICCPCT.2015.7159349&partnerID=40&md5=73e4a5e0a0fa98a8a6fb1537f7408210"
"Skin image illumination modeling and chromophore identification for melanoma diagnosis","Liu Z.; Zerubia J.","2015","1","1","0","0","0","Unique","0","","","","","","","The presence of illumination variation in dermatological images has a negative impact on the automatic detection and analysis of cutaneous lesions. This paper proposes a new illumination modeling and chromophore identification method to correct lighting variation in skin lesion images, as well as to extract melanin and hemoglobin concentrations of human skin, based on an adaptive bilateral decomposition and a weighted polynomial curve fitting, with the knowledge of a multi-layered skin model. Different from state-of-the-art approaches based on the Lambert law, the proposed method, considering both specular reflection and diffuse reflection of the skin, enables us to address highlight and strong shading effects usually existing in skin color images captured in an uncontrolled environment. The derived melanin and hemoglobin indices, directly relating to the pathological tissue conditions, tend to be less influenced by external imaging factors and are more efficient in describing pigmentation distributions. Experiments show that the proposed method gave better visual results and superior lesion segmentation, when compared to two other illumination correction algorithms, both designed specifically for dermatological images. For computer-aided diagnosis of melanoma, sensitivity achieves 85.52% when using our chromophore descriptors, which is 8∼20% higher than those derived from other color descriptors. This demonstrates the benefit of the proposed method for automatic skin disease analysis. © 2015 Institute of Physics and Engineering in Medicine.","10.1088/0031-9155/60/9/3415","adaptive bilateral decomposition; hemoglobin identification; melanin identification; skin disease analysis; weighted polynomial curve fitting","28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928485695&doi=10.1088%2f0031-9155%2f60%2f9%2f3415&partnerID=40&md5=031f2d2664217c36877336b8a1fbc3d1"
"Detection of melanoma skin cancer using digital camera images","Jeya Ramya V.; Navarajan J.; Prathipa R.; Ashok Kumar L.","2015","1","1","0","0","0","Unique","0","","","","","","","Skin cancer is rapidly increasing in western parts of the world. Survival rate of skin cancer is high, if detected early. So an efficient method is necessary to detect skin lesion at the earliest. Since the cost of dermatoscope scan for screening the patient is high, there is a need for an automated system to detect skin lesions captured using a standard digital camera. The main aim of a skin cancer detection system is to reduce the percentage of error by choosing the appropriate method in each stage. In this paper, for pre-processing stage adaptive histogram equalization technique and wiener filter is used. A novel method is proposed for the segmentation and classification of skin lesions. © 2006-2015 Asian Research Publishing Network (ARPN).","","GLCM; Pre -processing; Segmentation; Skin lesion; SVM","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928550459&partnerID=40&md5=70312db5b98cec70d0a68444bd7f9a40"
"Automatic segmentation methodology for dermatological images acquired via mobile devices","Rosado L.; Vasconcelos M.J.M.","2015","0","1","0","0","0","Unique","0","","","","","","","Nowadays, skin cancer is considered one of the most common malignancies in the Caucasian population, thus it is crucial to develop methodologies to prevent it. Because of that, Mobile Teledermatology (MT) is thriving, allowing patients to adopt an active role in their health status while facilitating doctors to early diagnose skin cancers. Skin lesion segmentation is one of the most important and difficult task in computerized image analysis process, and so far the attention is mainly turned to dermoscopic images. In order to turn MT more accurate, it is therefore fundamental to develop simple segmentation methodologies specifically designed for macroscopic images or images acquired via smartphones, which is the main focus of this work. The proposed method was applied in 80 images acquired via smartphones and promising results have been achieved: a mean Jaccard index of 81%, mean True Detection Rate of 96% and mean Accuracy around 98%. The major goal of this work is to develop a mobile application easily accessible for the general population, with the aim of raise awareness and help both patients and doctors in the early diagnosis of skin cancers.","10.5220/0005178302460251","Mobile devices; Segmentation; Teledermatology","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938877557&doi=10.5220%2f0005178302460251&partnerID=40&md5=3fd9147c749c72eb458b61872a3d5269"
"A simple hair removal algorithm from dermoscopic images","Borys D.; Kowalska P.; Frackiewicz M.; Ostrowski Z.","2015","0","1","0","0","0","Unique","0","","","","","","","The main goal of our work is initial preprocessing of dermoscopic images by hair removal. Dermoscopy is a basic technique in skin melanoma diagnostics. One of the main problems in dermoscopy images analysis are hairs objects in the image. Hairs partially shade the main region of interest that’s why it needs special treatment. We have developed a simple and fast hair removal algorithm based on basic image processing algorithms. The algorithm was tested on available online test database PH2 [8]. Primary results of proposed algorithm show that even if hair contamination in the image is significant algorithm can find those objects. There is still a place for improvements as long as some air bubbles are marked as a region of interest. © Springer International Publishing Switzerland 2015.","10.1007/978-3-319-16483-0_27","Dermatoscopy image; Hair removal algorithm; Melanoma","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944472831&doi=10.1007%2f978-3-319-16483-0_27&partnerID=40&md5=b94ae2241175ca81fdf1747c51734593"
"Automated detection of streaks in dermoscopy images","Delibasis K.; Kottari K.; Maglogiannis I.","2015","0","1","0","0","0","First occurrence","0","","","","","","","In this paper we present a novel algorithm for the detection of dark linear structures, which appear in digital dermoscopy images of skin lesions and they are called as streaks in relevant literature. The proposed algorithm is capable of detecting such linear structures using local image curvature information obtained by the Hessian matrix. A linear structure is characterized as streak, based on its geometric characteristics. The streak detection algorithm is applied to a number of dermoscopy images containing malignant and non-malignant skin lesions. In this work we propose also a new class of streak based image features and we investigate their value in image classification according to malignancy. © IFIP International Federation for Information Processing 2015.","10.1007/978-3-319-23868-5_4","Computer vision; Dermoscopy images; Image Segmentation; Melanoma classification; Skin lesions; Streaks detection","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946069828&doi=10.1007%2f978-3-319-23868-5_4&partnerID=40&md5=2af0e3c0d6b831144e29e4d3a7bfd380"
"Cutaneous melanoma risk evaluation through digital image processing","Pirnog I.; Oprea C.","2015","0","1","0","0","0","Unique","0","","","","","","","Melanoma is the most aggressive type of human cancer but also the most likely to be cured if detected in its early stages. The risk of skin lesions to turn into melanoma can be easily evaluated by dermatologists using a non-invasive procedure called dermoscopy. This paper addresses the issue of melanoma risk evaluation through digital processing of macroscopic skin lesions images. The main goal of our research is the development of an application for tracking the time evolution of skin lesions and evaluating the risk of these lesions to turn into melanoma. The first step in the evaluation process is the extraction of the pigmented skin lesions by means of image segmentation. The two objectives presented in this paper are the determination of the best suited segmentation method in terms of computational complexity and the evaluation of the color space used for digital image representation in order to obtain good initial segmentation results. © 2014 IEEE.","10.1109/ISETC.2014.7010796","color space; image; melanoma; segmentation","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922567198&doi=10.1109%2fISETC.2014.7010796&partnerID=40&md5=c7179f5ea1c7cfed948b50e2384b2429"
"Segmentation of skin cancer images using an extension of Chan and Vese model","Adjed F.; Faye I.; Ababsa F.","2015","1","1","0","0","0","First occurrence","0","","","","","","","Recently, more attention is given to automatic detection of cancer. However, the multitude kind of cancer (lung, breast, brain, skin etc.) complicates the detection of this disease with common approaches. An adaptive method for each cancer is the only response to achieve this aim. The segmentation of interest region is the first main step to differentiate between the suspicious and non suspicious part in the image. In this specific work, we focus on a segmentation approach based on Total Variation methods. We propose a generalization of Chan and Vese (CV) model theory and implement it to the particular case of skin cancer images. © 2015 IEEE.","10.1109/ICITEED.2015.7408987","Chan and Vese Model; Segemntation; Skin Cancer; Total Variation","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966676820&doi=10.1109%2fICITEED.2015.7408987&partnerID=40&md5=27e6b47489f10d7cc7a4bf7572a199c1"
"Segmentation of inhomogeneous skin tissues in high-frequency 3D ultrasound images, the advantage of non-parametric log-likelihood methods","Sciolla B.; Ceccato P.; Cowell L.; Dambry T.; Guibert B.; Delachartre P.","2015","1","1","0","0","0","Unique","0","","","","","","","We propose a multi-purpose level-set segmentation algorithm to detect the boundary of tumors and tissues in high-frequency 3D ultrasound images of the skin. Whereas most proposed algorithms assume a specific (e.g. Rayleigh) distribution of the speckle noise, we do not make such assumption and use non-parametric Parzen estimates of the distribution. We discuss the advantage of the method on synthetic and clinical images of the skin and tumors.","10.1016/j.phpro.2015.08.253","3D ultrasound imaging; Level-set; Non-parametric methods; Segmentation","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948652346&doi=10.1016%2fj.phpro.2015.08.253&partnerID=40&md5=f0b2fb39b444757b48c5938fc8db0b14"
"Streak detection in dermoscopic color images using localized radial flux of principal intensity curvature","Mirzaalian H.; Lee T.K.; Hamarneh G.","2015","0","1","0","0","0","Unique","0","","","","","","","Malignant melanoma (MM) is one of the common cancers among the white population [1]. Dermoscopy, a noninvasive method for early recognition of MM, allows a clear visualization of skin internal structures, which are often analyzed by a dermoscopic algorithm, such as the ABCD rule of dermoscopy or the 7-point checklist [2]. These methods utilize different dermoscopic features for diagnosing pigmented melanocytic lesions; for example, ABCD analyzes the weighted features of asymmetry (A), border (B), color (C), and differential structures (D). On the other hand, the 7-point checklist looks for the presence of seven different patterns (atypical pigment network, blue-white veil, atypical vascular pattern, irregular streaks, irregular dots/globules, irregular blotches, regression structures). Depending on the presence or absence of each of these patterns, a weight score is assigned to a pigmented lesion. These scores are added up and used for the diagnosis of melanoma. Studies showed that these dermoscopic algorithms can improve the diagnostic accuracy of melanoma. © 2016 by Taylor and Francis Group, LLC.","10.1201/b19107","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022186350&doi=10.1201%2fb19107&partnerID=40&md5=f4711c6c229f7f1110f3dcfd4a9339df"
"Layer measurement in high frequency ultra-sonography images for skin","Wawrzyniak Z.M.; Szyszka M.","2015","1","1","0","0","0","Unique","0","","","","","","","In this paper, the problem of automatic determination of the position and measuring the thickness of the human skin layers in high-frequency ultrasound images (HFUS) is solved. Location and the process of position determination of the skin layers are not an obvious process due to the phenomenological nature of the images received in HFUS, the so-called speckle noise and the lack of the objective measures. In order to determine the positions of the boundaries of the skin layers, the image analysis methods were used, based on the specific features of the HFUS images, such as layered structure and echogenicity features. Only the fusion of the results of the analysis algorithms based on global (histogram of intensity levels) and local image features (cross-sectional and topological characteristics) improves discriminative features applicable to complete the information about the properties of the HFUS images with layered structure and to develop a method assessing the thickness of the skin layers. The knowledge gathered from such layers checks can improve understanding of the nature of the human skin and provide a more objective conditions for HFUS diagnostic imaging with speeding up the diagnostic process for dermatologists. We proposed a new method for automatic segmentation on HFUS images using fusion of discriminative information based on nonlinear segmentation with a reasonable threshold setting, boundary selecting and linking, and false boundary point removing strategies for intensity distributions. © 2015 SPIE.","10.1117/12.2205938","Image processing; Layered structure objects; Thickness measurement; Ultra-sonography","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951320566&doi=10.1117%2f12.2205938&partnerID=40&md5=86ed835652e930720a69722dfd5180a1"
"Four-class classification of skin lesions with task decomposition strategy","Shimizu K.; Iyatomi H.; Celebi M.E.; Norton K.-A.; Tanaka M.","2015","1","1","0","0","0","Unique","0","","","","","","","This paper proposes a new computer-aided method for the skin lesion classification applicable to both melanocytic skin lesions (MSLs) and nonmelanocytic skin lesions (NoMSLs). The computer-aided skin lesion classification has drawn attention as an aid for detection of skin cancers. Several researchers have developed methods to distinguish between melanoma and nevus, which are both categorized as MSL. However, most of these studies did not focus on NoMSLs such as basal cell carcinoma (BCC), the most common skin cancer and seborrheic keratosis (SK) despite their high incidence rates. It is preferable to deal with these NoMSLs as well as MSLs especially for the potential users who are not enough capable of diagnosing pigmented skin lesions on their own such as dermatologists in training and physicians with different expertise. We developed a new method to distinguish among melanomas, nevi, BCCs, and SKs. Our method calculates 828 candidate features grouped into three categories: color, subregion, and texture. We introduced two types of classification models: a layered model that uses a task decomposition strategy and flat models to serve as performance baselines. We tested our methods on 964 dermoscopy images: 105 melanomas, 692 nevi, 69 BCCs, and 98 SKs. The layered model outperformed the flat models, achieving detection rates of 90.48%, 82.51%, 82.61%, and 80.61% for melanomas, nevi, BCCs, and SKs, respectively. We also identified specific features effective for the classification task including irregularity of color distribution. The results show promise for enhancing the capability of the computer-aided skin lesion classification. © 1964-2012 IEEE.","10.1109/TBME.2014.2348323","","102","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919941351&doi=10.1109%2fTBME.2014.2348323&partnerID=40&md5=edee166ce52f66e693bfd9ef35cd31f6"
"Redesigning EHRs and Clinical Decision Support Systems for the Precision Medicine Era","Maglogiannis I.; Goudas T.; Billiris A.; Karanikas H.; Valavanis I.; Papadodima O.; Kontogianni G.; Chatziioannou A.","2015","0","1","0","0","0","Unique","0","","","","","","","In this work we present a distributed Health Record System Architecture, capable of integrating and duly accommodating the processing of heterogeneous, multi-layered (omics, histological images and clinical) data concerning the multi-angled description and management of melanoma patients. The proposed solution comprises a novel design of a layered analytical framework as an expansion of current Electronic Health Record (EHR) systems, which may integrate EHR data, high-volume molecular -omic data, imaging data as well as relevant clinical observations. The case study used is in the field of dermatology, where we attempt to combine the multilayered information for the early detection of skin cancer. The specific architecture, aspires to lower the barrier for the introduction of personalized therapeutic approaches, in the 21st century in the context of precision medicine. The adopted schema, presumes that through the massive integration of multi-layered, voluminous data, describing the disease state at various organizational scales and the parallel processing of those streams, either alone or in conjunction with the others, significant advancement and speed up will occur concerning the quality and output of medical diagnostic tasks or patient management overall, thus paving the way for the introduction of personalized approaches in the therapeutic course. The paper describes in detail the technical issues of implementation along with an initial evaluation and discussion. © 2015 ACM.","10.1145/2797143.2797158","Clinical Decision Support Systems; Dermoscopy; Melanoma Patient Management; Skin Cancer; Translational Biomedical Research; Web Services","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988527484&doi=10.1145%2f2797143.2797158&partnerID=40&md5=ac049e1c405d06726a66352f3c32a712"
"Automatic detection and segmentation of vascular structures in dermoscopy images using a novel vesselness measure based on pixel redness and tubularness","Kharazmi P.; Lui H.; Stoecker W.V.; Lee T.","2015","0","1","0","0","0","Unique","0","","","","","","","Vascular structures are one of the most important features in the diagnosis and assessment of skin disorders. The presence and clinical appearance of vascular structures in skin lesions is a discriminating factor among different skin diseases. In this paper, we address the problem of segmentation of vascular patterns in dermoscopy images. Our proposed method is composed of three parts. First, based on biological properties of human skin, we decompose the skin to melanin and hemoglobin component using independent component analysis of skin color images. The relative quantities and pure color densities of each component were then estimated. Subsequently, we obtain three reference vectors of the mean RGB values for normal skin, pigmented skin and blood vessels from the hemoglobin component by averaging over 100000 pixels of each group outlined by an expert. Based on the Euclidean distance thresholding, we generate a mask image that extracts the red regions of the skin. Finally, Frangi measure was applied to the extracted red areas to segment the tubular structures. Finally, Otsu's thresholding was applied to segment the vascular structures and get a binary vessel mask image. The algorithm was implemented on a set of 50 dermoscopy images. In order to evaluate the performance of our method, we have artificially extended some of the existing vessels in our dermoscopy data set and evaluated the performance of the algorithm to segment the newly added vessel pixels. A sensitivity of 95% and specificity of 87% were achieved. © 2015 SPIE.","10.1117/12.2082720","dermoscopy; Frangi filtering; independent component analysis; Telangiectasia; vessel segmentation","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948783639&doi=10.1117%2f12.2082720&partnerID=40&md5=1635d532a8785c93f7f41766ef989ad2"
"Noninvasive real-time automated skin lesion analysis system for melanoma early detection and prevention","Abuzaghleh O.; Barkana B.D.; Faezipour M.","2015","1","1","0","0","0","First occurrence","0","","","","","","","Melanoma spreads through metastasis, and therefore, it has been proved to be very fatal. Statistical evidence has revealed that the majority of deaths resulting from skin cancer are as a result of melanoma. Further investigations have shown that the survival rates in patients depend on the stage of the cancer; early detection and intervention of melanoma implicate higher chances of cure. Clinical diagnosis and prognosis of melanoma are challenging, since the processes are prone to misdiagnosis and inaccuracies due to doctors' subjectivity. Malignant melanomas are asymmetrical, have irregular borders, notched edges, and color variations, so analyzing the shape, color, and texture of the skin lesion is important for the early detection and prevention of melanoma. This paper proposes the two major components of a noninvasive real-time automated skin lesion analysis system for the early detection and prevention of melanoma. The first component is a real-time alert to help users prevent skinburn caused by sunlight; a novel equation to compute the time for skin to burn is thereby introduced. The second component is an automated image analysis module, which contains image acquisition, hair detection and exclusion, lesion segmentation, feature extraction, and classification. The proposed system uses PH2 Dermoscopy image database from Pedro Hispano Hospital for the development and testing purposes. The image database contains a total of 200 dermoscopy images of lesions, including benign, atypical, and melanoma cases. The experimental results show that the proposed system is efficient, achieving classification of the benign, atypical, and melanoma images with accuracy of 96.3%, 95.7%, and 97.5%, respectively. © 2013 IEEE.","10.1109/JTEHM.2015.2419612","image segmentation; melanoma; skin cancer","168","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928404914&doi=10.1109%2fJTEHM.2015.2419612&partnerID=40&md5=772f372ddb647b964498031b08d0c56e"
"Interactive Image Feature Selection Aided by Dimensionality Reduction","Rauber P.E.; Da Silva R.R.O.; Feringa S.; Celebi M.E.; Falcão A.X.; Telea A.C.","2015","0","1","0","0","0","Unique","0","","","","","","","Feature selection is an important step in designing image classification systems. While many automatic feature selection methods exist, most of them are opaque to their users. We consider that users should be able to gain insight into how observations behave in the feature space, since this may allow the design of better features and the incorporation of domain knowledge. For this purpose, we propose a methodology for interactive and iterative selection of image features aided by dimensionality reduction plots and complementary exploration tools. We evaluate our proposal on the problem of feature selection for skin lesion image classification. © 2019 International Workshop on Visual Analytics. All rights reserved.","10.2312/eurova.20151098","","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121665394&doi=10.2312%2feurova.20151098&partnerID=40&md5=5f50244b47e9b82b2a7991791655b3d3"
"Comparison of image processing techniques for reticular pattern recognition in melanoma detection","Arroyo J.L.G.; Zapirain B.G.","2015","0","1","0","0","0","Unique","0","","","","","","","Melanoma is a type of skin cancer that accounts for approximately 1.6% of the total number of cancer cases worldwide [1]. In the fight against this type of cancer, early detection is a key factor: if detected early, before the tumor has penetrated the skin (noninvasive melanoma or melanoma in situ), the survival rate is 98%, falling to 15% in advanced cases (invasive melanoma), when the tumor has spread (metastasized) [2]. © 2016 by Taylor and Francis Group, LLC.","10.1201/b19107","","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053975840&doi=10.1201%2fb19107&partnerID=40&md5=51a8e8c261e763d91ebc9703faf51c18"
"Enhancing classification accuracy utilizing globules and dots features in digital dermoscopy","Maglogiannis I.; Delibasis K.K.","2015","0","1","0","0","0","Unique","0","","","","","","","The interest in image dermoscopy has been significantly increased recently and skin lesion images are nowadays routinely acquired for a number of skin disorders. An important finding in the assessment of a skin lesion severity is the existence of dark dots and globules, which are hard to locate and count using existing image software tools. In this work we present a novel methodology for detecting/segmenting and count dark dots and globules from dermoscopy images. Segmentation is performed using a multi-resolution approach based on inverse non-linear diffusion. Subsequently, a number of features are extracted from the segmented dots/globules and their diagnostic value in automatic classification of dermoscopy images of skin lesions into melanoma and non-malignant nevus is evaluated. The proposed algorithm is applied to a number of images with skin lesions with known histo-pathology. Results show that the proposed algorithm is very effective in automatically segmenting dark dots and globules. Furthermore, it was found that the features extracted from the segmented dots/globules can enhance the performance of classification algorithms that discriminate between malignant and benign skin lesions, when they are combined with other region-based descriptors. © 2014 Elsevier Ireland Ltd.","10.1016/j.cmpb.2014.12.001","Dark dot segmentation; Dermoscopy images; Globule segmentation; Image classification; Melanoma detection; Skin lesions","44","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922445570&doi=10.1016%2fj.cmpb.2014.12.001&partnerID=40&md5=4efa18dd5204e726d4a3d468b4ac933d"
"Content-based image retrieval techniques for the analysis of dermatological lesions using particle swarm optimization technique","Jiji G.W.; Durairaj P.J.","2015","0","1","0","0","0","Unique","0","","","","","","","This method presents extraction of effective color and shape features for the analysis of dermatology images. We employ three phases of operation in order to perform efficient retrieval of images of skin lesions. Our proposed algorithm used color and shape feature vectors and the features are normalized using Min-Max normalization. Particle swarm optimization (PSO) technique for multi-class classification is used to converge the search space more efficiently. The results using receiver operating characteristic (ROC) curve proved that the proposed architecture is highly contributed to computer-aided diagnosis of skin lesions. Experiments on a set of 1450 images yielded a specificity of 98.22% and a sensitivity of 94%. Our empirical evaluation has a superior retrieval and diagnosis performance when compared to the performance of other works. We present explicit combinations of feature vectors corresponding to healthy and lesion skin. © 2015 Elsevier B.V. All rights reserved.","10.1016/j.asoc.2015.01.058","Classification; Features; Particle swarm optimization; Retrieval","40","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923796734&doi=10.1016%2fj.asoc.2015.01.058&partnerID=40&md5=f58361250c3bab1edbcadbccb9ff41b9"
"Pigmented skin lesion diagnosis using geometric and chromatic features","Sheha M.A.; Sharwy A.; Mabrouk M.S.","2015","1","1","0","0","0","Unique","0","","","","","","","Skin cancer appears to be one of the most dangerous types among others by the presence of malignant melanoma as one of pigmented skin lesion forms. Automated system for the purpose of pigmented skin lesion diagnosis mentioned through that paper is recommended as a non-invasive diagnosis tool. To obviate the problem of qualitative interpretation, two different image sets are used to examine the proposed system, a set of images acquired by standard camera (clinical images) and another set of dermoscopic images captured from the magnified dermoscope. Images are enhanced and segmented to separate the lesion from the background. Different geometric and chromatic features are extracted from the region of interest resulting from segmentation process. Then, the most prominent features that can cause an effect are selected by different selection methods; which are the Fisher score ranking and the t-test method. Most prominent features were introduced to two different classifiers; artificial neural network and Support vector machine for the discrimination of the two groups of lesions. System performance was measured regarding Specificity, Sensitivity and Accuracy. The artificial neural network designed with the combined geometric and chromatic features selected by fisher score ranking enabled a diagnostic accuracy of 95% for dermoscopic and 93.75% for clinical images. © 2014 IEEE.","10.1109/CIBEC.2014.7020931","ANN; Color Space; Geometric features; Pigmented Skin lesions; SVM","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923171967&doi=10.1109%2fCIBEC.2014.7020931&partnerID=40&md5=563b25a6f7062f41275f4e3a7135be44"
"In vivo visualization of skin inflammation by optical coherence tomography and two-photon microscopy","Kim B.; Lee S.H.; Yoon C.J.; Gho Y.S.; Ahn G.-O.; Kim K.H.","2015","1","1","0","0","0","Unique","0","","","","","","","Inflammation is a non-specific immune response to injury intended to protect biological tissue from harmful stimuli such as pathogens, irritants, and damaged cells. In vivo optical tissue imaging has been used to provide spatial and dynamic characteristics of inflammation within the tissue. In this paper, we report in vivo visualization of inflammation in the skin at both cellular and physiological levels by using a combination of label-free two-photon microscopy (TPM) and optical coherence tomography (OCT). Skin inflammation was induced by topically applying lipopolysaccharide (LPS) on the mouse ear. Temporal OCT imaging visualized tissue swelling, vasodilation, and increased capillary density 30 min and 1 hour after application. TPM imaging showed immune cell migration within the inflamed skin. Combined OCT and TPM was applied to obtain complementary information from each modality in the same region of interest. The information provided by each modality were consistent with previous reports about the characteristics of inflammation. Therefore, the combination of OCT and TPM holds potential for studying inflammation of the skin. © 2015, Optical Society of America.","10.1364/BOE.6.002512","","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946542134&doi=10.1364%2fBOE.6.002512&partnerID=40&md5=5e7bfaab2b74dd870a73cc60cc47a48b"
"The effects of skin lesion segmentation on the performance of dermatoscopic image classification","Mahbod A.; Tschandl P.; Langs G.; Ecker R.; Ellinger I.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Background and Objective: Malignant melanoma (MM) is one of the deadliest types of skin cancer. Analysing dermatoscopic images plays an important role in the early detection of MM and other pigmented skin lesions. Among different computer-based methods, deep learning-based approaches and in particular convolutional neural networks have shown excellent classification and segmentation performances for dermatoscopic skin lesion images. These models can be trained end-to-end without requiring any hand-crafted features. However, the effect of using lesion segmentation information on classification performance has remained an open question. Methods: In this study, we explicitly investigated the impact of using skin lesion segmentation masks on the performance of dermatoscopic image classification. To do this, first, we developed a baseline classifier as the reference model without using any segmentation masks. Then, we used either manually or automatically created segmentation masks in both training and test phases in different scenarios and investigated the classification performances. The different scenarios included approaches that exploited the segmentation masks either for cropping of skin lesion images or removing the surrounding background or using the segmentation masks as an additional input channel for model training. Results: Evaluated on the ISIC 2017 challenge dataset which contained two binary classification tasks (i.e. MM vs. all and seborrheic keratosis (SK) vs. all) and based on the derived area under the receiver operating characteristic curve scores, we observed four main outcomes. Our results show that 1) using segmentation masks did not significantly improve the MM classification performance in any scenario, 2) in one of the scenarios (using segmentation masks for dilated cropping), SK classification performance was significantly improved, 3) removing all background information by the segmentation masks significantly degraded the overall classification performance, and 4) in case of using the appropriate scenario (using segmentation for dilated cropping), there is no significant difference of using manually or automatically created segmentation masks. Conclusions: We systematically explored the effects of using image segmentation on the performance of dermatoscopic skin lesion classification. © 2020 Elsevier B.V.","10.1016/j.cmpb.2020.105725","deep learning; dermatoscopy; effect of segmentation on classification; medical image analysis; Skin cancer","88","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090043899&doi=10.1016%2fj.cmpb.2020.105725&partnerID=40&md5=cdd09df90e44e9e85a902959618aa05f"
"Convolutional Neural Network Based Desktop Applications to Classify Dermatological Diseases","Goceri E.","2020","0","1","0","0","0","Unique","0","","","","","","","Convolutional Neural Networks (CNNs) have the potential to assist medical doctors in diagnosis and treatment stage. This paper has been prepared to help dermatologists by presenting (i) fundamental information on deep learning and CNNs, and (ii) applications of CNN s for skin diseases classification. Also, this work shows that although CNN based methods have a strong potential for automated diagnosis, further researches and new techniques are still required in image processing and pattern recognition area to provide diagnosis of dermatological diseases with higher performances. In this work, these two groups of applications of CNN s in dermatology have been handled: (i) disease classification from medical images (e.g., dermoscopy and pathological images); (ii) disease classification from digital photographs. Therefore, important contributions of this work are two-fold: First, main concepts of deep learning and CNNs are presented, which will be helpful for dermatologists to understand and follow up CNN based computerized methods. Second, the state-of-The-Art applications developed for lesion classifications from medical images and colored photographs are presented. Also, disadvantages or limitations of these applications are explained. In addition, this paper indicates shortage of desktop applications developed for other dermatological diseases except skin cancer. © 2020 IEEE.","10.1109/IPAS50080.2020.9334956","automated diagnosis; convolutional networks; dermatological diseases; melanoma; skin cancer","54","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100760712&doi=10.1109%2fIPAS50080.2020.9334956&partnerID=40&md5=36d0394c3c590681d6ad0311efa51fd6"
"Deep learning-assisted automatic classification of skin images; [深度学习辅助皮肤影像自动分类的研究进展]","Wang S.; Liu J.","2020","1","1","0","0","0","Unique","0","","","","","","","Conventional machine learning techniques can not be directly used to process natural data in their raw form, and have to rely on experts to design feature extractors. However, the emergence of deep learning has broken this limitation. It is a method that allows a machine to be fed with raw data and to automatically discover representative information needed for detection or classification, and has become a key technology for medical image classification with artificial intelligence. Deep learning has achieved a level comparable to or even higher than that of dermatologists in terms of classification between malignant melanoma and pigmented nevus, as well as classification between skin diseases other than melanocyte-derived tumors, such as squamous cell tumor, basal cell carcinoma and nail disorders. The review introduces some basic concepts of deep learning in skin image classification and common evaluation methods for deep learning models, and summarizes research progress in the application of deep learning in skin image classification. Copyright © 2020 by the Chinese Medical Association.","10.35541/cjd.20190660","Artificial intelligence; Deep learning; Dermoscopy; Neural networks (computer); Nevi and melanomas; Skin diseases; Skin imaging","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098587074&doi=10.35541%2fcjd.20190660&partnerID=40&md5=8eb32f00fddbd7e02681ce6863453c36"
"Bucket of Deep Transfer Learning Features and Classification Models for Melanoma Detection","Manzo M.; Pellino S.","2020","0","1","0","0","0","Unique","0","","","","","","","Malignant melanoma is the deadliest form of skin cancer and, in recent years, is rapidly growing in terms of the incidence worldwide rate. The most effective approach to targeted treatment is early diagnosis. Deep learning algorithms, specifically convolutional neural networks, represent a methodology for the image analysis and representation. They optimize the features design task, essential for an automatic approach on different types of images, including medical. In this paper, we adopted pretrained deep convolutional neural networks architectures for the image representation with purpose to predict skin lesion melanoma. Firstly, we applied a transfer learning approach to extract image features. Secondly, we adopted the transferred learning features inside an ensemble classification context. Specifically, the framework trains individual classifiers on balanced subspaces and combines the provided predictions through statistical measures. Experimental phase on datasets of skin lesion images is performed and results obtained show the effectiveness of the proposed approach with respect to state-of-the-art competitors. © 2020 by the authors.","10.3390/jimaging6120129","Deep learning; Ensemble classification; Melanoma detection; Transfer learning","27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100025145&doi=10.3390%2fjimaging6120129&partnerID=40&md5=b7c2eb934d2db4ae37b255513d53d7d3"
"Skin Cancer Classification using Transfer Learning","Kondaveeti H.K.; Edupuganti P.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Today, Cancer is one of the major lethal diseases in the world. Globally out of every three cancers diagnosed, one is identified as skin cancer. Some reports suggest that one out of every five Americans might fall prey to skin cancer in the course of their life. Early detection of the disease plays a pivotal role in the treatment of skin cancer. Though these skin lesions can be seen without the help of any external clinical device, it is a challenging task to distinguish between malignant and benign skin lesions as they are alike in their physical appearances. This leads to an increased number of unnecessary biopsies where in one study it was revealed that nearly 5,00,000 biopsies are done in children every year to diagnose a mere 400 melanomas. To tackle this problem and help dermatologists in the diagnosis process, we developed an enhanced image classification model which can act as a preliminary check before moving to a costlier biopsy. This model can identify 7 distinct types of skin lesions. An analysis has been carried out on the HAM10000 dataset. We used transfer learning utilizing multiple pre-Trained models, combined with class-weighted loss and data augmentation techniques for the classification process. Experimental analysis shows that the modified ResNet50 model is capable of identifying skin lesion images into one of the seven classes with categorical accuracy, weighted average precision, and recall of 90 percent, 0.89, 0.90, respectively. Our model can be used as a clinical decision support system to help dermatologists in the diagnosis process.  © 2020 IEEE.","10.1109/ICATMRI51801.2020.9398388","Convolutional Neural Networks (CNN); Deep Learning; Skin Cancer classification; Transfer Learning","76","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104666254&doi=10.1109%2fICATMRI51801.2020.9398388&partnerID=40&md5=e7e8ec7a433a68293742c0d0320a01d9"
"Smart apps for risk assessment of skin cancer","Vocaturo E.; Zumpano E.","2020","1","1","0","0","0","Unique","0","","","","","","","Skin cancer is one of the most insidious and aggressive tumors. The growing spread of this particular type of cancer is also a cause for concern. In fact, the American Cancer Society reports more than 87.000 new cases of melanoma in the United States by the end of 2017, with nearly 10.000 estimated deaths. Fortunately, a diagnosis in the initial stages allows a successful treatment of this type of skin lesion. Early detection and removal becomes essential when the tumor is still small and thin. This justifies the need to provide tools that allow early and accurate diagnosis, both facilitating the work of specialists and allowing the release of low-cost solutions for effective self-diagnosis. Mobile version of health (mHealth) is becoming a key topic in our digitalized society. In this paper we survey the state of art of most popular smart Apps for risk assessment of skin cancer. © 2020 IEEE.","10.1109/WIIAT50758.2020.00106","Computer Vision Systems; Medical Image Analysis; Skin Cancer","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114438804&doi=10.1109%2fWIIAT50758.2020.00106&partnerID=40&md5=e4ab4f0ab1e4485fb09bac5fe791c920"
"Image Augmentation for Deep Learning Based Lesion Classification from Skin Images","Goceri E.","2020","1","1","0","0","0","Unique","0","","","","","","","Skin lesion classification based on deep learning models, which are data-hungry, is a challenging issue because of the shortage of annotated images and unbalanced classes in image sets. The lack of sufficient number of labeled data or class unbalancing in image sets lead to overfitting problems affecting robustness and generalization ability of network models. Image augmentation is an efficient approach to deal with this issue using existing images more efficiently. In addition to image augmentations, various solutions have been developed in the literature to solve the overfitting problem and to obtain well-generalizing network models. However, there is not a clear way how the most appropriate solution should be selected. Therefore, in this paper, those alternative solutions and image augmentations applied recently in deep learning based skin lesion classifications are presented. © 2020 IEEE.","10.1109/IPAS50080.2020.9334937","automated diagnosis; convolutional neural networks; data augmentation; deep learning; image processing; skin lesion classification","78","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100800605&doi=10.1109%2fIPAS50080.2020.9334937&partnerID=40&md5=fb94982a7042c491893d9801a4838bb3"
"AMIL:An attentional multi-instance learning for computer-aided diagnosis of skin diagnosis","Jin M.; Zhang D.; Cao P.","2020","1","1","0","0","0","Unique","0","","","","","","","Skin diseases are becoming a most common health issues among all the countries worldwide. To support disease diagnosis, many types of local or global feature representations have been derived from medical images. Since the local regions of skin lesion images may share strong visual similarity across different types of skin diseases, a local feature learning method for skin lesion classification task is proposed in this paper. With the idea of local representation learning, we develop a multi-instance learning method to predict the diagnosis of skin diagnosis. To model the relationship between the suspicious instances and bag label, a multi-instance learning with attention mechanism is developed to acquire the location information of highly suspected lesions and predict the labels of skin diseases. We evaluate our proposed algorithm on ISIC 2018 Skin Lesion dataset, and the experimental results demonstrate that it achieves an average accuracy of 0.755 and an AUC value of 0.836, respectively. © 2020 ACM.","10.1145/3451421.3451459","Attention; Classification; Multi-instance learning; Skin diseases","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114275618&doi=10.1145%2f3451421.3451459&partnerID=40&md5=0c7a09a08ae9724d7d8c72552f05630a"
"A comparative study of features selection for skin lesion detection from dermoscopic images","Javed R.; Rahim M.S.M.; Saba T.; Rehman A.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Melanoma is rare and mainly considered as the dangerous category of skin cancer. Many researchers proposed diverse efficient techniques for melanoma detection. The main focus of this research is: (1) to discuss the traditional clinical methods for diagnosing skin cancer melanoma, and (2) to review the existing researcher’s attempts in response the critical and challenging task is features selection and extraction for skin cancer melanoma detection from dermoscopy images. This research will also be helpful to recognize the research background of skin cancer melanoma detection through image processing techniques. This cannot be done without a broad literature survey. The literature survey was performed keeping the main category as skin cancer melanoma and the survey included articles, journals, and conferences papers. To perform this study, different databases are considered. All of these databases cover medical image processing and technical literature. To conclude the review, some graphs and tables are presented which perform the comparison between existing techniques. © 2019, Springer-Verlag GmbH Austria, part of Springer Nature.","10.1007/s13721-019-0209-1","ABCD rule; Biopsy; Dermatoscopy; Melanoma; Skin cancer","105","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076570984&doi=10.1007%2fs13721-019-0209-1&partnerID=40&md5=4322b8edbc83340e7dfbdb24c6dd30e3"
"Multiple Instance Learning approaches for Melanoma and Dysplastic Nevi images classification","Vocaturo E.; Zumpano E.","2020","0","1","0","0","0","First occurrence","0","","","","","","","Malignant melanoma is responsible for the highest number of deaths related to skin lesions. The similarities of melanoma with other skin lesions such as dysplastic nevi, however, constitute a pitfall for early diagnosis. The research community is committed to proposing software solutions that favor the computerized analysis of lesions for melanoma detection. Existing methods have typically focused on the dichotomous distinction of melanoma from benign lesions. Currently, there is debate about Dysplastic Nevi Syndrome (DNS), or rather about the number of moles present on the human body as potential melanoma risk factors. Distinguishing dysplastic nevi from common ones is a challenging yet mostly unexplored classification problem. The classification phase is particularly delicate: over time, a series of automatic learning algorithms have been proposed to better face this issue. In this paper, we refer to the emergencing role of Multiple Instance Learning approaches for discriminating melanoma from dysplastic nevi and to outline the even more complex challenge related to the classification of dysplastic nevi from common ones. © 2020 IEEE.","10.1109/ICMLA51294.2020.00217","Image Classification; Melanoma Detection; Multiple Instance Learning","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102503600&doi=10.1109%2fICMLA51294.2020.00217&partnerID=40&md5=cf1ea74b9ec841ffbafeb5cf7057b594"
"Artificial intelligence-based image classification methods for diagnosis of skin cancer: Challenges and opportunities","Goyal M.; Knackstedt T.; Yan S.; Hassanpour S.","2020","1","1","0","0","0","Unique","0","","","","","","","Recently, there has been great interest in developing Artificial Intelligence (AI) enabled computer-aided diagnostics solutions for the diagnosis of skin cancer. With the increasing incidence of skin cancers, low awareness among a growing population, and a lack of adequate clinical expertise and services, there is an immediate need for AI systems to assist clinicians in this domain. A large number of skin lesion datasets are available publicly, and researchers have developed AI solutions, particularly deep learning algorithms, to distinguish malignant skin lesions from benign lesions in different image modalities such as dermoscopic, clinical, and histopathology images. Despite the various claims of AI systems achieving higher accuracy than dermatologists in the classification of different skin lesions, these AI systems are still in the very early stages of clinical application in terms of being ready to aid clinicians in the diagnosis of skin cancers. In this review, we discuss advancements in the digital image-based AI solutions for the diagnosis of skin cancer, along with some challenges and future opportunities to improve these AI systems to support dermatologists and enhance their ability to diagnose skin cancer. © 2020 The Author(s)","10.1016/j.compbiomed.2020.104065","Artificial intelligence; Computer-aided diagnostics; Deep learning; Dermatologists; Digital dermatology; Skin cancer","294","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096707182&doi=10.1016%2fj.compbiomed.2020.104065&partnerID=40&md5=2100ebcacd16f45014880eca479e93b8"
"Skin lesion segmentation using fully convolutional networks: A comparative experimental study","Kaymak R.; Kaymak C.; Ucar A.","2020","1","1","0","0","0","Unique","0","","","","","","","Because the most dangerous type of skin cancer, melanoma, is very difficult for dermatologists to detect because of the low contrast between the lesion and the adjacent skin, the automatic application of skin lesion segmentation is regarded as very challenging. This paper proposes the implementation of a medical image segmentation that will accelerate a melanoma diagnosis by dermatologists. In the implementation, Fully Convolutional Network (FCN) architectures generated by modifying Convolutional Neural Network (CNN) architectures are used. The proposed algorithm for an automatic semantic segmentation of skin lesions utilizes four different FCN architectures, FCN-AlexNet, FCN-8s, FCN-16s, and FCN-32s. The experimental studies in this paper are constructed on the ISIC 2017 dataset, and the evaluations of these architectures on the dataset are carried out for the first time with this study. In the experimental studies, once the images in the dataset are preprocessed, the FCNs are first trained separately. Secondly, the accuracies and Dice coefficients on the validation dataset are calculated by using these trained FCN architectures. Thirdly, the obtained results are compared. Finally, the inferences of lesion segmentation are visualized in order to exhibit how exactly the FCN architectures can segment the lesions. The experimental results show that the FCNs in the proposed algorithm are suitable for skin lesion segmentation. In addition, it is thought that the experimental results will contribute to the scientific literature and assist the researchers who are working on medical image segmentation. © 2020 Elsevier Ltd","10.1016/j.eswa.2020.113742","Convolutional Neural Network; Deep Learning; Fully Convolutional Network; Medical Image Segmentation","75","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088386379&doi=10.1016%2fj.eswa.2020.113742&partnerID=40&md5=211ac66f9c1c74060359a78d99d90410"
"An improved UNet++ network applied in detection of skin lesions in melanoma; [一种改进UNet++网络用于检测黑色素瘤皮肤病变]","Yang G.; Lai Z.; Yu D.","2020","1","1","0","0","0","Unique","0","","","","","","","Objective: To explore the value of an improved UNet++ network applied in detection of skin lesions in melanoma. Methods: An improved UNet++ network structure-AT-UNet++ network using soft attention gate and Tversky-Focal loss (TFL) function asloss function was proposed. Evaluation metrics was calculated of AT-UNet++ network, U-Net network, UNet++ network, UNet++ network with TFL function and UNet++ network with soft attention gate after training on International Skin Imaging Collaboration (ISIC) Challenge 2016 and 2017 test set, respectively. Then evaluation indexes of the first five competition models in ISIC Challenge 2016 and 2017 Leadership were compared with those of AT-UNet++ network. Results: The pixel-wise accuracy (ACC), DICE similarity coefficient (DIC) and Jaccard index (JAI) of AT-UNet++ network based on ISIC Challenge 2016 test set were 3.36%, 4.15% and 3.95% higher than those of UNet++ network, respectively, while ACC, DIC and JAI of AT-UNet++ network based on ISIC Challenge 2017 test set were 2.65%, 5.01% and 4.39% higher than those of UNet++ network,respectively. Conclusion: Evaluation indexes of the improved UNet++ network model were improved to different extents compared with those of other models. Copyright © 2020 by the Press of Chinese Journal of Medical Imaging and Technology.","10.13929/j.issn.1003-3289.2020.12.025","Machine learning; Melanoma","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099761517&doi=10.13929%2fj.issn.1003-3289.2020.12.025&partnerID=40&md5=d9859b849108ace0d98cb03a85ea6d3d"
"Learning to Classify Skin Lesions via Self-Training and Self-Paced Learning","Asare S.K.; You F.; Nartey O.T.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Automatically classifying skin lesion is a challenging task owing to reasons such as high intra class variations, similarities between inter-class images, occlusions in dermoscopy images that impede accurate lesion localization, not to mention data unavailability. Considering that unlabeled data is abundant and cheap, this work proposes a classification framework that integrates the semi-supervised learning concepts of self-training and self-paced learning to classifying skin lesions. First, accurate instance segmentation is performed using the Mask R-CNN model to effectively localize and preserve the appearance and size of the skin lesions in an image. Then, a semi-supervised self-training scheme that utilizes self-paced learning strategy is implemented to generate and select pseudo-labeled samples to augment the training data. The proposed framework ensures that; 1) the spatial locations of skin lesions are accurately localized and preserved, which is critical for extracting semantically meaningful information akin to classification; 2) sufficient data samples are generated to enlarge the training data to avoid overfitting; 3) a model learns both 'easy' and 'hard' samples during training without necessarily ignoring features from less represented classes. Extensive experiments are performed using the ISIC dataset and results obtained demonstrate the effectiveness of the proposed approach. © 2020 IEEE.","10.1109/BIBM49941.2020.9313150","instance segmentation; self-paced learning; self-training; semi-supervised learning; Skin lesions classification","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100348213&doi=10.1109%2fBIBM49941.2020.9313150&partnerID=40&md5=5e11da4bf4da0f734369b3193dcac541"
"Skin Cancer Dermoscopy Images Classification with Meta Data via Deep Learning Ensemble","Lin T.-C.; Lee H.-C.","2020","1","1","0","0","0","First occurrence","0","","","","","","","The incidence of both non-melanoma and melanoma skin cancers has been increasing over the past decades. Currently, between 2 and 3 million non-melanoma skin cancers and 132,000 melanoma skin cancers occur globally each year. In this study, we proposed an ensemble CNNs for multi-class classification study based on integration of image preprocess, deep learning and risk management on skin cancer dermoscopy images with Meta-data. We basically demonstrate general stacking ensemble flow by stages from data preprocessing, CNNs grouping, Meta-data concatenating and 1st CNNs ensemble and 2nd meta-classifiers ensemble. Our result showed good performance, especially the contribution from 1st ensemble while we check break-down details. With our 5% holdout validation dataset, we saw accuracy maximum 91% in our ensemble model, compared with best single CNN (DenseNet121) 87.3%. Furthermore, we also introduced cost adjustment analysis in ensemble phase to manipulate different risk management trade-off strategy for specific categories or metrics, rather than in deep learning phase, so that no need to retrain CNN via loss function adjustment.  © 2020 IEEE.","10.1109/ICS51289.2020.00055","CNN; Dermoscopy image; Ensemble; Melanoma; Meta data; Skin Cancer; Transfer Learning","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102184662&doi=10.1109%2fICS51289.2020.00055&partnerID=40&md5=f2d5e14202f2e381e778480efac52cfd"
"Augmented deep learning architecture to effectively segment the cancerous regions in biomedical images","Tripathi S.; Verma A.; Sharma N.","2020","0","1","0","0","0","First occurrence","0","","","","","","","The segmentation of cancerous region is most crucial task in biomedical image processing. The detection of cancerous tissues in early stage is essential for planning the treatment of cancer. In this manuscript, we proposes a modified deep learning architecture for efficient segmentation of biomedical images. Our proposed network effectively Figure out the boundaries of the cancerous region. The network once trained produced exceedingly good results on other datasets without retraining. The evaluation metrics mIoU and BF score shows an improvement of 2.5% and 3% for brain tumour segmentation when trained network is tested on other dataset. Improvement of 2% in both the metrics was achieved for skin lesion segmentation when trained network was tested on other dataset for 100 epochs of training. © 2020 IEEE.","10.1109/iSSSC50941.2020.9358876","Brain Tumour; Deep Learning; Medical Image Segmentation; Skin Lesion","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102443238&doi=10.1109%2fiSSSC50941.2020.9358876&partnerID=40&md5=f1035dde9b2d0b4d2b0f54cee3207ae6"
"Computer-aided diagnosis for burnt skin images using deep convolutional neural network","Khan F.A.; Butt A.U.R.; Asif M.; Ahmad W.; Nawaz M.; Jamjoom M.; Alabdulkreem E.","2020","1","0","0","0","0","First occurrence","0","","","","","","","Numerous patients died every year due to the leading causes of deaths all over the world and burn injuries are one of them. Burn injury cases are most viewed in low and middle-income countries (LMIC). Researchers show great interest to classify the burn into different depths through digital means. In Pakistan, at provisional level, it’s really a significant issue to categorize the burn and its depths due to the non-availability of expert doctors and surgeons; hence the decision for the correct first treatment can't be made, so this may cause a serious issue later on. The main objectives of this research work are to segment the burn wounds and classification of burn depths into 1st, 2nd and 3rd degrees respectively. A real-time dataset of burnt patients has been collected from the burn unit of Allied Hospital Faisalabad, Pakistan. The dataset used for this research task contains 450 images of all the three levels of burn depths. Segmentation of the burnt area was done by the use of Otsu's method of thresholding and feature vector was obtained through the use of statistical methods. We have used the Deep Convolutional Neural Network (DCNN) to estimate the burn depths. The network was trained by 65 percent of the images and the remaining 35 percent images were used for testing the accuracy of the classifier. The maximum average accuracy obtained by using the Deep Convolutional Neural Network (DCNN) classifier is reported round about 79.4% and these results are the best if we compare them with previous results. From the obtained results of this research work, non-expert doctors will be able to apply the correct first treatment for the quality evaluation of burn depths. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","10.1007/s11042-020-08768-y","Burnt skin images; CAD; Classification; DCNN; Feature extraction; Image enhancement; Image mining; Segmentation","34","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082717076&doi=10.1007%2fs11042-020-08768-y&partnerID=40&md5=5d7351326114b85a1e52924c583c697c"
"Assessment of skin barrier function using skin images with topological data analysis","Koseki K.; Kawasaki H.; Atsugi T.; Nakanishi M.; Mizuno M.; Naru E.; Ebihara T.; Amagai M.; Kawakami E.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Recent developments of molecular biology have revealed diverse mechanisms of skin diseases, and precision medicine considering these mechanisms requires the frequent objective evaluation of skin phenotypes. Transepidermal water loss (TEWL) is commonly used for evaluating skin barrier function; however, direct measurement of TEWL is time-consuming and is not convenient for daily clinical practice. Here, we propose a new skin barrier assessment method using skin images with topological data analysis (TDA). TDA enabled efficient identification of structural features from a skin image taken by a microscope. These features reflected the regularity of the skin texture. We found a significant correlation between the topological features and TEWL. Moreover, using the features as input, we trained machine-learning models to predict TEWL and obtained good accuracy (R2 = 0.524). Our results suggest that assessment of skin barrier function by topological image analysis is promising. © 2020, The Author(s).","10.1038/s41540-020-00160-8","","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097786911&doi=10.1038%2fs41540-020-00160-8&partnerID=40&md5=5802871809f4dd496ea65486fbb76619"
"Dermoscopic image lesion segmentation method based on deep separable convolutional network; [基于深度可分离卷积网络的皮肤镜图像病灶分割方法]","Cui W.; Zhang P.; Shao H.","2020","0","1","0","0","0","Unique","0","","","","","","","Aiming at the problem of the difficulty in locating the lesions in dermoscopic images and achieving precise segmentation of the lesions, a method of lesion segmentation in dermatological images based on deep separable convolutional network was proposed. Firstly, perform the black frame removal and hair removal processing on the dermoscopic image to remove the artificial and natural noise that hinders the location of the lesion in the image. Then the image after the noise reduction process was deformed and rotated to expand the data set. Finally, a encoder-decoder segmentation model based on depth separable convolution and hole convolution was constructed. The coding part extracts the features of the image, and the decoding part fuses the feature maps and restores the image details. Experimental results show that this method can achieve better segmentation results for the problem of skin disease image lesion segmentation. The accuracy of segmenting lesions reaches 95.24%. Compared with the segmentation model U-Net, the accuracy is improved by 6.17%. © 2020 Beijing Xintong Media Co., Ltd. All Rights Reserved.","10.11959/j.issn.2096-6652.202041","deep separable convolution; dermoscopic image; encoder-decoder model; hole convolution; lesion segmentation","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132392328&doi=10.11959%2fj.issn.2096-6652.202041&partnerID=40&md5=c0e5d6e4cacfbe107747d86a4b756186"
"Melanoma and Nevi Classification using Convolution Neural Networks","Grove R.; Green R.","2020","0","1","0","0","0","Unique","0","","","","","","","Early identification of melanoma skin cancer is vital for the improvement of patients' prospects of five year disease free survival. The majority of malignant skin lesions present at a general practice level where a diagnosis is based on a clinical decision algorithm. As a false negative diagnosis is an unacceptable outcome, clinical caution tends to result in a low positive predictive value of as low at 8%. There has been a large burden of surgical excisions that retrospectively prove to have been unnecessary.This paper proposes a method to identify melanomas in dermoscopic images using a convolution neural network (CNN). The proposed method implements transfer learning based on the ResNet50 CNN, pretrained using the ImageNet dataset. Datasets from the ISIC Archive were implemented during training, validation and testing. Further tests were performed on a smaller dataset of images taken from the Dermnet NZ website and from recent clinical cases still awaiting histological results to indicate the trained network's ability to generalise to real cases. The 86% test accuracy achieved with the proposed method was comparable to the results of prior studies but required significantly less pre-processing actions to classify a lesion and was not dependant on consistent image scaling or the presence of a scale on the image. This method also improved on past research by making use of all of the information present in an image as opposed to focusing on geometric and colour-space based aspects independently.  © 2020 IEEE.","10.1109/IVCNZ51579.2020.9290736","classification; identification; melanoma; ResNet50","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099435088&doi=10.1109%2fIVCNZ51579.2020.9290736&partnerID=40&md5=ad67d58ff36fe95d3ab121f4b9fec784"
"EOCNet:Improving Edge Omni-scale Convolution Networks for Skin Lesion Segmentation","Ma R.; Zhang S.; Gan C.; Zhao H.","2020","1","1","0","0","0","First occurrence","0","","","","","","","What makes medical imaging detection based on artificial intelligence detection, segmentation and classification to help doctors better diagnose skin cancers particularly important. Due to the different shape, size, structure, occluding hair and skin pigmentation of the lesion area, the lesion segmentation of skin cancer is challenging. We introduce a remarkably I mproving edge segmentation CNN named Edge Omni-scale Convolution Networks (EOCNet), which is represented as an encoder-decoder network. The encoder network is based on ResNet-50. The feature boundary Omni-scale module fused with the last three layers of Resnet-50 is used for the decoder. Experiments on Skin Lesion segmentation dataset achieve excellent performance.  © 2020 ACM.","10.1145/3441369.3441377","Convolutional neural network; Edge feature fusion; Omni-scale upsampling module","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103616032&doi=10.1145%2f3441369.3441377&partnerID=40&md5=ebe6c1a0532c0a8ebfbcad2a34f7471d"
"Skin Lesion Segmentation based on Integrating EfficientNet and Residual block into U-Net Neural Network","Nguyen D.K.; Tran T.-T.; Nguyen C.P.; Pham V.-T.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Skin lesion segmentation is an important step in computer aided diagnosis for automated melanoma diagnosis. However, in the field of medical images analysis, skin lesion segmentation from dermoscopic images is stilla challenging task be-cause of presence of various artifacts, blurring and irregular edges of the lesion. This paper proposes an efficient deep learning-based approach for skin lesion segmentation. Particularly, the paper proposes an improved version of the U-Net to perform skin lesion segmentation tasks. To this end, we propose to utilize Effi-cientNetB4 in encoder part of the original U-Net. In addition, the decoder part of the proposed network is constructed by residual block from Resnet architecture. By this way, the proposed approach could take advantages of the EfficientNet and Resnet architectures such as preserving efficient reception field size for the model, and avoiding the overfitting problem. The proposed approach is applied to segment images from ISIC 2017 and 2018 datasets. Experimental results show the desired performances of the proposed approach in terms of metrics of Dice coefficient and Jaccard indexes. © 2020 IEEE.","10.1109/GTSD50082.2020.9303084","Deep learning; Deep neural networks; Image segmentation; Skin cancer; Skin lesion segmentation","35","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099478829&doi=10.1109%2fGTSD50082.2020.9303084&partnerID=40&md5=944094ddba2bd223a80227a8c36aa489"
"Open Set Deep Networks Based on Extreme Value Theory (EVT) for Open Set Recognition in Skin Disease Classification","Yasin Y.; Rumala D.J.; Purnomo M.H.; Ratna A.A.P.; Hidayati A.N.; Nurtanio I.; Rachmadi R.F.; Purnama I.K.E.","2020","1","1","0","0","0","First occurrence","0","","","","","","","A computerized skin disease classification system generally works on closed-set data, meaning images from unknown classes will still be classified as one of the known classes. In the Teledermatology system, skin disease classes are usually defined before the training process. However, in the real world application, it may receive images that belong to a new class or disease. To avoid misclassification, we have implemented the Extreme Value Theory of Weibull distribution function for out of distribution detection and incorporated the OpenMax layer to the deep networks for open-set recognition in skin disease classification. The system can classify seven classes of common skin disease in Indonesia with an accuracy of 71.64% using Inception v3 for closed-set data, while it achieved an accuracy of 83.33% for open-set recognition. The result indicates that the proposed method in this study has reached the purpose of recognizing open-set data in skin disease classification. © 2020 IEEE.","10.1109/CENIM51130.2020.9297994","Deep Learning; Extreme Value Theory; Image Classification; Open Set Recognition; Skin Disease","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099647969&doi=10.1109%2fCENIM51130.2020.9297994&partnerID=40&md5=11a26b23f19fe0416180a77490373e4e"
"Classification of Skin Disease from Skin images using Transfer Learning Technique","Janoria H.; Minj J.; Patre P.","2020","1","1","0","0","0","Unique","0","","","","","","","Skin Diseases are one of the most common ailments in today's era. Due to skin disease some small circular or random shaped area can be seen on the patient's skin. This disease may be very dangerous in some situations when it converts to skin cancer. Here in this article, some deep learning-based approaches were discussed which can be used to extract features from the different skin cancer images, and then these features are used to detect the type of skin disease using some machine learning classifiers. For our experiments, a transfer learning model is developed in which, for feature extraction the VGG- 16 layer CNN architecture can extract 1000 features from the input image and, for the classification purpose, and used a support vector machine, decision tree, linear discriminate analysis, and K-Nearest Neighbor algorithm as they are best suited for linear classification. The experiments have been performed on well known public datasets of ISIC. The experimental results show that the highest accuracy of 99% was achieved by using the VGG 16 CNN model with the K-Nearest Neighbor algorithm. © 2020 IEEE.","10.1109/ICECA49313.2020.9297567","Convolutional Neural Network; Deep Learning; Melanoma; Skin Lesion; Support Vector Machine; Transfer Learning","27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099553180&doi=10.1109%2fICECA49313.2020.9297567&partnerID=40&md5=3c3566ef7528b386eb30acb880189a7a"
"Assessment of deep neural networks for the diagnosis of benign and malignant skin neoplasms in comparison with dermatologists: A retrospective validation study","Han S.S.; Moon I.J.; Kim S.H.; Na J.-I.; Kim M.S.; Park G.H.; Park I.; Kim K.; Lim W.; Lee J.H.; Chang S.E.","2020","1","1","0","0","0","Unique","0","","","","","","","Background The diagnostic performance of convolutional neural networks (CNNs) for diagnosing several types of skin neoplasms has been demonstrated as comparable with that of dermatologists using clinical photography. However, the generalizability should be demonstrated using a large-scale external dataset that includes most types of skin neoplasms. In this study, the performance of a neural network algorithm was compared with that of dermatologists in both real-world practice and experimental settings. Methods and findings To demonstrate generalizability, the skin cancer detection algorithm (https://rcnn. modelderm.com) developed in our previous study was used without modification. We conducted a retrospective study with all single lesion biopsied cases (43 disorders; 40,331 clinical images from 10,426 cases: 1,222 malignant cases and 9,204 benign cases); mean age (standard deviation [SD], 52.1 [18.3]; 4,701 men [45.1%]) were obtained from the Department of Dermatology, Severance Hospital in Seoul, Korea between January 1, 2008 and March 31, 2019. Using the external validation dataset, the predictions of the algorithm were compared with the clinical diagnoses of 65 attending physicians who had recorded the clinical diagnoses with thorough examinations in real-world practice. In addition, the results obtained by the algorithm for the data of randomly selected batches of 30 patients were compared with those obtained by 44 dermatologists in experimental settings; the dermatologists were only provided with multiple images of each lesion, without clinical information. With regard to the determination of malignancy, the area under the curve (AUC) achieved by the algorithm was 0.863 (95% confidence interval [CI] 0.852–0.875), when unprocessed clinical photographs were used. The sensitivity and specificity of the algorithm at the predefined high-specificity threshold were 62.7% (95% CI 59.9–65.1) and 90.0% (95% CI 89.4–90.6), respectively. Furthermore, the sensitivity and specificity of the first clinical impression of 65 attending physicians were 70.2% and 95.6%, respectively, which were superior to those of the algorithm (McNemar test; p < 0.0001). The positive and negative predictive values of the algorithm were 45.4% (CI 43.7–47.3) and 94.8% (CI 94.4–95.2), respectively, whereas those of the first clinical impression were 68.1% and 96.0%, respectively. In the reader test conducted using images corresponding to batches of 30 patients, the sensitivity and specificity of the algorithm at the predefined threshold were 66.9% (95% CI 57.7–76.0) and 87.4% (95% CI 82.5–92.2), respectively. Furthermore, the sensitivity and specificity derived from the first impression of 44 of the participants were 65.8% (95% CI 55.7–75.9) and 85.7% (95% CI 82.4–88.9), respectively, which are values comparable with those of the algorithm (Wilcoxon signed-rank test; p = 0.607 and 0.097). Limitations of this study include the exclusive use of high-quality clinical photographs taken in hospitals and the lack of ethnic diversity in the study population. Conclusions Our algorithm could diagnose skin tumors with nearly the same accuracy as a dermatologist when the diagnosis was performed solely with photographs. However, as a result of limited data relevancy, the performance was inferior to that of actual medical examination. To achieve more accurate predictive diagnoses, clinical information should be integrated with imaging information. © 2020 Han et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","10.1371/journal.pmed.1003381","","37","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096809332&doi=10.1371%2fjournal.pmed.1003381&partnerID=40&md5=51d0dfa1bb4630abf473fcf38f77eaa4"
"Automated diagnosis of skin cancer for healthcare: Highlights and procedures","Wahba M.A.; Ashour A.S.","2020","1","1","0","0","0","First occurrence","0","","","","","","","This chapter outlines the framework of the automated dermoscopy-based skin cancer diagnostic systems by highlighting the main approaches that are commonly followed throughout the different processes of the system. It introduces the dermoscopic-based features which are derived from clinical rules, such as the ABCD rule, Menzies method and the 7-point checklist to diagnose the malignancy of a lesion. The ABCD rule differentiates between malignant melanomas and the benign nevus through main criteria which are the asymmetry (A), the border irregularity (B), the color variations (C), and the diameter or differential structures (D). Subsequently, the chapter discusses the feature selection process, along with some of its techniques. The different classifiers that were adopted in the context of dermoscopy-based skin cancer classification are reported. Finally, the chapter discusses the evaluation criteria of the classifier's performance. © 2021 John Wiley & Sons Ltd.","","Automated skin cancer diagnostic system; Computer-aided skin cancer classification systems; Flat model classifier; Malignant melanomas; Menzies method","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147722207&partnerID=40&md5=816cbc3cdda1dfa4c084464e5e2191eb"
"Semi-Supervised Medical Image Classification With Relation-Driven Self-Ensembling Model","Liu Q.; Yu L.; Luo L.; Dou Q.; Heng P.A.","2020","0","1","0","0","0","First occurrence","0","","","","","","","Training deep neural networks usually requires a large amount of labeled data to obtain good performance. However, inmedical image analysis, obtaining high-quality labels for the data is laborious and expensive, as accurately annotating medical images demands expertise knowledge of the clinicians. In this paper, we present a novel relation-driven semi-supervised framework for medical image classification. It is a consistency-based method which exploits the unlabeled data by encouraging the prediction consistency of given input under perturbations, and leverages a self-ensembling model to produce high-quality consistency targets for the unlabeled data. Considering that human diagnosis often refers to previous analogous cases to make reliable decisions, we introduce a novel sample relation consistency (SRC) paradigm to effectively exploit unlabeled data by modeling the relationship information among different samples. Superior to existing consistency-based methods which simply enforce consistency of individual predictions, our framework explicitly enforces the consistency of semantic relation among different samples under perturbations, encouraging the model to explore extra semantic information from unlabeled data. We have conducted extensive experiments to evaluate our method on two public benchmark medical image classification datasets, i.e., skin lesion diagnosis with ISIC 2018 challenge and thorax disease classification with ChestX-ray14. Our method outperforms many stateof- the-art semi-supervised learning methods on both single-label and multi-label image classification scenarios. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","10.1109/TMI.2020.2995518","medical image classification; sample relation modelling; self-ensembling model; Semi-supervised learning","270","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092925209&doi=10.1109%2fTMI.2020.2995518&partnerID=40&md5=e66c0d132bbff9ddf85b4a8ac6d1e1e8"
"Artificial Intelligence in Dermatology: A Practical Introduction to a Paradigm Shift","Eapen B.R.","2020","0","1","0","0","0","Unique","0","","","","","","","Artificial Intelligence (AI) has surpassed dermatologists in skin cancer detection, but dermatology still lags behind radiology in its broader adoption. Building and using AI applications are becoming increasingly accessible. However, complex use cases may still require specialized expertise for design and deployment. AI has many applications in dermatology ranging from fundamental research, diagnostics, therapeutics, and cosmetic dermatology. The lack of standardization of images and privacy concerns are the foremost challenges stifling AI adoption. Dermatologists have a significant role to play in standardized data collection, curating data for machine learning, clinically validating AI solutions, and ultimately adopting this paradigm shift that is changing the way we practice. © 2020 Indian Dermatology Online Journal | Published by Wolters Kluwer - Medknow.","10.4103/idoj.IDOJ_388_20","Artificial intelligence; machine learning; neural networks","29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102130241&doi=10.4103%2fidoj.IDOJ_388_20&partnerID=40&md5=79fc41c52ef9033b146b065cd812fc0f"
"Overdiagnosis of melanoma – causes, consequences and solutions","Kutzner H.; Jutzi T.B.; Krahl D.; Krieghoff-Henning E.I.; Heppt M.V.; Hekler A.; Schmitt M.; Maron R.C.R.; Fröhling S.; von Kalle C.; Brinker T.J.","2020","0","1","0","0","0","Unique","0","","","","","","","Malignant melanoma is the skin tumor that causes most deaths in Germany. At an early stage, melanoma is well treatable, so early detection is essential. However, the skin cancer screening program in Germany has been criticized because although melanomas have been diagnosed more frequently since introduction of the program, the mortality from malignant melanoma has not decreased. This indicates that the observed increase in melanoma diagnoses be due to overdiagnosis, i.e. to the detection of lesions that would never have created serious health problems for the patients. One of the reasons is the challenging distinction between some benign and malignant lesions. In addition, there may be lesions that are biologically equivocal, and other lesions that are classified as malignant according to current criteria, but that grow so slowly that they would never have posed a threat to patient’s life. So far, these “indolent” melanomas cannot be identified reliably due to a lack of biomarkers. Moreover, the likelihood that an in-situ melanoma will progress to an invasive tumor still cannot be determined with any certainty. When benign lesions are diagnosed as melanoma, the consequences are unnecessary psychological and physical stress for the affected patients and incurred therapy costs. Vice versa, underdiagnoses in the sense of overlooked melanomas can adversely affect patients’ prognoses and may necessitate more intense therapies. Novel diagnostic options could reduce the number of over- and underdiagnoses and contribute to more objective diagnoses in borderline cases. One strategy that has yielded promising results in pilot studies is the use of artificial intelligence-based diagnostic tools. However, these applications still await translation into clinical and pathological routine. © 2020 Deutsche Dermatologische Gesellschaft (DDG). Published by John Wiley & Sons Ltd.","10.1111/ddg.14233","","31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089784363&doi=10.1111%2fddg.14233&partnerID=40&md5=d325f770cb9ffc75a67ca791288332f8"
"Efficient fusion of handcrafted and pre-trained CNNs features to classify melanoma skin cancer","Filali Y.; EL Khoukhi H.; Sabri M.A.; Aarab A.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Skin cancer is one of the most aggressive cancers in the world. Computer-Aided Diagnosis (CAD) system for cancer detection and classification is a top-rated solution that decreases human effort and time with very high classification accuracy. Machine learning (ML) and deep learning (DL) based approaches have been widely used to develop robust skin-lesion classification systems. Each of the techniques excels when the other fails. Their performances are closely related to the size of the learning dataset. Thus, approaches that are based on the ML are less potent than those found on the DL when working with large datasets and vice versa. In this article, we propose a powerful skin-lesion classification approach based on a fusion of handcrafted features (shape, skeleton, color, and texture) and features extracted from most powerful DL architectures. This combination will make it possible to remedy the limitations of both the ML and DL approaches for the case of large and small datasets. Features engineering is then applied to remove redundant features and to select only relevant features. The proposed approach is validated and tested on both small and large datasets. A comparative study is also conducted to compare the proposed approach with different and recent approaches applied to each dataset. The results obtained show that this features-fusion based approach is very promising and can effectively combine the power of ML and DL based approaches. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","10.1007/s11042-020-09637-4","CNNs; Features fusion; Genetic algorithm; Handcrafted features; Melanoma; Skin cancer","55","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089601722&doi=10.1007%2fs11042-020-09637-4&partnerID=40&md5=58953fb458c73a9bc6b70b8c1a3b0238"
"Experiments using deep learning for dermoscopy image analysis","Vasconcelos C.N.; Vasconcelos B.N.","2020","0","1","0","0","0","Unique","0","","","","","","","Skin cancer is a major public health problem, as is the most common type of cancer and represents more than half of cancer diagnosed worldwide. Early detection influences the outcome of the disease and motivates the research presented in this paper. Recent results show that deep learning based approaches learn from data, and can outperform human specialists in a set of tasks when large databases are available for training. This research investigates the scenario where the amount of data available for training is small. It obtains relevant results for the ISBI 2016 melanoma classification challenge (named Skin Lesion Analysis for Melanoma Detection) facing the peculiarities of dealing with such a small and unbalanced biological database. To do this, it explores committees of Deep Convolutional Neural Networks (DCNN), the augmentation of the training data set by image processing classical transforms and by deformations guided by expert knowledge about the lesion axis, and it introduces a third class aiming to improve the classifiers’ distinction of the region of interest of the lesion. The experiments show that the proposed approach improves the final classifier invariance for common melanoma variations, common skin patterns and markers, and dermatoscope capturing conditions. © 2017 Elsevier B.V.","10.1016/j.patrec.2017.11.005","Convolutional neural networks; Data augmentation; Deep learning; Dermoscopy image analysis; Lesion dermoscopic feature extraction and classification; Skin lesion classification","50","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035799257&doi=10.1016%2fj.patrec.2017.11.005&partnerID=40&md5=f1f6ddcd2b2d019e0472d534335a79ee"
"Self-supervised learning to increase the performance of skin lesion classification","Kwasigroch A.; Grochowski M.; Mikołajczyk A.","2020","1","1","0","0","0","Unique","0","","","","","","","To successfully train a deep neural network, a large amount of human-labeled data is required. Unfortunately, in many areas, collecting and labeling data is a difficult and tedious task. Several ways have been developed to mitigate the problem associated with the shortage of data, the most common of which is transfer learning. However, in many cases, the use of transfer learning as the only remedy is insufficient. In this study, we improve deep neural models training and increase the classification accuracy under a scarcity of data by the use of the self-supervised learning technique. Self-supervised learning allows an unlabeled dataset to be used for pretraining the network, as opposed to transfer learning that requires labeled datasets. The pretrained network can be then fine-tuned using the annotated data. Moreover, we investigated the effect of combining the self-supervised learning approach with transfer learning. It is shown that this strategy outperforms network training from scratch or with transfer learning. The tests were conducted on a very important and sensitive application (skin lesion classification), but the presented approach can be applied to a broader family of applications, especially in the medical domain where the scarcity of data is a real problem. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/electronics9111930","Computer vision; Deep learning; Malignant melanoma; Medical screening; Neural networks; Self-supervised learning; Skin lesion","28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096174591&doi=10.3390%2felectronics9111930&partnerID=40&md5=42a00d2c7b0c58745470cebbd866238d"
"A systematic overview of recent methods for non-contact chronic wound analysis","Marijanović D.; Filko D.","2020","0","1","0","0","0","Unique","0","","","","","","","Chronic wounds or wounds that are not healing properly are a worldwide health problem that affect the global economy and population. Alongside with aging of the population, increasing obesity and diabetes patients, we can assume that costs of chronic wound healing will be even higher. Wound assessment should be fast and accurate in order to reduce the possible complications, and therefore shorten the wound healing process. Contact methods often used by medical experts have drawbacks that are easily overcome by non-contact methods like image analysis, where wound analysis is fully or partially automated. Two major tasks in wound analysis on images are segmentation of the wound from the healthy skin and background, and classification of the most important wound tissues like granulation, fibrin, and necrosis. These tasks are necessary for further assessment like wound measurement or healing evaluation based on tissue representation. Researchers use various methods and algorithms for image wound analysis with the aim to outperform accuracy rates and show the robustness of the proposed methods. Recently, neural networks and deep learning algorithms have driven considerable performance improvement across various fields, which has a led to a significant rise of research papers in the field of wound analysis as well. The aim of this paper is to provide an overview of recent methods for non-contact wound analysis which could be used for developing an end-to-end solution for a fully automated wound analysis system which would incorporate all stages from data acquisition, to segmentation and classification, ending with measurement and healing evaluation. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/app10217613","3D reconstruction; Chronic wounds; Healing evaluation; Imaging; Tissue classification; Wound measurement; Wound segmentation","29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094653193&doi=10.3390%2fapp10217613&partnerID=40&md5=ceb5cfdc79b4bd0162d000e0ef340235"
"ARTIFICIAL INTELLIGENT SYSTEM for SKIN DISEASES CLASSIFICATION","Mohammed K.K.; Afify H.M.; Hassanien A.E.","2020","1","1","0","0","0","Unique","0","","","","","","","In this paper, an artificial intelligent technique is proposed for skin disease detection and classification. The suggested method comprises four stages, including segmentation, extraction of textural features, and classification. The stretch-based enhanced algorithm has been adapted for image enhancement. Then the method of an active contour is used for segmentation to determine the skin lesion in tissue. Textural features are obtained from the segmented skin lesion. As several numbers of the features can affect the classification precision, ideal feature selection is made to exclude features that are less informative and unnecessary. The feature selection is adjusted with a regularized random forest. Finally, the classification algorithms by support vector machine and a back-propagation neural network (BPNN) are implemented. The dataset consists of 400 dermoscopic images in total divided into 200 benign and 200 malignant skin diseases extracted from the dermoscopic images PH2 database. The result of detecting and classifying the dermoscopic images on these images yielded an accuracy of 99.7%, a sensitivity of 99.4%, and a specificity of 100% by BPNN. The experiential results confirmed that the BPNN classifier is best rather than an SVM classifier for skin disease images. This proposed model will be advanced to support the skin image processing techniques that provided a more accurate diagnosis and rapid treatment plan.  © 2020 National Taiwan University.","10.4015/S1016237220500362","Active contour segmentation; back-propagation neural network; Regularized random forest; Skin cancer; support vector machine","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094944667&doi=10.4015%2fS1016237220500362&partnerID=40&md5=c67437d6d04ee69a8e350c6b383633fc"
"Comparison of machine learning methods in stochastic skin optical model inversion","Annala L.; Äyrämö S.; Pölönen I.","2020","1","1","0","0","0","Unique","0","","","","","","","In this study, we compare six different machine learning methods in the inversion of a stochastic model for light propagation in layered media, and use the inverse models to estimate four parameters of the skin from the simulated data: melanin concentration, hemoglobin volume fraction, and thicknesses of epidermis and dermis. The aim of this study is to determine the best methods for stochastic model inversion in order to improve current methods in skin related cancer diagnostics and in the future develop a non-invasive way to measure the physical parameters of the skin based partially on the results of the study. Of the compared methods, which are convolutional neural network, multi-layer perceptron, lasso, stochastic gradient descent, and linear support vector machine regressors, we find the convolutional neural network to be the most accurate in the inversion task. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/app10207097","Convolutional neural network; Machine learning; Model inversion; Neural networks; Physical parameter retrieval; Skin","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092782223&doi=10.3390%2fapp10207097&partnerID=40&md5=be3e8c481581811abb1fea4425b516fe"
"Attentive boundary aware network for multi-scale skin lesion segmentation with adversarial training","Wei Z.; Shi F.; Song H.; Ji W.; Han G.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Because of the large variation in appearance, the existence of artifacts, the low contrast, skin lesion segmentation remains a challenging task. In this paper, we propose a novel Scale Attention based Atrous Spatial Pyramid Pooling (Scale-Att-ASPP) module for skin lesion segmentation with attentive boundary aware. Our network is based on the Generative Adversarial Network (GAN), which includes the segmentation network and the critic network. In the segmentation network, we design the Scale-Att-ASPP module to automatically select the optimal scale of the skin lesion feature of the intermediate convolution layer (Inter-CL) in the encoding path, meanwhile, the irrelevant artifacts features are automatically diminished without using complex pre-processing. After introducing the output of the Scale-Att-ASPP module to the same level layer in the decoding path through skip connection in pixel-wise addition way, the more meaningful semantic segmentation is gained. The Jaccard distance loss is employed to solve the problem of label imbalance in skin lesion segmentation. Our network is adversarially trained on ISBI 2017 dataset by the multi-scale L1 loss introduced by the critic network, which guides the Scale-Att-ASPP module learning to focus on the optimal scale of the skin lesion feature. Finally, our network significantly improves the segmentation performance compared with other state-of-the-art methods, especially for the JAC and SEN scores. Besides, our proposed network works efficiently and shows robustness for different datasets. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","10.1007/s11042-020-09334-2","ASPP; Attention; GAN; Multi-scale; Skin lesion segmentation","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088396388&doi=10.1007%2fs11042-020-09334-2&partnerID=40&md5=ba33fe89109821241d2c6d02c606854c"
"A survey on U-shaped networks in medical image segmentations","Liu L.; Cheng J.; Quan Q.; Wu F.-X.; Wang Y.-P.; Wang J.","2020","0","1","0","0","0","Unique","0","","","","","","","The U-shaped network is one of the end-to-end convolutional neural networks (CNNs). In electron microscope segmentation of ISBI challenge 2012, the concise architecture and outstanding performance of the U-shaped network are impressive. Then, a variety of segmentation models based on this architecture have been proposed for medical image segmentations. We present a comprehensive literature review of U-shaped networks applied to medical image segmentation tasks, focusing on the architectures, extended mechanisms and application areas in these studies. The aim of this survey is twofold. First, we report the different extended U-shaped networks, discuss main state-of-the-art extended mechanisms, including residual mechanism, dense mechanism, dilated mechanism, attention mechanism, multi-module mechanism, and ensemble mechanism, analyze their pros and cons. Second, this survey provides the overview of studies in main application areas of U-shaped networks, including brain tumor, stroke, white matter hyperintensities (WMHs), eye, cardiac, liver, musculoskeletal, skin cancer, and neuronal pathology. Finally, we summarize the current U-shaped networks, point out the open challenges and directions for future research. © 2020 Elsevier B.V.","10.1016/j.neucom.2020.05.070","Convolutional neural networks; Extended mechanism; Medical image segmentation; U-shaped network","248","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086428956&doi=10.1016%2fj.neucom.2020.05.070&partnerID=40&md5=1558a4b0b1cc32bc59310997cf7a81b6"
"Analysis and Classification of Skin Cancer Images using Convolutional Neural Network Approach","Zaman K.; Bangash J.I.; Maghdid S.S.; Hassan S.; Afridi H.; Zohaib M.","2020","1","1","0","0","0","First occurrence","0","","","","","","","In this modern era skin cancer is a serious problem around the globe and so it is the age of technology and it is important to solve this problem through intelligence machines which using different algorithms rather than conventional method. Intelligent machine using different algorithms to classify the skin cancer images in a reliable way to save effort, time and ease human life. For this purpose, deep learning (CNN) algorithm is used by intelligent machine to classify the skin cancer images according to its types. In this current research work there are three types of skin cancer types name is Basal cell Carcinoma (BBC), Melanocytic Nevus (NV) and Vascular Lesion (VASC) are used. The study showed that implementing deep learning in the field of cancer diseases may be the most appropriate way to classify and recognize the images of skin cancer according to their type, which can be very useful in the field of medicine for early diagnosis and improve the exact result of the diagnosis. This current work has shown and produced results with 98.89% accuracy. © 2020 IEEE.","10.1109/ISMSIT50672.2020.9255356","Convolutional Neural Network; Deep Learning; Machine Learning; Skin Cancer","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097672310&doi=10.1109%2fISMSIT50672.2020.9255356&partnerID=40&md5=a0414493a2ff27a5d87b3a1778600f43"
"A GAN-based image synthesis method for skin lesion classification","Qin Z.; Liu Z.; Zhu P.; Xue Y.","2020","1","1","0","0","0","Unique","0","","","","","","","Background and Objective: There are many types of skin cancer, and melanoma is the most lethal one. Dermoscopy is an important imaging technique to screen melanoma and other skin lesions. However, Skin lesion classification based on computer-aided diagnostic techniques is a challenging task owing to the scarcity of labeled data and class-imbalanced dataset. It is necessary to apply data augmentation technique based on generative adversarial networks (GANs) to skin lesion classification for helping dermatologists in more accurate diagnostic decisions. Methods: A whole process of using GAN-based data augmentation technology to improve the skin lesion classification performance has been established in this article. First of all, the skin lesion style-based GANs is proposed according to the basic architecture of style-based GANs. The proposed model modifies the structure of style control and noise input in the original generator, adjusts both the generator and discriminator to efficiently synthesize high-quality skin lesion images. As for image classification, the classifier is constructed on the pretrained deep neural network using transfer learning method. The synthetic images from the proposed skin lesion style-based GANs are finally added to the training set to help train the classifier for better classification performance. Results: The proposed skin lesion style-based GAN has been evaluated by Inception Score (IS), Fréchet Inception Distance (FID), Precision and Recall, and is superior to other compared GAN models in these quantitative evaluation metrics. By adding the synthesized images to the training set, the main classification indicators like accuracy, sensitivity, specificity, average precision and balanced multiclass accuracy are 95.2%, 83.2%, 74.3%, 96.6% and 83.1% on the dataset of International Skin Imaging Collaboration (ISIC) 2018 Challenge, which have been improved by 1.6%, 24.4%, 3.6%, 23.2% and 5.6% respectively compared to the CNN model. Conclusions: The proposed skin lesion style-based GANs can generate high-quality skin lesion images efficiently, leading to the performance improvement of the classification model. This work provides a valuable reference for medical image analysis based on deep learning. © 2020 Elsevier B.V.","10.1016/j.cmpb.2020.105568","Data augmentation; Generative adversarial networks; Image synthesis; Skin lesion classification; Transfer learning","215","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086068778&doi=10.1016%2fj.cmpb.2020.105568&partnerID=40&md5=966fca81984b19020791b2b06ce6a42e"
"Computer-aided diagnosis of malignant melanoma using gabor-based entropic features and multilevel neural networks","Bakheet S.; Al-Hamadi A.","2020","0","1","0","0","0","Unique","0","","","","","","","The American Cancer Society has recently stated that malignant melanoma is the most serious type of skin cancer, and it is almost 100% curable, if it is detected and treated early. In this paper, we present a fully automated neural framework for real-time melanoma detection, where a low-dimensional, computationally inexpensive but highly discriminative descriptor for skin lesions is derived from local patterns of Gabor-based entropic features. The input skin image is first preprocessed by filtering and histogram equalization to reduce noise and enhance image quality. An automatic thresholding by the optimized formula of Otsu’s method is used for segmenting out lesion regions from the surrounding healthy skin regions. Then, an extensive set of optimized Gabor-based features is computed to characterize segmented skin lesions. Finally, the normalized features are fed into a trained Multilevel Neural Network to classify each pigmented skin lesion in a given dermoscopic image as benign or melanoma. The proposed detection methodology is successfully tested and validated on the public PH2 benchmark dataset using 5-cross-validation, achieving 97.5%, 100% and 96.87% in terms of accuracy, sensitivity and specificity, respectively, which demonstrate competitive performance compared with several recent state-of-the-art methods. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/diagnostics10100822","Computer-aided diagnosis; Cross-validation; Dermoscopy; Gabor-based entropic features; Level neural network; Melanoma skin cancer; Skin cancer","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092701732&doi=10.3390%2fdiagnostics10100822&partnerID=40&md5=a78edabe57209cfc815498f2721d754c"
"Effective melanoma recognition using deep convolutional neural network with covariance discriminant loss","Guo L.; Xie G.; Xu X.; Ren J.","2020","0","1","0","0","0","Unique","0","","","","","","","Melanoma recognition is challenging due to data imbalance and high intra-class variations and large inter-class similarity. Aiming at the issues, we propose a melanoma recognition method using deep convolutional neural network with covariance discriminant loss in dermoscopy images. Deep convolutional neural network is trained under the joint supervision of cross entropy loss and covariance discriminant loss, rectifying the model outputs and the extracted features simultaneously. Specifically, we design an embedding loss, namely covariance discriminant loss, which takes the first and second distance into account simultaneously for providing more constraints. By constraining the distance between hard samples and minority class center, the deep features of melanoma and non-melanoma can be separated effectively. To mine the hard samples, we also design the corresponding algorithm. Further, we analyze the relationship between the proposed loss and other losses. On the International Symposium on Biomedical Imaging (ISBI) 2018 Skin Lesion Analysis dataset, the two schemes in the proposed method can yield a sensitivity of 0.942 and 0.917, respectively. The comprehensive results have demonstrated the efficacy of the designed embedding loss and the proposed methodology. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/s20205786","Covariance discriminant loss; Deep convolutional neural network; Dermoscopy image; Embedding loss; Melanoma recognition","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093705772&doi=10.3390%2fs20205786&partnerID=40&md5=68832c7c00ff23a45b2466a1bee179f7"
"Classification Cherry's Coffee using k-Nearest Neighbor (KNN) and Artificial Neural Network (ANN)","Anita S.; Albarda","2020","0","1","0","0","0","Unique","0","","","","","","","The quality of coffee is determined from 60% when planted, 30% when roasted and 10% when brewed. This research examines more deeply the process of sorting the coffee cherries using the dry method. The technology that is possible to solve this coffee cherry fruit sorting problem is image processing, this is seen because the current conventional method uses human eyes and hands in sorting. This sorting process aims to separate superior fruit (red, half red, broken red, brown)., black, half black, orange, yellow, and green) of inferior fruit (spotted, moldy, with 1 hole, and more than 1 hole) and coffee cherries (round, oval, broken, perfect).The purpose of this study was to develop a coffee cherry sorting machine technology with faster and more accurate results so that it could replace the conventional coffee cherry sorting process. The coffee cherries are categorized into ripe, undercooked, raw, and damaged cherries using the GLCM (Gray-Level Co-Occurrence Matrix) algorithm for feature extraction and the KNN (k-Nearest Neighbor) and ANN (Artificial Neural Network) classification algorithm. newrb. The success obtained from this research is ANN accuracy of 24.41% and using the KNN method of 72.12%. With the simulation carried out, the coffee cherries classification process with an amount of 1, 885 can be carried out in a total time of 356.02 seconds or the equivalent of 6 minutes. Author identifies indicators of coffee cherries as skin color (red, half red, cracked red, brown, black, half black, orange, yellow, and green), cherri shape (round, oval, broken, perfect), and cherries skin defects (speckled -button, moldy, with 1 hole, and more than 1 hole). It is hoped that the results of this study can serve as a consideration for developing a more advanced national coffee industry.  © 2020 IEEE.","10.1109/ICITSI50517.2020.9264927","ANN; Cherry's coffee; Classification; GLCM; Image processing; KNN; Machine learning; RGB","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099594385&doi=10.1109%2fICITSI50517.2020.9264927&partnerID=40&md5=f49c2a9ccd582de6d81232451c6b2e9d"
"Fast fully automatic skin lesions segmentation probabilistic with Parzen window","Chagas J.V.S.D.; Ivo R.F.; Guimarães M.T.; de A. Rodrigues D.; de S. Rebouças E.; Rebouças Filho P.P.","2020","1","1","0","0","0","Unique","0","","","","","","","Cutaneous melanoma accounts for over 90% of all melanoma, causing up to 55,500 annual deaths. However, it is a potentially curable type of cancer. Since melanoma is potentially curable, the disease's mortality rate is directly linked to late detection. This work proposes an approach that presents the balance between time and efficiency. This paper proposes the method of fast and automatic segmentation of skin lesions using probabilistic characteristics with the Parzen window (SPPW). The results obtained by the method were based on PH2 and ISIC datasets. The SPPW approach reached the following averages between the two datasets Specificity of 98.55%, Accuracy of 95.48%, Dice of 91.12%, Sensitivity of 88.45%, Mattheus of 87.86%, and Jaccard Index of 84.90%. The highlights of the proposed method are its short average segmentation time per image, and its metrics values, which are often higher than the ones obtained by other methods. Therefore, the SPPW method of segmentation is a quick, viable, and easily accessible option to aid in the diagnosis of diseased skin. © 2020 Elsevier Ltd","10.1016/j.compmedimag.2020.101774","Melanoma skin; Parzen window; Probability density","19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089580780&doi=10.1016%2fj.compmedimag.2020.101774&partnerID=40&md5=c11e36802a92e5de2d93b94499d0f04a"
"Skin Lesion Segmentation Based on Deep Learning","Huang C.; Yu Y.; Qi M.","2020","1","1","0","0","0","First occurrence","0","","","","","","","The precise segmentation of the skin pathology area plays an important role in the determination of the skin disease type. This paper proposed the method in Deep learning, Mask R-CNN, to segment skin diseases, and introduced K-means clustering algorithm in the pre-processing of the data set. This method can ensure the accurate labeling of the data set itself, while accurately segmenting the skin pathology area. Experiment results based on ISIC (International Skin Imaging Collaboration) data set with 23906 images demonstrate that the segmentation effect on skin image and the segmentation accuracy of its test results is as high as 91.87%. Further more, It can segment lesions within a given skin image, even in the presence of fuzzy boundaries and complex textures.  © 2020 IEEE.","10.1109/ICCT50939.2020.9295941","Deep learning; K-means Clustering; Mask R-CNN; Skin disease segmentation","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099544323&doi=10.1109%2fICCT50939.2020.9295941&partnerID=40&md5=69149975d28a605ae043b8bcfea199f0"
"An End-to-End Multi-Task Deep Learning Framework for Skin Lesion Analysis","Song L.; Lin J.; Wang Z.J.; Wang H.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Automatic skin lesion analysis of dermoscopy images remains a challenging topic. In this paper, we propose an end-to-end multi-task deep learning framework for automatic skin lesion analysis. The proposed framework can perform skin lesion detection, classification, and segmentation tasks simultaneously. To address the class imbalance issue in the dataset (as often observed in medical image datasets) and meanwhile to improve the segmentation performance, a loss function based on the focal loss and the jaccard distance is proposed. During the framework training, we employ a three-phase joint training strategy to ensure the efficiency of feature learning. The proposed framework outperforms state-of-the-art methods on the benchmarks ISBI 2016 challenge dataset towards melanoma classification and ISIC 2017 challenge dataset towards melanoma segmentation, especially for the segmentation task. The proposed framework should be a promising computer-aided tool for melanoma diagnosis.  © 2013 IEEE.","10.1109/JBHI.2020.2973614","convolution neural networks; deep learning; end-to-end multi-task framework; melanoma segmentation; Skin lesion analysis","126","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092750266&doi=10.1109%2fJBHI.2020.2973614&partnerID=40&md5=3c0e8f8432a21b9659a9e4724a86f00f"
"A comparative study of melanoma skin cancer detection in traditional and current image processing techniques","Sreedhar B.; Swamy M.B.E.; Sunil Kumar M.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Skin cancer is a major health issue in the present day especially melanoma skin cancer. In general most of the skin cancers are cured if they are detectedin the early stage. With the rapid growth of skin cancer, there is a need for an automated computerized diagnosis mechanism of skin cancer in the early stage is required. Many of the skin cancer images have similar visual characteristics. It is an important challenging task to extract the features from the skin cancer images. The automated computerized diagnosis mechanism helps to improve the accurate analysis of skin diseases which helps the dermatologists to accelerate the diagnostic time and improve the better treatment for the patients. This paper mainly presents the comparative study on traditional image processing and current technologies of different image processing techniques for skin cancer image classification, preprocessing techniques, Feature extraction, and image segmentation datasets. © 2020 IEEE.","10.1109/I-SMAC49090.2020.9243501","ABCD rule; Dermoscopy; Image Processing; Melanoma; Skin Cancer","58","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097824829&doi=10.1109%2fI-SMAC49090.2020.9243501&partnerID=40&md5=039a9dbce43a2cd15954ec2516090ded"
"Machine Learning Applications in the Evaluation and Management of Psoriasis: A Systematic Review","Yu K.; Syed M.N.; Bernardis E.; Gelfand J.M.","2020","0","1","0","0","0","Unique","0","","","","","","","Background: Machine learning (ML), a subset of artificial intelligence (AI) that aims to teach machines to automatically learn tasks by inferring patterns from data, holds significant promise to aid psoriasis care. Applications include evaluation of skin images for screening and diagnosis as well as clinical management including treatment and complication prediction. Objective: To summarize literature on ML applications to psoriasis evaluation and management and to discuss challenges and opportunities for future advances. Methods: We searched MEDLINE, Google Scholar, ACM Digital Library, and IEEE Xplore for peer-reviewed publications published in English through December 1, 2019. Our search queries identified publications with any of the 10 computing-related keywords and “psoriasis” in the title and/or abstract. Results: Thirty-three studies were identified. Articles were organized by topic and synthesized as evaluation- or management-focused articles covering 5 content categories: (A) Evaluation using skin images: (1) identification and differential diagnosis of psoriasis lesions, (2) lesion segmentation, and (3) lesion severity and area scoring; (B) clinical management: (1) prediction of complications and (2) treatment. Conclusion: Machine learning has significant potential to aid psoriasis evaluation and management. Current topics popular in ML research on psoriasis are the evaluation of medical images, prediction of complications, and treatment discovery. For patients to derive the greatest benefit from ML advancements, it is helpful for dermatologists to have an understanding of ML and how it can effectively aid their assessments and decision-making. © The Author(s) 2020.","10.1177/2475530320950267","artificial intelligence; dermatology/trends; machine learning; psoriasis; systematic review","40","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090067450&doi=10.1177%2f2475530320950267&partnerID=40&md5=c7e9a47f76d09fc5c0c9eb716fa7c788"
"Skin disease detection and segmentation using dynamic graph cut algorithm and classification through Naive Bayes classifier","Balaji V.R.; Suganthi S.T.; Rajadevi R.; Krishna Kumar V.; Saravana Balaji B.; Pandiyan S.","2020","1","1","0","0","0","Unique","0","","","","","","","The largest organ and the outer covering of the human body is the skin. With seven layers of it covering the other organs inside, skin is one of the important part to take care of. A skin condition is one which affects the integumentary system and that includes a wide variety of diseases including dermatoses. Classifications of these skin conditions are always a challenge for any medical practitioner and they look at the machine learning systems to assist them in predicting and classifying the skin conditions. This in turn will help to cure or at least reduce the effect. If the skin symptoms such as acne, cellulitis, candidiasis, varicella, scleroderma, fungal skin, psoriasis, inflamed skin condition, etc. are left without treatment in its initial stage, then they can effect in different health impediments leading to even death. Image partitioning is a method which supports with the skin disease detection. Any abnormal skin growth is referred to as skin lesion which could either be primary or secondary. Graph cut algorithms are debated and used in the literature for variety of purposes including image smoothing, image segmentation and other problems involving energy minimization as objective. In this work, we intend to use a novel dynamic graph cut algorithm for skin lesion segmentation followed by a probabilistic classifier called as Naïve Bayes classifier for skin disease classification purposes. We have used ISIC 2017 dataset for testing our proposed method and found that the results outperform many state of the art methods including FCN and SegNet by 6.5% and 8.7% respectively. This dataset is available at the International Skin Imaging Collaboration (ISIC) website for public study and experimentation. In terms of accuracy, we could achieve 94.3% for benign cases, 91.2% for melanoma and 92.9% for keratosis on this data set. © 2020 Elsevier Ltd","10.1016/j.measurement.2020.107922","Colour and texture features; Computed tomography; Filtering; Graphs; Sensitivity; Skin lesion; Specificity; Symptoms; Transformation","156","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086435947&doi=10.1016%2fj.measurement.2020.107922&partnerID=40&md5=e7caaf7fbfba65dad3de11bc3f71fbab"
"PAD-UFES-20: A skin lesion dataset composed of patient data and clinical images collected from smartphones","Pacheco A.G.C.; Lima G.R.; Salomão A.S.; Krohling B.; Biral I.P.; de Angelo G.G.; Alves F.C.R., Jr.; Esgario J.G.M.; Simora A.C.; Castro P.B.C.; Rodrigues F.B.; Frasson P.H.L.; Krohling R.A.; Knidel H.; Santos M.C.S.; do Espírito Santo R.B.; Macedo T.L.S.G.; Canuto T.R.P.; de Barros L.F.S.","2020","1","1","0","0","0","Unique","0","","","","","","","Over the past few years, different Computer-Aided Diagnosis (CAD) systems have been proposed to tackle skin lesion analysis. Most of these systems work only for dermoscopy images since there is a strong lack of public clinical images archive available to evaluate the aforementioned CAD systems. To fill this gap, we release a skin lesion benchmark composed of clinical images collected from smartphone devices and a set of patient clinical data containing up to 21 features. The dataset consists of 1373 patients, 1641 skin lesions, and 2298 images for six different diagnostics: three skin diseases and three skin cancers. In total, 58.4% of the skin lesions are biopsy-proven, including 100% of the skin cancers. By releasing this benchmark, we aim to support future research and the development of new tools to assist clinicians to detect skin cancer. © 2020 The Author(s)","10.1016/j.dib.2020.106221","Cancer research; Clinical data; Computer-Aided Diagnosis (CAD); Skin cancer; Skin lesion","182","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090045952&doi=10.1016%2fj.dib.2020.106221&partnerID=40&md5=e5303c190a8720604e1f8b2b2d2ed2c4"
"A multi-class skin Cancer classification using deep convolutional neural networks","Chaturvedi S.S.; Tembhurne J.V.; Diwan T.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Skin Cancer accounts for one-third of all diagnosed cancers worldwide. The prevalence of skin cancers have been rising over the past decades. In recent years, use of dermoscopy has enhanced the diagnostic capability of skin cancer. The accurate diagnosis of skin cancer is challenging for dermatologists as multiple skin cancer types may appear similar in appearance. The dermatologists have an average accuracy of 62% to 80% in skin cancer diagnosis. The research community has been made significant progress in developing automated tools to assist dermatologists in decision making. In this work, we propose an automated computer-aided diagnosis system for multi-class skin (MCS) cancer classification with an exceptionally high accuracy. The proposed method outperformed both expert dermatologists and contemporary deep learning methods for MCS cancer classification. We performed fine-tuning over seven classes of HAM10000 dataset and conducted a comparative study to analyse the performance of five pre-trained convolutional neural networks (CNNs) and four ensemble models. The maximum accuracy of 93.20% for individual model amongst the set of models whereas maximum accuracy of 92.83% for ensemble model is reported in this paper. We propose use of ResNeXt101 for the MCS cancer classification owing to its optimized architecture and ability to gain higher accuracy. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","10.1007/s11042-020-09388-2","Classification; Deep convolutional neural network; Dermoscopy; Skin Cancer","225","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089101122&doi=10.1007%2fs11042-020-09388-2&partnerID=40&md5=690af0a34192a3c49b89e0dace5b775f"
"Progress of residual neural network optimization algorithm for medical imaging disease diagnosis; [医学影像疾病诊断的残差神经网络优化算法研究进展]","Zhou T.; Huo B.; Lu H.; Shi H.","2020","0","1","0","0","0","Unique","0","","","","","","","Residual neural network (ResNet) has gained considerable attention in deep learning research over the last few years and has made great achievements in computer vision. The deep convolutional network represented by ResNet is increasingly used in the field of medical imaging and has achieved good results in the clinical diagnosis, staging, metastasis, treatment decision, and target area delineation of major diseases, such as tumors, cardiovascular and cerebrovascular diseases, and nervous system diseases. The optimization of the ResNet algorithm is an important part of the ResNet research. It largely determines model performance, such as generalization and convergence. This article summarizes the learning optimization of ResNet. First, the optimization of the learning algorithm of ResNet is elaborated, and the six aspects of activation function, loss function, parameter optimization algorithm, learning decay rate algorithm, normalization, and regularization are summarized. Nine improvement methods exist for the activation function; they are sigmoid, tanh, ReLU, PReLU, randomized ReLU, exponential linear units(ELU), softplus function, noisy softplus function, and maxout. The loss function includes 12 types: cross-entropy, mean square, Euclidean distance, contrast, hinge, softmax, L-softmax, A-softmax, L2 softmax, cosine, center, and focus losses. Eight learning rate decay methods, namely, piecewise constant, polynomial, exponential, inverse time, natural exponential, cosine, linear cosine, and noise linear cosine, are summarized. The normalization algorithms include batch normalization and renormalization. The regularization technologies include seven types: input data, data enhancement, early stop method, L1 regularization, L2 regularization, dropout, and dropout connect. Second, the application study of the residual network model in the diagnosis of medical imaging diseases is reviewed. ResNet is used to diagnose six types of diseases: lung tumor, skin disease, breast cancer, brain disease, diabetes, and hematological disease. 1) Lung cancer. Considerable data show that the incidence of lung cancer is increasing yearly, which is a serious threat to human health. Early diagnosis and detection are essential for the treatment of lung cancer. The main contributions of ResNet in lung tumor research are particle swarm optimization(PSo)+convolutional neural network(CNN), intermediate dense projection method+DenseNet, DenseNet+fully convolutional network(FCN), attention mechanism+ResNet, dense network+U-Net, and 3D+CNN. 2) Skin cancer. Malignant melanoma is one of the most common and deadly skin cancers. Melanoma can be cured if it is properly treated in the early stage. The main contributions of ResNet in the diagnosis and research of skin diseases are integrated learning+CNN, multichannel ResNet, ResNet+support vector machine(SVM), integrated learning+ResNet, and whale optimization algorithm+CNN. 3) Breast cancer. It is a malignant tumor in women, which seriously affects their physical and mental health. The main contributions of ResNet in the diagnosis and research of breast cancer include transfer learning+ResNet, decision tree+ResNet, CNN+SVM, DesneNet-II, and SE-attention+CNN. 4) Alzheimer's disease (AD). It is an irreversible brain disease accompanied with progressive impairment of memory and cognitive functions. No effective cure method exists for AD. Early diagnosis of AD is particularly important for patient care and treatment. The main contributions of ResNet in the diagnosis and research of brain diseases are DenseNet, multiscale ResNet, 3DResNet, and multitask CNN+3D DenseNet. 5) Diabetic retinopathy (glycemic retinopathy). It is an eye disease induced by long-term diabetes, which will cause the patient to lose sight and eventually lead to blindness. The main contributions of ResNet in relevant diagnosis and research are migration learning+CNN, FCN+ResNet, multicategory ResNet, and ResNet+SVM. 6) Blood diseases. The proportion of white blood cells in liquid is usually an indicator of diseases. The classification and counting of white blood cells are used in the process of diagnosing diseases. White blood cell test plays a vital role in the detection and treatment of leukemia, anemia, and other diseases. The main contributions of ResNet in the diagnosis and research of blood diseases are as follows: deep supervision ResNet, fine-tuned ResNet, deep cross ResNet, and deep supervision FCN. Lastly, the future development of deep learning in medical imaging is summarized. In this paper, the algorithms of ResNet are systematically summarized, which has a positive significance to the research and development of ResNet. © 2020, Editorial and Publishing Board of Journal of Image and Graphics. All right reserved.","10.11834/jig.200207","Deep learning; Disease diagnosis; Medical image; Optimization algorithm; Residual neural network(ResNet)","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093941157&doi=10.11834%2fjig.200207&partnerID=40&md5=cb8379e5f979f659be73048ecb7a7c36"
"Multitask learning with boundary awareness for skin lesion segmentation","Phan T.; Kim S.-H.; Yang H.-J.; Lee G.-S.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Image segmentation is one of the key steps in skin lesion diagnosis before lesion classification. The precise area of skin lesion aids in conclusion to the state of lesion which is benign or malignant. At the present, deep learning methods are the best tools for this task thanks to the outstanding performances on several datasets. Those methods mostly used the fully convolutional neural networks and region-based loss to discriminate the impaired skin area from the healthy neighborhood. They produced adequate delineation of lesion but in challenging cases such as low contrast between foreground and background or the boundary of lesion is vague, the output is unsatisfactory. From our observation of the groundtruths of lesion images, in almost all of the cases, the desired region follows a unified structure with no holes inside. Providing that we are able to draw a line at the transition of foreground and background, the pixels inside definitely belong to the group of lesion's. Based on that idea, we introduce the utilization of an auxiliary decoder along with the U-Net model, which serves for the task of boundary distance map regression. The parallel decoder is assigned to grab the information of shape and boundary from the own-generated groundtruth. Multiple experiments were implemented to verify the efficacy of the proposed method in this paper.  © 2020 ACM.","10.1145/3426020.3426087","Boundary awareness; Deep learning; Multitask learning; Semantic segmentation; Skin lesion","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119094733&doi=10.1145%2f3426020.3426087&partnerID=40&md5=3388c35f7bfbead6d9f52e6ff333cd79"
"Assisted deep learning framework for multi-class skin lesion classification considering a binary classification support","Harangi B.; Baran A.; Hajdu A.","2020","1","1","0","0","0","Unique","0","","","","","","","In this paper, we propose a deep convolutional neural network framework to classify dermoscopy images into seven classes. With taking the advantage that these classes can be merged into two (healthy/diseased) ones we can train a part of the network regarding this binary task only. Then, the confidences regarding the binary classification are used to tune the multi-class confidence values provided by the other part of the network, since the binary task can be solved more accurately. For both the classification tasks we used GoogLeNet Inception-v3, however, any CNN architectures could be applied for these purposes. The whole network is trained in the usual way, and as our experimental results on the skin lesion image classification show, the accuracy of the multi-class problem has been remarkably raised (by 7% considering the balanced multi-class accuracy) via embedding the more reliable binary classification outcomes. © 2020 Elsevier Ltd","10.1016/j.bspc.2020.102041","Assisted learning; Deep learning; Ensemble learning; Skin lesion","61","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087589024&doi=10.1016%2fj.bspc.2020.102041&partnerID=40&md5=2564d81f4d22f33e11dbfad02261ca08"
"Explainable fully connected visual words for the classification of skin cancer confocal images: Interpreting the influence of visual words in classifying benign vs malignant pattern","Kallipolitis A.; Stratigos A.; Zarras A.; Maglogiannis I.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Skin cancer is affecting the lives of million people worldwide. Early detection and treatment of the cause can reduce drastically morbidity. Although the main workflow in dermatology clinics includes invasive skin removal procedures for diagnostic purposes, Reflectance Confocal Microscopy (RCM) provides an ancillary, non-invasive methodology for reviewing areas of interest of the human skin at a high resolution. In this paper, we propose a method for the classification and the interpretation of visual patterns in skin cancer confocal images. Both tasks are based on the formation of a visual vocabulary from Speeded up Robust Features (SURF) and the utilization of simple shallow artificial neural network with fully connected layers. Interpretability of the predictive models is also quite important, since it improves their reliability, accountability, transparency and provides useful insight of how to evolve the predictive model towards better performance. The paper discusses the technical details of both approaches along with some initial results.  © 2020 ACM.","10.1145/3411408.3411435","Bag of Visual Words; Interpretability; Reflectance Confocal Microscopy; Skin Cancer","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091116151&doi=10.1145%2f3411408.3411435&partnerID=40&md5=df7be13b5f8ceda4b015e7045cd10f41"
"Classification of Skin Lesions in Digital Images for the Diagnosis of Skin Cancer","Shahana Sherin K.C.; Shayini R.","2020","1","1","0","0","0","First occurrence","0","","","","","","","According to modern research skin cancer is increasing day by day, early detection of skin cancer can increase the survival rate up to a larger extend. Image processing techniques play an important role to detect the skin malignancies in its initial stages. This paper presents an image proceeding techniques to classify skin lesion image into melanoma or nevus. Input image undergoes image pre-processing stages such as smoothing or blurring, segment the lesion part using most faster and accurate multi thresholding approach, extract the features of the lesion by an 18-feature vector and pre-Trained ANN is used as the classifier to distinguish between melanoma and nevus. The proposed system takes 166 selected images from the PH2 data set.. © 2020 IEEE.","10.1109/ICOSEC49089.2020.9215271","Classifiers; Feature extraction; Image processing; Melanoma; Nevus","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094193082&doi=10.1109%2fICOSEC49089.2020.9215271&partnerID=40&md5=128868fa09e496abbd58a879880aba4c"
"Anatomical region segmentation method from dermoscopic images of pigmented skin lesions","Chakkaravarthy A.P.; Chandrasekar A.","2020","1","0","0","0","0","Unique","0","","","","","","","Melanoma tumor can cause a serious life threatening problem in humans, if left untreated for a long time without early diagnosis. For early diagnosis of melanoma, it is more significant to develop novel methods based on biophysics analyses, molecular targets recognitions, and new image analysis criteria. In this article, anatomical region segmentation and diameter identification is proposed to detect melanoma from dermoscopic images. Four main steps of the proposed system are as follows: In the first step, the preprocessing is performed to smooth the melanoma extraction process. The region segmentation is done in the second step using watershed segmentation and Sobel operator. In the third step, the postprocessing procedures like as morphological open, canny edge detection also applied to improve the region of interest. Finally, the melanoma region is identified using color symmetry features. The proposed method is tested with two data sets to prove the performance proposed method. The proposed method achieved an accuracy of 95.31% and specificity of 98.3%, which is better than other methods. Experimental results show that the effectiveness of the proposed method and illustrate viability of real-time clinical applications. © 2020 Wiley Periodicals, Inc.","10.1002/ima.22404","canny edge detection; color segmentation; Gaussian filter; image gradient; morphological dilation; salt and pepper noise; Sobel operator; watershed segmentation","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079369667&doi=10.1002%2fima.22404&partnerID=40&md5=25a1a95037868dbb57124126aea9adb7"
"What is AI? Applications of artificial intelligence to dermatology","Du-Harpur X.; Watt F.M.; Luscombe N.M.; Lynch M.D.","2020","0","1","0","0","0","Unique","0","","","","","","","In the past, the skills required to make an accurate dermatological diagnosis have required exposure to thousands of patients over many years. However, in recent years, artificial intelligence (AI) has made enormous advances, particularly in the area of image classification. This has led computer scientists to apply these techniques to develop algorithms that are able to recognize skin lesions, particularly melanoma. Since 2017, there have been numerous studies assessing the accuracy of algorithms, with some reporting that the accuracy matches or surpasses that of a dermatologist. While the principles underlying these methods are relatively straightforward, it can be challenging for the practising dermatologist to make sense of a plethora of unfamiliar terms in this domain. Here we explain the concepts of AI, machine learning, neural networks and deep learning, and explore the principles of how these tasks are accomplished. We critically evaluate the studies that have assessed the efficacy of these methods and discuss limitations and potential ethical issues. The burden of skin cancer is growing within the Western world, with major implications for both population skin health and the provision of dermatology services. AI has the potential to assist in the diagnosis of skin lesions and may have particular value at the interface between primary and secondary care. The emerging technology represents an exciting opportunity for dermatologists, who are the individuals best informed to explore the utility of this powerful novel diagnostic tool, and facilitate its safe and ethical implementation within healthcare systems. © 2020 The Authors. British Journal of Dermatology published by John Wiley & Sons Ltd on behalf of British Association of Dermatologists","10.1111/bjd.18880","","207","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081404412&doi=10.1111%2fbjd.18880&partnerID=40&md5=b29250dd967ac010ab949b4e7a7dfe93"
"Asymmetric Encode-Decode Network with Two Decoding Paths for Skin Lesion Segmentation","Qin K.; Sun D.; Zhang S.; Zhao H.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Automated skin lesion segmentation is an important and challenging task. Due to the fact that the edges of melanomas are uneven and the color changes constantly, some may have image artifacts. Most of the existing segmentation methods are based on the encode-decode network, which often cannot effectively combine low-level simple features with high-level semantic features, thereby improving the final segmentation results. In this paper, we propose a novel encode-decode network with two asymmetric decoding paths, which can better fuse low-level and high-level features. In our architecture, multi-scale features can be captured through our proposed New Dense Atrous Convolution (NDAC) block, and the re-designed skip pathways can transmit more representative features from the encoder to the decoder. Experimental results conducted on ISBI 2017 Skin Lesion Challenge dataset show that our model outperforms other state-of-the-art deep learning-based methods.  © 2020 ACM.","10.1145/3436349.3436366","Deep learning; encode-decode; skin lesion segmentation; two decoding paths","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100710919&doi=10.1145%2f3436349.3436366&partnerID=40&md5=ee4a6f92e3c42dc994d9b1321ed16d99"
"Deep Learning in Skin Lesion Analysis towards Cancer Detection","Waweru A.K.; Ahmed K.; Miao Y.; Kawan P.","2020","1","1","0","0","0","Unique","0","","","","","","","Detecting Melanoma, the deadliest skin cancer, at the early stage can exceptionally escalate the possibility of the cure up to 99.2% 5-year survival rate. Manual examination by the dermatologist continues to be used as the core and most trusted method till today, albeit a decade of effort in using the technology. Therefore, given the low supply of dermatologists, it is impossible to proactively run the surveillance on people at highest risk for early finding. Deep Convolutional Neural Networks (DCNNs) have demonstrated a dramatic breakthrough in automatic skin lesion classification, which is imperative to improve the diagnostic performance over the mass population with limited access to specialists. Web-Application based dermoscopic imaging with integrated artificial intelligence (AI) is a plausible accessible method for future skin lesion analysis. The artificially intelligent plugin, consequently, can serve as enablers for the dermatology community. In this paper, we report the findings of our investigation of using DCNNs for automated Melanoma region segmentation in dermoscopy images. For training and evaluation, we use the HAM10000 public dataset. We aim to realize our model by creating a web tool that can tell general practitioners (GP) and lab technologists the probability diagnoses for a given skin lesion. This automation will assist in fast segregation of the high-risk patients and speed up the follow-up diagnosis and treatment workflow. © 2020 IEEE.","10.1109/IV51561.2020.00130","Dataset; DCNNs; Deep Learning; DenseNet201; Dermoscopic; Melanoma; Skin Disease","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102943010&doi=10.1109%2fIV51561.2020.00130&partnerID=40&md5=53713e3ed8bf657167e1fb08fa6b76b9"
"Predicting bovine tuberculosis status of dairy cows from mid-infrared spectral data of milk using deep learning","Denholm S.J.; Brand W.; Mitchell A.P.; Wells A.T.; Krzyzelewski T.; Smith S.L.; Wall E.; Coffey M.P.","2020","0","1","0","0","0","Unique","0","","","","","","","Bovine tuberculosis (bTB) is a zoonotic disease in cattle that is transmissible to humans, distributed worldwide, and considered endemic throughout much of England and Wales. Mid-infrared (MIR) analysis of milk is used routinely to predict fat and protein concentration, and is also a robust predictor of several other economically important traits including individual fatty acids and body energy. This study predicted bTB status of UK dairy cows using their MIR spectral profiles collected as part of routine milk recording. Bovine tuberculosis data were collected as part of the national bTB testing program for Scotland, England, and Wales; these data provided information from over 40,500 bTB herd breakdowns. Corresponding individual cow life–history data were also available and provided information on births, movements, and deaths of all cows in the study. Data relating to single intradermal comparative cervical tuberculin (SICCT) skin-test results, culture, slaughter status, and presence of lesions were combined to create a binary bTB phenotype labeled 0 to represent nonresponders (i.e., healthy cows) and 1 to represent responders (i.e., bTB-affected cows). Contemporaneous individual milk MIR spectral data were collected as part of monthly routine milk recording and matched to bTB status of individual animals on the single intradermal comparative cervical tuberculin test date (±15 d). Deep learning, a sub-branch of machine learning, was used to train artificial neural networks and develop a prediction pipeline for subsequent use in national herds as part of routine milk recording. Spectra were first converted to 53 × 20-pixel PNG images, then used to train a deep convolutional neural network. Deep convolutional neural networks resulted in a bTB prediction accuracy (i.e., the number of correct predictions divided by the total number of predictions) of 71% after training for 278 epochs. This was accompanied by both a low validation loss (0.71) and moderate sensitivity and specificity (0.79 and 0.65, respectively). To balance data in each class, additional training data were synthesized using the synthetic minority over sampling technique. Accuracy was further increased to 95% (after 295 epochs), with corresponding validation loss minimized (0.26), when synthesized data were included during training of the network. Sensitivity and specificity also saw a 1.22- and 1.45-fold increase to 0.96 and 0.94, respectively, when synthesized data were included during training. We believe this study to be the first of its kind to predict bTB status from milk MIR spectral data. We also believe it to be the first study to use milk MIR spectral data to predict a disease phenotype, and posit that the automated prediction of bTB status at routine milk recording could provide farmers with a robust tool that enables them to make early management decisions on potential reactor cows, and thus help slow the spread of bTB. © 2020 American Dairy Science Association","10.3168/jds.2020-18328","bovine tuberculosis; dairy cow; deep learning; mid-infrared spectroscopy; noninvasive","46","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089558967&doi=10.3168%2fjds.2020-18328&partnerID=40&md5=a1ae45ee6212b96ef079c4e0d69875f9"
"Classification of hyperspectral endocrine tissue images using support vector machines","Maktabi M.; Köhler H.; Ivanova M.; Neumuth T.; Rayes N.; Seidemann L.; Sucher R.; Jansen-Winkeln B.; Gockel I.; Barberio M.; Chalopin C.","2020","0","1","0","0","0","Unique","0","","","","","","","Background: Thyroidectomy is one of the most commonly performed surgical procedures. The region of the neck has a very complex structural organization. It would be beneficial to introduce a tool that can assist the surgeon in tissue discrimination during the procedure. One such solution is the noninvasive and contactless technique, called hyperspectral imaging (HSI). Methods: To interpret the HSI data, we implemented a supervised classification method to automatically discriminate the parathyroid, the thyroid, and the recurrent laryngeal nerve from surrounding tissue(muscle, skin) and materials (instruments, gauze). A leave-one-patient-out cross-validation was performed. Results: The best performance was obtained using support vector machine (SVM) with a classification and visualization in less than 1.4 seconds. A mean patient accuracy of 68% ± 23% was obtained for all tissues and material types. Conclusions: The proposed method showed promising results and have to be confirmed on a larger cohort of patient data. © 2020 The Authors. The International Journal of Medical Robotics and Computer Assisted Surgery published by John Wiley & Sons Ltd.","10.1002/rcs.2121","computer assisted surgery; head and neck; imaged guided surgery; intraoperative imaging; surgery; thyroidectomy","30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085595570&doi=10.1002%2frcs.2121&partnerID=40&md5=6dda1e46d2fc6d7e7799e261fed75d7d"
"Automatic skin lesion classification based on mid-level feature learning","Liu L.; Mou L.; Zhu X.X.; Mandal M.","2020","1","1","0","0","0","Unique","0","","","","","","","Dermoscopic images are widely used for melanoma detection. Many existing works based on traditional classification methods and deep learning models have been proposed for automatic skin lesion analysis. The traditional classification methods use hand-crafted features as input. However, due to the strong visual similarity between different classes of skin lesions and complex skin conditions, the hand-crafted features are not discriminative enough and fail in many cases. Recently, deep convolutional neural networks (CNN) have gained popularity since they can automatically learn optimal features during the training phase. Different from existing works, a novel mid-level feature learning method for skin lesion classification task is proposed in this paper. In this method, skin lesion segmentation is first performed to detect the regions of interest (ROI) of skin lesion images. Next, pretrained neural networks including ResNet and DenseNet are used as the feature extractors for the ROI images. Instead of using the extracted features directly as input of classifiers, the proposed method obtains the mid-level feature representations by utilizing the relationships among different image samples based on distance metric learning. The learned feature representation is a soft discriminative descriptor, having more tolerance to the hard samples and hence is more robust to the large intra-class difference and inter-class similarity. Experimental results demonstrate advantages of the proposed mid-level features, and the proposed method obtains state-of-the-art performance compared with the existing CNN based methods. © 2020 Elsevier Ltd","10.1016/j.compmedimag.2020.101765","Feature learning; Medical image analysis; Metric learning; Skin lesion analysis","64","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089372808&doi=10.1016%2fj.compmedimag.2020.101765&partnerID=40&md5=867ecba0ba7ddf17704d1736a51ecba1"
"An Automatic Diagnosis of Melanoma based on Multi-feature Fusion","Ju K.","2020","0","1","0","0","0","First occurrence","0","","","","","","","Melanoma is a malignant skin disease. Melanoma is difficult to be detected in the early stage, and it is difficult to cure once this disease develops to the late stage. The mortality rate of patients with advanced melanoma is as high as 98%. Melanoma dermatosis can be effectively controlled by early screening and timely treatment. However, due to the large population and uneven distribution of medical resources in China, it is difficult for most melanoma patients to get early diagnosis and treatment from doctors. Therefore, it is necessary to study the computer-aided diagnosis technology of melanoma. At present, deep learning is the most advanced melanoma diagnosis method, which has a good performance in terms of accuracy of automatic diagnosis. With the latest ISIC2019 dermatological data set, we study and implement the automatic diagnosis method based on traditional handcrafted features and the automatic diagnosis method based on deep learning. The traditional handcrafted features include the color features, shape features and boundary features of the lesion area. A total of 89 handcrafted features were extracted. The method based on deep learning is to use Inception V3 model which is pre-trained on ImageNet and we get the final model by fine-tuning. Finally, we use the dense layer of artificial neural network to fuse traditional handcrafted features and deep-learning features. We implement a feature fusion model based on traditional methods and deep learning, and its accuracy of diagnosis is 82.02%. Compared with the deep-learning model of the same convolutional neural network, the feature fusion model can effectively improve the accuracy of automatic diagnosis. The feature fusion model of this topic can also be applied to the use of multi-modal data. © 2020 ACM.","10.1145/3397391.3397401","Computer aided diagnosis; Deep learning; Handcrafted features; Melanoma; Multi-feature fusion","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088162453&doi=10.1145%2f3397391.3397401&partnerID=40&md5=86323b5350f4a2b3c9f6d9a01071585a"
"Fitness adaptive deer hunting-based region growing and recurrent neural network for melanoma skin cancer detection","Divya D.; Ganeshbabu T.R.","2020","1","1","0","0","0","Unique","0","","","","","","","This proposal aims to enhance the accuracy of a dermoscopic skin cancer diagnosis with the aid of novel deep learning architecture. The proposed skin cancer detection model involves four main steps: (a) preprocessing, (b) segmentation, (c) feature extraction, and (d) classification. The dermoscopic images initially subjected to a preprocessing step that includes image enhancement and hair removal. After preprocessing, the segmentation of lesion is deployed by an optimized region growing algorithm. In the feature extraction phase, local features, color morphology features, and morphological transformation-based features are extracted. Moreover, the classification phase uses a modified deep learning algorithm by merging the optimization concept into recurrent neural network (RNN). As the main contribution, the region growing and RNN improved by the modified deer hunting optimization algorithm (DHOA) termed as Fitness Adaptive DHOA (FA-DHOA). Finally, the analysis has been performed to verify the effectiveness of the proposed method. © 2020 Wiley Periodicals, Inc.","10.1002/ima.22414","dermoscopic image; melanoma skin cancer; modified deer hunting algorithm; optimized region growing; recurrent neural network","24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081753587&doi=10.1002%2fima.22414&partnerID=40&md5=0f9e49cdb879e545064f1ec89a5b929a"
"Visual saliency based global-local feature representation for skin cancer classification","Xiao F.; Wu Q.","2020","1","1","0","0","0","Unique","0","","","","","","","With the rapid increase in the cases of deadly skin cancer, the classification on different types of skin cancer has been emerging as one of the most significant issues in the field of medical image. Several approaches have been proposed to help in diagnosing the categories of the skin lesions by means of traditional features or leveraging the widely used deep learning models. However, there are lack of the integrated frameworks to combine the hand-crafted traditional features and the deep Conv-features. Furthermore, the effective way to extract global and local features is also conducive to distinguish the specific lesions from normal skin. Hence, in this study, the authors present an integrated model to acquire more representative global-local features including the traditional local binary pattern features and deep Conv-features. In addition, several fusion strategies have conducted on the Global-DNN and Local-DNN for better performance. In order to extract more explicit features from the specific lesion areas, a target segmentation method based on visual saliency detection is employed to eliminate the background interference. Experimental results on ISIC-2017 skin cancer dataset demonstrate that the proposed Global-DNN and Global-Local models can obtain more effective feature representation which achieve outperformed results for skin cancer classification. © The Institution of Engineering and Technology 2020","10.1049/iet-ipr.2019.1018","","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093861734&doi=10.1049%2fiet-ipr.2019.1018&partnerID=40&md5=5f523379292756857eec3de2e2c5543a"
"A deep dive into understanding tumor foci classification using multiparametric MRI based on convolutional neural network","Zong W.; Lee J.K.; Liu C.; Carver E.N.; Feldman A.M.; Janic B.; Elshaikh M.A.; Pantelic M.V.; Hearshen D.; Chetty I.J.; Movsas B.; Wen N.","2020","0","1","0","0","0","Unique","0","","","","","","","Purpose: Deep learning models have had a great success in disease classifications using large data pools of skin cancer images or lung X-rays. However, data scarcity has been the roadblock of applying deep learning models directly on prostate multiparametric MRI (mpMRI). Although model interpretation has been heavily studied for natural images for the past few years, there has been a lack of interpretation of deep learning models trained on medical images. In this paper, an efficient convolutional neural network (CNN) was developed and the model interpretation at various convolutional layers was systematically analyzed to improve the understanding of how CNN interprets multimodality medical images and the predictive powers of features at each layer. The problem of small sample size was addressed by feeding the intermediate features into a traditional classification algorithm known as weighted extreme learning machine (wELM), with imbalanced distribution among output categories taken into consideration. Methods: The training data collection used a retrospective set of prostate MR studies, from SPIE-AAPM-NCI PROSTATEx Challenges held in 2017. Three hundred twenty biopsy samples of lesions from 201 prostate cancer patients were diagnosed and identified as clinically significant (malignant) or not significant (benign). All studies included T2-weighted (T2W), proton density-weighted (PD-W), dynamic contrast enhanced (DCE) and diffusion-weighted (DW) imaging. After registration and lesion-based normalization, a CNN with four convolutional layers were developed and trained on tenfold cross validation. The features from intermediate layers were then extracted as input to wELM to test the discriminative power of each individual layer. The best performing model from the tenfolds was chosen to be tested on the holdout cohort from two sources. Feature maps after each convolutional layer were then visualized to monitor the trend, as the layer propagated. Scatter plotting was used to visualize the transformation of data distribution. Finally, a class activation map was generated to highlight the region of interest based on the model perspective. Results: Experimental trials indicated that the best input for CNN was a modality combination of T2W, apparent diffusion coefficient (ADC) and DWIb50. The convolutional features from CNN paired with a weighted extreme learning classifier showed substantial performance compared to a CNN end-to-end training model. The feature map visualization reveals similar findings on natural images where lower layers tend to learn lower level features such as edges, intensity changes, etc, while higher layers learn more abstract and task-related concept such as the lesion region. The generated saliency map revealed that the model was able to focus on the region of interest where the lesion resided and filter out background information, including prostate boundary, rectum, etc. Conclusions: This work designs a customized workflow for the small and imbalanced dataset of prostate mpMRI where features were extracted from a deep learning model and then analyzed by a traditional machine learning classifier. In addition, this work contributes to revealing how deep learning models interpret mpMRI for prostate cancer patient stratification. © 2020 American Association of Physicists in Medicine","10.1002/mp.14255","convolutional neural network; model interpretation; prostate cancer mpMRI lesion classification; saliency map; small sample size","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086222948&doi=10.1002%2fmp.14255&partnerID=40&md5=b0b70efa4fa4cb95545fb7a4f9aeab43"
"2020 International Conference on Advanced Technologies for Signal and Image Processing, ATSIP 2020","","2020","0","1","0","0","0","Unique","0","","","","","","","The proceedings contain 97 papers. The topics discussed include: target recognition from ISAR image using polar mapping and shape matrix; nuclei segmentation approach for digestive neuroendocrine tumors analysis using optimized color space conversion; face emotion recognition from static image based on convolution neural networks; monaural speech separation based on linear regression optimized using gradient descent; melanoma skin cancer detection using deep learning and classical machine learning techniques: a hybrid approach; EWMA kernel generalized likelihood ratio test for fault detection of chemical processes; AI-based pilgrim detection using convolutional neural networks; and multi-label learning embedding approach based on multi-temporal spectral signature for hyperspectral images classification.","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096551772&partnerID=40&md5=29a923284318dd697180dcdbda4c85d7"
"Skin melanoma classification using ROI and data augmentation with deep convolutional neural networks","Hosny K.M.; Kassem M.A.; Foaud M.M.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Automatic classification of color images of skin helps clinicians and dermatologists in examining and investigating skin melanoma. In this paper, a new deep convolutional neural network-based classification method is proposed. The proposed method consists of three main steps. First, the input color images of skin are preprocessed where the region of interest (ROI) are segmented. Second, the segmented ROI images are augmented using rotation and translation transformations. Third, different deep convolutional neural network (DCNN) architectures such as Alex-net, ResNet101, and GoogleNet are utilized. The last three layers are dropped out and replaced with new layers to be more appropriate with the task of lesion classification. The performance of the proposed method has been evaluated using three different datasets, MED-NODE, DermIS & DermQuest and ISIC 2017. The proposed DCNN have fine-tuned and trained using 85%, tested and verified using 15% of the overall datasets. The proposed method significantly improved the classification process especially with modified GoogleNet where the classification accuracy was 99.29%, 99.15%, and 98.14% for MED-NODE, DermIS & DermQuest, and ISIC 2017 respectively. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","10.1007/s11042-020-09067-2","Classification; DCNN; GoogleNet; Melanoma; Skin Cancer; SVM","73","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086879212&doi=10.1007%2fs11042-020-09067-2&partnerID=40&md5=d02e18771f6b5af9bb637bdd8ef33b24"
"Recent advancement in cancer detection using machine learning: Systematic survey of decades, comparisons and challenges","Saba T.","2020","0","1","0","0","0","Unique","0","","","","","","","Cancer is a fatal illness often caused by genetic disorder aggregation and a variety of pathological changes. Cancerous cells are abnormal areas often growing in any part of human body that are life-threatening. Cancer also known as tumor must be quickly and correctly detected in the initial stage to identify what might be beneficial for its cure. Even though modality has different considerations, such as complicated history, improper diagnostics and treatement that are main causes of deaths. The aim of the research is to analyze, review, categorize and address the current developments of human body cancer detection using machine learning techniques for breast, brain, lung, liver, skin cancer leukemia. The study highlights how cancer diagnosis, cure process is assisted using machine learning with supervised, unsupervised and deep learning techniques. Several state of art techniques are categorized under the same cluster and results are compared on benchmark datasets from accuracy, sensitivity, specificity, false-positive metrics. Finally, challenges are also highlighted for possible future work. © 2020 The Author(s)","10.1016/j.jiph.2020.06.033","Cancer; Health systems; Image analysis; Life expectancy; Machine learning","246","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088994428&doi=10.1016%2fj.jiph.2020.06.033&partnerID=40&md5=05426ee302dc5c17634a352f901d017f"
"Human–computer collaboration for skin cancer recognition","Tschandl P.; Rinner C.; Apalla Z.; Argenziano G.; Codella N.; Halpern A.; Janda M.; Lallas A.; Longo C.; Malvehy J.; Paoli J.; Puig S.; Rosendahl C.; Soyer H.P.; Zalaudek I.; Kittler H.","2020","1","1","0","0","0","First occurrence","0","","","","","","","The rapid increase in telemedicine coupled with recent advances in diagnostic artificial intelligence (AI) create the imperative to consider the opportunities and risks of inserting AI-based support into new paradigms of care. Here we build on recent achievements in the accuracy of image-based AI for skin cancer diagnosis to address the effects of varied representations of AI-based support across different levels of clinical expertise and multiple clinical workflows. We find that good quality AI-based support of clinical decision-making improves diagnostic accuracy over that of either AI or physicians alone, and that the least experienced clinicians gain the most from AI-based support. We further find that AI-based multiclass probabilities outperformed content-based image retrieval (CBIR) representations of AI in the mobile technology environment, and AI-based support had utility in simulations of second opinions and of telemedicine triage. In addition to demonstrating the potential benefits associated with good quality AI in the hands of non-expert clinicians, we find that faulty AI can mislead the entire spectrum of clinicians, including experts. Lastly, we show that insights derived from AI class-activation maps can inform improvements in human diagnosis. Together, our approach and findings offer a framework for future studies across the spectrum of image-based diagnostics to improve human–computer collaboration in clinical practice. © 2020, The Author(s), under exclusive licence to Springer Nature America, Inc.","10.1038/s41591-020-0942-0","","604","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086729711&doi=10.1038%2fs41591-020-0942-0&partnerID=40&md5=21f7b76b45860e36600a1e4c279dbe4b"
"Comparison of multiplexed immunofluorescence imaging to chromogenic immunohistochemistry of skin biomarkers in response to monkeypox virus infection","Sood A.; Sui Y.; McDonough E.; Santamaría-Pang A.; Al-Kofahi Y.; Pang Z.; Jahrling P.B.; Kuhn J.H.; Ginty F.","2020","1","1","0","0","0","Unique","0","","","","","","","Over the last 15 years, advances in immunofluorescence-imaging based cycling methods, antibody conjugation methods, and automated image processing have facilitated the development of a high-resolution, multiplexed tissue immunofluorescence (MxIF) method with single cell-level quantitation termed Cell DIVETM. Originally developed for fixed oncology samples, here it was evaluated in highly fixed (up to 30 days), archived monkeypox virus-induced inflammatory skin lesions from a retrospective study in 11 rhesus monkeys to determine whether MxIF was comparable to manual H-scoring of chromogenic stains. Six protein markers related to immune and cellular response (CD68, CD3, Hsp70, Hsp90, ERK1/2, ERK1/2 pT202_pY204) were manually quantified (H-scores) by a pathologist from chromogenic IHC double stains on serial sections and compared to MxIF automated single cell quantification of the same markers that were multiplexed on a single tissue section. Overall, there was directional consistency between the H-score and the MxIF results for all markers except phosphorylated ERK1/2 (ERK1/2 pT202_pY204), which showed a decrease in the lesion compared to the adjacent non-lesioned skin by MxIF vs an increase via H-score. Improvements to automated segmentation using machine learning and adding additional cell markers for cell viability are future options for improvement. This method could be useful in infectious disease research as it conserves tissue, provides marker colocalization data on thousands of cells, allowing further cell level data mining as well as a reduction in user bias. © 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/).","10.3390/v12080787","IHC; Immunohistochemistry; Monkeypox; Monkeypox virus; MPXV; Multiplexed immunofluorescence; MxIF; Orthopoxvirus; Poxviridae; Poxvirus","30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088812183&doi=10.3390%2fv12080787&partnerID=40&md5=59bf6476c8bf190a3988f296b635ae97"
"Skin Lesion Segmentation with Improved Convolutional Neural Network","Öztürk Ş.; Özkaya U.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Recently, the incidence of skin cancer has increased considerably and is seriously threatening human health. Automatic detection of this disease, where early detection is critical to human life, is quite challenging. Factors such as undesirable residues (hair, ruler markers), indistinct boundaries, variable contrast, shape differences, and color differences in the skin lesion images make automatic analysis quite difficult. To overcome these challenges, a highly effective segmentation method based on a fully convolutional network (FCN) is presented in this paper. The proposed improved FCN (iFCN) architecture is used for the segmentation of full-resolution skin lesion images without any pre- or post-processing. It is to support the residual structure of the FCN architecture with spatial information. This situation, which creates a more advanced residual system, enables more precise detection of details on the edges of the lesion, and an analysis independent of skin color can be performed. It offers two contributions: determining the center of the lesion and clarifying the edge details despite the undesirable effects. Two publicly available datasets, the IEEE International Symposium on Biomedical Imaging (ISBI) 2017 Challenge and PH2 datasets, are used to evaluate the performance of the iFCN method. The mean Jaccard index is 78.34%, the mean Dice score is 88.64%, and the mean accuracy value is 95.30% for the proposed method for the ISBI 2017 test dataset. Furthermore, the mean Jaccard index is 87.1%, the mean Dice score is 93.02%, and the mean accuracy value is 96.92% for the proposed method for the PH2 test dataset. © 2020, Society for Imaging Informatics in Medicine.","10.1007/s10278-020-00343-z","CNN; FCN; Melanoma; Segmentation; Skin lesion segmentation","113","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085100289&doi=10.1007%2fs10278-020-00343-z&partnerID=40&md5=7211b910ccbb8fcac43c8e46cb7b4267"
"The development of a skin cancer classification system for pigmented skin lesions using deep learning","Jinnai S.; Yamazaki N.; Hirano Y.; Sugawara Y.; Ohe Y.; Hamamoto R.","2020","1","1","0","0","0","Unique","0","","","","","","","Recent studies have demonstrated the usefulness of convolutional neural networks (CNNs) to classify images of melanoma, with accuracies comparable to those achieved by dermatologists. However, the performance of a CNN trained with only clinical images of a pigmented skin lesion in a clinical image classification task, in competition with dermatologists, has not been reported to date. In this study, we extracted 5846 clinical images of pigmented skin lesions from 3551 patients. Pigmented skin lesions included malignant tumors (malignant melanoma and basal cell carcinoma) and benign tumors (nevus, seborrhoeic keratosis, senile lentigo, and hematoma/hemangioma). We created the test dataset by randomly selecting 666 patients out of them and picking one image per patient, and created the training dataset by giving bounding-box annotations to the rest of the images (4732 images, 2885 patients). Subsequently, we trained a faster, region-based CNN (FRCNN) with the training dataset and checked the performance of the model on the test dataset. In addition, ten board-certified dermatologists (BCDs) and ten dermatologic trainees (TRNs) took the same tests, and we compared their diagnostic accuracy with FRCNN. For six-class classification, the accuracy of FRCNN was 86.2%, and that of the BCDs and TRNs was 79.5% (p = 0.0081) and 75.1% (p < 0.00001), respectively. For two-class classification (benign or malignant), the accuracy, sensitivity, and specificity were 91.5%, 83.3%, and 94.5% by FRCNN; 86.6%, 86.3%, and 86.6% by BCD; and 85.3%, 83.5%, and 85.9% by TRN, respectively. False positive rates and positive predictive values were 5.5% and 84.7% by FRCNN, 13.4% and 70.5% by BCD, and 14.1% and 68.5% by TRN, respectively. We compared the classification performance of FRCNN with 20 dermatologists. As a result, the classification accuracy of FRCNN was better than that of the dermatologists. In the future, we plan to implement this system in society and have it used by the general public, in order to improve the prognosis of skin cancer. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/biom10081123","Artificial intelligence (AI); Deep learning; Melanoma; Neural network; Skin cancer","206","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088984605&doi=10.3390%2fbiom10081123&partnerID=40&md5=9f0e69918c04a366670b253533b3e954"
"Analysis of Adversarial Attacks on Skin Cancer Recognition","Huq A.; Pervin T.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Cancer is one of the most detrimental diseases having the highest death rates in recent years. There are various types of cancers; among them, skin cancer is the most familiar one. Early detection and treatment of it can lead to full recovery for the patients. Deep learning based image classification models have been proven to perform exclusively well to classify images. This is also true for images in the domain of medical image analysis. However, in recent years researchers have shown that adding small calculated noises which are not noticeable by human eyes can induce these models to generate wrong answers. These adversarial examples have proven to be harmful with regards to security measures and hamper launching of deep learning based models in to the real world. In this regard, here we performed experiments to improve the robustness of deep learning based models from these type of attacks for skin cancer recognition. We performed adversarial training based on Projected Gradient Descent (PGD) to increase the robustness of two popular deep learning models, namely MobileNet and VGG16, against white-box attacks of PGD and FGSM attacks. We performed our experiments on a dataset of 10015 images and have shown that our models are much robust than standard training ones and achieved almost similar results as them.  © 2020 IEEE.","10.1109/ICoDSA50139.2020.9212850","adversarial machine learning; deep learning; PGD attack; skin cancer","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094616380&doi=10.1109%2fICoDSA50139.2020.9212850&partnerID=40&md5=fdbe4f028be554a68334463f09eaa7f3"
"DC-SMIL: A multiple instance learning solution via spherical separation for automated detection of displastyc nevi","Vocaturo E.; Zumpano E.; Giallombardo G.; Miglionico G.","2020","0","1","0","0","0","First occurrence","0","","","","","","","Among skin cancers, melanoma is the most aggressive and most lethal form. Despite these terrible premises, an excision treatment carried out thanks to an early diagnosis is almost always decisive, guaranteeing the patient's survival. The early detection of melanoma is hampered by the extreme similarity of melanoma with other skin lesions such as dysplastic nevi. The current research is aimed at defining software solutions that support the computerized diagnosis of lesions for the detection of melanoma. To date, the proposals, both in terms of algorithms and frameworks, have focused on the dichotomous distinction of melanoma from benign lesions. However, the current debate on Dysplastic Nevi Syndrome (DNS), makes issues relating to the nature of the lesions, central to subjects who present a large number of moles throughout the body. In fact, individuals with DNS have a greater chance of being attacked by melanoma. The classification task relating to the distinction of dysplastic nevi from common ones is totally unexplored. In this document, we consider the difficult task of applying multiple-instance learning (MIL) approaches to discriminate melanoma from dysplastic nevi and outline an even more complex challenge related to the classification of dysplastic nevi from common ones. In particular, we introduce the application of a MIL approach that uses spherical separation surfaces. Since the results seem promising, we conclude that a MIL technique could be the basis of more sophisticated tools useful for detecting skin lesions.  © 2020 ACM.","10.1145/3410566.3410611","dermoscopy imaging classification; dysplastic moles; melanoma; spherical multiple instance learning","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091093148&doi=10.1145%2f3410566.3410611&partnerID=40&md5=d5bfa74ee7f87cc5be018951a6d887d8"
"Modeling and Anlysis for Diagnosis Skin Lesions using Modern Artificial Swarm Intelligence Techniques (MASITs)","Aljanabi M.; Ajel A.R.; Al-Azawi A.; Abdul-Nab R.A.","2020","1","1","0","0","0","Unique","0","","","","","","","MASITs provides an optimum outcomes if it is not probable to become the solutions of huge inflexible optimization difficulties. Computerized investigation of skin lesions is a significant problem in data retrieval for medical imaging, it supports human experts to enhance their choice construction for rapid and accurate analysis of unhealthy nevi and other skin diseases. In this article, computerized investigation of skin lesions has been addressed, by an adjustment of controlling swarm intelligence system (Artifical Bee Colony{ABC}).The modified system is hybridized with a search technique for improved performance. Experimental outcomes on a level of medical images of early diagnosis skin lesions confirmation that this technique outclasses conventional mathematical approaches for the cases in the standard. It is identical good and regularly higher to advanced systems in the area in relationships of mathematical accuracy. The chief benefit of the proposed technique is that this diagnosis can segment skin lesions by resolve images. So, additional comprehensive features can be found from the segmented portion of the lesion, which in turn contributes on organization medical service accuracy. © 2020 Published under licence by IOP Publishing Ltd.","10.1088/1757-899X/881/1/012133","Boundary Detection; Dermatologist; MASITs System; Medical Imaging; Skin Lesions","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090273678&doi=10.1088%2f1757-899X%2f881%2f1%2f012133&partnerID=40&md5=1a1c41be4d0c92898fa68157a6a5a9a2"
"Skin lesion segmentation via generative adversarial networks with dual discriminators","Lei B.; Xia Z.; Jiang F.; Jiang X.; Ge Z.; Xu Y.; Qin J.; Chen S.; Wang T.; Wang S.","2020","1","1","0","0","0","Unique","0","","","","","","","Skin lesion segmentation from dermoscopy images is a fundamental yet challenging task in the computer-aided skin diagnosis system due to the large variations in terms of their views and scales of lesion areas. We propose a novel and effective generative adversarial network (GAN) to meet these challenges. Specifically, this network architecture integrates two modules: a skip connection and dense convolution U-Net (UNet-SCDC) based segmentation module and a dual discrimination (DD) module. While the UNet-SCDC module uses dense dilated convolution blocks to generate a deep representation that preserves fine-grained information, the DD module makes use of two discriminators to jointly decide whether the input of the discriminators is real or fake. While one discriminator, with a traditional adversarial loss, focuses on the differences at the boundaries of the generated segmentation masks and the ground truths, the other examines the contextual environment of target object in the original image using a conditional discriminative loss. We integrate these two modules and train the proposed GAN in an end-to-end manner. The proposed GAN is evaluated on the public International Skin Imaging Collaboration (ISIC) Skin Lesion Challenge Datasets of 2017 and 2018. Extensive experimental results demonstrate that the proposed network achieves superior segmentation performance to state-of-the-art methods. © 2020 Elsevier B.V.","10.1016/j.media.2020.101716","Dense convolution U-Net; Dual discriminators; Generative adversarial network; Skin lesion segmentation","232","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085554310&doi=10.1016%2fj.media.2020.101716&partnerID=40&md5=33a62ccf4c5deaed87eaf83dd7a3c294"
"Melanoma diagnosis using deep learning and fuzzy logic","Banerjee S.; Singh S.K.; Chakraborty A.; Das A.; Bag R.","2020","0","1","0","0","0","Unique","0","","","","","","","Melanoma or malignant melanoma is a type of skin cancer that develops when melanocyte cells, damaged by excessive exposure to harmful UV radiations, start to grow out of control. Though less common than some other kinds of skin cancers, it is more dangerous because it rapidly metastasizes if not diagnosed and treated at an early stage. The distinction between benign and melanocytic lesions could at times be perplexing, but the manifestations of the disease could fairly be distinguished by a skilled study of its histopathological and clinical features. In recent years, deep convolutional neural networks (DCNNs) have succeeded in achieving more encouraging results yet faster and computationally effective systems for detection of the fatal disease are the need of the hour. This paper presents a deep learning-based 'You Only Look Once (YOLO)' algorithm, which is based on the application of DCNNs to detect melanoma from dermoscopic and digital images and offer faster and more precise output as compared to conventional CNNs. In terms with the location of the identified object in the cell, this network predicts the bounding box of the detected object and the class confidence score. The highlight of the paper, however, lies in its infusion of certain resourceful concepts like two phase segmentation done by a combination of the graph theory using minimal spanning tree concept and L-type fuzzy number based approximations and mathematical extraction of the actual affected area of the lesion region during feature extraction process. Experimented on a total of 20250 images from three publicly accessible datasets-PH2, International Symposium on Biomedical Imaging (ISBI) 2017 and The International Skin Imaging Collaboration (ISIC) 2019, encouraging results have been obtained. It achieved a Jac score of 79.84% on ISIC 2019 dataset and 86.99% and 88.64% on ISBI 2017 and PH2 datasets, respectively. Upon comparison of the pre-defined parameters with recent works in this area yielded comparatively superior output in most cases. © 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/).","10.3390/diagnostics10080577","Deep learning; Melanoma; Skin cancer; Skin lesion segmentation; YOLO","77","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090249765&doi=10.3390%2fdiagnostics10080577&partnerID=40&md5=47b4251a52baaeaf3b5e73c667b0159e"
"Past and present of computer-assisted dermoscopic diagnosis: performance of a conventional image analyser versus a convolutional neural network in a prospective data set of 1,981 skin lesions","Sies K.; Winkler J.K.; Fink C.; Bardehle F.; Toberer F.; Buhl T.; Enk A.; Blum A.; Rosenberger A.; Haenssle H.A.","2020","1","1","0","0","0","Unique","0","","","","","","","Background: Convolutional neural networks (CNNs) have shown a dermatologist-level performance in the classification of skin lesions. We aimed to deliver a head-to-head comparison of a conventional image analyser (CIA), which depends on segmentation and weighting of handcrafted features, to a CNN trained by deep learning. Methods: Cross-sectional study using a real-world, prospectively acquired, dermoscopic dataset of 1981 skin lesions to compare the diagnostic performance of a market-approved CNN (Moleanalyzer-Pro™, developed in 2018) to a CIA (Moleanalyzer-3™/Dynamole™; developed in 2004, all FotoFinder Systems Inc, Germany). As a reference standard, we used histopathological diagnoses (n = 785) or, in non-excised benign lesions (n = 1196), expert consensus plus an uneventful follow-up by sequential digital dermoscopy for at least 2 years. Results: A total of 281 malignant lesions and 1700 benign lesions from 435 patients (62.2% male, mean age: 52 years) were prospectively imaged. The CNN showed a sensitivity of 77.6% (95% confidence interval [CI]: [72.4%–82.1%]), specificity of 95.3% (95% CI: [94.2%–96.2%]), and receiver operating characteristic (ROC)-area under the curve (AUC) of 0.945 (95% CI: [0.930–0.961]). In contrast, the CIA achieved a sensitivity of 53.4% (95% CI: [47.5%–59.1%]), specificity of 86.6% (95% CI: [84.9%–88.1%]) and ROC-AUC of 0.738 (95% CI: [0.701–0.774]). The data set included melanomas originally diagnosed by dynamic changes during sequential digital dermoscopy (52 of 201, 20.6%), which reduced the sensitivities of both classifiers. Pairwise comparisons of sensitivities, specificities, and ROC-AUCs indicated a clear outperformance by the CNN (all p < 0.001). Conclusions: The superior diagnostic performance of the CNN argues against a continued application of former CIAs as an aide to physicians’ clinical management decisions. © 2020 Elsevier Ltd","10.1016/j.ejca.2020.04.043","Automated melanoma detection; Computer-assisted diagnosis; Convolutional neural network; Deep learning; Dermoscopy; Skin cancer; Skin lesions","27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086133129&doi=10.1016%2fj.ejca.2020.04.043&partnerID=40&md5=c17ff113bf3d78c9e39a3eb42bbbcf7a"
"Study of UV Skin Image Generation from an RGB Color Image with Deep Learning for Beauty Industries","Matsuo R.; Hasegawa M.","2020","1","1","0","0","0","Unique","0","","","","","","","Skin visualization for beauty industries using deep learning is discussed. UV skin images were taken by a medical dermoscopy digital camera, and we created datasets for training. Neural networks called U-net and convolutional autoencoder were constructed and trained with our datasets. Once our neural network was trained, skin images that approximated the UV image could be generated without the medical camera. The performance of our U-net and convolutional autoencoder is discussed.  © 2020 IEICE.","","and beauty industry; convolutional autoencoder; deep learning; U-net; UV skin image","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091414823&partnerID=40&md5=b19c6707cb468a0c722140deeefd146b"
"Effect of Image Downsizing and Color Reduction on Skin Cancer Pre-screening","Setiawan A.W.; Faisal A.; Resfita N.","2020","1","1","0","0","0","Unique","0","","","","","","","Every year, the skin cancer burden is increasing due to ultraviolet exposure caused by the gradual thinning of Earth's ozone layer. One of the main methods to detect skin lesion is using image processing techniques, including the use of machine learning. This research tries to explore the effect of skin cancer image downsizing and color dimensional reduction using k-means clustering on skin lesion pre-screening. The contribution of this research is that for skin cancer pre-screening using CNN, the optimal combination that can be used in terms of accuracy (training and validation); image size; the number of colors; and computing time, is the combination of 8 colors and 200× 150 pixels image. The significance of this study is that the penetration of smartphones as low-cost computation resources are tremendous, particularly in Indonesia. This device can be used to detect the skin lesion in an easy way due to it is already equipped with a camera, processor, memory, and other computing peripherals.  © 2020 IEEE.","10.1109/ISITIA49792.2020.9163734","image downsizing; k-means; machine-learning; pre-screening; skin cancer","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091698560&doi=10.1109%2fISITIA49792.2020.9163734&partnerID=40&md5=cc9165109659f614e53af11351f234b5"
"Convolutional descriptors aggregation via cross-net for skin lesion recognition","Yu Z.; Jiang F.; Zhou F.; He X.; Ni D.; Chen S.; Wang T.; Lei B.","2020","1","1","0","0","0","Unique","0","","","","","","","Malignant melanoma is one of the rare but deadliest types of skin cancers. Clinically, the early diagnosis of this disease is based on human visual inspection with dermoscopy imaging. However, human observations are subjective and prone to errors due to huge variations within dermoscopy images. To address it, we propose a framework for automatic skin lesion recognition using cross-net based aggregation of multiple convolutional networks. The output activation maps of each network are extracted as indicator maps to select the local deep convolutional descriptors (i.e., local patterns and color) in dermoscopy images. Also, this map of a convolutional layer captures the semantic regions of the input image and localizes the target object. These selected features are aggregated into an informative feature map, which are potentially better preserved in the convolutional feature maps. Finally, we use Fisher vector (FV) to encode the selected features. Extensive experiments demonstrate the effectiveness of our proposed method. Comparing with aggregation strategy using pooling approaches, the proposed method learns more robust and discriminative representations based on the publicly available skin lesion challenge datasets from the International Symposium on Biomedical Imaging (ISBI) 2016 and 2017. © 2020","10.1016/j.asoc.2020.106281","Cross-net model; Deep learning; Dermoscopy image; Melanoma recognition; Residual network","42","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083467511&doi=10.1016%2fj.asoc.2020.106281&partnerID=40&md5=62bf1c4443711f97583b099d0d209a78"
"Analysis on melanoma skin segmentation by utilization of morphological process with PCA algorithms","Sravanathi P.; Ravikanth P.; Ramesh T.; Raghava","2020","1","1","0","0","0","Unique","0","","","","","","","Skin is the largest organ as it is located throughout the human body and it is one of the five sense organs. Skin protects the human body against heat, sunlight and injury. Skin cancer is a major dangerous manifestation of disease by late days, skin growth may be viewed as will a chance to be a standout amongst the A large portion hazardous types of tumor discovered to people. Skin growth is discovered On Different types, which incorporate melanoma, basal cell carcinoma, and squamous cell carcinoma, the vast undetermined being melanoma. Early detection of melanoma cancer can be effective in treating it. It is caused by-exposure to UV rays. The early detection of a deadly form of skin cancer can be done by using image-based computer aided diagnostic systems. These image processing systems have a significant potential to detect malignant melanoma. The acquired original image is processed in such a way that the quality of image is enhanced by removal of noise and structures like hair. The process is mainly carried out through Principal Component Analysis and Morphological operators for feature extraction. The algorithm can be implemented through Matlab tool with version R2015b or above. The main goal of this work is to extract and outline the skin lesion for early detection, which can help in prompt treatment at the right time to prevent loss of life. © 2020, Advanced Scientific Research. All rights reserved.","10.31838/ijpr/2020.SP2.425","Morphological and Melanoma; Principle Component Analysis","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094129313&doi=10.31838%2fijpr%2f2020.SP2.425&partnerID=40&md5=666a8334f58737668ee8f3dd75a60fc8"
"Melanoma skin cancer classification using deep learning convolutional neural network","Mohan Kumar S.; Ram Kumar J.; Gopalakrishnan K.","2020","1","1","0","0","0","Unique","0","","","","","","","In the recent years skin cancer skin cancer is emerging as one of the most complex diseases in which diagnosis is very challenging. Melanoma is generally characterized by the uncontrolled growth of body cells which might be caused due to prolonged exposure to UV rays produced by sun. Skin cancer can be categorized as basal cell carcinoma, squamous cell carcinoma and melanoma among which melanoma is considered as the most difficult to detect and if detected on time, melanoma is curable. Computer vision and Image processing toolboxes plays a pivotal portion in the field of medical imaging and diagnosis and is widely used. This paper focuses on a computer aided tool for skin cancer detection (i.e. melanoma). Dermoscopic images are used as inputs to the CAD system which is subjected to further image processing in which segmentation, feature extraction and classification is done to finally to differentiate between normal and melanoma images. © 2020, World Informations Syndicate. All rights reserved.","","Computer Aided Diagnosis; Convolutional Neural Network; Feature Extraction; Skin cancer","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093067569&partnerID=40&md5=c6c123d30ee2774622b910e6f88c8a2a"
"Directional Vector-Based Skin Lesion Segmentation - A Novel Approach to Skin Segmentation","Nikesh P.; Raju G.","2020","1","1","0","0","0","Unique","0","","","","","","","Efficient skin lesion segmentation algorithms are required for computer aided diagnosis of skin cancer. Several algorithms were proposed for skin lesion segmentation. The existing algorithms are short of achieving ideal performance. In this paper, a novel semi-automatic segmentation algorithm is proposed. The fare concept of the proposed is 8-directional search based on threshold for lesion pixel, starting from a user provided seed point. The proposed approach is tested on 200 images from PH2 and 900 images from ISBI 2016 datasets. In comparison to a chosen set of algorithms, the proposed approach gives high accuracy and specificity values. A significant advantage of the proposed method is the ability to deal with discontinuities in the lesion. © 2020 World Scientific Publishing Company.","10.1142/S0219467820500217","8-directional vector; dermoscopy; DVBSLS; PH2 lesion pixel; secondary seed; semi-automatic","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089584569&doi=10.1142%2fS0219467820500217&partnerID=40&md5=930f9edee2f15003473f847af81adb0e"
"Multiple skin lesions diagnostics via integrated deep convolutional networks for segmentation and classification","Al-masni M.A.; Kim D.-H.; Kim T.-S.","2020","1","1","0","0","0","Unique","0","","","","","","","Background and objective: Computer automated diagnosis of various skin lesions through medical dermoscopy images remains a challenging task. Methods: In this work, we propose an integrated diagnostic framework that combines a skin lesion boundary segmentation stage and a multiple skin lesions classification stage. Firstly, we segment the skin lesion boundaries from the entire dermoscopy images using deep learning full resolution convolutional network (FrCN). Then, a convolutional neural network classifier (i.e., Inception-v3, ResNet-50, Inception-ResNet-v2, and DenseNet-201) is applied on the segmented skin lesions for classification. The former stage is a critical prerequisite step for skin lesion diagnosis since it extracts prominent features of various types of skin lesions. A promising classifier is selected by testing well-established classification convolutional neural networks. The proposed integrated deep learning model has been evaluated using three independent datasets (i.e., International Skin Imaging Collaboration (ISIC) 2016, 2017, and 2018, which contain two, three, and seven types of skin lesions, respectively) with proper balancing, segmentation, and augmentation. Results: In the integrated diagnostic system, segmented lesions improve the classification performance of Inception-ResNet-v2 by 2.72% and 4.71% in terms of the F1-score for benign and malignant cases of the ISIC 2016 test dataset, respectively. The classifiers of Inception-v3, ResNet-50, Inception-ResNet-v2, and DenseNet-201 exhibit their capability with overall weighted prediction accuracies of 77.04%, 79.95%, 81.79%, and 81.27% for two classes of ISIC 2016, 81.29%, 81.57%, 81.34%, and 73.44% for three classes of ISIC 2017, and 88.05%, 89.28%, 87.74%, and 88.70% for seven classes of ISIC 2018, respectively, demonstrating the superior performance of ResNet-50. Conclusions: The proposed integrated diagnostic networks could be used to support and aid dermatologists for further improvement in skin cancer diagnosis. © 2020","10.1016/j.cmpb.2020.105351","CAD; Classification; CNN; Deep learning; ISIC; Melanoma; Segmentation; Skin lesion","311","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078780551&doi=10.1016%2fj.cmpb.2020.105351&partnerID=40&md5=b232d473289572e7864d37e6af4b1eb3"
"Entropy-based breast cancer detection in digital mammograms using world cup optimization algorithm","Razmjooy N.; Estrela V.V.; Loschi H.J.","2020","0","1","0","0","0","First occurrence","0","","","","","","","Breast cancer is one of the deadliest cancers for women. Early detection of skin cancer gives a high chance for the women to escape from the malady and obtain a cure at the initial stages. In other words, early detection of breast cancer has a direct relation by the women's quality of life. In this case, mammography images are important. Indeed, the main test used for screening and early diagnosis of breast cancer is mammography. In recent years, computer-aided cancer detection has been turned into an active field of research and showed a promising future. In this study, a new optimization algorithm based on thresholding is introduced. A WCO algorithm is employed as the optimization algorithm. WCO is a new meta-heuristic approach which is inspired by the FIFA world cup challenge. The presented method utilizes random samples as candidate solutions from the search space inside the image histogram with considering to the objective function that is utilized by the Kapur's method. © 2020, IGI Global.","10.4018/IJSIR.2020070101","Breast Cancer; Entropy; Image Processing; Kapur Thresholding; Mammography; Segmentation; World Cup Optimization","35","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085747585&doi=10.4018%2fIJSIR.2020070101&partnerID=40&md5=387a9144db980d27208753d5b2cae90e"
"A Novel Fuzzy Multilayer Perceptron (F-MLP) for the Detection of Irregularity in Skin Lesion Border Using Dermoscopic Images","Ali A.-R.; Li J.; Kanwal S.; Yang G.; Hussain A.; Jane O'Shea S.","2020","1","1","0","0","0","Unique","0","","","","","","","Skin lesion border irregularity, which represents the B feature in the ABCD rule, is considered one of the most significant factors in melanoma diagnosis. Since signs that clinicians rely on in melanoma diagnosis involve subjective judgment including visual signs such as border irregularity, this deems it necessary to develop an objective approach to finding border irregularity. Increased research in neural networks has been carried out in recent years mainly driven by the advances of deep learning. Artificial neural networks (ANNs) or multilayer perceptrons have been shown to perform well in supervised learning tasks. However, such networks usually don't incorporate information pertaining the ambiguity of the inputs when training the network, which in turn could affect how the weights are being updated in the learning process and eventually degrading the performance of the network when applied on test data. In this paper, we propose a fuzzy multilayer perceptron (F-MLP) that takes the ambiguity of the inputs into consideration and subsequently reduces the effects of ambiguous inputs on the learning process. A new optimization function, the fuzzy gradient descent, has been proposed to reflect those changes. Moreover, a type-II fuzzy sigmoid activation function has also been proposed which enables finding the range of performance the fuzzy neural network is able to attain. The fuzzy neural network was used to predict the skin lesion border irregularity, where the lesion was firstly segmented from the skin, the lesion border extracted, border irregularity measured using a proposed measure vector, and using the extracted border irregularity measures to train the neural network. The proposed approach outperformed most of the state-of-the-art classification methods in general and its standard neural network counterpart in particular. However, the proposed fuzzy neural network was more time-consuming when training the network. © Copyright © 2020 Ali, Li, Kanwal, Yang, Hussain and Jane O'Shea.","10.3389/fmed.2020.00297","dermoscopy; fuzzy logic; irregularity; melanoma; multilayer perceptron","23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084920768&doi=10.3389%2ffmed.2020.00297&partnerID=40&md5=558197b4e6513df48299f7f926b39550"
"Improved skin lesions detection using color space and artificial intelligence techniques","Sengupta S.; Mittal N.; Modi M.","2020","1","1","0","0","0","Unique","0","","","","","","","Background: Automatic skin lesion image identification is of utmost importance to develop a fully automatized computer-aided skin analysis system. This will be helping the medical practitioners to provide skin lesions disease treatment more efficiently and effectively. Material and method: In this article, two image processing techniques for accurate detection of skin lesions have been proposed. In first technique, the optimization of edge detection has been carried out by using a branch of artificial intelligence called nature inspired algorithm. Ant colony optimization (ACO) is used to increase effectiveness of edge detection in skin lesion. The second technique deals with the color space-based split-and-merge process in combination with global thresholding segmentation and edge smoothing operations. Result: The performance of both techniques has been measured by entropy performance evaluation parameter. The results show remarkable improvement in output images obtained by Canny edge detection technique optimized by ACO in comparison with ACO-Sobel, ACO-Prewitt and Edge Smoothing-Color Space techniques. Conclusion: ACO-Canny Edge detection technique shows far better effieciency for skin lesion detection as compared to ACO-Sobel, ACO-Prewitt and Edge Smoothing Color Space technique. © 2020, © 2020 Taylor & Francis Group, LLC.","10.1080/09546634.2019.1708239","ant colony optimization; artificial intelligence; Canny; color space; edge detection; edge smoothing; Prewitt; segmentation; Skin lesions; Sobel; threshold","28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078601636&doi=10.1080%2f09546634.2019.1708239&partnerID=40&md5=579f3376057aee1aa8c60f7d90a15e35"
"Unique Color Circle Design for A Novel Screening Tool to Identify Cancerous Skin Lesions","Prasad R.S.; Kumar Singh G.; Prasad S.; Prasad V.","2020","1","1","0","0","0","Unique","0","","","","","","","Diagnosis of skin cancer is mostly based on clinical examination and biopsy. Despite advances in diagnostic tools, both invasive and non-invasive, more than 2 people die of the disease every hour and more than 9,500 people are diagnosed with skin cancer every day in the US. This emphasizes the need to have a screening tool which can differentiate between non-cancerous (NC) and cancerous (C) skin lesions, quickly and effectively. As most of the skin lesions are apparent to naked eyes and have different color textures, it was hypothesized that segmental analyses of photographs of suspicious lesions should be able to differentiate NC from C lesions on skin. For this study, a new and unique color circle design (CCD) for establishing a relation between wavelength (λ) and hue of the HSV (hue Saturation and Value) model is proposed. Using MATLAB, enlarged dermatoscopic images of 23 authentic skin lesions (test samples) with known diagnoses were segmented in such a manner that the region of interest (ROI) included all the suspicious areas. Thereafter, the pixels data from ROI locations were standardized and transformed from RGB to HSV space. Again using MATLAB, hue (h) and Value (V) data were extracted from HSV data. Since each h represents a unique wavelength in the visible range of the spectrum, the CCD was used to identify the cancerous lesions aided by the V parameter. Using trial and error on several other skin cancer lesions (not included in the test samples), two thresholds and a set of criteria were selected to discriminate between C and NC. Results show that use of CCD has great potential as a screening tool for skin cancer detection, achieving over 90 % accuracy on the test samples.  © 2020 IEEE.","10.1109/CONECCT50063.2020.9198345","HSV; Image-based cancer diagnostics; RGB; Skin Cancer; Spectral Analysis","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093084058&doi=10.1109%2fCONECCT50063.2020.9198345&partnerID=40&md5=ff1a1775b48108033d74cdb57bc221bc"
"Spectrally-enforced global receptive field for contextual medical image segmentation and classification","Li Y.; Chi L.; Tian G.; Mu Y.; Ge S.; Qiao Z.; Wu X.; Fan W.","2020","0","1","0","0","0","First occurrence","0","","","","","","","Deep convolutional neural networks (CNNs) have recalibrated the state-of-the-art for a plethora of applications in medical image analyzing such as segmentation and classification. Large receptive field is crucial for modeling long-range spatial dependency in medical images. In this paper, we propose a novel architectural network design for accomplishing a full-image global receptive field, which we call spectral residual block (SRB). Specifically, we propose to utilize a unitary transform that essentially conducts a local-to-global transform. All elements are mapped to spectral domain and thus globally depend on each other. A variety of global operators are carefully devised and efficiently enforce a full-image receptive field, including spectral ReLU for frequency-sensitive filtering and spectral convolutions. The output in spectral domain is eventually converted back global-to-local via a reverse unitary transform. The proposed framework is generic and flexible, and could be applied to various network structures and tasks. Comprehensive evaluations on skin lesion segmentation and Chest X-Ray classification show that our method achieves the state-of-the-art performance, demonstrating both effectiveness and efficiency. © 2020 IEEE.","10.1109/ICME46284.2020.9102949","Classification; Medical image analysis; Neural network; Non-local; Segmentation","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090388012&doi=10.1109%2fICME46284.2020.9102949&partnerID=40&md5=ebef812fb89e0e1016ed525438169486"
"On Interpretability of Deep Learning based Skin Lesion Classifiers using Concept Activation Vectors","Lucieri A.; Bajwa M.N.; Alexander Braun S.; Malik M.I.; Dengel A.; Ahmed S.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Deep learning based medical image classifiers have shown remarkable prowess in various application areas like ophthalmology, dermatology, pathology, and radiology. However, the acceptance of these Computer-Aided Diagnosis (CAD) systems in real clinical setups is severely limited primarily because their decision-making process remains largely obscure. This work aims at elucidating a deep learning based medical image classifier by verifying that the model learns and utilizes similar disease-related concepts as described and employed by dermatologists. We used a well-trained and high performing neural network developed by REasoning for COmplex Data (RECOD) Lab for classification of three skin tumours, i.e. Melanocytic Naevi, Melanoma and Seborrheic Keratosis and performed a detailed analysis on its latent space. Two well established and publicly available skin disease datasets, PH2 and derm7pt, are used for experimentation. Human understandable concepts are mapped to RECOD image classification model with the help of Concept Activation Vectors (CAVs), introducing a novel training and significance testing paradigm for CAVs. Our results on an independent evaluation set clearly shows that the classifier learns and encodes human understandable concepts in its latent representation. Additionally, TCAV scores (Testing with CAVs) suggest that the neural network indeed makes use of disease-related concepts in the correct way when making predictions. We anticipate that this work can not only increase confidence of medical practitioners on CAD but also serve as a stepping stone for further development of CAV-based neural network interpretation methods. © 2020 IEEE.","10.1109/IJCNN48605.2020.9206946","Computer-Aided Diagnosis; Concept Activation Vectors; Convolutional Neural Networks; Explainable Artificial Intelligence; Medical Image Analysis; Skin Lesion Classification","55","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093844856&doi=10.1109%2fIJCNN48605.2020.9206946&partnerID=40&md5=97a38f11cebda64e85c62367e692ea21"
"Artificial Intelligence in Cutaneous Oncology","Chu Y.S.; An H.G.; Oh B.H.; Yang S.","2020","0","1","0","0","0","Unique","0","","","","","","","Skin cancer, previously known to be a common disease in Western countries, is becoming more common in Asian countries. Skin cancer differs from other carcinomas in that it is visible to our eyes. Although skin biopsy is essential for the diagnosis of skin cancer, decisions regarding whether or not to conduct a biopsy are made by an experienced dermatologist. From this perspective, it is easy to obtain and store photos using a smartphone, and artificial intelligence technologies developed to analyze these photos can represent a useful tool to complement the dermatologist's knowledge. In addition, the universal use of dermoscopy, which allows for non-invasive inspection of the upper dermal level of skin lesions with a usual 10-fold magnification, adds to the image storage and analysis techniques, foreshadowing breakthroughs in skin cancer diagnosis. Current problems include the inaccuracy of the available technology and resulting legal liabilities. This paper presents a comprehensive review of the clinical applications of artificial intelligence and a discussion on how it can be implemented in the field of cutaneous oncology. © Copyright © 2020 Chu, An, Oh and Yang.","10.3389/fmed.2020.00318","artificial intellegence; cutaneous oncology; deep learning; machine learning; skin cancer","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088532870&doi=10.3389%2ffmed.2020.00318&partnerID=40&md5=2087e06e87ee2e5ebddcc169c61a15b9"
"Dense-unet: A novel multiphoton in vivo cellular image segmentation model based on a convolutional neural network","Cai S.; Tian Y.; Lui H.; Zeng H.; Wu Y.; Chen G.","2020","0","1","0","0","0","Unique","0","","","","","","","Background: Multiphoton microscopy (MPM) offers a feasible approach for the biopsy in clinical medicine, but it has not been used in clinical applications due to the lack of efficient image processing methods, especially the automatic segmentation technology. Segmentation technology is still one of the most challenging assignments of the MPM imaging technique. Methods: The MPM imaging segmentation model based on deep learning is one of the most effective methods to address this problem. In this paper, the practicability of using a convolutional neural network (CNN) model to segment the MPM image of skin cells in vivo was explored. A set of MPM in vivo skin cells images with a resolution of 128×128 was successfully segmented under the Python environment with TensorFlow. A novel deep-learning segmentation model named Dense-UNet was proposed. The Dense-UNet, which is based on U-net structure, employed the dense concatenation to deepen the depth of the network architecture and achieve feature reuse. This model included four expansion modules (each module consisted of four down-sampling layers) to extract features. Results: Sixty training images were taken from the dorsal forearm using a femtosecond Ti:Sa laser running at 735 nm. The resolution of the images is 128×128 pixels. Experimental results confirmed that the accuracy of Dense-UNet (92.54%) was higher than that of U-Net (88.59%), with a significantly lower loss value of 0.1681. The 90.60% Dice coefficient value of Dense-UNet outperformed U-Net by 11.07%. The F1-Score of Dense-UNet, U-Net, and Seg-Net was 93.35%, 90.02%, and 85.04%, respectively. Conclusions: The deepened down-sampling path improved the ability of the model to capture cellular fined-detailed boundary features, while the symmetrical up-sampling path provided a more accurate location based on the test result. These results were the first time that the segmentation of MPM in vivo images had been adopted by introducing a deep CNN to bridge this gap in Dense-UNet technology. Dense-UNet has reached ultramodern performance for MPM images, especially for in vivo images with low resolution. This implementation supplies an automatic segmentation model based on deep learning for high-precision segmentation of MPM images in vivo. © Quantitative Imaging in Medicine and Surgery. All rights reserved.","10.21037/QIMS-19-1090","Dense-UNet; Image segmentation; Multiphoton microscopy (MPM); Skin in vivo; U-Net","237","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087514814&doi=10.21037%2fQIMS-19-1090&partnerID=40&md5=b4854550d1ad5b86058e191ee53118f1"
"Less is more: Sample selection and label conditioning improve skin lesion segmentation","Ribeiro V.; Avila S.; Valle E.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Segmenting skin lesions images is relevant both for itself and for assisting in lesion classification, but suffers from the challenge in obtaining annotated data. In this work, we show that segmentation may improve with less data, by selecting the training samples with best inter-annotator agreement, and conditioning the ground-truth masks to remove excessive detail. We perform an exhaustive experimental design considering several sources of variation, including three different test sets, two different deep-learning architectures, and several replications, for a total of 540 experimental runs. We found that sample selection and detail removal may have impacts corresponding, respectively, to 12% and 16% of the one obtained by picking a better deep-learning model. © 2020 IEEE.","10.1109/CVPRW50498.2020.00377","","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090121246&doi=10.1109%2fCVPRW50498.2020.00377&partnerID=40&md5=ee9dc33612502197c412d5ff1ba7496c"
"Automatic Segmentation of Epidermis and Hair Follicles in Optical Coherence Tomography Images of Normal Skin by Convolutional Neural Networks","del Amor R.; Morales S.; Colomer A.; Mogensen M.; Jensen M.; Israelsen N.M.; Bang O.; Naranjo V.","2020","1","1","0","0","0","Unique","0","","","","","","","Optical coherence tomography (OCT) is a well-established bedside imaging modality that allows analysis of skin structures in a non-invasive way. Automated OCT analysis of skin layers is of great relevance to study dermatological diseases. In this paper, an approach to detect the epidermal layer along with the follicular structures in healthy human OCT images is presented. To the best of the authors' knowledge, the approach presented in this paper is the only epidermis detection algorithm that segments the pilosebaceous unit, which is of importance in the progression of several skin disorders such as folliculitis, acne, lupus erythematosus, and basal cell carcinoma. The proposed approach is composed of two main stages. The first stage is a Convolutional Neural Network based on U-Net architecture. The second stage is a robust post-processing composed by a Savitzky-Golay filter and Fourier Domain Filtering to fully define the borders belonging to the hair follicles. After validation, an average Dice of 0.83 ± 0.06 and a thickness error of 10.25 μm is obtained on 270 human skin OCT images. Based on these results, the proposed method outperforms other state-of-the-art methods for epidermis segmentation. It demonstrates that the proposed image segmentation method successfully detects the epidermal region in a fully automatic way in addition to defining the follicular skin structures as main novelty. © Copyright © 2020 del Amor, Morales, Colomer, Mogensen, Jensen, Israelsen, Bang and Naranjo.","10.3389/fmed.2020.00220","convolutional neural networks; epidermis; follicular structures; layer segmentation; pilosebaceous unit; skin OCT","35","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087927888&doi=10.3389%2ffmed.2020.00220&partnerID=40&md5=533ca8e19391dacd9ac1807e782acc1c"
"Meta-DermDiagnosis: Few-shot skin disease identification using meta-learning","Mahajan K.; Sharma M.; Vig L.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Annotated images for diagnosis of rare or novel diseases are likely to remain scarce due to small affected patient population and limited clinical expertise to annotate images. Deep networks employed for image based diagnosis need to be robust enough to quickly adapt to novel diseases with few annotated images. Further, in case of the frequently occurring long-tailed class distributions in skin lesion and other disease classification datasets, conventional training approaches lead to poor generalization on classes at the tail end of the distribution due to biased class priors. This paper focuses on the problems of disease identification and quick model adaptation in such data-scarce and long-tailed class distribution scenarios by exploiting recent advances in meta-learning. This involves training a neural network on few-shot image classification tasks based on an initial set of class labels / head classes of the distribution, prior to adapting the model for classification on a set of unseen / tail classes. We named the proposed method Meta-DermDiagnosis because it utilizes meta-learning based few-shot learning techniques such as the gradient based Reptile and distance metric based Prototypical networks for identification of diseases in skin lesion datasets. We evaluate the effectiveness of our approach on publicly available skin lesion datasets, namely the ISIC 2018, Derm7pt and SD-198 datasets and obtain significant performance improvement over pretrained models with just a few annotated examples. Further, we incorporate Group Equivariant convolutions (G-convolutions) for the Meta-DermDiagnosis network to improve disease identification performance as these images generally do not have any prevailing global orientation / canonical structure and G-convolutions make the network equivariant to any discrete transformations like rotation, reflection and translation. © 2020 IEEE.","10.1109/CVPRW50498.2020.00373","","74","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090112897&doi=10.1109%2fCVPRW50498.2020.00373&partnerID=40&md5=e51f98283d1c81543bc7094ad27436bb"
"Review of Machine Learning in Predicting Dermatological Outcomes","Du A.X.; Emam S.; Gniadecki R.","2020","0","1","0","0","0","Unique","0","","","","","","","Artificial intelligence is a broad branch of computer science that has garnered significant interest in the field of medicine because of its problem solving, decision making and pattern recognition abilities. Machine learning, a subset of artificial intelligence, hones in on the ability of computers to receive data and learn for themselves, manipulating algorithms as they organize the information they are processing. Dermatology is at a particular advantage in the implementation of machine learning due to the availability of large clinical image databases that can be used for machine training and interpretation. While numerous studies have implemented machine learning in the diagnostic aspect of dermatology, less research has been conducted on the use of machine learning in predicting long-term outcomes in skin disease, with only a few studies published to date. Such an approach would assist physicians in selecting the best treatment methods, save patients' time, reduce treatment costs and improve the quality of treatment overall by reducing the amount of trial-and-error in the treatment process. In this review, we aim to provide a brief and relevant introduction to basic artificial intelligence processes, and to consolidate and examine the published literature on the use of machine learning in predicting clinical outcomes in dermatology. © Copyright © 2020 Du, Emam and Gniadecki.","10.3389/fmed.2020.00266","artificial intelligence; clinical outcomes; dermatology; machine learning; prediction","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087019000&doi=10.3389%2ffmed.2020.00266&partnerID=40&md5=e26a8d6a44b7da3bd73f09e5dafc0b0f"
"A deep learning system for differential diagnosis of skin diseases","Liu Y.; Jain A.; Eng C.; Way D.H.; Lee K.; Bui P.; Kanada K.; de Oliveira Marinho G.; Gallegos J.; Gabriele S.; Gupta V.; Singh N.; Natarajan V.; Hofmann-Wellenhof R.; Corrado G.S.; Peng L.H.; Webster D.R.; Ai D.; Huang S.J.; Liu Y.; Dunn R.C.; Coz D.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Skin conditions affect 1.9 billion people. Because of a shortage of dermatologists, most cases are seen instead by general practitioners with lower diagnostic accuracy. We present a deep learning system (DLS) to provide a differential diagnosis of skin conditions using 16,114 de-identified cases (photographs and clinical data) from a teledermatology practice serving 17 sites. The DLS distinguishes between 26 common skin conditions, representing 80% of cases seen in primary care, while also providing a secondary prediction covering 419 skin conditions. On 963 validation cases, where a rotating panel of three board-certified dermatologists defined the reference standard, the DLS was non-inferior to six other dermatologists and superior to six primary care physicians (PCPs) and six nurse practitioners (NPs) (top-1 accuracy: 0.66 DLS, 0.63 dermatologists, 0.44 PCPs and 0.40 NPs). These results highlight the potential of the DLS to assist general practitioners in diagnosing skin conditions. © 2020, The Author(s), under exclusive licence to Springer Nature America, Inc.","10.1038/s41591-020-0842-3","","553","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085168753&doi=10.1038%2fs41591-020-0842-3&partnerID=40&md5=86ae58ec086f467b85de765ebeab42f9"
"Quantifying the color changes in bruised skin using a color-calibrated imaging system","Li C.-R.; Tsai H.-Y.; Yang C.-C.; Lin M.-Y.; Huang K.-C.; Lin Y.-H.","2020","1","1","0","0","0","Unique","0","","","","","","","The color of human skin can indirectly reflect the course of certain diseases, especially trauma or chronic diseases. Traditionally, doctors inspect and notice the abnormalities in the patient's skin color and then perform further examinations, such as blood or urine tests. The color of the skin can only be seen as a reference through the naked eye. To quantify it depends on a measurement system with precise lighting control and color correction procedures. In this study, an imaging system with color correction was developed to quantify the color of the skin. Through the composition of high color rendering lighting, dark room module, camera and polynomial regression algorithm to achieve the standard color difference (ΔE∗) of less than 3. Measurements of artificial bruise and novel analytical methods were performed and developed to verify its performance. The results show that the developed system has the advantages of portability, high uniformity and high color accuracy. This research has successfully developed a novel inspection method for medical diagnostics, forensic science, and related applications. © 2020 IEEE.","10.1109/MeMeA49120.2020.9137217","color calibration; color rendering; skin color","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088899951&doi=10.1109%2fMeMeA49120.2020.9137217&partnerID=40&md5=510e5aeac855bd2af019b820cdea12e7"
"Augmenting data with GANs to segment melanoma skin lesions","Pollastri F.; Bolelli F.; Paredes R.; Grana C.","2020","1","1","0","0","0","First occurrence","0","","","","","","","This paper presents a novel strategy that employs Generative Adversarial Networks (GANs) to augment data in the skin lesion segmentation task, which is a fundamental first step in the automated melanoma detection process. The proposed framework generates both skin lesion images and their segmentation masks, making the data augmentation process extremely straightforward. In order to thoroughly analyze how the quality and diversity of synthetic images impact the efficiency of the method, we remodel two different well known GANs: a Deep Convolutional GAN (DCGAN) and a Laplacian GAN (LAPGAN). Experimental results reveal that, by introducing such kind of synthetic data into the training process, the overall accuracy of a state-of-the-art Convolutional/Deconvolutional Neural Network for melanoma skin lesion segmentation is increased. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.","10.1007/s11042-019-7717-y","Adversarial learning; Convolutional neural networks; Deep learning; Skin lesion segmentation","67","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066064848&doi=10.1007%2fs11042-019-7717-y&partnerID=40&md5=53eb2268b1cb3a49085aa185a41c904d"
"Illumination-based transformations improve skin lesion segmentation in dermoscopic images","Kumar A.; Hamarneh G.; Drew M.S.","2020","1","1","0","0","0","First occurrence","0","","","","","","","The semantic segmentation of skin lesions is an important and common initial task in the computer aided diagnosis of dermoscopic images. Although deep learning-based approaches have considerably improved the segmentation accuracy, there is still room for improvement by addressing the major challenges, such as variations in lesion shape, size, color and varying levels of contrast. In this work, we propose the first deep semantic segmentation framework for dermoscopic images which incorporates, along with the original RGB images, information extracted using the physics of skin illumination and imaging. In particular, we incorporate information from specific color bands, illumination invariant grayscale images, and shading-attenuated images. We evaluate our method on three datasets: the ISBI ISIC 2017 Skin Lesion Segmentation Challenge dataset, the DermoFit Image Library, and the PH2 dataset and observe improvements of 12.02%, 4.30%, and 8.86% respectively in the mean Jaccard index over a baseline model trained only with RGB images. © 2020 IEEE.","10.1109/CVPRW50498.2020.00372","","39","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090149590&doi=10.1109%2fCVPRW50498.2020.00372&partnerID=40&md5=9fd2edf3db1994e8f2398a1f3615f972"
"Simplification of neural networks for skin lesion image segmentation using color channel pruning","Hajabdollahi M.; Esfandiarpoor R.; Khadivi P.; Soroushmehr S.M.R.; Karimi N.; Samavi S.","2020","1","1","0","0","0","Unique","0","","","","","","","Automatic analysis of skin abnormality is an effective way for medical experts to facilitate diagnosis procedures and improve their capabilities. Efficient and accurate methods for analysis of the skin abnormalities such as convolutional neural networks (CNNs) are typically complex. Hence, the implementation of such complex structures in portable medical instruments is not feasible due to power and resource limitations. CNNs can extract features from the skin abnormality images automatically. To reduce the burden of the network for feature extraction, which can lead to the network simplicity, proper input color channels could be selected. In this paper, a pruning framework is proposed to simplify these complex structures through the selection of most informative color channels and simplification of the network. Moreover, hardware requirements of different network structures are identified to analyze the complexity of different networks. Experimental results are conducted for segmentation of images from two publicly available datasets of both dermoscopy and non-dermoscopy images. Simulation results show that using the proposed color channel selection method, simple and efficient neural network structures can be applied for segmentation of skin abnormalities. © 2020 Elsevier Ltd","10.1016/j.compmedimag.2020.101729","Lesion segmentation; Low complexity neural network; Portable devices; Pruning; Real-time; Skin lesions","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084760154&doi=10.1016%2fj.compmedimag.2020.101729&partnerID=40&md5=7f1b115bd4bcdcf837cca119bfbd5f60"
"Ensembling Learning Based Melanoma Classification Using Gradient Boosting Decision Trees","Han Y.; Zheng X.","2020","0","1","0","0","0","First occurrence","0","","","","","","","Melanoma has been regarded as one of the fatal skin cancer diseases all around the world. Early detection on melanoma can be quite helpful in the clinical treatment, to prevent the deterioration of the deadly diseases. Handcrafted-feature extraction and shallow architecture-based classifier (such as k-nearest neighbors algorithm, random forest, support vector machine) worked as the basis of the previous attempts in detecting process. During the recent years, the new approach named deep convolutional neural network (CNN) was used for the detecting task. Although the persistent progress and efforts have been achieved, the classification methods desire to go a further step in pursuing further improvement on its performance. The goal of this paper is to improve the detection performance using an ensemble learning framework. Both the personal information (such as the age, gender information of the patients) and latest deep learning approaches are applied in this paper. The two approaches have provided the mutual complements for each other, which demonstrated enormous advantages for the ensemble learning framework in detecting task. We conducted extensive experiments that provide a large dataset for detecting melanoma, which illustrates that our ensemble learning can provide superior performance with high accuracy. © 2020 ACM.","10.1145/3430199.3430215","convolutional neural; deep learning; ensemble learning; medical image classification; network","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099381468&doi=10.1145%2f3430199.3430215&partnerID=40&md5=cc61f09e1916d4737f362ac8aa8ce5dd"
"Agreement between saliency maps and human-labeled regions of interest: Applications to skin disease classification","Singh N.; Lee K.; Coz D.; Angermueller C.; Huang S.; Loh A.; Liu Y.","2020","1","1","0","0","0","First occurrence","0","","","","","","","We propose to systematically identify potentially problematic patterns in skin disease classification models via quantitative analysis of agreement between saliency maps and human-labeled regions of interest. We further compute summary statistics describing patterns in this agreement for various stratifications of input examples. Through this analysis, we discover candidate spurious associations learned by the classifier and suggest next steps to handle such associations. Our approach can be used as a debugging tool to systematically spot difficult examples and error categories. Insights from this analysis could guide targeted data collection and improve model generalizability. © 2020 IEEE.","10.1109/CVPRW50498.2020.00376","","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090126282&doi=10.1109%2fCVPRW50498.2020.00376&partnerID=40&md5=a718580247e8fc17592566bdb524ae58"
"Melanoma Skin Cancer Detection Method Based on Adaptive Principal Curvature, Colour Normalisation and Feature Extraction with the ABCD Rule","Thanh D.N.H.; Prasath V.B.S.; Hieu L.M.; Hien N.N.","2020","1","1","0","0","0","First occurrence","0","","","","","","","According to statistics of the American Cancer Society, in 2015, there are about 91,270 American adults diagnosed with melanoma of the skin. For the European Union, there are over 90,000 new cases of melanoma annually. Although melanoma only accounts for about 1% of all skin cancers, it causes most of the skin cancer deaths. Melanoma is considered one of the fastest-growing forms of skin cancer, and hence the early detection is crucial, as early detection is helpful and can provide strong recommendations for specific and suitable treatment regimens. In this work, we propose a method to detect melanoma skin cancer with automatic image processing techniques. Our method includes three stages: pre-process images of skin lesions by adaptive principal curvature, segment skin lesions by the colour normalisation and extract features by the ABCD rule. We provide experimental results of the proposed method on the publicly available International Skin Imaging Collaboration (ISIC) skin lesions dataset. The acquired results on melanoma skin cancer detection indicates that the proposed method has high accuracy, and overall, a good performance: for the segmentation stage, the accuracy, Dice, Jaccard scores are 96.6%, 93.9% and 88.7%, respectively; and for the melanoma detection stage, the accuracy is up to 100% for a selected subset of the ISIC dataset. © 2019, Society for Imaging Informatics in Medicine.","10.1007/s10278-019-00316-x","ABCD rule; Colour normalisation; Medical image processing; Medical image segmentation; Melanoma; Principal curvatures; Skin Cancer","106","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076896234&doi=10.1007%2fs10278-019-00316-x&partnerID=40&md5=f98a6c280589f35f599f28fa1eddcaf1"
"Artificial Intelligence in Skin Cancer Diagnostics: The Patients' Perspective","Jutzi T.B.; Krieghoff-Henning E.I.; Holland-Letz T.; Utikal J.S.; Hauschild A.; Schadendorf D.; Sondermann W.; Fröhling S.; Hekler A.; Schmitt M.; Maron R.C.; Brinker T.J.","2020","1","1","0","0","0","Unique","0","","","","","","","Background: Artificial intelligence (AI) has shown promise in numerous experimental studies, particularly in skin cancer diagnostics. Translation of these findings into the clinic is the logical next step. This translation can only be successful if patients' concerns and questions are addressed suitably. We therefore conducted a survey to evaluate the patients' view of artificial intelligence in melanoma diagnostics in Germany, with a particular focus on patients with a history of melanoma. Participants and Methods: A web-based questionnaire was designed using LimeSurvey, sent by e-mail to university hospitals and melanoma support groups and advertised on social media. The anonymous questionnaire evaluated patients' expectations and concerns toward artificial intelligence in general as well as their attitudes toward different application scenarios. Descriptive analysis was performed with expression of categorical variables as percentages and 95% confidence intervals. Statistical tests were performed to investigate associations between sociodemographic data and selected items of the questionnaire. Results: 298 individuals (154 with a melanoma diagnosis, 143 without) responded to the questionnaire. About 94% [95% CI = 0.91–0.97] of respondents supported the use of artificial intelligence in medical approaches. 88% [95% CI = 0.85–0.92] would even make their own health data anonymously available for the further development of AI-based applications in medicine. Only 41% [95% CI = 0.35–0.46] of respondents were amenable to the use of artificial intelligence as stand-alone system, 94% [95% CI = 0.92–0.97] to its use as assistance system for physicians. In sub-group analyses, only minor differences were detectable. Respondents with a previous history of melanoma were more amenable to the use of AI applications for early detection even at home. They would prefer an application scenario where physician and AI classify the lesions independently. With respect to AI-based applications in medicine, patients were concerned about insufficient data protection, impersonality and susceptibility to errors, but expected faster, more precise and unbiased diagnostics, less diagnostic errors and support for physicians. Conclusions: The vast majority of participants exhibited a positive attitude toward the use of artificial intelligence in melanoma diagnostics, especially as an assistance system. © Copyright © 2020 Jutzi, Krieghoff-Henning, Holland-Letz, Utikal, Hauschild, Schadendorf, Sondermann, Fröhling, Hekler, Schmitt, Maron and Brinker.","10.3389/fmed.2020.00233","acceptance; artificial intelligence; diagnostics; melanoma; online survey; patients view; skin cancer","117","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086511919&doi=10.3389%2ffmed.2020.00233&partnerID=40&md5=d82112a0add75e6f7c9809cc794b456d"
"A Comparative Study of Neural Network Architectures for Lesion Segmentation and Melanoma Detection","Rasul M.F.; Dey N.K.; Hashem M.M.A.","2020","0","1","0","0","0","First occurrence","0","","","","","","","Melanoma is a fast spreading and deadly form of skin cancer accounting for majority of deaths due to this type of disease. If not treated early, it can spread quickly to other organs. Luckily melanoma symptoms become visible to victims creating an opportunity to detect it at an early stage. As people know less about specific symptoms of it and due to the shortage of expert physicians, automating the detection of melanoma has become an important issue for public health. Several computer-aided diagnostic approaches have been proposed so far. Along with traditional image processing based techniques, lately researchers have successfully used deep learning for many different purposes. Deep neural networks are vastly being used in segmentation, object detection, classification etc. This paper shows how deep learning applied with augmentation can save us from complex pre-processing steps and it studies the performance of different neural network architectures for lesion segmentation as an integral part of image processing based techniques and finally evaluates network architectures for melanoma detection on dermoscopic images using transfer learning and presents a comparative view of those studies.  © 2020 IEEE.","10.1109/TENSYMP50017.2020.9230969","deep learning; lesion segmentation; Melanoma detection; Transfer Learning","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096425554&doi=10.1109%2fTENSYMP50017.2020.9230969&partnerID=40&md5=389dea1520164a0d9cac0724c80f473c"
"Study of Melanoma Detection and Classification Techniques","Gupta A.; Thakur S.; Rana A.","2020","0","1","0","0","0","First occurrence","0","","","","","","","Melanoma is a type of skin cancer that starts and evolves from the pigment-producing cells known as melanocytes. There has been quite some research done in the area of melanoma classification through image detection and classification using machine learning- specifically deep learning and neural networks. Researchers have used CNN-Convolutional Neural Networks, DNN-Deep Neural Networks, some have even used RNN- Recurrent Neural Network and transfer Learning. The Research work has not been up-to the mark as of yet, we know this because there has been no news of models being put to clinical testing. Another setback to the process of creating a perfect algorithm and mode is the lack of data regarding melanoma, the largest dataset publicly available is the one provided by ISCI for its 2020 competitions it has 25333 as training data and about 8240 as testing image datasets, but the issue with these is that the do not contain just the images and data for melanoma, the are a dataset for 7 different skin lesions to be detected and classified. In this review/survey paper we will be reviewing the research work done in the past couple of years on the topic of melanoma detection and classification using Deep learning. © 2020 IEEE.","10.1109/ICRITO48877.2020.9197820","CNN-Convolutional Neural Networks; Deep learning; DNN-Deep Neural Networks; Melanoma detection; RNN-Recurrent Neural Network","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093110514&doi=10.1109%2fICRITO48877.2020.9197820&partnerID=40&md5=589c16c355e4eeb6a7c43e97adeebfb9"
"Hybrid fully convolutional networks-based skin lesion segmentation and melanoma detection using deep feature","Jayapriya K.; Jacob I.J.","2020","1","1","0","0","0","Unique","0","","","","","","","Fully convolutional networks (FCNs) take the input of arbitrary size and produce correspondingly sized output with efficient inference and learning. The automatic diagnosis of melanoma is very essential for reducing the mortality rate by identifying the disease in earlier stages. A two-stage framework is used for implementing the melanoma detection, segmentation of skin lesion, and identification of melanoma lesions. Two FCNs based on VGG-16 and GoogLeNet are incorporated for improving the segmentation accuracy. A hybrid framework is used for incorporating these two FCNs. The classification is done by extracting the feature from segmented lesion by using deep residual network and a hand-crafted feature. Classification is done by support vector machine. The performance analysis of our framework gives a promising accuracy, that is, 0.8892 for classification in ISBI 2016 dataset and 0.853 for ISIC 2017 dataset. © 2019 Wiley Periodicals, Inc.","10.1002/ima.22377","deep residual network (DRN); hybrid fully convolutional networks; melanoma detection","63","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074781254&doi=10.1002%2fima.22377&partnerID=40&md5=bd78b8a855966dd1ea866ea92971fbe3"
"Improved U-net: Fully convolutional network model for skin-lesion segmentation","Sanjar K.; Bekhzod O.; Kim J.; Kim J.; Paul A.; Kim J.","2020","1","1","0","0","0","Unique","0","","","","","","","The early and accurate diagnosis of skin cancer is crucial for providing patients with advanced treatment by focusing medical personnel on specific parts of the skin. Networks based on encoder-decoder architectures have been effectively implemented for numerous computer-vision applications. U-Net, one of CNN architectures based on the encoder-decoder network, has achieved successful performance for skin-lesion segmentation. However, this network has several drawbacks caused by its upsampling method and activation function. In this paper, a fully convolutional network and its architecture are proposed with a modified U-Net, in which a bilinear interpolation method is used for upsampling with a block of convolution layers followed by parametric rectified linear-unit non-linearity. To avoid overfitting, a dropout is applied after each convolution block. The results demonstrate that our recommended technique achieves state-of-the-art performance for skin-lesion segmentation with 94% pixel accuracy and a 88% dice coefficient, respectively. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/app10103658","Interpolation; PReLU; Skin-lesion segmentation","30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085623987&doi=10.3390%2fapp10103658&partnerID=40&md5=3bc3b51e6f3d1eb598604caeaec7ec96"
"Analysis of Automatic Detection of Tumour Lesions Images using Bee Colony Technique","Aljanabi M.; Jumaa F.A.; Kaduim Abed J.; Al-Hamadani H.","2020","0","1","0","0","0","Unique","0","","","","","","","Nonstandard development of prison cell in any portion of the body is termed cancer lesions. Life duration of a tumour's lesions can be enlarged by the primary detection of cancer. This work contracts with cataloguing of images depend on factors extracted from multiresolution analysis based on bee colony technique to enhance of investigative performance and decrease of unhealthy moles demises. From now this technique system goals to improve a portion of the current approaches and new measures to make available the accurate, fast and dependable automated analysis of skin lesions. This information is then fed to several well-known algorithms to obtain a skin cancer categorization. By this method, the segmentation step can be utilized to enhance the handling of the information and create preventive approaches against harm, thus decreasing the danger of skin cancer lesions. One of the most significant stages in dermoscopy image examination is the segmentation of melanoma. The experimental results suggest that the proposed method accomplished a higher performance compared to the ground truth images supported by skin cancer lesions' dermatology. Investigational outcomes on the skin lesions databases designate that the bee colony prototypical acquires the utmost progressive performance. The factors of the scheme are estimated with accuracy, sensitivity and specificity. © Published under licence by IOP Publishing Ltd.","10.1088/1742-6596/1530/1/012012","ABC Technique; Automatic Detection; Dermatological Imaging; Tumour Lesions","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086409595&doi=10.1088%2f1742-6596%2f1530%2f1%2f012012&partnerID=40&md5=4e92cff07e58fbba30b6fcb78e6b1dd5"
"Multi-agent learning neural network and Bayesian model for real-time IoT skin detectors: a new evaluation and benchmarking methodology","Zaidan A.A.; Zaidan B.B.; Alsalem M.A.; Albahri O.S.; Albahri A.S.; Qahtan M.Y.","2020","1","1","0","0","0","First occurrence","0","","","","","","","This study aimed to develop a new methodology for evaluating and benchmarking a multi-agent learning neural network and Bayesian model for real-time skin detectors based on Internet of things (IoT) by using multi-criteria decision-making (MCDM). The novelty of this work is in the use of an evaluation matrix for the performance evaluation of real-time skin detectors that are based on IoT. Nevertheless, an issue with the performance evaluation of real-time skin detector approaches is the determination of sensible criteria for performance metrics and the trade-off amongst them on the basis of different colour spaces. An experiment was conducted on the basis of three phases. In the first phase, a real-time camera based on cloud IoT was used to gather different caption images. The second phase could be divided into two stages. In the first stage, a skin detection approach was developed by applying multi-agent learning based on different colour spaces. This stage aimed to create a decision matrix of various colour spaces and three groups of criteria (i.e. reliability, time complexity and error rate within a dataset) for testing and evaluating the developed skin detection approaches. In the second stage, Pearson rules were utilised to calculate the correlation between the criteria in order to make sure, either needs to use all of the criteria in decision matrix and the criteria facts that affect the behaviour of each criterion, in order to make sure that use all the criteria in evaluation as multidimensional measurements or not. In the third phase, the MCDM method was used by integrating between a technique in order of preference by similarity to the ideal solution and multi-layer analytic hierarchy process to benchmark numerous real-time IoT skin detection approaches based on the performed decision matrix from the second phase. Three groups of findings were obtained. Firstly, (1) statistically significant differences were found between the criteria that emphasise the need to use all of the criteria in evaluation. (2) The behaviour of the criteria in all scenarios was affected by the distribution of threshold values for each criterion based on the different colour spaces used. Therefore, the differences in the behaviour of criteria that highlight the use of the criteria in evaluation were included as multidimensional measurements. Secondly, an overall comparison of external and internal aggregation values in selecting the best colour space, namely the normalised RGB at the sixth threshold, was discussed. Thirdly, (1) the YIQ colour space had the lowest value and was the worst case, whereas the normalised RGB had the highest value and was the most recommended of all spaces. (2) The lowest threshold was obtained at 0.5, whereas the best value was 0.9. © 2019, Springer-Verlag London Ltd., part of Springer Nature.","10.1007/s00521-019-04325-3","Evaluation and benchmarking multi-criteria analysis; Multi-criteria decision-making techniques; Skin detector within IoT","60","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066298799&doi=10.1007%2fs00521-019-04325-3&partnerID=40&md5=93a5af3f140950ac2f66c1f657e4ff5d"
"A hierarchical structure based on Stacking approach for skin lesion classification","Ghalejoogh G.S.; Kordy H.M.; Ebrahimi F.","2020","1","1","0","0","0","Unique","0","","","","","","","Malignant melanoma is the most dangerous type of skin cancer. The diagnosis of melanoma in the early stages can greatly increase the possibility of its successful treatment. In the recent years, automated systems have played an pivotal role in increasing the skin cancer diagnosis rate. The main objective of this paper was to improve the performance of a skin cancer automated diagnostic system by introducing a new approach to combining classifiers in the classification stage. Therefore, the Stacking Ensemble Method based on the Meta Learning algorithm was proposed for the skin lesion classification. To classify skin lesions as melanoma, dysplastic and benign, two new hybrid approaches of Structure Based on Stacking (SBS) and Hierarchical Structure Based on Stacking (HSBS) were introduced to combine the heterogeneous classifiers. The proposed methods for skin lesions classification were implemented and evaluated based on the dermoscopic images of two PH2 and Ganster datasets using the Five Fold Cross Validation procedure and different numbers of the selected features. The results showed that the SBS approach had a good performance in diagnosing melanoma lesions from non-melanoma lesions for both datasets. Moreover, the results indicated that the HSBS method compared to the SBS approach and other works on the same dataset offers a far better performance in classifying skin lesions as benign, dysplastic and melanoma. © 2019","10.1016/j.eswa.2019.113127","Ensemble classifiers; Melanoma; Meta learning; Skin cancer; Stacking","54","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076426236&doi=10.1016%2fj.eswa.2019.113127&partnerID=40&md5=bcf7c5fa5f2fbfc277f1e28017ccd0a9"
"Effects of Label Noise on Deep Learning-Based Skin Cancer Classification","Hekler A.; Kather J.N.; Krieghoff-Henning E.; Utikal J.S.; Meier F.; Gellrich F.F.; Upmeier zu Belzen J.; French L.; Schlager J.G.; Ghoreschi K.; Wilhelm T.; Kutzner H.; Berking C.; Heppt M.V.; Haferkamp S.; Sondermann W.; Schadendorf D.; Schilling B.; Izar B.; Maron R.; Schmitt M.; Fröhling S.; Lipka D.B.; Brinker T.J.","2020","1","1","0","0","0","Unique","0","","","","","","","Recent studies have shown that deep learning is capable of classifying dermatoscopic images at least as well as dermatologists. However, many studies in skin cancer classification utilize non-biopsy-verified training images. This imperfect ground truth introduces a systematic error, but the effects on classifier performance are currently unknown. Here, we systematically examine the effects of label noise by training and evaluating convolutional neural networks (CNN) with 804 images of melanoma and nevi labeled either by dermatologists or by biopsy. The CNNs are evaluated on a test set of 384 images by means of 4-fold cross validation comparing the outputs with either the corresponding dermatological or the biopsy-verified diagnosis. With identical ground truths of training and test labels, high accuracies with 75.03% (95% CI: 74.39–75.66%) for dermatological and 73.80% (95% CI: 73.10–74.51%) for biopsy-verified labels can be achieved. However, if the CNN is trained and tested with different ground truths, accuracy drops significantly to 64.53% (95% CI: 63.12–65.94%, p < 0.01) on a non-biopsy-verified and to 64.24% (95% CI: 62.66–65.83%, p < 0.01) on a biopsy-verified test set. In conclusion, deep learning methods for skin cancer classification are highly sensitive to label noise and future work should use biopsy-verified training images to mitigate this problem. © Copyright © 2020 Hekler, Kather, Krieghoff-Henning, Utikal, Meier, Gellrich, Upmeier zu Belzen, French, Schlager, Ghoreschi, Wilhelm, Kutzner, Berking, Heppt, Haferkamp, Sondermann, Schadendorf, Schilling, Izar, Maron, Schmitt, Fröhling, Lipka and Brinker.","10.3389/fmed.2020.00177","artificial intelligence; dermatology; label noise; melanoma; nevi; skin cancer","50","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085189217&doi=10.3389%2ffmed.2020.00177&partnerID=40&md5=762b76577ac8ae6ae6b1c664dab1a686"
"Skin lesion segmentation using image bit-plane multilayer approach","Rizzi M.; Guaragnella C.","2020","1","1","0","0","0","Unique","0","","","","","","","The establishment of automatic diagnostic systems able to detect and classify skin lesions at the initial stage are getting really relevant and effective in providing support for medical personnel during clinical assessment. Image segmentation has a determinant part in computer-aided skin lesion diagnosis pipeline because it makes possible to extract and highlight information on lesion contour texture as, for example, skewness and area unevenness. However, artifacts, low contrast, indistinct boundaries, and different shapes and areas contribute to make skin lesion segmentation a challenging task. In this paper, a fully automatic computer-aided system for skin lesion segmentation in dermoscopic images is indicated. Adopting this method, noise and artifacts are initially reduced by the singular value decomposition; afterward lesion decomposition into a frame of bit-plane layers is performed. A specific procedure is implemented for redundant data reduction using simple Boolean operators. Since lesion and background are rarely homogeneous regions, the obtained segmentation region could contain some disjointed areas classified as lesion. To obtain a single zone classified as lesion avoiding spurious pixels or holes inside the image under test, mathematical morphological techniques are implemented. The performance obtained highlights the method validity. © 2020 by the authors.","10.3390/app10093045","Automatic segmentation; Bit-plane multilayer; Border detection; Computer aided detection (CADe); Dermoscopic images; Edge detection; Melanoma; Singular values decomposition (SVD); Skin cancer; Skin lesion segmentation","19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085546069&doi=10.3390%2fapp10093045&partnerID=40&md5=90218369bff6092217fcffdf55aa786c"
"Machine Learning in Melanoma Diagnosis. Limitations About to be Overcome; [Uso del aprendizaje automático en el diagnóstico del melanoma. Limitaciones por superar]","González-Cruz C.; Jofre M.A.; Podlipnik S.; Combalia M.; Gareau D.; Gamboa M.; Vallone M.G.; Faride Barragán-Estudillo Z.; Tamez-Peña A.L.; Montoya J.; América Jesús-Silva M.; Carrera C.; Malvehy J.; Puig S.","2020","0","1","0","0","0","Unique","0","","","","","","","Background: Automated image classification is a promising branch of machine learning (ML) useful for skin cancer diagnosis, but little has been determined about its limitations for general usability in current clinical practice. Objective: To determine limitations in the selection of skin cancer images for ML analysis, particularly in melanoma. Methods: Retrospective cohort study design, including 2,849 consecutive high-quality dermoscopy images of skin tumors from 2010 to 2014, for evaluation by a ML system. Each dermoscopy image was assorted according to its eligibility for ML analysis. Results: Of the 2,849 images chosen from our database, 968 (34%) met the inclusion criteria for analysis by the ML system. Only 64.7% of nevi and 36.6% of melanoma met the inclusion criteria. Of the 528 melanomas, 335 (63.4%) were excluded. An absence of normal surrounding skin (40.5% of all melanomas from our database) and absence of pigmentation (14.2%) were the most common reasons for exclusion from ML analysis. Discussion: Only 36.6% of our melanomas were admissible for analysis by state-of-the-art ML systems. We conclude that future ML systems should be trained on larger datasets which include relevant non-ideal images from lesions evaluated in real clinical practice. Fortunately, many of these limitations are being overcome by the scientific community as recent works show. © 2020 AEDV","10.1016/j.ad.2019.09.002","Artificial Intelligence; Convolutional neural networks; Dermoscopy; Image classification; Machine learning; Melanoma; Skin cancer","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082808971&doi=10.1016%2fj.ad.2019.09.002&partnerID=40&md5=7bbb4a5e8546a23d9be34598da7f38ce"
"Skin lesion segmentation using high-resolution convolutional neural network","Xie F.; Yang J.; Liu J.; Jiang Z.; Zheng Y.; Wang Y.","2020","1","1","0","0","0","Unique","0","","","","","","","Background and Objective: Skin lesion segmentation is an important but challenging task in computer-aided diagnosis of dermoscopy images. Many segmentation methods based on convolutional neural networks often fail to extract accurate lesion boundaries because the spatial size of feature maps decreases as the maps are processed throughout the network layers. We propose skin lesion segmentation in dermoscopy images based on a convolutional neural network with an attention mechanism, which can preserve edge details. Methods: We devised a high-resolution feature block containing three branches, namely, main, spatial attention, and channel-wise attention branches. The main branch takes high-resolution feature maps as input to extract spatial details around boundaries. The other two attention branches boost the discriminative features in the main branch regarding the spatial and channel-wise dimensions. By fusing the branch outputs, robust features with detailed spatial information can be extracted, and accurate skin lesion boundaries can be obtained. Results: Experiments on datasets from the International Symposium on Biomedical Imaging in 2016 and 2017 and the PH2 dataset retrieved Jaccard indices of 0.783, 0.858, and 0.857, respectively, for the proposed method. Hence, our method can accurately extract skin lesion boundaries and is robust to hair fibers and artifacts in the images. Overall, our method outperforms two typical segmentation networks (FCN-8 s and U-Net) and other state-of-the-art skin lesion segmentation methods. Conclusions: The proposed network endowed with high-resolution feature blocks preserves spatial details during feature extraction, and its attention mechanism enhances representative features while suppressing noise. Hence, the proposed approach provides high-performance skin lesion segmentation. © 2019","10.1016/j.cmpb.2019.105241","Attention mechanism; Convolutional neural network; High-resolution feature; Skin lesion segmentation","159","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076259205&doi=10.1016%2fj.cmpb.2019.105241&partnerID=40&md5=65a9479d32c91238451dce65a04894ef"
"Active dynamic thermography to detect the presence of stenosis in the carotid artery","Saxena A.; Ng E.Y.K.; Lim S.T.","2020","0","1","0","0","0","Unique","0","","","","","","","Unlike passive infrared (IR) thermal imaging/thermography, where no external stimulation is applied, active dynamic thermography (ADT) results in a high contrast thermal image. In ADT, transient thermal images of the skin surface are captured using an IR thermal camera while the skin surface is stimulated externally, followed by a recovery phase. Upon the application of external stimulation, the presence of stenosis in the carotid artery is expected to differ the recovery rate of the external neck skin surface from the case with no stenosis. In this prospective study, using an external cooling stimulation, the ADT procedure was performed on a total of 54 (N) samples (C: N = 19, 0% stenosis; D1: N = 17, 10%–29% stenosis; D2: N = 18, ≥30% stenosis using Duplex Ultrasound). Analyzing the ADT sequence with a parameter called tissue activity ratio (TAR), the samples were classified using a cut-off value: C versus (D1+D2) and (C + D1) versus D2. As the degree of stenosis increases, the value of the TAR parameter depreciates with a significant difference among the sample groups (C:0.97 ± 0.05, D1:0.80 ± 0.04, D2:0.75 ± 0.02; p < 0.05). Under the two classification scenarios, classification accuracies of 90% and 85%, respectively, were achieved. This study suggests the potential of screening CAS with the proposed ADT procedure. © 2020 Elsevier Ltd","10.1016/j.compbiomed.2020.103718","Active dynamic thermography; Atherosclerosis; Carotid synthetic image reconstruction; Cut-off value-based binary classification; Tissue activity ratio","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082463505&doi=10.1016%2fj.compbiomed.2020.103718&partnerID=40&md5=8b00702a528cdaddcd3e65c12643bea0"
"Melanoma and nevus skin lesion classification using handcraft and deep learning feature fusion via mutual information measures","Almaraz-Damian J.-A.; Ponomaryov V.; Sadovnychiy S.; Castillejos-Fernandez H.","2020","1","1","0","0","0","Unique","0","","","","","","","In this paper, a newComputer-AidedDetection (CAD) systemfor the detection and classification of dangerous skin lesions (melanoma type) is presented, through a fusion of handcraft features related to the medical algorithm ABCD rule (Asymmetry Borders-Colors-Dermatoscopic Structures) and deep learning features employing Mutual Information (MI) measurements. The steps of a CAD system can be summarized as preprocessing, feature extraction, feature fusion, and classification. During the preprocessing step, a lesion image is enhanced, filtered, and segmented, with the aim to obtain the Region of Interest (ROI); in the next step, the feature extraction is performed. Handcraft features such as shape, color, and texture are used as the representation of the ABCD rule, and deep learning features are extracted using a Convolutional Neural Network (CNN) architecture, which is pre-trained on Imagenet (an ILSVRC Imagenet task). MI measurement is used as a fusion rule, gathering the most important information from both types of features. Finally, at the Classification step, several methods are employed such as Linear Regression (LR), Support Vector Machines (SVMs), and Relevant Vector Machines (RVMs). The designed framework was tested using the ISIC 2018 public dataset. The proposed framework appears to demonstrate an improved performance in comparison with other state-of-the-art methods in terms of the accuracy, specificity, and sensibility obtained in the training and test stages. Additionally, we propose and justify a novel procedure that should be used in adjusting the evaluation metrics for imbalanced datasets that are common for different kinds of skin lesions. © 2020 by the authors.","10.3390/E22040484","Balance; Computer-aided systems; Convolutional neural networks; Data; Deep learning; Fusion; Handcraft; Melanoma; Mutual information; Transfer learning","142","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085093288&doi=10.3390%2fE22040484&partnerID=40&md5=e5a0b566ca57d3ba32112be0412218ed"
"Leveraging Adaptive Color Augmentation in Convolutional Neural Networks for Deep Skin Lesion Segmentation","Saha A.; Prasad P.; Thabit A.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Fully automatic detection of skin lesions in dermatoscopic images can facilitate early diagnosis and repression of malignant melanoma and non-melanoma skin cancer. Although convolutional neural networks are a powerful solution, they are limited by the illumination spectrum of annotated dermatoscopic screening images, where color is an important discriminative feature. In this paper, we propose an adaptive color augmentation technique to amplify data expression and model performance, while regulating color difference and saturation to minimize the risks of using synthetic data. Through deep visualization, we qualitatively identify and verify the semantic structural features learned by the network for discriminating skin lesions against normal skin tissue. The overall system achieves a Dice Ratio of 0.891 with 0.943 sensitivity and 0.932 specificity on the ISIC 2018 Testing Set for segmentation. © 2020 IEEE.","10.1109/ISBI45749.2020.9098344","color augmentation; convolutional neural network; dermatoscopy; lesion; melanoma; segmentation","23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085866909&doi=10.1109%2fISBI45749.2020.9098344&partnerID=40&md5=e85d167224c9700f3046b6193fefc637"
"Classification with Stochastic Learning Methods and Convolutional Neural Networks","Astudillo N.M.; Bolman R.; Sirakov N.M.","2020","0","1","0","0","0","First occurrence","0","","","","","","","The present study illustrates a convolution neural network designed to classify skin lesion images to benign and malignant melanoma. The convolutional neural network consists of 4 convolution layers, rectified linear activation function and a softmax classifier. The new architecture is experimented to extract features with the following learning methods: Adaptive Moment Estimation and Stochastic Gradient Descent which optimize the weight changing functions for quicker convergence to minimal error between the ground truth and the real output. To further strengthen the accuracy and accelerate the convergence of classification, random noise is added to the neural network learning methods. To validate the theoretical concepts, experiments are conducted with 3800 skin lesion images from the ISIC2018 dataset. At the end of the paper, the results obtained by the convolutional neural network with noisy Stochastic Gradient Descent and noisy Adaptive Moment Estimation are compared with other contemporary classifiers including convolution neural network. Table 3 reports the accuracy of 95.23%, obtained by the new classifier. This value establishes the supremacy of the newly proposed neural network over the other contemporary neural network classifiers. © 2020, Springer Nature Singapore Pte Ltd.","10.1007/s42979-020-00126-x","Classification; Machine learning; Noise; Skin lesion","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100074079&doi=10.1007%2fs42979-020-00126-x&partnerID=40&md5=9f094eb37cd9901e036984ddddd51f8d"
"Complementary Network with Adaptive Receptive Fields for Melanoma Segmentation","Guo X.; Chen Z.; Yuan Y.","2020","0","1","0","0","0","First occurrence","0","","","","","","","Automatic melanoma segmentation in dermoscopic images is essential in computer-aided diagnosis of skin cancer. Existing methods may suffer from the hole and shrink problems with limited segmentation performance. To tackle these issues, we propose a novel complementary network with adaptive receptive filed learning. Instead of regarding the segmentation task independently, we introduce a foreground network to detect melanoma lesions and a background network to mask non-melanoma regions. Moreover, we propose adaptive atrous convolution (AAC) and knowledge aggregation module (KAM) to fill holes and alleviate the shrink problems. AAC explicitly controls the receptive field at multiple scales and KAM convolves shallow feature maps by dilated convolutions with adaptive receptive fields, which are adjusted according to deep feature maps. In addition, a novel mutual loss is proposed to utilize the dependency between the foreground and background networks, thereby enabling the reciprocally influence within these two networks. Consequently, this mutual training strategy enables the semi-supervised learning and improve the boundary-sensitivity. Training with Skin Imaging Collaboration (ISIC) 2018 skin lesion segmentation dataset, our method achieves a dice coefficient of 86.4% and shows better performance compared with state-of-the-art melanoma segmentation methods11https://github.com/Guo-Xiaoqing/Skin-Seg. © 2020 IEEE.","10.1109/ISBI45749.2020.9098417","adaptive receptive fields; Melanoma segmentation; semi-supervised learning","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085862243&doi=10.1109%2fISBI45749.2020.9098417&partnerID=40&md5=00dff099778da2491b14b5cc91f177f8"
"Kappa Loss for Skin Lesion Segmentation in Fully Convolutional Network","Zhang J.; Petitjean C.; Ainouz S.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Skin melanoma represents a major health issue. Today, diagnosis and follow-up can rely on computer-aided diagnosis tools, to help dermatologists segment and quantitatively describe the image content. In particular, deep convolutional neural networks (CNN) have lately been become the state-of-the-art in automated medical image segmentation. The loss function plays an important role in CNN in the backpropagation process. In this work, we propose a metric-inspired loss function, based on the Kappa index. Unlike the Dice loss, a standard loss used in image segmentation CNN, the Kappa loss takes into account all the pixels in the image, including the true negative - we believe this can improve the accuracy of the evaluation process between prediction and ground truth. We demonstrate the differentiability of the Kappa loss and present some results on six public datasets of skin lesion. Experiments have shown promising results in skin lesion segmentation. © 2020 IEEE.","10.1109/ISBI45749.2020.9098404","agreement index; Image segmentation; loss function; melanoma; U-Net","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085863204&doi=10.1109%2fISBI45749.2020.9098404&partnerID=40&md5=eebe40e29df7f4ed62febf4035004388"
"Mobile-based skin lesions classification using convolution neural network","Hameed N.; Shabut A.; Hameed F.; Cirstea S.; Harriet S.; Hossain A.","2020","1","1","0","0","0","Unique","0","","","","","","","Received: 25th January 2020; Accepted: 7th March 2020; Published: 1st April 2020 Abstract: This research work is aimed at investing skin lesions classification problem using Convolution Neural Network (CNN) using cloud-server architecture. Using the cloud services and CNN, a real-time mobile-enabled skin lesions classification expert system “i-Rash” is proposed and developed. i-Rash aimed at early diagnosis of acne, eczema and psoriasis at remote locations. The classification model used in the “i-Rash” is developed using the CNN model “SqueezeNet”. The transfer learning approach is used for training the classification model and model is trained and tested on 1856 images. The benefit of using SqueezeNet results in a limited size of the trained model i.e. only 3 MB. For classifying new image, cloud-based architecture is used, and the trained model is deployed on a server. A new image is classified in fractions of seconds with overall accuracy, sensitivity and specificity of 97.21%, 94.42% and 98.14% respectively. i-Rash can serve in initial classification of skin lesions, hence, can play a very important role early classification of skin lesions for people living in remote areas. © 2020 by the author(s).","10.33166/AETiC.2020.02.003","Convolution neural network acne classification; Deep learning; Eczema classification; Mobile-enabled skin lesion classification; Psoriasis classification; Skin lesions classification; SqueezeNet","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088242198&doi=10.33166%2fAETiC.2020.02.003&partnerID=40&md5=0cd5fd04d563bc4a87ea82de32ac609d"
"Hyperspectral Imaging of in vivo Tissues: A Review; [高光谱在体组织成像方法的研究进展]","Ma X.; Liu R.; Li C.; Chen W.; Xu K.","2020","0","1","0","0","0","Unique","0","","","","","","","Hyperspectral imaging method can obtain two-dimensional images and spectral information of in vivo tissues, which has the advantages of high spatial and spectral resolution, large imaging range, noninvasive nature, and fast speed, providing abundant information for in vivo tissue diagnosis. In recent years, researchers have made great progress in imaging methods, instruments, and applications. In this study, the main advances of hyperspectral imaging methods and applications are reviewed, and the spectral imaging methods, system composition, and characteristics are discussed. This study introduces the research progress in in vivo tissue imaging methods and application in terms of spectral reconstruction, tissue optical parameter measurement, and image processing based on deep learning. Simultaneously, the application progress of hyperspectral imaging in clinical medicine, such as skin trauma and healing process detection, diagnosis of diabetic foot and retinal diseases, intraoperative detection, and microcirculation function evaluation, is also summarized. © 2020 Universitat zu Koln. All rights reserved.","10.3788/LOP57.080002","biomedical photonics; hyperspectral imaging; imaging systems; tissue optical imaging","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113280636&doi=10.3788%2fLOP57.080002&partnerID=40&md5=a2e9f3a4d54d3a64a1283045e751e50d"
"MMTDNN: Multi-view massive training deep neural network for segmentation and detection of abnormal tissues in medical images","Homayoun H.; Ebrahimpour-Komleh H.","2020","0","1","0","0","0","Unique","0","","","","","","","Purpose: Automated segmentation of abnormal tissues in medical images is considered as an essential part of those computer-aided detection and diagnosis systems which analyze medical images. However, automated segmentation of abnormalities is a challenging task due to the limitations of imaging technologies and complex structure of abnormalities, including low contrast between normal and abnormal tissues, shape diversity, appearance inhomogeneity, and the vague boundaries of abnormalities. Therefore, more intelligent segmentation techniques are required to tackle these challenges. Materials and Methods: In this study, a method, which is called MMTDNN, is proposed to segment and detect medical image abnormalities. MMTDNN, as a multi-view learning machine, utilizes convolutional neural networks in a massive training strategy. Moreover, the proposed method has four phases of preprocessing, view generation, pixel-level segmentation, and post-processing. The International Symposium on Biomedical Imaging (ISBI)-2016 dataset is used for the evaluation of the proposed method. Results: The performance of the proposed method has been evaluated on the task of skin lesion segmentation as one of the challenging applications of abnormal tissue segmentation. Both qualitative and quantitative results demonstrate outstanding performance. Meanwhile, the accuracy of 0.973, the Jaccard index of 0.876, and the Dice similarity coefficient of 0.931 have been achieved. Conclusion: In conclusion, the experimental result demonstrates that the proposed method outperforms state-of-the-art methods of skin lesion segmentation. Copyright © 2020 Tehran University of Medical Sciences","10.18502/fbt.v7i1.2722","Abnormal Tissues Segmentation; Artificial Neural Networks; Convolutional Neural Networks; Medical Imaging; Multi-View Learning; Multi-View Massive Training Deep Neural Network","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106469272&doi=10.18502%2ffbt.v7i1.2722&partnerID=40&md5=d74a55bc2554889dfd0862d5bee64b93"
"Data, depth, and design: Learning reliable models for skin lesion analysis","Valle E.; Fornaciali M.; Menegola A.; Tavares J.; Vasques Bittencourt F.; Li L.T.; Avila S.","2020","1","1","0","0","0","Unique","0","","","","","","","Deep learning fostered a leap ahead in automated skin lesion analysis in the last two years. Those models, however, are expensive to train and difficult to parameterize. Objective: We investigate methodological issues for designing and evaluating deep learning models for skin lesion analysis. We explore ten choices faced by researchers: use of transfer learning, model architecture, train dataset, image resolution, type of data augmentation, input normalization, use of segmentation, duration of training, additional use of Support Vector Machines, and test data augmentation. Methods: We perform two full factorial experiments, for five different test datasets, resulting in 2560 exhaustive trials in our main experiment, and 1280 trials in our assessment of transfer learning. We analyze both with multi-way analyses of variance (ANOVA). We use the exhaustive trials to simulate sequential decisions and ensembles, with and without the use of privileged information from the test set. Results main experiment: Amount of train data has disproportionate influence, explaining almost half the variation in performance. Of the other factors, test data augmentation and input resolution are the most influential. Deeper models, when combined, with extra data, also help. — transfer experiment: Transfer learning is critical, its absence brings huge performance penalties. — simulations: Ensembles of models are the best option to provide reliable results with limited resources, without using privileged information and sacrificing methodological rigor. Conclusions and Significance: Advancing research on automated skin lesion analysis requires curating larger public datasets. Indirect use of privileged information from the test set to design the models is a subtle, but frequent methodological mistake that leads to overoptimistic results. Ensembles of models are a cost-effective alternative to the expensive full-factorial and to the unstable sequential designs. © 2019","10.1016/j.neucom.2019.12.003","Cross dataset; Deep learning; Experimental design; Model parameterization; Skin lesion analysis","28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076865728&doi=10.1016%2fj.neucom.2019.12.003&partnerID=40&md5=5c0029f5ed867021f6d0798d897b898f"
"Image quality assessment of digital image capturing devices for melanoma detection","Dugonik B.; Dugonik A.; Marovt M.; Golob M.","2020","0","1","0","0","0","Unique","0","","","","","","","The fast-growing incidence of skin cancer, especially melanoma, is the guiding principle for intense development of various digital image-capturing devices providing easier recognition of melanoma by dermatologists. Handheld and digital dermoscopy, following of mole changes with smartphones and digital analysing of mole images, is based on evaluation of the colours, shape and deep structures in the skin moles. Incorrect colour information of an image, under-or overexposed images, lack of sharpness and low resolution of the images, can lead to melanoma misdiagnosis. The purpose of our study was to determine the colour error in the image according to the given lighting conditions and different camera settings. We focused on measuring the image quality parameters of smartphones and high-resolution cameras to compare them with the results of state-of-the-art dermoscopy device systems. We applied standardised measuring methods. The spatial frequency response method was applied for measuring the sharpness and resolution of the tested camera systems. Colour images with known reference values were captured from the test target, to evaluate colour error as a CIELAB (Commission Internationale de l'Eclairage) DEab colour difference as seen by a human observer. The results of our measurements yielded two significant findings. First, all tested cameras produced inaccurate colours when operating in automatic mode, and second, the amount of sharpening was too intensive. These deficiencies can be eliminated through adjusting the camera parameters manually or by image post-production. The presented two-step camera calibration procedure improves the colour accuracy of captured clinical and dermoscopy images significantly. © 2020 by the authors.","10.3390/APP10082876","Colour response; Dermoscopy; Image quality; Image resolution; Image sharpness; Melanoma detection; Mole screening; Spatial frequency response","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084652841&doi=10.3390%2fAPP10082876&partnerID=40&md5=46290953212256b45a1712efb3e1b0d9"
"Artificial Intelligence Applications in Dermatology: Where Do We Stand?","Gomolin A.; Netchiporouk E.; Gniadecki R.; Litvinov I.V.","2020","0","1","0","0","0","Unique","0","","","","","","","Artificial intelligence (AI) has become a progressively prevalent Research Topic in medicine and is increasingly being applied to dermatology. There is a need to understand this technology's progress to help guide and shape the future for medical care providers and recipients. We reviewed the literature to evaluate the types of publications on the subject, the specific dermatological topics addressed by AI, and the most challenging barriers to its implementation. A substantial number of original articles and commentaries have been published to date and only few detailed reviews exist. Most AI applications focus on differentiating between benign and malignant skin lesions, however; others exist pertaining to ulcers, inflammatory skin diseases, allergen exposure, dermatopathology, and gene expression profiling. Applications commonly analyze and classify images, however, other tools such as risk assessment calculators are becoming increasingly available. Although many applications are technologically feasible, important implementation barriers have been identified including systematic biases, difficulty of standardization, interpretability, and acceptance by physicians and patients alike. This review provides insight into future research needs and possibilities. There is a strong need for clinical investigation in dermatology providing evidence of success overcoming the identified barriers. With these research goals in mind, an appropriate role for AI in dermatology may be achieved in not so distant future. © Copyright © 2020 Gomolin, Netchiporouk, Gniadecki and Litvinov.","10.3389/fmed.2020.00100","artificial intelligence; barriers; contact allergens; dermatology; machine learning; melanoma; nevi; psoriasis","101","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083328000&doi=10.3389%2ffmed.2020.00100&partnerID=40&md5=d5cef7b35172541b26305efc0eeb1b05"
"Class-Center Involved Triplet Loss for Skin Disease Classification on Imbalanced Data","Lei W.; Zhang R.; Yang Y.; Wang R.; Zheng W.-S.","2020","1","1","0","0","0","Unique","0","","","","","","","It is ideal to develop intelligent systems to accurately diagnose diseases as human specialists do. However, due to the highly imbalanced data issue between common and rare diseases, it is still an open problem for the systems to effectively learn to recognize both common and rare diseases. In this paper, we novelly applied triplet modelling to overcome the data imbalance issue particularly for diagnosis of rare diseases. Moreover, we further applied a class-center based triplet loss in order to make the triplet-based learning more stable. Extensive evaluation on two skin image classification tasks shows that the triplet-based approach is very effective and outperforms the widely used methods for solving the imbalance problem. © 2020 IEEE.","10.1109/ISBI45749.2020.9098718","Data imbalance; medical image classification; triplet loss","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085855830&doi=10.1109%2fISBI45749.2020.9098718&partnerID=40&md5=5fd42b3eb2807b378d83dc8ccd839b11"
"Fusing Metadata and Dermoscopy Images for Skin Disease Diagnosis","Li W.; Zhuang J.; Wang R.; Zhang J.; Zheng W.-S.","2020","1","1","0","0","0","First occurrence","0","","","","","","","To date, it is still difficult and challenging to automatically classify dermoscopy images. Although the state-of-the-art convolutional networks were applied to solve the classification problem and achieved overall decent prediction results, there is still room for performance improvement, especially for rare disease categories. Considering that human dermatologists often make use of other information (e.g., body locations of skin lesions) to help diagnose, we propose using both dermoscopy images and non-image metadata for intelligent diagnosis of skin diseases. Specifically, the metadata information is innovatively applied to control the importance of different types of visual information during diagnosis. Comprehensive experiments with various deep learning model architectures demonstrated the superior performance of the proposed fusion approach especially for relatively rare diseases. All our codes will be made publicly available https://github.com/fatetail/MetaNet. © 2020 IEEE.","10.1109/ISBI45749.2020.9098645","data fusion; metadata; Skin disease classification","71","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085861533&doi=10.1109%2fISBI45749.2020.9098645&partnerID=40&md5=263c3149cde550aeb87eb3403e62d99f"
"MATLAB image processing tool-based GUI for high-throughput image segmentation and analysis to study structure and morphology of skin H&E stained sections","Osman O.S.","2020","1","1","0","0","0","Unique","0","","","","","","","The complex structure of skin tissue can make the analysis of high-throughput data manually inconvenient and leads to inaccurate analysis and time consumption. Therefore, automated system that can segment and detect features which might provide critical information for interesting phenotype is required. User friendly graphical user interface GUI in MATLAB can provide facilities to create a tool to enhance, segment and analyse images without having expert skills in image processing, this can be used in the study of skin morphology phenotyping to find interesting morphological and metabolic phenotypes. Using image processing capability facilitates to develop a tool to analyse a range of different images in term of intensity and quality because of the variation in histology performed in different laboratory. Consequently, develop of automated high-throughput bioimaging tool is considered to be a very important topic in disease diagnosis and drug development. Significant assessment of the morphological features in H&E skin section through the use of GUI MATLAB tool by quantifying all of epidermal and dermal thickness and number and size of adipocyte in subcutaneous. Using our developed tool, we were able to detect interesting epidermis, dermis and adipocyte phenotypes in mice skin sections. The Morphological Bio-imaging Tool provides facilities in the high-throughput analysis of H&E skin section to understand genetic basis of diseases. © Published under licence by IOP Publishing Ltd.","10.1088/1757-899X/737/1/012232","GUI; high-throughput analysis; Histology; Image processing; Morphology; Phenotype; Skin layers","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082043050&doi=10.1088%2f1757-899X%2f737%2f1%2f012232&partnerID=40&md5=1ac08706679282050a39ce5da7517c2e"
"Tailored for Real-World: A Whole Slide Image Classification System Validated on Uncurated Multi-Site Data Emulating the Prospective Pathology Workload","Ianni J.D.; Soans R.E.; Sankarapandian S.; Chamarthi R.V.; Ayyagari D.; Olsen T.G.; Bonham M.J.; Stavish C.C.; Motaparthi K.; Cockerell C.J.; Feeser T.A.; Lee J.B.","2020","0","1","0","0","0","First occurrence","0","","","","","","","Standard of care diagnostic procedure for suspected skin cancer is microscopic examination of hematoxylin & eosin stained tissue by a pathologist. Areas of high inter-pathologist discordance and rising biopsy rates necessitate higher efficiency and diagnostic reproducibility. We present and validate a deep learning system which classifies digitized dermatopathology slides into 4 categories. The system is developed using 5,070 images from a single lab, and tested on an uncurated set of 13,537 images from 3 test labs, using whole slide scanners manufactured by 3 different vendors. The system's use of deep-learning-based confidence scoring as a criterion to consider the result as accurate yields an accuracy of up to 98%, and makes it adoptable in a real-world setting. Without confidence scoring, the system achieved an accuracy of 78%. We anticipate that our deep learning system will serve as a foundation enabling faster diagnosis of skin cancer, identification of cases for specialist review, and targeted diagnostic classifications.","10.1038/s41598-020-59985-2","","91","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079827127&doi=10.1038%2fs41598-020-59985-2&partnerID=40&md5=89421d3aa70f1c42bb2461b8a0067b5c"
"Smart identification of psoriasis by images using convolutional neural networks: a case study in China","Zhao S.; Xie B.; Li Y.; Zhao X.; Kuang Y.; Su J.; He X.; Wu X.; Fan W.; Huang K.; Su J.; Peng Y.; Navarini A.A.; Huang W.; Chen X.","2020","0","1","0","0","0","Unique","0","","","","","","","Background: Psoriasis is a chronic inflammatory skin disease, which holds a high incidence in China. However, professional dermatologists who can diagnose psoriasis early and correctly are insufficient in China, especially in the rural areas. A smart approach to identify psoriasis by pictures would be highly adaptable countrywide and could play a useful role in early diagnosis and regular treatment of psoriasis. Objectives: Design and evaluation of a smart psoriasis identification system based on clinical images (without relying on a dermatoscope) that works effectively similar to a dermatologist. Methods: A set of deep learning models using convolutional neural networks (CNNs) was explored and compared in the system for automatic identification of psoriasis. The work was carried out on a standardized dermatological dataset with 8021 clinical images of 9 common disorders including psoriasis along with full electronic medical records of patients built over the last 9 years in China. A two-stage deep neural network was designed and developed to identify psoriasis. In the first stage, a multilabel classifier was trained to learn the visual patterns for each individual skin disease. In the second stage, the output of the first stage was utilized to distinguish psoriasis from other skin diseases. Results: The area under the curve (AUC) of the two-stage model reached 0.981 ± 0.015, which outperforms a single-stage model. And, the classifier showed superior performance (missed diagnosis rate: 0.03, misdiagnosis rate: 0.04) than 25 Chinese dermatologists (missed diagnosis rate: 0.19, misdiagnosis rate: 0.10) in the diagnosis of psoriasis on 100 clinical images. Conclusions: Using clinical images to identify psoriasis is feasible and effective based on CNNs, which also builds a solid technical base for smart care of skin diseases especially psoriasis using mobile/tablet applications for teledermatology in China. © 2019 European Academy of Dermatology and Venereology","10.1111/jdv.15965","","50","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074514483&doi=10.1111%2fjdv.15965&partnerID=40&md5=381014eb4a2f2abb1fbe00811bc7dbd7"
"DePicT Melanoma Deep-CLASS: A deep convolutional neural networks approach to classify skin lesion images","Nasiri S.; Helsper J.; Jung M.; Fathi M.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Background: Melanoma results in the vast majority of skin cancer deaths during the last decades, even though this disease accounts for only one percent of all skin cancers' instances. The survival rates of melanoma from early to terminal stages is more than fifty percent. Therefore, having the right information at the right time by early detection with monitoring skin lesions to find potential problems is essential to surviving this type of cancer. Results: An approach to classify skin lesions using deep learning for early detection of melanoma in a case-based reasoning (CBR) system is proposed. This approach has been employed for retrieving new input images from the case base of the proposed system DePicT Melanoma Deep-CLASS to support users with more accurate recommendations relevant to their requested problem (e.g., image of affected area). The efficiency of our system has been verified by utilizing the ISIC Archive dataset in analysis of skin lesion classification as a benign and malignant melanoma. The kernel of DePicT Melanoma Deep-CLASS is built upon a convolutional neural network (CNN) composed of sixteen layers (excluding input and ouput layers), which can be recursively trained and learned. Our approach depicts an improved performance and accuracy in testing on the ISIC Archive dataset. Conclusions: Our methodology derived from a deep CNN, generates case representations for our case base to use in the retrieval process. Integration of this approach to DePicT Melanoma CLASS, significantly improving the efficiency of its image classification and the quality of the recommendation part of the system. The proposed method has been tested and validated on 1796 dermoscopy images. Analyzed results indicate that it is efficient on malignancy detection. © 2020 The Author(s).","10.1186/s12859-020-3351-y","Case-based reasoning; Classification; Deep learning; Early detection; Information retrieval; Melanoma; Skin cancer","40","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081908399&doi=10.1186%2fs12859-020-3351-y&partnerID=40&md5=20d7de9278f463c89ed06cb92cf3da3d"
"Hill Climbing Optimization and Fuzzy C-Means Clustering for Melanoma Skin Cancer Identification and Segmentation","Ganesan P.; Vadivel M.; Sivakumar V.G.; Vasanth K.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Even though melanoma is not common as other skin cancers, it is one of the most dangerous skin cancer that grow any part of the skin such as chest, back, face, neck and legs. According to World Health Organization, the extreme sun UV radiation causes about 60,000 early demises every year worldwide. More than 80% of these deaths accounted for melanoma cancer. The proposed work explains the detection and segmentation of Melanoma skin cancer using hill climbing and FCM combined process. The process initiated with the transformation of image from RGB to CIELab space. The 3D histogram of CIELab image provides seeds for FCM. They act as initial clusters for the segmentation process. The experimental results of the proposed approach clearly illustrates that outcome of the process mainly depends on the number initial seeds. © 2020 IEEE.","10.1109/ICACCS48705.2020.9074333","fuzzy c-means clustering; hill climbing; melanoma; segmentation; skin cancer","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084642896&doi=10.1109%2fICACCS48705.2020.9074333&partnerID=40&md5=def7bf72a83d543f0445f1b729e665b4"
"Skin Disease Classification from Image - A Survey","Goswami T.; Dabhi V.K.; Prajapati H.B.","2020","1","1","0","0","0","Unique","0","","","","","","","Skin diseases are one of the most common types of health illnesses faced by the people for ages. The identification of skin disease mostly relies on the expertise of the doctors and skin biopsy results, which is a time-consuming process. An automated computer-based system for skin disease identification and classification through images is needed to improve the diagnostic accuracy as well as to handle the scarcity of human experts. Classification of skin disease from an image is a crucial task and highly depends on the features of the diseases considered in order to classify it correctly. Many skin diseases have highly similar visual characteristics, which add more challenges to the selection of useful features from the image. The accurate analysis of such diseases from the image would improve the diagnosis, accelerates the diagnostic time and leads to better and cost-effective treatment for patients. This paper presents the survey of different methods and techniques for skin disease classification namely; traditional or handcrafted feature-based as well as deep learning-based techniques. © 2020 IEEE.","10.1109/ICACCS48705.2020.9074232","classification; CNN; deep learning; lesions; Skin diseases; SVM","42","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084672992&doi=10.1109%2fICACCS48705.2020.9074232&partnerID=40&md5=8babca84491ecd3b5dc459b91408adbd"
"Further evaluation is required for smartphone-aided diagnosis of skin cancer","Walter F.M.; Emery J.D.","2020","1","0","0","0","0","Unique","0","","","","","","","[No abstract available]","10.1016/S2589-7500(20)30021-2","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079885102&doi=10.1016%2fS2589-7500%2820%2930021-2&partnerID=40&md5=2db811a65d25fb46fbce6f1ca93e0503"
"A Critical Analysis of Computer Aided Approaches for Skin Cancer Screening","Selvarasa M.; Aponso A.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Skin Cancer is life-threatening when diagnosed at a later stage. Early detection of skin cancers such as melanoma indicates a higher survival rate for the patient. Non-computer aided tools were used in the past such as the visual inspection using tools like the dermoscopy. Commercial tools were later introduced that allowed the examiners to examine the images obtained from the dermoscopy using techniques such as the ABCD rule and 7-point checklist. Deep Learning has proven to be the state-of-the-art for computer vision problems such as image classification. A lot of research has been carried out in the application of deep learning for automating skin cancer screening. This paper presents an analysis of the existing work carried out in the area of automatic skin cancer screening and the different steps involved in building a skin cancer classification tool for skin cancer screening. The limitations of the various existing approaches are explored, and the results of the analysis will be used as part of an ongoing research to design and develop a robust system that will address the identified cons.  © 2020 IEEE.","10.1109/ICIP48927.2020.9367370","Augmentation; CNN; Computer Vision; Deep Learning; Screening; Segmentation; Skin Cancer","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102736682&doi=10.1109%2fICIP48927.2020.9367370&partnerID=40&md5=4293456a19aaa8057c2b5f14be63329c"
"Teledermatology for Skin Cancer: The Australian Experience","Martin A.; Guitera P.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Purpose of Review: This review aims to understand how Australia compares internationally in the practice of teledermatology for the diagnosis and management of skin cancer, and in the process, ascertain the robustness of the evidence for teledermatology, as well as identify its limitations and current difficulties for its adoption in Australia. Recent Findings: Diagnostic and treatment concordance, time to detection and action, as well as expected cost in Australia were comparable with international studies. Earlier detection of skin cancer and convenience such as reduced travel are main reasons supportive of teledermatology. Potential limitations of teledermatology are seen in high-risk melanoma patients, the older population, and those with multiple co-morbidities requiring reviews by various specialties. Image documentation and storage on personal devices are ongoing issues despite existing guidelines. Summary: Australia remains a pioneer in the research of teledermatology, while collaborating with international groups to advocate quality research and its practical use, with a focus on patient-led mobile teledermoscopy. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","10.1007/s13671-020-00291-5","Australia; Diagnostic concordance; Mobile teledermoscopy; Skin cancer; Teledermatology; Teledermoscopy","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082025640&doi=10.1007%2fs13671-020-00291-5&partnerID=40&md5=fb48f6b7300e848717e4ebfca5c8543b"
"Skin Surface Detection in 3D Optoacoustic Mesoscopy Based on Dynamic Programming","Nitkunanantharajah S.; Zahnd G.; Olivo M.; Navab N.; Mohajerani P.; Ntziachristos V.","2020","1","1","0","0","0","Unique","0","","","","","","","Optoacoustic (photoacoustic) mesoscopy offers unique capabilities in skin imaging and resolves skin features associated with detection, diagnosis, and management of disease. A critical first step in the quantitative analysis of clinical optoacoustic images is to identify the skin surface in a rapid, reliable, and automated manner. Nevertheless, most common edge- and surface-detection algorithms cannot reliably detect the skin surface on 3D raster-scan optoacoustic mesoscopy (RSOM) images, due to discontinuities and diffuse interfaces in the image. We present herein a novel dynamic programming approach that extracts the skin boundary as a 2D surface in one single step, as opposed to consecutive extraction of several independent 1D contours. A domain-specific energy function is introduced, taking into account the properties of volumetric optoacoustic mesoscopy images. The accuracy of the proposed method is validated on scans of the volar forearm of 19 volunteers with different skin complexions, for which the skin surface has been traced manually to provide a reference. In addition, the robustness and the limitations of the method are demonstrated on data where the skin boundaries are low-contrast or ill-defined. The automatic skin surface detection method can improve the speed and accuracy in the analysis of quantitative features seen on the RSOM images and accelerate the clinical translation of the technique. Our method can likely be extended to identify other types of surfaces in the RSOM and other imaging modalities. © 1982-2012 IEEE.","10.1109/TMI.2019.2928393","2D front propagation; optoacoustic imaging; skin extraction; surface segmentation","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079017972&doi=10.1109%2fTMI.2019.2928393&partnerID=40&md5=9ee200d3f25ec451693e5f1001f144b7"
"Artificial Intelligence in Dermatology—Where We Are and the Way to the Future: A Review","Hogarty D.T.; Su J.C.; Phan K.; Attia M.; Hossny M.; Nahavandi S.; Lenane P.; Moloney F.J.; Yazdabadi A.","2020","0","1","0","0","0","First occurrence","0","","","","","","","Although artificial intelligence has been available for some time, it has garnered significant interest recently and has been popularized by major companies with its applications in image identification, speech recognition and problem solving. Artificial intelligence is now being increasingly studied for its potential uses in medicine. A sound understanding of the concepts of this emerging field is essential for the dermatologist as dermatology has abundant medical data and images that can be used to train artificial intelligence for patient care. There are already a number of artificial intelligence studies focusing on skin disorders such as skin cancer, psoriasis, atopic dermatitis and onychomycosis. This article aims to present a basic introduction to the concepts of artificial intelligence as well as present an overview of the current research into artificial intelligence in dermatology, examining both its current applications and its future potential. © 2019, Springer Nature Switzerland AG.","10.1007/s40257-019-00462-6","","127","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068843994&doi=10.1007%2fs40257-019-00462-6&partnerID=40&md5=7a42efb79335045990e8693eee60ac20"
"Improving Skin Lesion Segmentation with Deep Convolutional Generative Adversarial Networks","Shan P.-F.; Wang Y.-D.; Fu C.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Accurate segmentation of skin lesion is an important step in computer aided diagnosis of skin cancer. Recently, deep-learning-based image segmentation methods have drawn much attention and shown exacting results. Unfortunately, existing skin disease datasets can hardly satisfy the requirement of massive training samples for deep neural networks. To meet this challenge, we introduce a data augmentation method using deep convolutional generative adversarial network (DCGAN), which can generate realistic samples with lesion features learned from the existing dataset, increasing both the quantity and diversity of training samples. The architecture of our proposed segmentation algorithm is built upon deep fully connected networks (FCN) and the DenseNet is employed as feature extractor. Extensive experiments are carried out on “ISBI 2018: Skin Lesion Analysis Towards Melanoma Detection Challenge dataset”, and the results demonstrate that the proposed algorithm significantly improves the accuracy of skin lesions segmentation without requiring new actual training samples. © 2020, Springer Nature Singapore Pte Ltd.","10.1007/978-981-15-3250-4_17","Data augmentation; DCGAN; FC-densenet; Skin lesion segmentation","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082465735&doi=10.1007%2f978-981-15-3250-4_17&partnerID=40&md5=8626c843dccf24a52ec837aa8153264e"
"Skin Lesions Classification into Eight Classes for ISIC 2019 Using Deep Convolutional Neural Network and Transfer Learning","Kassem M.A.; Hosny K.M.; Fouad M.M.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Melanoma is a type of skin cancer with a high mortality rate. The different types of skin lesions result in an inaccurate diagnosis due to their high similarity. Accurate classification of the skin lesions in their early stages enables dermatologists to treat the patients and save their lives. This paper proposes a model for a highly accurate classification of skin lesions. The proposed model utilized the transfer learning and pre-trained model with GoogleNet. The model parameters are used as initial values, and then these parameters will be modified through training. The latest well-known public challenge dataset, ISIC 2019, is used to test the ability of the proposed model to classify different kinds of skin lesions. The proposed model successfully classified the eight different classes of skin lesions, namely, melanoma, melanocytic nevus, basal cell carcinoma, actinic keratosis, benign keratosis, dermatofibroma, vascular lesion, and Squamous cell carcinoma. The achieved classification accuracy, sensitivity, specificity, and precision percentages are 94.92%, 79.8%, 97%, and 80.36%, respectively. The proposed model can detect images that do not belong to any one of the eight classes where these images are classified as unknown images.  © 2013 IEEE.","10.1109/ACCESS.2020.3003890","bootstrap multiclass SVM; convolution neural network; GoogleNet; ISIC 2019; Melanoma classification; skin lesions; transfer learning","299","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087821586&doi=10.1109%2fACCESS.2020.3003890&partnerID=40&md5=a10b8d2b24d5238f1e0208c8364f1e80"
"Detecting nodular basal cell carcinoma in pathology imaging using deep learning image segmentation","Ren J.; Lax R.; Krueger J.G.; Browning J.; Carucci J.; White K.; Lish S.; Gareau D.S.","2020","0","1","0","0","0","Unique","0","","","","","","","With over 4.3 million new cases in the U.S. every year, basal cell carcinoma (BCC), is the most common form of skin cancer. Pathologists must examine pathology images to diagnose BCC, potentially resulting in delay, error, and inconsistency. To address the need for standardized, expedited diagnosis, we created an automated diagnostic machine to identify BCC given pathology images. In MATLAB, we adapted a deep neural network image segmentation model, UNet, to train on BCC images and their corresponding masks, which can learn to highlight these nodules in pathology images by outputting a computer-generated mask. We trained the U-Net on one image from the dataset and compared the computer-generated mask output from testing on three types of images: an image from a different region of the same image taken with the same microscope, an image from a different tissue sample with a different microscope, and an image taken with a confocal microscope. We observed good, medium and poor results, respectively, illustrating that performance depends on the similarity between test and training data. In subsequent tests using data augmentation, we achieved sensitivity of 0.82±0.07 and specificity of 0.87±0.16 on N = 6 sample sections from 3 different BCCs imaged with the same microscope system. These data show that the U-Net performed well with a relatively few number of training images. Examining the errors raised interesting questions regarding what the errors mean and how they possibly arose. By creating a surgeon interface for rapid pathological assessment and machine learning diagnostics for pathological features, the BCC diagnosis process will be expedited and standardized. © 2020 SPIE.","10.1117/12.2549950","Automated diagnosis; Basal Cell Carcinoma; Deep learning; Image segmentation; Machine learning; Skin cancer","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081549846&doi=10.1117%2f12.2549950&partnerID=40&md5=c46f3f7c7baadf3fd8fd99df6094ab4f"
"Deep learning-based histopathological image analysis for automated detection and staging of melanoma","Alheejawi S.; Mandal M.; Xu H.; Lu C.; Berendt R.; Jha N.","2020","0","1","0","0","0","Unique","0","","","","","","","With recent advances in digital microscopy, quantitative analysis of pathology images has become important in disease diagnosis as well as in understanding the underlying reasons. Digital whole slide images (WSI) are typically obtained from a biopsy slide using a high-resolution slide scanner. The hematoxylin and eosin (H&E) stain is typically used to stain the slides. However, immunospecific stains such as MART-1 (for melanoma) and PD-L1 (for lung cancer) are also sometimes used to validate detection. In advanced stages, cancer cells spread to lymph nodes through the lymph vessels. Therefore, a lymph node biopsy is typically done by doctors to determine if the cancer cells have invaded the lymph node system. High-resolution WSIs typically have very large size, in the order of a billion pixels. Hence, image analysis and diagnosis (quantitative as well as qualitative) is expected to take significant time.In this chapter, we present the state of the art on computer-aided diagnosis and grading of skin cancer/melanoma based on histopathology. The techniques generally include traditional image analysis modules such as preprocessing, segmentation, feature extraction, and classifications. Recently, deep learning techniques such as SegNet and U-Net have been used successfully in histopathological image analysis. The detailed implementation of our works on melanoma detection and proliferation index calculation using deep learning networks is presented and compared with traditional feature-based techniques. Experimental results show superior performance by the deep learning networks. © 2020 Elsevier Inc. All rights reserved.","10.1016/B978-0-12-819061-6.00010-0","Deep learning; Histopathological image analysis; Melanoma detection; Nuclei segmentation; Proliferation index calculation","25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086641597&doi=10.1016%2fB978-0-12-819061-6.00010-0&partnerID=40&md5=c9f4aff8c7c9b8c47f2f0267f0cb2465"
"A high-accuracy mathematical morphology and multilayer perceptron-based approach for melanoma detection","Sánchez-Reyes L.-M.; Rodríguez-Reséndiz J.; Salazar-Colores S.; Avecilla-Ramírez G.N.; Pérez-Soto G.I.","2020","0","1","0","0","0","Unique","0","","","","","","","According to theWorld Health Organization (WHO), melanoma is the most severe type of skin cancer and is the leading cause of death from skin cancer worldwide. Certain features of melanoma include size, shape, color, or texture changes of a mole. In this work, a novel, robust and efficient method for the detection and classification of melanoma in simple and dermatological images is proposed. It is achieved by using HSV (Hue, Saturation, Value) color space along with mathematical morphology and a Gaussian filter to detect the region of interest and estimate four descriptors: symmetry, edge, color, and size. Although these descriptors have been used for several years, the way they are computed for this proposal is one of the things that enhances the results. Subsequently, a multilayer perceptron is employed to classify between malignant and benign melanoma. Three datasets of simple and dermatological images commonly used in the literature were employed to train and evaluate the performance of the proposed method. According to k-fold cross-validation, the method outperforms three state-of-art works, achieving an accuracy of 98.5% and 98.6%, a sensitivity of 96.68% and 98.05%, and a specificity of 98.15%, and 98.01%, in simple and dermatological images, respectively. The results have proven that its use as an assistive device for the detection of melanoma would improve reliability levels compared to conventional methods. © 2020 by the authors.","10.3390/app10031098","Dermatological images; Gaussian filter; HSV color space; Mathematical morphology; Melanoma detection; Multilayer perceptron; Simple images","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081246219&doi=10.3390%2fapp10031098&partnerID=40&md5=86fdfa0c4813b9b3a73bc0e2aae1e35b"
"Convolutional Neural Network based Skin Lesion Classification and Identification","Aishwarya U.; Daniel I.J.; Raghul R.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Melanoma disease is the type of skin cancer in melanocytes, which are in the epidermis layer of the skin. The rate of msselanoma is in increasing order and found to be dangerous if not diagnosed at its beginning stage. To overcome this challenge, deep convolutional neural network techniques are used. The patient injured image is processing under different steps such as pre-processing using various filters followed by segmentation using the K-means clustering algorithm and Fuzzy C-means clustering algorithm. Finally, the detection and classification are executed with Convolutional Neural Network. Performance measures are evaluated for the proposed methodology with the accuracy of 98.43%, specificity of 98.77%, the sensitivity of 99.83%. The results drive that the proposed model of learning surpasses the existing algorithm and could be used to help medical practitioners to classify skin lesions. © 2020 IEEE.","10.1109/ICICT48043.2020.9112485","CNN; FCM; k-means; Melanoma","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086987827&doi=10.1109%2fICICT48043.2020.9112485&partnerID=40&md5=7ea2494669bdbcb76cb32a8edd082491"
"Deep Convolutional Network-Based Framework for Melanoma Lesion Detection and Segmentation","Adegun A.; Viriri S.","2020","0","1","0","0","0","First occurrence","0","","","","","","","Analysis of skin lesion images is very crucial in melanoma detection. Melanoma is a form of skin cancer with high mortality rate. Both semi and fully automated systems have been proposed in the recent past for analysis of skin lesions and detection of melanoma. These systems have however been restricted in performance due to the complex visual characteristics of the skin lesions. Skin lesions images are characterised with fuzzy borders, low contrast between lesions and the background, variability in size and resolution and with possible presence of noise and artefacts. In this work, an efficient deep learning framework has been proposed for melanoma lesion detection and segmentation. The proposed method performs pixel-wise classification of skin lesion images to identify melanoma pixels. The framework employs an end-to-end and pixel by pixels learning approach using Deep Convolutional Networks with softmax classifier. A novel framework which learns the complex visual characteristics of skin lesions via an encoder and decoder subnetworks that are connected through a series of skip pathways that brings the semantic level of the encoder feature maps closer to that of the decoder feature maps is hereby designed. This efficiently handles multi-size, multi-resolution and noisy skin lesion images. The proposed system was evaluated on both the ISBI 2018 and PH2 skin lesion datasets. © 2020, Springer Nature Switzerland AG.","10.1007/978-3-030-40605-9_5","Deep convolution network; Deep learning; Melanoma; Segmentation; Skin lesion; Softmax classifier","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080942399&doi=10.1007%2f978-3-030-40605-9_5&partnerID=40&md5=b15e4c58b7b292795e512cb4e5cc2e1c"
"Comparative study of SVM and cnn in identifying the types of skin cancer","Gokila Brindha P.; Rajalaxmi R.R.; Kabhilan S.; Sangitkumar C.; Sanjeevan L.","2020","1","1","0","0","0","Unique","0","","","","","","","The objective of the paper is to analyze the performance of the machine learning algorithms in detecting the types of skin cancer. There are different types of skin cancer and some of them may lead to death. So, the early prediction of skin cancer helps in reducing the death rate. The dataset is downloaded from Kaggle website. The train data consists of 2637 images of benign and malignant images and the test data consists of 660 images of benign and malignant images. The aim of the paper is to identify the algorithm, which gives maximum accuracy in detecting the types of skin cancer when applied on the image dataset. The algorithms used are Convolution Neural Network (CNN) and Support Vector Machine (SVM). The algorithms are executed using Tensor Flow in Python. © 2020 by Advance Scientific Research.","10.31838/jcr.07.11.117","CNN; Deep Learning; Image Processing; SVM; TensorFlow","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087390597&doi=10.31838%2fjcr.07.11.117&partnerID=40&md5=ef86e02fb99917b03ace6f563f493ebc"
"IMSCGnet: Iterative Multi-Scale Context-Guided Segmentation of Skin Lesion in Dermoscopic Images","Tang Y.; Fang Z.; Yuan S.; Zhan C.; Xing Y.; Zhou J.T.; Yang F.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Despite much effort has been devoted to skin lesion segmentation, the performance of existing methods is still not satisfactory enough for practical applications. The challenges may include fuzzy lesion boundary, uneven and low contrast, and variation of colors across space, which often lead to fragmentary segmentation and inaccurate boundary. To alleviate this problem, we propose a multi-scale context-guided network named as MSCGnet to segment the skin lesions accurately. In MSCGnet, the context information is utilized to guide the feature encoding procedure. Moreover, because of the information loss in spatial down-sampling, a context-based attention structure (CAs) is designed to select effective context features in the decoding path. Furthermore, we boost the performance of MSCGnet with iterations and term this upgraded version as iterative MSCGnet, denoted as iMSCGnet. To supervise the training of iMSCGnet in an end-to-end fashion, a novel objective function of deep supervision, which consists of the terms of each encoding layers and the terms from each MSCGnet output of iMSCGnet, is employed. Our method is evaluated extensively on the four publicly available datasets, including ISBI2016 [1], ISBI2017 [2], ISIC2018 [3] and PH2 [4] datasets. The experimental results prove the effectiveness of proposed components and show that our method generally outperforms the state-of-the-art methods. © 2013 IEEE.","10.1109/ACCESS.2020.2974512","attention; deep supervision; multi-scale context; Skin lesion segmentation","29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081561810&doi=10.1109%2fACCESS.2020.2974512&partnerID=40&md5=2bbfed7b1b12d76a32467132af881024"
"Supporting the diagnosis of Dysplastic Nevi Syndrome via Multiple Instance Learning approaches","Vocaturo E.; Zumpano E.","2020","0","1","0","0","0","Unique","0","","","","","","","Malignant melanoma is the form responsible for the greatest number of deaths among skin cancers. The possibility of ensuring survival passes through an early diagnosis and subsequent skin excision. One of the problems that most hinders early diagnosis, conducted both with the naked eye and through dedicated frameworks, is the extreme similarity of melanoma with other skin lesions such as dysplastic nevi. The possibility of intercepting recurring patterns through increasingly advanced diagnostic tools pushes the research community to propose software solutions that favor the detection of melanoma. Currently the existing solutions are typically concentrated in the binary discrimination of melanoma from common nevi. The high presence of common and atypical nevi on the body surface constitutes a potential risk factor for the onset of melanoma and characterizes the current debate on Dysplastic Nevi Syndrome (DNS). The presence of dysplastic nevi complicates the classification of melanoma from benign nevi, and raises a new classification problem relating to the distinction between dysplastic and common nevi, mostly unexplored. Over time, several machine learning algorithms have been proposed to support the image classification phase. In this article, we highlight multiple-instance learning approaches to discriminate melanoma from dysplastic nevi and to address the new challenge of classifying dysplastic from common nevi. Copyright © 2020 for this paper by its authors.","","Image Classification; Melanoma Detection; Multiple Instance Learning","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101929320&partnerID=40&md5=876ae8db97410beb4e405cf5e0139e91"
"Detector-SegMentor Network for Skin Lesion Localization and Segmentation","Saini S.; Gupta D.; Tiwari A.K.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Melanoma is a life-threatening form of skin cancer when left undiagnosed at the early stages. Although there are more cases of non-melanoma cancer than melanoma cancer, melanoma cancer is more deadly. Early detection of melanoma is crucial for the timely diagnosis of melanoma cancer and prohibit its spread to distant body parts. Segmentation of skin lesion is a crucial step in the classification of melanoma cancer from the cancerous lesions in dermoscopic images. Manual segmentation of dermoscopic skin images is very time consuming and error-prone resulting in an urgent need for an intelligent and accurate algorithm. In this study, we propose a simple yet novel network-in-network convolution neural network (CNN) based approach for segmentation of the skin lesion. A Faster Region-based CNN (Faster RCNN) is used for preprocessing to predict bounding boxes of the lesions in the whole image which are subsequently cropped and fed into the segmentation network to obtain the lesion mask. The segmentation network is a combination of the UNet and Hourglass networks. We trained and evaluated our models on ISIC 2018 dataset and also cross-validated on PH2 and ISBI 2017 datasets. Our proposed method surpassed the state-of-the-art with Dice Similarity Coefficient of 0.915 and Accuracy 0.959 on ISIC 2018 dataset and Dice Similarity Coefficient of 0.947 and Accuracy 0.971 on ISBI 2017 dataset. © 2020, Springer Nature Singapore Pte Ltd.","10.1007/978-981-15-8697-2_55","CNN; Dermoscopic; Dice Similarity Coefficient; Faster RCNN; Melanoma; Segmentation","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097272914&doi=10.1007%2f978-981-15-8697-2_55&partnerID=40&md5=044eaa2aef56e79fe409e1564d370c03"
"Classification of melanoma through fused color features and deep neural networks","Maiti A.; Shekhargiri H.; Chatterjee B.; Rajinikanth V.; Shi F.; Dey N.","2020","0","1","0","0","0","Unique","0","","","","","","","Skin malignancy is a catastrophic health problems witnessed in Europeans and western area of the world because of the changes in the ozone layer. Ultraviolet (UV) rays common threats for the human health. Scientists have studied on Computer-Aided Diagnosis (CAD) scheme to ease interpretation detection of melanoma. There are several variations of features of the lesions and different Artificial Intelligence (AI) based design participates in an essential role for building CAD system. This study has refined skin lesions with diffusion and dull razor technique. Lesion images have taken for color-based shape and texture feature extraction. Scientists have found new fused color features are effective for melanoma and nevus classification. It has discovered details of 2000 images from ISIC (database archive) helped to build improved feature set. These features were analyzed through various 12 machine learning models as highest accuracy of 93.9%. Proposed Deep Neural Network (DNN) has reached 95.8% accuracy within few epochs. This model was assessed specific limits which were discussed in the results section. In future this exercise will motivate investigators to experience with color features and its variations with other AI based models. © 2020 The authors and IOS Press. All rights reserved.","10.3233/FAIA200049","Artificial intelligence; Color features; Computer-Aided Diagnosis; Deep neural network; Dull razor; Melanoma","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082306723&doi=10.3233%2fFAIA200049&partnerID=40&md5=6c5feea7481a399dc80fee60e09ffcc8"
"Skin Lesion Segmentation in Dermoscopic Images with Ensemble Deep Learning Methods","Goyal M.; Oakley A.; Bansal P.; Dancey D.; Yap M.H.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Early detection of skin cancer, particularly melanoma, is crucial to enable advanced treatment. Due to the rapid growth in the number of skin cancers, there is a growing need of computerised analysis for skin lesions. The state-of-the-art public available datasets for skin lesions are often accompanied with a very limited amount of segmentation ground truth labeling. Also, the available segmentation datasets consist of noisy expert annotations reflecting the fact that precise annotations to represent the boundary of skin lesions are laborious and expensive. The lesion boundary segmentation is vital to locate the lesion accurately in dermoscopic images and lesion diagnosis of different skin lesion types. In this work, we propose the fully automated deep learning ensemble methods to achieve high sensitivity and high specificity in lesion boundary segmentation. We trained the ensemble methods based on Mask R-CNN and DeeplabV3+ methods on ISIC-2017 segmentation training set and evaluate the performance of the ensemble networks on ISIC-2017 testing set and PH2 dataset. Our results showed that the proposed ensemble methods segmented the skin lesions with Sensitivity of 89.93% and Specificity of 97.94% for the ISIC-2017 testing set. The proposed ensemble method Ensemble-A outperformed FrCN, FCNs, U-Net, and SegNet in Sensitivity by 4.4%, 8.8%, 22.7%, and 9.8% respectively. Furthermore, the proposed ensemble method Ensemble-S achieved a specificity score of 97.98% for clinically benign cases, 97.30% for the melanoma cases, and 98.58% for the seborrhoeic keratosis cases on ISIC-2017 testing set, exhibiting better performance than FrCN, FCNs, U-Net, and SegNet. © 2013 IEEE.","10.1109/ACCESS.2019.2960504","deep learning; ensemble segmentation methods; instance segmentation; melanoma; semantic segmentation; Skin cancer; skin lesion segmentation","264","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078108565&doi=10.1109%2fACCESS.2019.2960504&partnerID=40&md5=f2e1165709b1281be705093f807e6540"
"Photonics in Dermatology and Plastic Surgery 2020","","2020","0","1","0","0","0","Unique","0","","","","","","","The proceedings contain 18 papers. The topics discussed include: polarization sensitive optical coherence tomography for assessing skin roughness; automatic classification of melanocytic skin tumors based on hyperparameters optimized by cross-validation using support vector machines; detecting nodular basal cell carcinoma in pathology imaging using deep learning image segmentation; clinical multimodal multiphoton tomography of pigmented skin lesions with an ultracompact femtosecond fiber laser; comparing reduced scattering variation by skin type and tissue location using spatial frequency domain imaging for clinical burn wound imaging; and visible light optical coherence microscopy for quantitative imaging of human skin in vivo.","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081561262&partnerID=40&md5=1ec45be02490923f984e317b29e38da1"
"Skin Lesion Diagnosis with Imbalanced ECOC Ensembles","Ali Ahmed S.A.; Yanikoglu B.; Zor C.; Awais M.; Kittler J.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Diagnosis of skin lesions is a challenging task due to the similarities between different lesion types, in terms of appearance, location, and size. We present a deep learning method for skin lesion classification by fine-tuning three pre-trained deep learning architectures (Xception, Inception-ResNet-V2, and NasNetLarge), using the training set provided by ISIC2019 organizers. We combine deep convolutional networks with the Error Correcting Output Codes (ECOC) framework to address the open set classification problem and to deal with the heavily imbalanced dataset of ISIC2019. Experimental results show that the proposed framework achieves promising performance that is comparable with the top results obtained in the ISIC2019 challenge leaderboard. © 2020, Springer Nature Switzerland AG.","10.1007/978-3-030-64580-9_25","Classification; Data augmentation; Deep learning; ECOC; Ensemble; Imbalanced dataset; Skin cancer","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101327630&doi=10.1007%2f978-3-030-64580-9_25&partnerID=40&md5=4d89acddd6bb060df4bfe770b1f47fbe"
"Multi-class skin lesions classification system using probability map based region growing and DCNN","Sreekesh Namboodiri T.; Jayachandran A.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Background: Melanoma is a type of threatening pigmented skin lesion, and as of now is among the most hazardous existing diseases. Suitable automated diagnosis of skin lesions and Melanoma classification can extraordinarily enhance early identification of Melanomas. Methods: However, classification models based on deterministic skin lesion can influence multi-dimensional nonlinear problem which leads to inaccurate and inefficient classification. This paper presents a Deep Convolutional Neural Network (DCNN) classification approach for segmented skin lesions in dermoscopy images. As an initial step, the skin lesion is preprocessed by an automatic preprocessing algorithm together with a fusion hair detection and removal strategy. Also a new probability map based region growing and optimal thresholding algorithm is integrated in our system which yields tremendous accuracy. Results: For obtaining more prominent results a set of features containing ABCD features as well as geometric features are calculated in the feature extraction step to describe the malignancy of the lesion. Conclusions: The experimental result shows that the system is efficient and works well on dermoscopy images, achieving considerable accuracy. © 2020 The Authors. Published by Atlantis Press SARL.","10.2991/ijcis.d.200117.002","Black frame removal; Gaussian filtering; Geometric features; Optimal thresholding; Region growing; SVM classification","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079340320&doi=10.2991%2fijcis.d.200117.002&partnerID=40&md5=a48b6180c396d84b33044ee16cb1cc76"
"Investigating and exploiting image resolution for transfer learning-based skin lesion classification","Mahbod A.; Schaefer G.; Wang C.; Ecker R.; Dorffner G.; Ellinger I.","2020","1","1","0","0","0","Unique","0","","","","","","","Skin cancer is among the most common cancer types. Dermoscopic image analysis improves the diagnostic accuracy for detection of malignant melanoma and other pigmented skin lesions when compared to unaided visual inspection. Hence, computer-based methods to support medical experts in the diagnostic procedure are of great interest. Fine-tuning pre-trained convolutional neural networks (CNNs) has been shown to work well for skin lesion classification. Pre-trained CNNs are typically trained with natural images of a fixed image size significantly smaller than captured skin lesion images and consequently dermoscopic images are downsampled for fine-tuning. However, useful medical information may be lost during this transformation. In this paper, we explore the effect of input image size on skin lesion classification performance of fine-tuned CNNs. For this, we resize dermoscopic images to different resolutions, ranging from 64 × 64 to 768 × 768 pixels and investigate the resulting classification performance of three well-established CNNs, namely DenseNet-121, ResNet-18, and ResNet-50. Our results show that using very small images (of size 64×64 pixels) degrades the classification performance, while images of size 128 × 128 pixels and above support good performance with larger image sizes leading to slightly improved classification. We further propose a novel fusion approach based on a three-level ensemble strategy that exploits multiple fine-tuned networks trained with dermoscopic images at various sizes. When applied on the ISIC 2017 skin lesion classification challenge, our fusion approach yields an area under the receiver operating characteristic curve of 89.2% and 96.6% for melanoma classification and seborrheic keratosis classification, respectively, outperforming state-of-the-art algorithms. © 2020 IEEE","10.1109/ICPR48806.2021.9412307","Deep learning; Dermatology; Dermoscopy; Image resolution; Medical image analysis; Skin cancer; Transfer learning","23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104367086&doi=10.1109%2fICPR48806.2021.9412307&partnerID=40&md5=34373d7cb888102efb20a0b2db0e6f72"
"Scalable skin lesion multi-classification recognition system","Liu F.; Yan J.; Wang W.; Liu J.; Li J.; Yang A.","2020","1","1","0","0","0","Unique","0","","","","","","","Skin lesion recognition is an important challenge in the medical field. In this paper, we have implemented an intelligent classification system based on convolutional neural network. First of all, this system can classify whether the input image is a dermascopic image with an accuracy of 99%. And then diagnose the dermoscopic image and the non-skin mirror image separately. Due to the limitation of the data, we can only realize the recognition of vitiligo by non-skin mirror. We propose a vitiligo recognition based on the probability average of three structurally identical CNN models. The method is more efficient and robust than the traditional RGB color space-based image recognition method. For the dermoscopic classification model, we were able to classify 7 skin lesions, use weighted optimization to overcome the unbalanced data set, and greatly improve the sensitivity of the model by means of model fusion. The optimization and expansion of the system depend on the increase of database. © 2020 Tech Science Press. All rights reserved.","10.32604/cmc.2020.07039","Classification; Ensemble; Neural networks; Skin disease","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079182181&doi=10.32604%2fcmc.2020.07039&partnerID=40&md5=9ea2e2f620d6ba002e3c9c4debaffc65"
"Decision support software for melanoma skin cancer detection (DECIME)","Sousa C.E.B.; Nascimento L.B.G.; Medeiros C.M.S.; Oliveira M.; Trajano I.A.","2020","1","1","0","0","0","Unique","0","","","","","","","In this paper is proposed a software to decision support for the detection of melanoma cancer. This approach is proposed, as this type of skin cancer is the only one that can metastasize, that is, proliferate to other organs such as lungs, liver, etc. The proposed system is elaborated through the acquisition of a set of images with 17805 samples, extractors of attributes gray level co-occurrence matrix (GLCM), Local Binary Pattern (LBP) and Central Moments. For the training and sample classification process, the Single Layer Perceptron (SLP), Multilayer Perceptron (MLP) and Support Vector Machine (SVM) classifiers are used. Subsequently, the best-evaluated model is implanted in a Raspberry Pi computer that, together with a webcam and a computer screen, allows the capture and classification of skin lesions in real-time. In the applied methodology, the authors obtained the best result of a 93 % accuracy from the use of Central Moments extractor and MLP classifier. In contrast to the state of the art of this problem, a high level of similarity is found between the accuracy rates of the Single Layer Perceptron (SLP) and the Multilayer Perceptron (MLP), demonstrating a possible resolution of the problem in a linear format. Copyright © 2020 for this paper by its authors.","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101901377&partnerID=40&md5=dcce02d3d5b4e8c26d12bfa68c3bda95"
"Benign and Malignant Skin Lesion Classification Comparison for Three Deep-Learning Architectures","Yilmaz E.; Trocan M.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Early detection of melanoma, which is a deadly form of skin cancer, is vital for patients. Differential diagnosis of malignant and benign melanoma is a challenging task even for specialist dermatologists. The diagnostic performance of melanoma has significantly improved with the use of images obtained via dermoscopy devices. With the recent advances in medical image processing field, it is possible to improve the dermatological diagnostic performance by using computer-assisted diagnostic systems. For this purpose, various machine learning algorithms are designed and tested to be used in the diagnosis of melanoma. Deep learning models, which have gained popularity in recent years, have been effective in solving image recognition and classification problems. Concurrently with these developments, studies on the classification of dermoscopic images using CNN models are being performed. In this study, the performance of AlexNet, GoogLeNet and Resnet50 CNNs were examined for the classification problem of benign and malignant melanoma cancers on dermoscopic images. Dermoscopic images of 19373 benign and 2197 malignant lesions obtained from ISIC database were used in the experiments. All three CNNs, which were the former winners of the ImageNet competition, have been reconfigured to perform binary classification. In the experiments 80% of the images were used for training and the remaining 20% were used for validation. All experiments were performed with the same parameters for each CNN models. According to the experiments ResNET50 model achieved the best performance with 92.81% classification accuracy and AlexNet was first-ranked in terms of the time complexity measurements. The development of new models based on existing CNN models with a focus on dermoscopic images will be the subject of future studies. © 2020, Springer Nature Switzerland AG.","10.1007/978-3-030-41964-6_44","AlexNet; Benign and Malignant lesion classification; Convolutional neural networks; Deep learning; GoogLeNet; Melanoma; ResNet","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082309013&doi=10.1007%2f978-3-030-41964-6_44&partnerID=40&md5=1b0c49c9c1a7cc3a4a1bae21f765b4d7"
"Computer-aided diagnosis of melanoma: A review of existing knowledge and strategies","Maiti A.; Chatterjee B.; Ashour A.S.; Dey N.","2020","0","1","0","0","0","Unique","0","","","","","","","Computer-aided diagnosis (CAD) systems are the best alternative for immediate disclo-sure and diagnosis of skin diseases. Such systems comprise several image processing procedures, including segmentation, feature extraction and artificial intelligence (AI) based methods. This survey highlights different CAD methodologies for diagnosing Melanoma and related skin diseas-es. It has also discussed types, stages, treatments and various imaging techniques of skin cancer. Currently, researchers developed new techniques to detect each stage. Extensive studies on melanoma cancer detection were performed by incorporating advanced machine learning. Still, there is a high need for an accurate, faster, affordable, portable methodology for a CAD system. This will strengthen the work in related fields and address the future direction of a similar kind of research. © 2020 Bentham Science Publishers.","10.2174/1573405615666191210104141","CAD; Classification; Melanoma; Pre-processing; Segmentation; Skin cancer; Treatment","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091096300&doi=10.2174%2f1573405615666191210104141&partnerID=40&md5=4575a3fdbdeab667cc311ccaf02e5686"
"Deep learning approaches towards skin lesion segmentation and classification from dermoscopic images - a review","Baig R.; Bibi M.; Hamid A.; Kausar S.; Khalid S.","2020","1","1","0","0","0","Unique","0","","","","","","","Background: Automated intelligent systems for unbiased diagnosis are primary requirement for the pigment lesion analysis. It has gained the attention of researchers in the last few decades. These systems involve multiple phases such as pre-processing, feature extraction, segmentation, classification and post processing. It is crucial to accurately localize and segment the skin lesion. It is observed that recent enhancements in machine learning algorithms and dermoscopic techniques reduced the misclassification rate therefore, the focus towards computer aided systems increased exponentially in recent years. Computer aided diagnostic systems are reliable source for dermatologists to analyze the type of cancer, but it is widely acknowledged that even higher accuracy is needed for computer aided diagnostic systems to be adopted practically in the diagnostic process of life threatening diseases. Introduction: Skin cancer is one of the most threatening cancers. It occurs by the abnormal multiplication of cells. The core three types of skin cells are: Squamous, Basal and Melanocytes. There are two wide classes of skin cancer; Melanocytic and non-Melanocytic. It is difficult to differentiate between benign and malignant melanoma, therefore dermatologists sometimes misclassify the benign and malignant melanoma. Melanoma is estimated as 19th most frequent cancer, it is riskier than the Basel and Squamous carcinoma because it rapidly spreads throughout the body. Hence, to lower the death risk, it is critical to diagnose the correct type of cancer in early rudimentary phases. It can occur on any part of body, but it has higher probability to occur on chest, back and legsMethods: The paper. presents a systematic review of segmentation and classification techniques for skin lesion detection. Dermoscopy and its features are discussed briefly. After that Image preprocessing techniques are described. A thorough review of Segmentation and Classification phases of skin lesion detection using deep learning techniques is presented Literature is discussed and a comparative analysis of discussed methods is presented. Conclusion: In this paper, we have presented the survey of more than 100 papers and comparative analysis of state of the art techniques, model and methodologies. Malignant melanoma is one of the most threating and deadliest cancers. Since the last few decades, researchers are putting extra attention and effort in accurate diagnosis of melanoma. The main challenges of dermoscopic skin lesion images are: low contrasts, multiple lesions, irregular and fuzzy borders, blood vessels, regression, hairs, bubbles, variegated coloring and other kinds of distortions. The lack of large training dataset makes these problems even more challenging. Due to recent advancement in the paradigm of deep learning, and specially the outstanding performance in medical imaging, it has become important to review the deep learning algorithms performance in skin lesion segmentation. Here, we have discussed the results of different techniques on the basis of different evaluation parameters such as Jaccard coefficient, sensitivity, specificity and accuracy. And the paper listed down the major achievements in this domain with the detailed discussion of the techniques. In future, it is expected to improve results by utilizing the capabilities of deep learning frameworks with other pre and post processing techniques so reliable and accurate diagnostic systems can be built. © 2020, Bentham Science Publishers. All rights reserved.","10.2174/1573405615666190129120449","Convolution neural network; Deep learning; Melanoma; Segmentation; Skin cancer; Skin lesion","48","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083425087&doi=10.2174%2f1573405615666190129120449&partnerID=40&md5=100108e98a785b1aa5e3abf7b345d220"
"Skin melanoma detection based on hyperspectral imaging and deep learning techniques","Chen J.; Wang X.; Wu Q.; Mo J.","2020","1","1","0","0","0","Unique","0","","","","","","","Skin cancer is one of the most common cancers. Most skin cancers are not life threatening, but malignant melanoma is fatal. Currently, it still remains a challenge to discriminate malignant melanoma from benign melanoma by using conventional diagnostic techniques, such as ultrasonography, computed tomography, magnetic resonance imaging and positron emission tomography. As a new type of bio-optical imaging technology, hyperspectral imaging (HSI) has become the focus of research. It can provide information about hemoglobin and melanin content for the differentiation of various skin diseases. In this study, we propose a hyperspectral imaging system based on push-broom imaging spectrometer to image skin-pigmented nevus, and then segment the nevus out from surrounding normal skin through pixel-wised spectrum classification with deep learning techniques. The HIS system can produce hyperspectral image over the spectral range of 465-630nm and with a spectral resolution of 2.1 nm. Meanwhile, we evaluated the performance of K-means, Gaussian Mixture Model (GMM) and Hierarchical Clustering (HAC) in detecting the nevus with manual segmentation as the gold standard. The results show that these three techniques all have a good accuracy in differentiating the nevus from normal skin, which proves that the hyperspectral system combined with classification techniques has a good potential to detect the pigmented nevus on the skin.  © 2020 SPIE.","10.1117/12.2575269","Deep Learning; Hyperspectral imaging; Melanoma","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097128263&doi=10.1117%2f12.2575269&partnerID=40&md5=368575e36b173fd48a28a2c0cc584b46"
"New Auxiliary Function with Properties in Nonsmooth Global Optimization for Melanoma Skin Cancer Segmentation","Masoud Abdulhamid I.A.; Sahiner A.; Rahebi J.","2020","1","1","0","0","0","Unique","0","","","","","","","In this paper, an algorithm is introduced to solve the global optimization problem for melanoma skin cancer segmentation. The algorithm is based on the smoothing of an auxiliary function that is constructed using a known local minimizer and smoothed by utilising Bezier curves. This function achieves all filled function properties. The proposed optimization method is applied to find the threshold values in melanoma skin cancer images. The proposed algorithm is implemented on PH2, ISBI2016 challenge, and ISBI 2017 challenge datasets for melanoma segmentation. The results show that the proposed algorithm exhibits high accuracy, sensitivity, and specificity compared with other methods. © 2020 Idris A. Masoud Abdulhamid et al.","10.1155/2020/5345923","","19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084276817&doi=10.1155%2f2020%2f5345923&partnerID=40&md5=e3858318bb7978a28a97b1ca53004be0"
"FCN-Based DenseNet Framework for Automated Detection and Classification of Skin Lesions in Dermoscopy Images","Adegun A.A.; Viriri S.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Skin Lesion detection and classification are very critical in diagnosing skin malignancy. Existing Deep learning-based Computer-aided diagnosis (CAD) methods still perform poorly on challenging skin lesions with complex features such as fuzzy boundaries, artifacts presence, low contrast with the background and, limited training datasets. They also rely heavily on a suitable turning of millions of parameters which often leads to over-fitting, poor generalization, and heavy consumption of computing resources. This study proposes a new framework that performs both segmentation and classification of skin lesions for automated detection of skin cancer. The proposed framework consists of two stages: the first stage leverages on an encoder-decoder Fully Convolutional Network (FCN) to learn the complex and inhomogeneous skin lesion features with the encoder stage learning the coarse appearance and the decoder learning the lesion borders details. Our FCN is designed with the sub-networks connected through a series of skip pathways that incorporate long skip and short-cut connections unlike, the only long skip connections commonly used in the traditional FCN, for residual learning strategy and effective training. The network also integrates the Conditional Random Field (CRF) module which employs a linear combination of Gaussian kernels for its pairwise edge potentials for contour refinement and lesion boundaries localization. The second stage proposes a novel FCN-based DenseNet framework that is composed of dense blocks that are merged and connected via the concatenation strategy and transition layer. The system also employs hyper-parameters optimization techniques to reduce network complexity and improve computing efficiency. This approach encourages feature reuse and thus requires a small number of parameters and effective with limited data. The proposed model was evaluated on publicly available HAM10000 dataset of over 10000 images consisting of 7 different categories of diseases with 98% accuracy, 98.5% recall, and 99% of AUC score respectively.  © 2013 IEEE.","10.1109/ACCESS.2020.3016651","CAD; classification; CRF; deep leraning; DenseNet; encoder-decoder; FCN; hyper-parameter; skin cancer; Skin lesion","164","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090266848&doi=10.1109%2fACCESS.2020.3016651&partnerID=40&md5=bacd85fb4940a97d3f720c9824704853"
"Data Augmentation and Feature Fusion for Melanoma Detection with Content Based Image Classification","Das R.; De S.; Bhattacharyya S.; Platos J.; Snasel V.; Hassanien A.E.","2020","0","1","0","0","0","First occurrence","0","","","","","","","Computer aided diagnosis has leveraged a new horizon for accurate diagnosis of numerous fatal diseases. Melanoma is considered as one of the most lethal form of skin cancer which is increasingly affecting the population in recent times. The disease can be completely healed if diagnosed and addressed at an early stage. However, in most of the cases patients receive delayed care which results in fatal consequences. The authors have attempted to design an automated melanoma detection system in this work by means of content based image classification. Extraction of content based descriptors can nullify the requirement for manual annotation of the dermoscopic images which consumes considerable time and effort. The work has also undertaken a fusion based approach for feature combination for evaluating classification performances of hybrid architecture. The results have outclassed the state-of-the-art outcomes and have established significant performance improvement. © 2020, Springer Nature Switzerland AG.","10.1007/978-3-030-14118-9_70","Colour histogram; Computer aided diagnosis; Content based image classification; Feature fusion; HOG; Melanoma","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064043020&doi=10.1007%2f978-3-030-14118-9_70&partnerID=40&md5=956dc166b7c0252b5c2ad110d72bfe86"
"Developed Newton-Raphson based deep features selection framework for skin lesion recognition","Khan M.A.; Sharif M.; Akram T.; Bukhari S.A.C.; Nayak R.S.","2020","1","1","0","0","0","Unique","0","","","","","","","Melanoma is the fatal form of skin cancer; however, its diagnosis at the primary stages significantly reduces the mortality rate. These days, the increasing numbers of skin cancer patients have boosted the requirement for a care decision support system - capable of detecting the lesions with high accuracy. In this work, a method is proposed for skin cancer localization and recognition by implementing a novel combination of a deep learning model and iteration-controlled Newton-Raphson (IcNR) based feature selection method. The proposed framework follows three primary steps - lesion localization through faster region based convolutional neural network (RCNN), deep feature extraction, and feature selection by IcNR approach. In the localization step, a new contrast stretching approach based on bee colony method (ABC) is being followed. The enhanced images along with their ground truths are later plugged into Fast-RCNN to get segmented images. A pre-trained model, DenseNet201, is utilized to extract deep features via transfer learning, which are later subjected to selection step using proposed IcNR approach. The selected most discriminant features are finally utilized for classification using multilayered feed forward neural networks. Tests are performed on ISBI2016 and ISBI2017 datasets to achieving an accuracy of 94.5% and 93.4%, respectively. Simulation results reveal that the proposed technique outperforms existing methods with greater accuracy, and time. © 2019","10.1016/j.patrec.2019.11.034","Best features; Contrast stretching; Deep features; Lesion localization; Skin cancer","126","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076015246&doi=10.1016%2fj.patrec.2019.11.034&partnerID=40&md5=767aa97693a4f7af9d34fddd092fd79e"
"Evaluation of color spaces for unsupervised and deep learning skin lesion segmentation","Osadebey M.; Pedersen M.; Waaler D.","2020","1","1","0","0","0","Unique","0","","","","","","","The reliability of skin cancer diagnosis is dependent on accurate lesion segmentation. The choice of a color space in most contributions on skin lesion segmentation for melanoma detection are based on qualitative rather than quantitative approaches. User experience and theoretical properties of the color space are the two major factors influencing the choice of the color space. For this reason, it may be difficult to optimize segmentation accuracy. This paper evaluates the discrimination power of 5 color spaces and 16 color channels for two unsupervised approaches and a deep learning approach on the segmentation of skin lesion in dermatoscopy images. 600 dermatoscopy images with different levels of cluttering and occluding objects from two different databases were utilized. This study suggests that no single color space or color channel is most suitable in real-world scenarios. Therefore, this study can be regarded as a general framework to select a single or combination of color channels that will enhance the segmentation accuracy of images with different level of scene complexities and illumination variations. © Proceedings of the 14th IADIS International Conference Computer Graphics, Visualization, Computer Vision and Image Processing 2020, CGVCVIP 2020 and Proceedings of the 5th IADIS International Conference Big Data Analytics, Data Mining and Computational Intelligence 2020, BigDaCI 2020 and Proceedings of the 9th IADIS International Conference Theory and Practice in Modern Computing 2020, TPMC 2020 - Part of the 14th Multi Conference on Computer Science and Information Systems, MCCSIS 2020. All rights reserved.","","Color channel; Color space; Deep learning; Expectation maximization; Segmentation; Skin lesion","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101117060&partnerID=40&md5=91860441b93000f04019032cb65cd0cc"
"Automatic skin lesion segmentation based on saliency and color","Ramella G.","2020","1","1","0","0","0","Unique","0","","","","","","","Segmenting skin lesions in dermoscopic images is a key step for the automatic diagnosis of melanoma. In this framework, this paper presents a new algorithm that after a pre-processing phase aimed at reducing the computation burden, removing artifacts and improving contrast, selects the skin lesion pixels in terms of their saliency and color. The method is tested on a publicly available dataset and is evaluated both qualitatively and quantitatively. Copyright © 2020 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved","10.5220/0009144904520459","Color Image Processing; Dermoscopic Images; Saliency Map; Skin Lesion Segmentation","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083570074&doi=10.5220%2f0009144904520459&partnerID=40&md5=e83866765e46464a4636c3afb8454322"
"Detection of squamous cell carcinoma through smart technologies","Sagari S.M.; Venkatesan S.","2020","0","1","0","0","0","First occurrence","0","","","","","","","Oral cancer is the sixth most cancer type that occurs common among population who have addiction habit of chewing gutka, overconsumption of alcohol, excessive smoking and improper care for health. Squamous cell carcinoma is the most common type of oral cancer that occurs in mucosa lining of oral cavity. The proposed work implements simple and smart techniques based on colour feature to detect and localise the squamous cell carcinoma of oral cavity, as malignant tumour occur by changing the colour texture of tissue. Diagnosing colour appearance of any organ in human body plays a major role to locate the difference between healthy and abnormal changes of skin due to some underlying cause. The experimental results of the work locate region of interest (ROI) by converting RGB (red, green and blue) colour space to HSV (hue, saturation and value) colour space. Since HSV are used more common for tracking objects using computer vision and helps human to interpret colour changes easily. Then localised ROI is segmented into binary mask, by varying pixel intensity through track bars manually. Separation of susceptible cancerous region becomes more robust by applying contours on ROI of an image. This work also focuses on noise removal, thus making prediction possible for a physician. © Springer Nature Switzerland AG 2020.","10.1007/978-3-030-42934-8_12","Active contours; Colour texture of cancer tumour; HSV colour space; RGB colour space; Squamous cell carcinoma","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091126386&doi=10.1007%2f978-3-030-42934-8_12&partnerID=40&md5=5803de862110dd0d604ecedb235b52c2"
"A comparison of neural network approaches for melanoma classification","Frasca M.; Nappi M.; Risi M.; Tortora G.; Citarella A.A.","2020","0","1","0","0","0","Unique","0","","","","","","","Melanoma is the deadliest form of skin cancer and it is diagnosed mainly visually, starting from initial clinical screening and followed by dermoscopic analysis, biopsy and histopathological examination. A dermatologist's recognition of melanoma may be subject to errors and may take some time to diagnose it. In this regard, deep learning can be useful in the study and classification of skin cancer. In particular, by classifying images with Deep Neural Network methodologies, it is possible to obtain comparable or even superior results compared to those of dermatologists. In this paper, we propose a methodology for the classification of melanoma by adopting different deep learning techniques applied to a common dataset, composed of images from the ISIC dataset and consisting of different types of skin diseases, including melanoma on which we applied a specific pre-processing phase. In particular, a comparison of the results is performed in order to select the best effective neural network to be applied to the problem of recognition and classification of melanoma. Moreover, we also evaluate the impact of the pre-processing phase on the final classification. Different metrics such as accuracy, sensitivity, and specificity have been selected to assess the goodness of the adopted neural networks and compare them also with the manual classification of dermatologists. © 2020 IEEE","10.1109/ICPR48806.2021.9412893","","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105381839&doi=10.1109%2fICPR48806.2021.9412893&partnerID=40&md5=5702c561d35822a1eb2ee4719eb95737"
"Deep Semantic Segmentation and Multi-Class Skin Lesion Classification Based on Convolutional Neural Network","Anjum M.A.; Amin J.; Sharif M.; Khan H.U.; Malik M.S.A.; Kadry S.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Skin cancer is developed due to abnormal cell growth. These cells are grown rapidly and destroy the normal skin cells. However, it's curable at an initial stage to reduce the patient's mortality rate. In this article, the method is proposed for localization, segmentation and classification of the skin lesion at an early stage. The proposed method contains three phases. In phase I, different types of the skin lesion are localized using tinyYOLOv2 model in which open neural network (ONNX) and squeeze Net model are used as a backbone. The features are extracted from depthconcat7 layer of squeeze Net and passed as an input to the tinyYOLOv2. The propose model accurately localize the affected part of the skin. In Phase II, 13-layer 3D-semantic segmentation model (01 input, 04 convolutional, 03 batch-normalization, 03 ReLU, softmax and pixel classification) is used for segmentation. In the proposed segmentation model, pixel classification layer is used for computing the overlap region between the segmented and ground truth images. Later in Phase III, extract deep features using ResNet-18 model and optimized features are selected using ant colony optimization (ACO) method. The optimized features vector is passed to the classifiers such as optimized (O)-SVM and O-NB. The proposed method is evaluated on the top MICCAI ISIC challenging 2017, 2018 and 2019 datasets. The proposed method accurately localized, segmented and classified the skin lesion at an early stage. © 2013 IEEE.","10.1109/ACCESS.2020.3009276","ant colony optimization; ONNX; ResNet-18; squeeze Net; SVM; YOLOv2","60","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089508765&doi=10.1109%2fACCESS.2020.3009276&partnerID=40&md5=9af8ee8221e65d15711e287d5b2d037d"
"Skin lesion analysis using ensemble of CNN with dermoscopic images and metadata","Milantev S.; Olyunin V.; Milanteva N.; Bykov I.; Bessmertny I.","2020","1","1","0","0","0","Unique","0","","","","","","","Skin cancer is the most common type of cancer in the existing world, accounting for one third of all cancer cases. This paper describes approach for ISIC Skin Lesion Classification Challenge.Its main purpose is to classify skin lesions basing on dermoscopic images and additional patient metadata. A diverse dataset of 25331 images containing images from eight classes, including an additional unknown class provided by ISIC was used for training. There also were used about 8 thousand images from external private datasets: seven-point criteria database, SD-198, MED-NODE, PH2 and SKINL2v2. Ultimately there were 32748 images to train neural network models. The data has different resolutions and a large class imbalance, so different input model resizes, data augmentation and weighted cross-entropy loss was used. In this paper, there was considered the use of deep learning for skin lesions with advanced data preprocessing. There was decided to classify skin lesions using convolutional neural networks. Each image was segmented using R2U-Net and and black areas were removed from it before being fed into the convolutional network for classification. The unnecessary parts of the image was removed using segmentation method which returned accurate extraction of the skin lesion region. Shades of Grey and data augmentation processed each image. We used R2U-Net for segmentation and EfficientNetB0-B7, SENet-154, ResNeXt-101 32x4d and Inception-ResNet-v2 to classify skin diseases. We applied a fully-connected dense layers to each model to attach metadata. Median method was applied for outlier or missing values. Label encoding was performed binary features and one-hot encoding was used for other non-binary features. We experimented with this approach and the results of this experiments were spectacular. All models with an ensemble were combined. The best ensemble can achieve a sensitivity of 81.5% and specificity of 97.7%. © 2020 Copyright for this paper by its authors.","","Convolutional neural network; Deep learning; EfficientNet; Inception-ResNet; R2U-Net; ResNeXt; SENet; Skin lesion analysis","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109211258&partnerID=40&md5=dac812e4dd2bddbc28330d5d6da8b977"
"An efficient skin cancer diagnostic system using bendlet transform and support vector machine","Poovizhi S.; Ganesh Babu T.","2020","1","1","0","0","0","Unique","0","","","","","","","Skin is the outermost and largest organ of the human body that protects us from the external agents. Among the various types of diseases affecting the skin, melanoma (skin cancer) is the most dangerous and deadliest disease. Though it is one of the dangerous forms of cancer, it has a high survival rate if and only if it is diagnosed at the earliest. In this study, skin cancer classification (SCC) system is developed using dermoscopic images. It is considered as a classification problem with the help of Bendlet Transform (BT) as features and Support Vector Machine (SVM) as a classifier. First, the unwanted information’s such as hair and noises are removed using median filtering approach. Then, directional representation based feature extraction system that precisely classifies curvature, location and orientation is employed. Finally, two SVM classifiers are designed for the classification. The performance of the SCC system based on Bendlet is superior to other image representation systems such as Wavelets, Curvelets, Contourlets and Shearlets. © 2020, Academia Brasileira de Ciencias. All rights reserved.","10.1590/0001-3765202020190554","Bendlet Transform; Medical image classification; Multi-resolution analysis; Skin cancer; Support vector machine","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086457658&doi=10.1590%2f0001-3765202020190554&partnerID=40&md5=f5c6922733810afa815bfec0d726ea73"
"Transition region-based approach for skin lesion segmentation","Parida P.; Rout R.","2020","1","1","0","0","0","Unique","0","","","","","","","Skin melanoma is a skin disease that affects nearly 40% of people globally. Manual detection of the area is a time-consuming process and requires expert knowledge. The application of computer vision techniques can simplify this. In this article, a novel unsupervised transition region-based approach for skin lesion segmentation for melanoma detection is proposed. The method starts with the Gaussian blurring of the green channel dermoscopic image. Further, the transition region is extracted using local variance features and a global thresholding operation. It achieves the region of interest (binary mask) using various morphological operations. Finally, the melanoma regions are segregated from normal skin regions using the binary mask. The proposed method is tested using the DermQuest dataset along with the ISIC 2017 dataset, and it achieves better results as compared to other state-of-the-art methods in effectively segmenting the melanoma regions from the normal skin regions. © 2020.","10.5565/rev/elcvia.1177","Gaussian blurring; Morphological operation; Skin melanoma; Transition region","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086579059&doi=10.5565%2frev%2felcvia.1177&partnerID=40&md5=679160833dcbfe5888aa66f1c078bd93"
"Dermoscopic image segmentation based on modified GrabCut with octree color quantization","Frants V.; Agaian S.","2020","0","1","0","0","0","Unique","0","","","","","","","Skin lesion segmentation (SLS) has a vital role in the early and precise diagnosis of skin cancer by computer-aided diagnosis (CAD) systems. But, the automatic SLS in dermoscopic images is a challenging task due to the substantial differences in color, texture, artifacts (hairs, gel bubbles, ruler markers), indistinct boundaries, low contrast, and varying sizes, position, and shapes of the lesion images. In the paper, we propose an extended GrabCut image segmentation algorithm for Foreground/Backgrounds dermoscopic image segmentation applications. The method integrates octree color quantization and a modified GrabCut method with a new energy function. Extensive computer simulation on ISIC 2017 has shown to compare favorably on both qualitative and quantitative evaluations with commonly used segmentation tools. © 2020 SPIE","10.1117/12.2556699","Color quantization; Dermoscopy; Graph cut; Image segmentation; Medical image; Minimum flow; Structural similarity","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095941792&doi=10.1117%2f12.2556699&partnerID=40&md5=083e51aa1cea08fc4dbed7a1f850b453"
"Entropy-Based Skin Lesion Segmentation Using Stochastic Fractal Search Algorithm","Bingöl O.; Paçacı S.; Güvenç U.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Skin cancer is a type of cancer that attracts attention with the increasing number of cases. Detection of the lesion area on the skin has an important role in the diagnosis of dermatologists. In this study, 5 different entropy methods such as Kapur, Tsallis, Havrda and Charvat, Renyi and Minimum Cross were applied to determine the lesion area on dermoscopic images. Stochastic fractal search algorithm was used to determine threshold values with these 5 methods. PH2 data set was used for skin lesion images. © 2020, Springer Nature Switzerland AG.","10.1007/978-3-030-36178-5_69","Entropy; Lesion segmentation; Stochastic fractal search","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083430554&doi=10.1007%2f978-3-030-36178-5_69&partnerID=40&md5=a1990d779eb81491ffa05a0d5d6e5fd2"
"Melanoma detection system based on a game theory model","Dahmani D.; Larabi S.; Djelouah S.; Benhebbadj N.; Cheref M.","2020","0","1","0","0","0","Unique","0","","","","","","","We propose in this paper a new method for Melanoma detection (the most dangerous form of skin cancer) based on ABCD medical procedure. The ABCD features play a crucial role in the accuracy of diagnosis rates. However, the search for such distinctive data remains difficult, because of the small variability in the appearance of benign and cancerous skin lesions. To cope with this problem, each feature is calculated using different formulas. Then if all the used formulas agree about the lesion classification, it will be classified according to the full agreement. Otherwise, for doubtful pigmented skin lesions, the game theory model is applied for final decision. The game model proposed in our work, estimates that the conflict is between two agents (melanoma and non-melanoma). The different formulas applied in the computation of the features A, B, C, and D are the pure strategies. The value sign in the mixed extension of the game allows classifying correctly the skin lesion. The method was tested on two publically available databases PH2 and ISIC, the obtained results are promising. Copyright © 2020 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.","10.5220/0008879807030711","ABCD; Melanoma; Skin; Zero-sum Game Theory","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083499621&doi=10.5220%2f0008879807030711&partnerID=40&md5=da05716456560d503259680da50b4f74"
"Melanoma detection using HSV with SVM classifier and de-duplication technique to increase efficiency","Patil M.; Dongre N.","2020","0","1","0","0","0","First occurrence","0","","","","","","","Around one third of all recorded cancers account worldwide for skin cancer, according to the World Health Organization. Every year in the USA there are over 5 million non-melanoma, although about 13,000 cases of melanoma are reported in the UK and Australia. Over the last few decades, occurrences of skin cancer have also risen by 119%, from 1990 to 91270, from 27,600 in 2018. Melanoma has risen 119 million in nations such as the United Kingdom. Not only has the ozone layer reduced ultraviolet radiation safety but the misuse of the atmosphere and heat and tanning [2] has explained this trend. The medical fraternity has spent enormous time and energy on sensitizing people by awareness initiatives. Human skin cancer is the most dangerous variety, with its effects growing rapidly. Early detection of melanoma in dermoscopic photos is extremely important as they are useful for early diagnosis and treatment of ailment. Computer-aided diagnostic tools may promote the detection of cancer early for dermatologists. In this method pre-processing shall take place by applying a list of filters for removing hair, spots and assorted noises from pictures and the methodology of photographs painting shall then be used to fill unspecified areas. In this paper system uses PH2 dataset for evaluation. Also proposed de-duplication method will help in image preprocessing time which will also help in detection of melanoma. KNN, Naïve Bayes and SVM classifier are used for training and testing purpose also SVM shows the highest accuracy of classifier with de-duplication techniques. © Springer Nature Singapore Pte Ltd 2020.","10.1007/978-981-15-6648-6_9","Data de duplication; Image processing; Melanoma; SVM","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089239381&doi=10.1007%2f978-981-15-6648-6_9&partnerID=40&md5=12c1c697c0884b2a58374b1181d62636"
"Defending Deep Learning-Based Biomedical Image Segmentation from Adversarial Attacks: A Low-Cost Frequency Refinement Approach","Liu Q.; Jiang H.; Liu T.; Liu Z.; Li S.; Wen W.; Shi Y.","2020","0","1","0","0","0","First occurrence","0","","","","","","","Deep learning has demonstrated superb performance and efficiency in medical image segmentation. However, recently the community has also found the first practical adversarial example crafting algorithm dedicated to misleading deep learning-based biomedical image segmentation models. The generated segmentation-oriented adversarial examples, while almost indistinguishable by human eyes, can always produce target incorrect segmentation prediction with high intersection-over-union (IoU) rate, significantly concerning the safe use of such an emerging technique in medical diagnosis tasks. On the other hand, research on defending such an emerging attack in the context of medical image segmentation is lacking. In this work, we make the very first attempt to develop a low-cost and effective input-transformation based defense technique. To maximize the defense efficiency (or recovered segmentation results) of adversarial samples while minimizing the segmentation performance loss of benign samples after applying defense, we propose a novel low-cost image compression-based defense approach guided by fine-grained frequency refinement (FR). Extensive experimental results on various deep learning segmentation models show that our defense can offer very high defense efficiency against adversarial examples with very marginal segmentation performance loss of benign images on both ISIC skin lesion segmentation challenge and the problem of glaucoma optic disc segmentation. To further validate our method’s effectiveness, we also extend our evaluation to the image classification model. We show the influence of our recovered segmentation prediction by our defense on disease prediction in adversarial settings. The code is released at: https://github.com/qiliu08/frequency-refinement-defense. © 2020, Springer Nature Switzerland AG.","10.1007/978-3-030-59719-1_34","","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092775472&doi=10.1007%2f978-3-030-59719-1_34&partnerID=40&md5=9128ccbbebfccf57a7f0d64434cfb081"
"Skin Lesion Segmentation Based on Multi-Scale Attention Convolutional Neural Network","Jiang Y.; Cao S.; Tao S.; Zhang H.","2020","1","1","0","0","0","First occurrence","0","","","","","","","The incidence of skin cancer around the world is increasing year by year. However, early diagnosis and treatment can greatly improve the survival rate of patients. Skin lesion boundary segmentation is essential to accurately locate lesion areas in dermatoscopic images. It is true that accurate segmentation of skin lesions is still challenging dues to problems such as blurred borders, which requires an accurate and automatic skin lesion segmentation method. In this paper, we propose an end-to-end framework which can perform skin lesion segmentation automatically and efficiently, called the CSARM-CNN (Channel Spatial Attention Residual Module) model. Each CSARM block of the model combines channel attention and spatial attention to form a new attention module to enhance segmentation results. The multi-scale input images are obtained by the spatial pyramid pooling. Finally, a weighted cross-entropy loss function is used at each side of the output layer to sum the total loss of the model. We evaluated in two published standard datasets, ISIC 2017 and PH2, and achieved competitive results in terms of specificity and accuracy, with 99.03% and 99.45% specificity, 94.96% and 95.23% accuracy, respectively.  © 2013 IEEE.","10.1109/ACCESS.2020.3007512","attention mechanism; Deep convolutional neural network; multi-scale; skin lesion segmentation","36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088634614&doi=10.1109%2fACCESS.2020.3007512&partnerID=40&md5=414524b86ad369a86eba8d22bf006e78"
"Skin cancer classification computer system development with deep learning","Demidova A.V.; Kulyabov D.S.; Shchetinin E.Yu.","2020","1","1","0","0","0","Unique","0","","","","","","","Melanoma is a deadly form of skin cancer that is often undiagnosed or misdiagnosed as a benign skin lesion. Its early detection is extremely important, since the life of patients with melanoma depends on accurate and early diagnosis of the disease. However, doctors often rely on personal experience and assess each patient's injuries based on a personal examination. Clinical studies allow us to get the accuracy of the diagnosis of melatoma from 65 to 80 percents, which was a good result for some time. However, modern research claims that the use of dermoscopic images in diagnosis significantly increases the accuracy of diagnosis of skin lesions. The visual differences between melanoma and benign skin lesions can be very small, making diagnosis difficult even for an expert doctor. Recent advances in the use of artificial intelligence methods in the analysis of medical images have made it possible to consider the development of intelligent medical diagnostic systems based on visualization as a very promising direction that will help the doctor in making more effective decisions about the health of patients and making a diagnosis at an early stage and in adverse conditions. In this paper, we propose an approach to solving the problem of classification of skin diseases, namely, melanoma at an early stage, based on deep learning. In particular, a solution to the problem of classification of a dermoscopic image containing either malignant or benign skin lesions is proposed. For this purpose, the deep neural network architecture was developed and applied to image processing. Computer experiments on the ISIC data set have shown that the proposed approach provides 92% accuracy on the test sample, which is significantly higher than other algorithms in this data set have shown. © 2020 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0). CEUR Workshop Proceedings (CEUR-WS.org)","","Cancer; Convolutional networks; Deep learning; Image classification; Melanoma","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091193990&partnerID=40&md5=a175ed4375d1ebf9b768f9437c9c1590"
"Bi-Directional Dermoscopic Feature Learning and Multi-Scale Consistent Decision Fusion for Skin Lesion Segmentation","Wang X.; Jiang X.; Ding H.; Liu J.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Accurate segmentation of skin lesion from dermoscopic images is a crucial part of computer-aided diagnosis of melanoma. It is challenging due to the fact that dermoscopic images from different patients have non-negligible lesion variation, which causes difficulties in anatomical structure learning and consistent skin lesion delineation. In this paper, we propose a novel bi-directional dermoscopic feature learning (biDFL) framework to model the complex correlation between skin lesions and their informative context. By controlling feature information passing through two complementary directions, a substantially rich and discriminative feature representation is achieved. Specifically, we place biDFL module on the top of a CNN network to enhance high-level parsing performance. Furthermore, we propose a multi-scale consistent decision fusion (mCDF) that is capable of selectively focusing on the informative decisions generated from multiple classification layers. By analysis of the consistency of the decision at each position, mCDF automatically adjusts the reliability of decisions and thus allows a more insightful skin lesion delineation. The comprehensive experimental results show the effectiveness of the proposed method on skin lesion segmentation, achieving state-of-the-art performance consistently on two publicly available dermoscopic image databases. © 1992-2012 IEEE.","10.1109/TIP.2019.2955297","bi-directional dermoscopic feature learning; dermoscopic images; multi-scale consistent decision fusion; Skin lesion segmentation","70","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079575089&doi=10.1109%2fTIP.2019.2955297&partnerID=40&md5=30cdfde963dd767255e4e0ad606dad2d"
"Melanoma detection using an objective system based on multiple connected neural networks","Ichim L.; Popescu D.","2020","0","1","0","0","0","First occurrence","0","","","","","","","Melanoma is a common form of skin cancer that dangerously affects many people around the world. Detection of melanoma with the naked eye by dermatologists may be subject to errors. Therefore, the implementation of image processing devices equipped with artificial intelligence can act as a support for the dermatologist in examination and decision making. However, due to the various characteristics of this type of lesions and the presence of noises and artifacts in the images, it is difficult to distinguish melanomas from benign lesions. In this article, we propose a new type of intelligent system which is based on several neural networks connected on two levels of classification. The first level contains five classifiers (subjective classifiers): The perceptron coupled with color local binary patterns, the perceptron coupled with color histograms of oriented gradients, the generative adversarial network (for segmentation) coupled with ABCD rule, the ResNet, and the AlexNet. They are chosen experimentally and consider the following features of melanomas: Texture, shape, color, size, and convolutional pixel connections. At the second level (objective level), one classifier (perceptron-type) decides whether the lesion is a melanoma, based on learning-adjusted weight and the decisions at the first level. The second level is based on back-propagation perceptron that provides the final decision (melanoma or non-melanoma). The subjective and objective levels undergo two separate training phases. This approach allows an easier transition of the system from one database to another. This study shows that the use of the objective classifier brings an accuracy of 97.5% and an F1 score of 97.47%. These results are better than those of the individual classifier and those of the previous literature mentioned in References. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","10.1109/ACCESS.2020.3028248","Artificial neural networks; Decision fusion; Dermoscopic images; Feature extraction; Image classification; Image decomposition; Image segmentation; Melanoma detection","38","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099879408&doi=10.1109%2fACCESS.2020.3028248&partnerID=40&md5=dca735707dc907157db50a5c8945e482"
"Skin Lesion Classification with Deep Convolutional Neural Network: Process Development and Validation","Ray A.; Gupta A.; Al A.","2020","1","1","0","0","0","Unique","0","","","","","","","Background: Skin cancer is the most common cancer and is often ignored by people at an early stage. There are 5.4 million new cases of skin cancer worldwide every year. Deaths due to skin cancer could be prevented by early detection of the mole. Objective: We propose a skin lesion classification system that has the ability to detect such moles at an early stage and is able to easily differentiate between a cancerous and noncancerous mole. Using this system, we would be able to save time and resources for both patients and practitioners. Methods: We created a deep convolutional neural network using an Inceptionv3 and DenseNet-201 pretrained model. Results: We found that using the concepts of fine-tuning and the ensemble learning model yielded superior results. Furthermore, fine-tuning the whole model helped models converge faster compared to fine-tuning only the top layers, giving better accuracy overall. Conclusions: Based on our research, we conclude that deep learning algorithms are highly suitable for classifying skin cancer images. ©Arnab Ray, Aman Gupta, Amutha Al.","10.2196/18438","cancer; deep convolutional neural network; DenseNet; Inception ResNet V2; machine learning; melanoma; neural network; skin cancer; VGG16, Inceptionv3","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107879751&doi=10.2196%2f18438&partnerID=40&md5=e37d5060926cc291b5dd8285e69035b3"
"Melanoma detection on dermoscopic images using superpixels segmentation and shape-based features","Patiño D.; Ceballos-Arroyo A.M.; Rodriguez-Rodriguez J.A.; Sanchez-Torres G.; Branch-Bedoya J.W.","2020","0","1","0","0","0","Unique","0","","","","","","","In this work, we present a shape-based approach to automatic skin lesion segmentation and classification in dermoscopic images. We aim to differentiate three types of lesion 1) common nevi, 2) atypical nevi, and 3) melanomas by exploring the morphology features of segmented skin lesions. Our method is an attempt to design a computer-aided ABCDEs of melanoma, where the Asymmetry and Border components are estimated using morphological features. The lesions are first segmented using a super-pixel merging strategy with an RGB criterion. Later, the segmentation method was evaluated on the PH2 dataset, and compared with other state-of-the-art skin segmentation methods. The classification was also conducted on the PH2 dataset through a 10-fold cross-validation set-up with a training and testing set partition of 90% and 10% respectively. We employed logistic regression, SVM and a neural network as classification algorithms. The best performances was 86.5% on average with the neural network. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","10.1117/12.2545300","","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081114053&doi=10.1117%2f12.2545300&partnerID=40&md5=fdf8ab8afa1ccda6e9fc9d1386f1297b"
"A machine learning approach to automatic detection of irregularity in skin lesion border using dermoscopic images","Ali A.-R.; Li J.; Yang G.; O’Shea S.J.","2020","1","1","0","0","0","Unique","0","","","","","","","Skin lesion border irregularity is considered an important clinical feature for the early diagnosis of melanoma, representing the B feature in the ABCD rule. In this article we propose an automated approach for skin lesion border irregularity detection. The approach involves extracting the skin lesion from the image, detecting the skin lesion border, measuring the border irregularity, training a Convolutional Neural Network and Gaussian naive Bayes ensemble, to the automatic detection of border irregularity, which results in an objective decision on whether the skin lesion border is considered regular or irregular. The approach achieves outstanding results, obtaining an accuracy, sensitivity, specificity, and F-score of 93.6%, 100%, 92.5% and 96.1%, respectively. © 2020. Ali et al.","10.7717/peerj-cs.268","Dermoscopy; Machine learning; Melanoma; Segmentation; Skin lesion","42","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120305564&doi=10.7717%2fpeerj-cs.268&partnerID=40&md5=8620d268b67e3dc2f42b68cb6d2a038f"
"Multi-class semantic segmentation of skin lesions via fully convolutional networks","Goyal M.; Yap M.H.; Hassanpour S.","2020","1","1","0","0","0","Unique","0","","","","","","","Melanoma is clinically difficult to distinguish from common benign skin lesions, particularly melanocytic naevus and seborrhoeic keratosis. The dermoscopic appearance of these lesions has huge intra-class variations and high inter-class visual similarities. Most current research is focusing on single-class segmentation irrespective of classes of skin lesions. In this work, we evaluate the performance of deep learning on multi-class segmentation of ISIC-2017 challenge dataset, which consists of 2,750 dermoscopic images. We propose an end-to-end solution using fully convolutional networks (FCNs) for multi-class semantic segmentation to automatically segment the melanoma, seborrhoeic keratosis and naevus. To improve the performance of FCNs, transfer learning and a hybrid loss function are used. We evaluate the performance of the deep learning segmentation methods for multi-class segmentation and lesion diagnosis (with post-processing method) on the testing set of the ISIC-2017 challenge dataset. The results showed that the two-tier level transfer learning FCN-8s achieved the overall best result with Dice score of 78.5% in a naevus category, 65.3% in melanoma, and 55.7% in seborrhoeic keratosis in multi-class segmentation and Accuracy of 84.62% for recognition of melanoma in lesion diagnosis. Copyright © 2020 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.","","Fully Convolutional Networks; Lesion Diagnosis; Multi-class Segmentation; Skin Cancer","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083574730&partnerID=40&md5=45b83ef7bf314bb2478d7c3610ae0a98"
"Deep learning-based, computer-aided classifier developed with dermoscopic images shows comparable performance to 164 dermatologists in cutaneous disease diagnosis in the Chinese population","Wang S.-Q.; Zhang X.-Y.; Liu J.; Tao C.; Zhu C.-Y.; Shu C.; Xu T.; Jin H.-Z.","2020","0","1","0","0","0","Unique","0","","","","","","","Background: Diagnoses of Skin diseases are frequently delayed in China due to lack of dermatologists. A deep learning-based diagnosis supporting system can facilitate pre-screening patients to prioritize dermatologists’ efforts. We aimed to evaluate the classification sensitivity and specificity of deep learning models to classify skin tumors and psoriasis for Chinese population with a modest number of dermoscopic images. Methods: We developed a convolutional neural network (CNN) based on two datasets from a consecutive series of patients who underwent the dermoscopy in the clinic of the Department of Dermatology, Peking Union Medical College Hospital, between 2016 and 2018, prospectively. In order to evaluate the feasibility of the algorithm, we used two datasets. Dataset I consisted of 7192 dermoscopic images for a multi-class model to differentiate three most common skin tumors and other diseases. Dataset II consisted of 3115 dermoscopic images for a two-class model to classify psoriasis from other inflammatory diseases. We compared the performance of CNN with 164 dermatologists in a reader study with 130 dermoscopic images. The experts’ consensus was used as the reference standard except for the cases of basal cell carcinoma (BCC), which were all confirmed by histopathology. Results: The accuracies of multi-class and two-class models were 81.49% ± 0.88% and 77.02% ± 1.81%, respectively. In the reader study, for the multi-class tasks, the diagnosis sensitivity and specificity of 164 dermatologists were 0.770 and 0.962 for BCC, 0.807 and 0.897 for melanocytic nevus, 0.624 and 0.976 for seborrheic keratosis, 0.939 and 0.875 for the “others” group, respectively; the diagnosis sensitivity and specificity of multi-class CNN were 0.800 and 1.000 for BCC, 0.800 and 0.840 for melanocytic nevus, 0.850 and 0.940 for seborrheic keratosis, 0.750 and 0.940 for the “others” group, respectively. For the two-class tasks, the sensitivity and specificity of dermatologists and CNN for classifying psoriasis were 0.872 and 0.838, 1.000 and 0.605, respectively. Both the dermatologists and CNN achieved at least moderate consistency with the reference standard, and there was no significant difference in Kappa coefficients between them (P > 0.05). Conclusions: The performance of CNN developed with relatively modest number of dermoscopic images of skin tumors and psoriasis for Chinese population is comparable with 164 dermatologists. These two models could be used for screening in patients suspected with skin tumors and psoriasis respectively in primary care hospital. Copyright © 2020 The Chinese Medical Association, produced by Wolters Kluwer, Inc. under the CC-BY-NC-ND license. This is an open access article distributed under the terms of the Creative Commons Attribution-Non Commercial-No Derivatives License 4.0 (CCBY-NC-ND), where it is permissible to download and share the work provided it is properly cited. The work cannot be changed in any way or used commercially without permission from the journal.","10.1097/CM9.0000000000001023","Artificial intelligence; Convolutional neural network; Dermoscopy; Psoriasis; Skin tumor","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090509706&doi=10.1097%2fCM9.0000000000001023&partnerID=40&md5=b9a93851cbec7a9d0b03900b3b578cc3"
"Improving Skin-Disease Classification Based on Customized Loss Function Combined with Balanced Mini-Batch Logic and Real-Time Image Augmentation","Pham T.-C.; Doucet A.; Luong C.-M.; Tran C.-T.; Hoang V.-D.","2020","1","1","0","0","0","Unique","0","","","","","","","Skin cancer is one of the most common cancers in the world. However, the disease is curable if detected in the beginning stage. Early detection of malignant lesions through accurate techniques and innovative technologies has a significant impact on reducing skin cancer mortality rates. Recently, artificial intelligence has come to the forefront to facilitate skin cancer diagnosis based on medical images. Many deep learning models have been studied and developed, but the imbalance of performance among classes in the multi-class classification is still a challenging problem. This study proposes a hybrid method for handling class imbalance of skin-disease classification. This method combines the data level method of balanced mini-batch logic followed by real-time image augmentation with the algorithm level method of designing new loss function. The training dataset includes 24,530 dermoscopic images of seven skin disease categories, which is by far the largest dataset of skin cancer. The performance metrics of six proposed methods are evaluated on a test dataset of 2,453 images. Our proposed EfficientNetB4-CLF model achieves the highest accuracy of 89.97% and also the highest mean recall of 86.13% with the smallest recalls' standard deviations of 7.60%. Compared to the original methods, our proposed solution not only surpasses 4.65% (86.13% vs 81.48%) of mean recalls but also reduces 4.24% of the recalls' standard deviations (from ±11.84% to ±7.60%). This result indicates that our hybrid method is highly effective in training the Deep CNN network on the skin-disease imbalanced dataset. It addresses the problem of slow learning of the minority classes in the networks by combining the data level method of balanced mini-batch logic followed by the real-time image augmentation with the algorithm level method of the newly designed loss function. © 2013 IEEE.","10.1109/ACCESS.2020.3016653","balanced mini-batch logic; deep neural networks; hybrid method; imbalanced dataset; loss function; Skin disease","80","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090294072&doi=10.1109%2fACCESS.2020.3016653&partnerID=40&md5=1c5adb5da67cbb75a7682c6fbb2e77ac"
"Weakly and semi-supervised deep level set network for automated skin lesion segmentation","Deng Z.; Xin Y.; Qiu X.; Chen Y.","2020","1","0","0","0","0","First occurrence","0","","","","","","","In this paper, we proposed an end-to-end deep convolutional neural model to implement weakly and semi-supervised learning in order to resolve insufficient training data with pixel-wised annotation. Entire model consists of two branches. At first, the segmentor is trained by small amount of training data with high-level annotation serving certain ability of semantic segmentation. In addition, deep level set and conditional random field branches are responsible for converting image-level annotation to pixels, which provide sufficient data to retrain the segmentor holding excellent capability for lesion segmentation. Finally, experiments benchmarked our proposed method with the state-of-the-art models demonstrating superior performance and generalization. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2020.","10.1007/978-981-15-5852-8_14","","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087013400&doi=10.1007%2f978-981-15-5852-8_14&partnerID=40&md5=f7ca428b471aec7fb84237211f8f8c84"
"Deep learning model deploying on embedded skin cancer diagnostic device","Bliznuks D.; Cibulska E.; Bondarenko A.; Chizhov Y.; Lihacova I.","2020","1","1","0","0","0","Unique","0","","","","","","","The number of research papers, where neural networks are applied in medical image analysis is growing. There is a proof that Convolutional Neural Networks (CNN) are able to differentiate skin cancer from nevi with greater accuracy than experienced specialists on average (sensitivity 82% and 73% accordingly). Team's latest research2 allows achieving even greater accuracy, by using specific narrow-band illumination. Nevertheless, the overall probability of early skin cancer detection depends on the availability of diagnostic tools. If screening tools will be available to a high number of general practices, the chance of disease detection will increase. The previous research3 shows that scalable cloud service is able to process a high number of users. After a certain number of users, the overall cost of the system, including cloud processing expenses and cost of high computational power portable device, might be higher if compared to an on-premises solution, where each device is capable of diagnosing without Internet access. It might be cheaper to equip devices with additional neural processing unit (NPU) and exclude cloud processing. Another option is to make screening available by using the newest smartphones that are equipped with NPU.4 The problem of using the NPU is that they are limited in storage space, accuracy, and features. Therefore, a full-size CNN model should be adapted and minimized to fit in a limited NPU. Research reviews existing CNN optimization methods and proposes the most accurate for skin cancer diagnostics. The paper evaluates CNN prediction losses when the model's elements' precision is reduced from 32 bits to 8 and rounded to integer values.  © 2020 SPIE.","10.1117/12.2582108","biophotonics; convolutional neural network; Skin cancer","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096544430&doi=10.1117%2f12.2582108&partnerID=40&md5=dd401676c215a8adc04315f2b9915512"
"Multi-class Skin Lesion Segmentation for Cutaneous T-cell Lymphomas on High-Resolution Clinical Images","Liu Z.; Pan H.; Gong C.; Fan Z.; Wen Y.; Jiang T.; Xiong R.; Li H.; Wang Y.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Automated skin lesion segmentation is essential to assist doctors in diagnosis. Most methods focus on lesion segmentation of dermoscopy images, while a few focus on clinical images. Nearly all the existing methods tackle the binary segmentation problem as to distinguish lesion parts from normal skin parts, and are designed for diseases with localized solitary skin lesion. Besides, the characteristics of both the dermoscopy images and the clinical images are four-fold: (1) Only one skin lesion exists in the image. (2) The skin lesion mostly appears in the center of the image. (3) The backgrounds are similar between different images of same modality. (4) The resolution of images isn’t high, with an average of about 1500 × 1200 in several popular datasets. In contrast, this paper focuses on a four-class segmentation task for Cutaneous T-cell lymphomas (CTCL), an extremely aggressive skin disease with three visually similar kinds of lesions. For the first time, we collect a new dataset, which only contains clinical images captured from different body areas of human. The main characteristics of these images differ from all the existing images in four aspects: (1) Multiple skin lesion parts exist in each image. (2) The skin lesion parts are widely scattered in different areas of the image. (3) The background of the images has a large variety. (4) All the images have high resolutions, with an average of 3255 × 2535. According to the characteristics and difficulties of CTCL, we design a new Multi Knowledge Learning Network (MKLN). The experimental results demonstrate the superiority of our method, which meet the clinical needs. © 2020, Springer Nature Switzerland AG.","10.1007/978-3-030-59725-2_34","Clinical image; Neural network; Skin lesion segmentation","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092758346&doi=10.1007%2f978-3-030-59725-2_34&partnerID=40&md5=786b219687bf9fda96b7d53db75b70a8"
"Automatic Detection of Dysplastic Nevi: A Multiple Instance Learning Solution.","Vocaturo E.; Zumpano E.","2020","0","1","0","0","0","Unique","0","","","","","","","Malignant melanoma is responsible for the highest number of deaths related to skin lesions. The similarities of melanoma with other skin lesions, such as dysplastic nevi, constitute a pitfall for computerized detection. The proposed algorithms and methods have had as main fo-cus the dichotomous distinction of melanoma from benign lesions and they rarely focused on the case of melanoma against dysplastic nevi. Currently, there is a debate about dysplastic nevi syndrome, or rather about the number of moles present on the human body as potential melanoma risk factors. In this document, we consider the challenging task of applying a multi-instance learning (MIL) algorithm for discriminating melanoma from dysplastic nevi and outline an even more complex chal-lenge related to the classification of dysplastic nevi from common nevi. Since the results appear promising, we conclude that a MIL technique could be at the basis of tools useful for skin lesion detection.  Copyright © 2020 for this paper by its authors.","","Dysplas-tic nevi detection; Image classification; Multiple instance learning","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090874250&partnerID=40&md5=b1ba2cff5cf63e08a7857fa2f9360ed5"
"Automatic skin disease detection using modified level set and dragonfly based neural network","Melbin K.; Jacob Vetha Raj Y.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Dermatology is an essential fields that are to be analyzed, monitored, and treated to avoid skin disorders. The skin disease is caused because many factors influence humans such as age, sex, and lifestyle. Also, less amount of exposure to sunlight, bacteria, hot weather leads to skin diseases. Hence it is important to detect the skin disease at the earlier stage to avoid the fading condition of skin. In this paper we have developed an efficient automatic detection of skin disease using a two-stage adaptive process. At first stage modified level set approach is used for segmentation of skin images, later using color, shape and texture features are extracted and in the final stage dragonfly optimization-based Neural network is used for classification of types of skin diseases such as normal or abnormal. The proposed dragonfly based NN is evaluated using existing methods such as SVM, ANN for different evaluation metrics such as accuracy, sensitivity, and specificity to show the system efficiency. © Springer Nature Switzerland AG 2020.","10.1007/978-3-030-38040-3_57","Accuracy; Dermatology; Dragonfly; Feature extraction; Level set; Neural network; Segmentation; Skin disease; SVM","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083462575&doi=10.1007%2f978-3-030-38040-3_57&partnerID=40&md5=6c6062e3c41581cd2029e854f1750aa9"
"A Novel Selective Encryption Method Based on Skin Lesion Detection","An D.; Lu J.; Zhang S.; Li Y.","2020","1","1","0","0","0","Unique","0","","","","","","","Due to the semitrusted cloud, privacy protection of medical images in medical imaging clouds has become a precondition. For the privacy of patients and the security of medical images in the cloud, this paper proposes a selective encryption based on DNA sequence and chaotic maps for skin lesion image. Initially, we design a transition region-based level set evolution functional which is merged into a variational level set expression with two extra energy functionals, to segment skin lesion image. Once skin lesion detection has been performed, the detected skin lesion pixels are encrypted by employing chaotic systems and DNA sequences. We apply 2D-LASM and 1D-LSS to produce the pseudorandom sequences and use the hash function of the plaintext image to calculate the secret keys of the encryption system. Results demonstrate that the proposed segmentation method is particularly suitable for the detection of skin lesion images with strong noise and complex background. Meanwhile, security analysis also reveals that this selective encryption has a large security key space and high sensitivity to the plaintext image and the secret key.  © 2020 Dezhi An et al.","10.1155/2020/7982192","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093915081&doi=10.1155%2f2020%2f7982192&partnerID=40&md5=92d88e6e9a9fea67fb2616c88fda30f8"
"Inferring Skin Lesion Segmentation with Fully Connected CRFs Based on Multiple Deep Convolutional Neural Networks","Qiu Y.; Cai J.; Qin X.; Zhang J.","2020","1","1","0","0","0","First occurrence","0","","","","","","","This article presents a method to infer skin lesion segmentation based on multiple deep convolutional neural network (DCNN) models by employing fully connected conditional random fields (CRFs). This method is on the strength of the synergism between ensemble learning which is responsible for introducing diversity from multiple DCNN models and CRFs inference which is in charge of probabilistic inference based on random fields over dermoscopy images. Contrasting to single DCNN models, the proposed method can gain better segmentation by comprehensively utilizing the advances and performance preferences of multiple different DCNN models. In comparison with simple ensemble schemes, it can effectively and precisely refine the fuzzy lesion boundary by utilizing the information in test images to maximize label agreement between similar pixels. Further, an engineering bonus is the feasibility of parallelization for the heavy operation, predicting on multiple DCNN models. In experiments, we tested the effectiveness and robustness of the proposed method on the mainstream datasets ISIC 2017 and PH2, and the results were competitive with the state-of-art methods. we also confirmed that the proposed method can capture the local information in fuzzy dermoscopy images being able to find more accurate lesion borders with a good boost on Boundary Recall (BR) metric. Moreover, since the hyper-parameters in CRFs are explainable, it is possible to adjust them manually to reach better results case by case, being attractive in practice. This work is of value on integration between the deep learning technologies and probabilistic inference in resolving lesion segmentation, and has great potential to be applied in similar tasks.  © 2013 IEEE.","10.1109/ACCESS.2020.3014787","Deep convolutional neural networks; ensemble learning; fully connected CRFs; pigmented skin lesion segmentation","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090272453&doi=10.1109%2fACCESS.2020.3014787&partnerID=40&md5=2b47e59c28c938b744de5ba973e36734"
"Enhanced Skin Condition Prediction through Machine Learning Using Dynamic Training and Testing Augmentation","Putra T.A.; Rufaida S.I.; Leu J.-S.","2020","1","0","0","0","0","Unique","0","","","","","","","In recent years, deep learning has taken the spotlight in automated medical bioimaging. However, the performance of current state-of-the-art score stems primarily from well-tuned parameters and architecture. There is still only limited research focused on dynamic data augmentation, even in the fields of machine learning and computer vision. In this study, we propose a dynamic training and testing augmentation capable of increasing performance significantly. The searching augmentation framework used in this study requires fewer GPU hours than a conventional search algorithm, which needs to train a new model every time augmentation is proposed. Speeding up of the search algorithm is achieved by using Bayesian optimization on a trained model, so we do not have to train a new model every time a new augmentation policy is proposed. The performance of our method is compared with that of a single model and the ensemble model that happens to be the winner of the ISIC 2019 challenge. Furthermore, we use the latest compact yet significantly accurate network architecture EfficientNet as the backbone system. Our method delivers a superior result, and this study also shares the searched augmentation policy utilized, which requires extraordinary resources. Thus, other researchers can use the searched augmentation policies for dermoscopic images to improve performance. © 2013 IEEE.","10.1109/ACCESS.2020.2976045","Augmentation; Dermoscopic images; Machine learning; Skin cancer","51","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081933107&doi=10.1109%2fACCESS.2020.2976045&partnerID=40&md5=ee9b94e1031a4f144edba830c058df37"
"11th International Workshop on Machine Learning in Medical Imaging, MLMI 2020, held in conjunction with the 23rd International Conference on Medical Image Computing and Computer Assisted Intervention, MICCAI 2020","","2020","0","1","0","0","0","Unique","0","","","","","","","The proceedings contain 68 papers. The special focus in this conference is on Machine Learning in Medical Imaging. The topics include: Out-of-Distribution Detection for Skin Lesion Images with Deep Isolation Forest; A 3D+2D CNN Approach Incorporating Boundary Loss for Stroke Lesion Segmentation; Linking Adolescent Brain MRI to Obesity via Deep Multi-cue Regression Network; robust Multiple Sclerosis Lesion Inpainting with Edge Prior; segmentation to Label: Automatic Coronary Artery Labeling from Mask Parcellation; GSR-Net: Graph Super-Resolution Network for Predicting High-Resolution from Low-Resolution Functional Brain Connectomes; anatomy-Aware Cardiac Motion Estimation; division and Fusion: Rethink Convolutional Kernels for 3D Medical Image Segmentation; LDGAN: Longitudinal-Diagnostic Generative Adversarial Network for Disease Progression Prediction with Missing Structural MRI; Unsupervised MRI Homogenization: Application to Pediatric Anterior Visual Pathway Segmentation; error Attention Interactive Segmentation of Medical Image Through Matting and Fusion; boundary-Aware Network for Kidney Tumor Segmentation; o-Net: An Overall Convolutional Network for Segmentation Tasks; label-Driven Brain Deformable Registration Using Structural Similarity and Nonoverlap Constraints; eczemaNet: Automating Detection and Severity Assessment of Atopic Dermatitis; deep Distance Map Regression Network with Shape-Aware Loss for Imbalanced Medical Image Segmentation; Joint Appearance-Feature Domain Adaptation: Application to QSM Segmentation Transfer; exploring Functional Difference Between Gyri and Sulci via Region-Specific 1D Convolutional Neural Networks; detection of Ischemic Infarct Core in Non-contrast Computed Tomography; bayesian Neural Networks for Uncertainty Estimation of Imaging Biomarkers; extended Capture Range of Rigid 2D/3D Registration by Estimating Riemannian Pose Gradients; A Novel fMRI Representation Learning Framework with GAN; structural Connectivity Enriched Functional Brain Network Using Simplex Regression with GraphNet.","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092709915&partnerID=40&md5=bbf0611524d2ce2a9d3fd5b51530ce73"
"Detection of malignant melanoma using artificial intelligence: An observational study of diagnostic accuracy","Phillips M.; Greenhalgh J.; Marsden H.; Palamaras I.","2020","0","1","0","0","0","Unique","0","","","","","","","Background: Malignant melanoma can most successfully be cured when diagnosed at an early stage in the natural history. However, there is controversy over screening programs and many advocate screening only for high-risk individuals. Objectives: This study aimed to evaluate the accuracy of an artificial intelligence neural network (Deep Ensemble for Recognition of Melanoma [DERM]) to identify malignant melanoma from dermoscopic images of pigmented skin lesions and to show how this compared to doctors' performance assessed by meta-analysis. Methods: DERM was trained and tested using 7,102 dermoscopic images of both histologically confirmed melanoma (24%) and benign pigmented lesions (76%). A meta-analysis was conducted of studies examining the accuracy of naked-eye examination, with or without dermoscopy, by specialist and general physicians whose clinical diagnosis was compared to histopathology. The meta-analysis was based on evaluation of 32,226 pigmented lesions including 3,277 histopathology-confirmed malignant melanoma cases. The receiver operating characteristic (ROC) curve was used to examine and compare the diagnostic accuracy. Results: DERM achieved a ROC area under the curve (AUC) of 0.93 (95% confidence interval: 0.92- 0.94), and sensitivity and specificity of 85.0% and 85.3%, respectively. Avoidance of false-negative results is essential, so different decision thresholds were examined. At 95% sensitivity DERM achieved a specificity of 64.1% and at 95% specificity the sensitivity was 67%. The meta-analysis showed primary care physicians (10 studies) achieve an AUC of 0.83 (95% confidence interval: 0.79-0.86), with sensitivity and specificity of 79.9% and 70.9%; and dermatologists (92 studies) 0.91 (0.88-0.93), 87.5%, and 81.4%, respectively. Conclusions: DERM has the potential to be used as a decision support tool in primary care, by providing dermatologist-grade recommendation on the likelihood of malignant melanoma. ©2019 Phillips et al.","10.5826/dpc.1001a11","Artificial intelligence; Detection; Identification; Melanoma; Primary care","46","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089107599&doi=10.5826%2fdpc.1001a11&partnerID=40&md5=b9e113ba2c101a23c9aaae8c49a92d37"
"Improving model accuracy for imbalanced image classification tasks by adding a final batch normalization layer: An empirical study","Kocaman V.; Shir O.M.; Bäck T.","2020","0","1","0","0","0","First occurrence","0","","","","","","","Some real-world domains, such as Agriculture and Healthcare, comprise early-stage disease indications whose recording constitutes a rare event, and yet, whose precise detection at that stage is critical. In this type of highly imbalanced classification problems, which encompass complex features, deep learning (DL) is much needed because of its strong detection capabilities. At the same time, DL is observed in practice to favor majority over minority classes and consequently suffer from inaccurate detection of the targeted early-stage indications. To simulate such scenarios, we artificially generate skewness (99% vs. 1%) for certain plant types out of the PlantVillage dataset as a basis for classification of scarce visual cues through transfer learning. By randomly and unevenly picking healthy and unhealthy samples from certain plant types to form a training set, we consider a base experiment as fine-tuning ResNet34 and VGG19 architectures and then testing the model performance on a balanced dataset of healthy and unhealthy images. We empirically observe that the initial F1 test score jumps from 0.29 to 0.95 for the minority class upon adding a final Batch Normalization (BN) layer just before the output layer in VGG19. We demonstrate that utilizing an additional BN layer before the output layer in modern CNN architectures has a considerable impact in terms of minimizing the training time and testing error for minority classes in highly imbalanced data sets. Moreover, when the final BN is employed, minimizing the loss function may not be the best way to assure a high F1 test score for minority classes in such problems. That is, the network might perform better even if it is not 'confident' enough while making a prediction; leading to another discussion about why softmax output is not a good uncertainty measure for DL models. We also report on the corroboration of these findings on the ISIC Skin Cancer as well as the Wall Crack datasets. © 2020 IEEE","10.1109/ICPR48806.2021.9412907","","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110518508&doi=10.1109%2fICPR48806.2021.9412907&partnerID=40&md5=8acda64908ca9bee335ecbebe1cba429"
"Distractor-Aware Neuron Intrinsic Learning for Generic 2D Medical Image Classifications","Gong L.; Ma K.; Zheng Y.","2020","0","1","0","0","0","First occurrence","0","","","","","","","Medical image analysis benefits Computer Aided Diagnosis (CADx). A fundamental analyzing approach is the classification of medical images, which serves for skin lesion diagnosis, diabetic retinopathy grading, and cancer classification on histological images. When learning these discriminative classifiers, we observe that the convolutional neural networks (CNNs) are vulnerable to distractor interference. This is due to the similar sample appearances from different categories (i.e., small inter-class distance). Existing attempts select distractors from input images by empirically estimating their potential effects to the classifier. The essences of how these distractors affect CNN classification are not known. In this paper, we explore distractors from the CNN feature space via proposing a neuron intrinsic learning method. We formulate a novel distractor-aware loss that encourages large distance between the original image and its distractor in the feature space. The novel loss is combined with the original classification loss to update network parameters by back-propagation. Neuron intrinsic learning first explores distractors crucial to the deep classifier and then uses them to robustify CNN inherently. Extensive experiments on medical image benchmark datasets indicate that the proposed method performs favorably against the state-of-the-art approaches. © 2020, Springer Nature Switzerland AG.","10.1007/978-3-030-59713-9_57","Distractor-awareness; Medical Image Classification; Neuron Intrinsic Learning","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092731645&doi=10.1007%2f978-3-030-59713-9_57&partnerID=40&md5=1e6d14cf2458477294d3cb3531ff412d"
"Research on Dermoscopic Segmentation based on Multi-scale Convolutional Neural Network","Wang J.; Zhang G.; He Z.; Wang S.; Sun Y.","2020","0","1","0","0","0","Unique","0","","","","","","","The skin is an important organ of the human body, and the major skin diseases represented by melanoma are difficult to find and difficult to treat, which directly threaten the patient's life safety. Therefore, rapid and accurate dermatoscopy diagnosis[1] is particularly important. The lack of experienced dermatologists limits the large-scale early diagnosis or screening of melanoma. Based on the above problems, this paper uses the method of multi-scale convolutional neural network to segment the Dermoscopic image by means of image segmentation in artificial intelligence to help medical personnel to achieve reliable diagnostic reference. In the overall segmentation network, this paper first enhances the contrast of the original image through preprocessing, and uses data enhancement and segmentation to increase the dataset. In the model training phase, this paper adopts the basic segmentation framework of U-Net[2] network. Different from U-Net networks, this paper introduces multi-scale features and multi-scale fusion mechanisms to deeply mine and fuse dermoscopic image features. Secondly, the model uses Focal Loss as the fundus segmentation loss function, and finds the optimal parameters of the loss function through a random grid search algorithm. In this paper, for the problem of positive and negative sample imbalance in dermoscopic images, this paper proposes an adaptive Focal Loss loss function and Channel-Wise Attention mechanism to adaptively weight the feature maps. © 2020 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)","10.1016/j.procs.2020.06.112","Convolutional Neural Networks; Deep Learning; Dermatoscopy Segmentation; Multiscale Structure","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122181009&doi=10.1016%2fj.procs.2020.06.112&partnerID=40&md5=b7568543663601162c74a8e47be5072c"
"Deep Learning Performance for Triage and Diagnosis","Iglesias-Puzas A.; Boixeda P.","2020","0","1","0","0","0","First occurrence","0","","","","","","","Artificial intelligence has changed the landscape of medical imaging. As machines learn to detect patterns by processing massive datasets, computer aid diagnosis is placed to revolutionize the standards of healthcare. Extending upon classical diagnostic tools, machine learning may outperform diagnostic accuracy of knowledge level experts, thereby contributing positively to patient care. Here, we introduce some fundamental concepts about deep learning and highlight its application for skin lesions’ triage and diagnosis. © Springer Nature Switzerland AG 2020.","10.1007/978-3-030-24544-3_41","Artificial intelligence; Computer aid diagnosis; Convolutional neuronal networks; Decision support; Deep learning; Generative adversarial networks; Machine learning; Melanoma","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149594314&doi=10.1007%2f978-3-030-24544-3_41&partnerID=40&md5=25e89249e760d5e41d334b12c30b5c4c"
"Detection of the DEJ and segmentation of its morphological patterns in RCM images of melanocytic skin lesions","Kose K.; Bozkurt A.; Fox C.A.; Gill M.; Brooks D.; Dy J.; Rajadhyaksha M.","2020","1","1","0","0","0","Unique","0","","","","","","","Reflectance confocal microscopy (RCM) provides a real-time noninvasive (in-vivo) proxy for histology. Here, we present machine learning models to delineate skin layers in RCM image stacks and analyze morphological patterns in RCM mosaics of skin. © 2020 The Author(s)","10.1364/MICROSCOPY.2020.MW2A.1","","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091398034&doi=10.1364%2fMICROSCOPY.2020.MW2A.1&partnerID=40&md5=59745b52d1010b3997be7b274c4f87dc"
"Analysis of image features for the characterization of skin optical clearing kinetics performed on in vivo and ex vivo human skin using linefield-confocal optical coherence tomography (LC-OCT)","Tran S.; Zaytsev S.; Charykova V.; Yusupova M.; Bashkatov A.; Genina E.; Tuchin V.; Blondel W.; Amouroux M.","2020","1","1","0","0","0","Unique","0","","","","","","","Skin cancers including carcinomas and melanomas are currently the most common cancers in fair skinned humans. Histopathology, requiring invasive tissue biopsy and processing, is the gold standard for cancer diagnosis. Optical Coherence Tomography (OCT) has emerged as a label-free, non-traumatic and non-invasive method that can be used in vivo to image skin tissues (from stratum corneum to dermis) and therefore contribute to skin cancer diagnosis. Some of the major limitations of OCT imaging techniques are a lower resolution compared to histology and a limited penetration depth due to skin tissues' strong optical scattering. Optical clearing has been investigated for several years as one of the solutions to overcome these problems by inducing a reversible decreased scattering and thus allowing a better contrast and an improved light penetration depth within biological tissues. Clearing is achieved using optical clearing agents (OCA) combined with chemical enhancers (used to better pass through the stratum corneum layer). As a first step, the current study aims at defining the quantitative features (intensity profile, image statistics, texture descriptors) that are best suited to quantify optical clarification kinetics from images acquired using Linefield Confocal-OCT (LC-OCT) device. This will help analyzing the relationship between visible optical clearing and OCT devices resolution. © 2020 SPIE. All rights reserved.","10.1117/12.2575173","Analysis in vivo; Human skin; Image processing; LC-OCT; OCT; Optical clearing agents; Quantitative features; Tissue optical clearing","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097189005&doi=10.1117%2f12.2575173&partnerID=40&md5=6011ce6629a92ecd051e2206ae8cd593"
"Dermoscopic attributes classification using deep learning and multi-Task learning","Saitov I.; Polevaya T.; Filchenkov A.","2020","0","1","0","0","0","Unique","0","","","","","","","Melanoma is a serious condition affecting people around the world. Therefore, automatic diagnostics of pigmented skin lesions is an area of high interest. Possible approach to diagnostics is based on detection of dermoscopic attributes. In this study we consider developing an end-To-end solution for the task of dermoscopic attributes detection based on the data of ISIC (International Skin Imaging Collaboration) competition dataset. We investigate the possibility to improve performance using labeling of different modality in the form of segmentation masks. We propose to use the segmentation task as an auxiliary task and allow sharing knowledge between these two tasks by training a neural network of Y-Net architecture, which allows sharing of the weights between segmentation and classification branches. Additionally, we propose several modes of combining training of Y-Net based on segmentation and classification labels. The best of proposed methods has reached F1score of 0.527 comparing to plain classification's 0.502. © 2020 Elsevier B.V.. All rights reserved.","10.1016/j.procs.2020.11.034","deep learning; dermoscopic attributes; multi-label classification; multi-Task learning","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098564509&doi=10.1016%2fj.procs.2020.11.034&partnerID=40&md5=262cc53ba533135b031ef209146752ed"
"A visually explainable learning system for skin lesion detection using multiscale input with attention u-net","Nguyen D.M.H.; Ezema A.; Nunnari F.; Sonntag D.","2020","1","0","0","0","0","First occurrence","0","","","","","","","In this work, we propose a new approach to automatically predict the locations of visual dermoscopic attributes for Task 2 of the ISIC 2018 Challenge. Our method is based on the Attention U-Net with multi-scale images as input. We apply a new strategy based on transfer learning, i.e., training the deep network for feature extraction by adapting the weights of the network trained for segmentation. Our tests show that, first, the proposed algorithm is on par or outperforms the best ISIC 2018 architectures (LeHealth and NMN) in the extraction of two visual features. Secondly, it uses only 1/30 of the training parameters; we observed less computation and memory requirements, which are particularly useful for future implementations on mobile devices. Finally, our approach generates visually explainable behaviour with uncertainty estimations to help doctors in diagnosis and treatment decisions. © Springer Nature Switzerland AG 2020.","10.1007/978-3-030-58285-2_28","Attention U-Net; Diagnose features; Skin lesion","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091130810&doi=10.1007%2f978-3-030-58285-2_28&partnerID=40&md5=e4317804f14beb9c19c63bef6300e570"
"Review of Skin Diseases Classification Methods Using Different Color Phase Models","Ubale A.V.; Paikrao P.L.","2020","1","1","0","0","0","First occurrence","0","","","","","","","There are number of disease caused due to many reasons and diagnosis of this diseases can be based on blood test, symptoms, clinical tests. In this paper, this method is used for diagnosis of skin diseases by considering the signatures like size, color, skin lesion texture. This signatures can be diagnosed on simple statistics. For remote monitoring of patient, dermatologist uses this method as a complementary tool for skin diseases classification using different color phase models. By using more number of photographs we increases the accuracy. © 2020, Springer Nature Singapore Pte Ltd.","10.1007/978-981-15-1420-3_92","Histogram; Image processing; Lesions; Skin diseases; Skin infections","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085521818&doi=10.1007%2f978-981-15-1420-3_92&partnerID=40&md5=15bfff156786f6b37807007ffc997497"
"Neural architecture search for skin lesion classification","Kwasigroch A.; Grochowski M.; Mikolajczyk A.","2020","1","0","0","0","0","Unique","0","","","","","","","Deep neural networks have achieved great success in many domains. However, successful deployment of such systems is determined by proper manual selection of the neural architecture. This is a tedious and time-consuming process that requires expert knowledge. Different tasks need very different architectures to obtain satisfactory results. The group of methods called the neural architecture search (NAS) helps to find effective architecture in an automated manner. In this paper, we present the use of an architecture search framework to solve the medical task of malignant melanoma detection. Unlike many other methods tested on benchmark datasets, we tested it on practical problem, which differs greatly in terms of difficulty in distinguishing between classes, resolution of images, data balance within the classes, and the number of data available. In order to find a suitable network structure, the hill-climbing search strategy was employed along with network morphism operations to explore the search space. The network morphism operations allow for incremental increases in the network size with the use of the previously trained network. This kind of knowledge reusing allows significantly reducing the computational cost. The proposed approach produces structures that achieve similar results to those provided by manually designed structures, at the same time making use of almost 20 times fewer parameters. What is more, the search process lasts on average only 18h on single GPU. © 2013 IEEE.","10.1109/ACCESS.2020.2964424","convolutional neural network; Deep learning; malignant melanoma; network morphism; neural architecture search","64","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078227947&doi=10.1109%2fACCESS.2020.2964424&partnerID=40&md5=e2731c4fb12bce5a8703a5a129831523"
"Difficulty-aware meta-learning for rare disease diagnosis","Li X.; Yu L.; Jin Y.; Fu C.-W.; Xing L.; Heng P.-A.","2020","0","1","0","0","0","First occurrence","0","","","","","","","Rare diseases have extremely low-data regimes, unlike common diseases with large amount of available labeled data. Hence, to train a neural network to classify rare diseases with a few per-class data samples is very challenging, and so far, catches very little attention. In this paper, we present a difficulty-aware meta-learning method to address rare disease classifications and demonstrate its capability to classify dermoscopy images. Our key approach is to first train and construct a meta-learning model from data of common diseases, then adapt the model to perform rare disease classification. To achieve this, we develop the difficulty-aware meta-learning method that dynamically monitors the importance of learning tasks during the meta-optimization stage. To evaluate our method, we use the recent ISIC 2018 skin lesion classification dataset, and show that with only five samples per class, our model can quickly adapt to classify unseen classes by a high AUC of 83.3%. Also, we evaluated several rare disease classification results in the public Dermofit Image Library to demonstrate the potential of our method for real clinical practice. © Springer Nature Switzerland AG 2020.","10.1007/978-3-030-59710-8_35","","50","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093078009&doi=10.1007%2f978-3-030-59710-8_35&partnerID=40&md5=e5942121bc458cfa6ca0a8b63ee0b2ed"
"Gray Level Co-Occurrence Matrix (GLCM) parameters analysis for pyoderma image variants","Gupta C.; Gondhi N.K.; Lehana P.K.","2020","0","1","0","0","0","Unique","0","","","","","","","Analysis of different visual textures present in the given images is one of the important perspectives of human vision for objects segregation and identification. Texture-based features are widely used in medical diagnosis for informal prediction of dermatological diseases. Dermatological diseases are the most universal diseases affecting all the living beings worldwide. Recent advancements in image processing have considerably improved the classification, identification, and treatment of various dermatological diseases. Present paper reports the results of Gray Level Co-occurrence Matrix (GLCM) based texture analysis of skin diseases for parametric variations. The investigations were carried out using three Pyoderma variants (Boil, Carbuncle, and Impetigo Contagiosa) using GLCM. GLCM parameters (Energy, Correlation, Contrast, and Homogeneity) were extracted for each colour component of the images taken for the investigation. Contrast, correlation, energy, and homogeneity represent the coarseness, linear dependency, textural uniformity, and pixel distribution of the texture, respectively. The analysis of the GLCM parameters and their histograms showed that the said textural features are disease dependent. The approach may be used for the identification of dermatological diseases with satisfactory accuracy by employing a suitable machine learning algorithm. © 2020 American Scientific Publishers.","10.1166/jctn.2020.8674","Dermatology; Feature Selection; Gray Level Co-Occurrence Matrix; Image Segmentation; Skin Abnormalities; Texture Analysis","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080058517&doi=10.1166%2fjctn.2020.8674&partnerID=40&md5=502a2e799e1dbac1c0878e4fe372c8ec"
"Spec-Net and Spec-CGAN: Deep learning models for specularity removal from faces","Muhammad S.; Dailey M.N.; Farooq M.; Majeed M.F.; Ekpanyapong M.","2020","0","1","0","0","0","Unique","0","","","","","","","The process of splitting an image into specular and diffuse components is a fundamental problem in computer vision, because most computer vision algorithms, such as image segmentation and tracking, assume diffuse surfaces, so existence of specular reflection can mislead algorithms to make incorrect decisions. Existing decomposition methods tend to work well for images with low specularity and high chromaticity, but they fail in cases of high intensity specular light and on images with low chromaticity. In this paper, we address the problem of removing high intensity specularity from low chromaticity images (faces). We introduce a new dataset, Spec-Face, comprising face images corrupted with specular lighting and corresponding ground truth diffuse images. We also introduce two deep learning models for specularity removal, Spec-Net and Spec-CGAN. Spec-Net takes an intensity channel as input and produces an output image that is very close to ground truth, while Spec-CGAN takes an RGB image as input and produces a diffuse image very similar to the ground truth RGB image. On Spec-Face, with Spec-Net, we obtain a peak signal-to-noise ratio (PSNR) of 3.979, a local mean squared error (LMSE) of 0.000071, a structural similarity index (SSIM) of 0.899, and a Fréchet Inception Distance (FID) of 20.932. With Spec-CGAN, we obtain a PSNR of 3.360, a LMSE of 0.000098, a SSIM of 0.707, and a FID of 31.699. With Spec-Net and Spec-CGAN, it is now feasible to perform specularity removal automatically prior to other critical complex vision processes for real world images, i.e., faces. This will potentially improve the performance of algorithms later in the processing stream, such as face recognition and skin cancer detection. © 2019 Elsevier B.V.","10.1016/j.imavis.2019.11.001","Convolutional neural networks; Deep learning; Dichromatic reflection model; Specularity","33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075884350&doi=10.1016%2fj.imavis.2019.11.001&partnerID=40&md5=ee2512ee6d68e8f8b25b5197ccc75d26"
"Dual stream network with selective optimization for skin disease recognition in consumer grade images","Gupta K.; Jaiprasad; Krishnan M.; Narayanan A.; Narayan N.S.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Skin disease localisation and classification on consumer-grade images is more challenging compared to that on dermoscopic imaging. Consumer grade images refer to the images taken using commonly available imaging devices such as a mobile camera or a hand held digital camera. Such images, in addition to having the skin condition of interest in a very small area of the image, has other noisy non-clinical details introduced due to the lighting conditions and the distance of the hand held device from the anatomy at the time of acquisition. We propose a novel deep network architecture & a new optimization strategy for classification with implicit localisation of skin diseases from clinical/consumer grade images. A weakly supervised segmentation algorithm is first employed to extract Region of Interests (RoI) from the image, the RoI and the original image form the two input streams of the proposed architecture. Each stream of the architecture learns high level and low level features from the original image and the RoI, respectively. The two streams are independently optimised until the loss stops decreasing after which both the streams are optimised collectively with the help of a third combiner sub-network. Such a strategy resulted in a 5% increase of accuracy over the current state-of-the-art methods on SD-198 dataset, which is publicly available. The proposed algorithm is also validated on a new dataset containing over 12,000 images across 75 different skin conditions. We intend to release this dataset as SkiD-75 to aid in the advancement of research on skin condition classification on consumer grade images. © 2020 IEEE","10.1109/ICPR48806.2021.9413193","Consumer grade images; Dual stream deep networks; Skin disease classification","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110442795&doi=10.1109%2fICPR48806.2021.9413193&partnerID=40&md5=023e39839381ff8a8d1cf7dfae3dc5ff"
"Pathological Changes Discover Network: Discover the Pathological Changes of Perivascular Dermatitis by Semi-supervised Learning","He X.; Fu Y.; Bao Y.; Chang J.; Xie Y.; Li W.; Zhang J.","2020","0","1","0","0","0","First occurrence","0","","","","","","","Deep learning method becomes increasingly popular in many fields, especially in computer vision area, and it is gradually being applied in the medical image area to solve medical image problems such as lesion segmentation, nucleus detection and disease classification. However, training deep learning segment models requires a lot of accurate pixel-level segmentation medical image labels, which is very hard to obtain. Lacking accurate pixel-level segmentation labels is an important factor restricting the development of deep learning method in medical image processing. In this paper, we propose a perivascular dermatitis classification network based on semi-supervised learning which is trained by image-level supervision. Our network can accurately and effectively segment the pathological changes contributed to the disease classification while classifying perivascular dermatitis. We use U-Net as the pathological change discover module to segment the pathological changes, propose the restricted boundary loss to improve the accuracy of the segmentation area boundary and introduce the pathological changes guided module to guide the pathological changes discover module to generate pathological changes contribute to the classification task. We evaluate our network on the dataset of skin pathological images with image-level classification labels. With the image-level labels of the perivascular dermatitis pathological images and normal skin pathological images, our network is trained to discover the pathological changes and classify the skin pathological images. Experiments show that our network discovers the skin pathological changes by using image-level classification labels. The perivascular dermatitis classification accuracy, AUC and PR of our network is 0.8793, 0.8954 and 0.8041. © 2020, Springer Nature Singapore Pte Ltd.","10.1007/978-981-15-5199-4_12","Deep learning; Pathological changes; Perivascular dermatitis; Semi-supervised learning","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088583412&doi=10.1007%2f978-981-15-5199-4_12&partnerID=40&md5=a6a60f9d5ec68ea1d779274a79c96890"
"LesionMap: A Method and Tool for the Semantic Annotation of Dermatological Lesions for Documentation and Machine Learning","Eapen B.R.; Archer N.; Sartipi K.","2020","0","1","0","0","0","Unique","0","","","","","","","Diagnosis and follow-up of patients in dermatology rely on visual cues. Documentation of skin lesions in dermatology is time-consuming and inaccurate. Digital photography is resource-intensive, difficult to standardize, and has privacy concerns. We propose a simple method—LesionMap—and an electronic health software tool—LesionMapper—for semantically annotating dermatological lesions on a body wireframe. We discuss how the type, distribution, and progression of lesions can be represented in a standardized way. The tool is an open-source JavaScript package that can be integrated into web-based electronic medical records. We believe that LesionMapper will facilitate documentation in dermatology that can be used for machine learning in a privacy-preserving manner. ©Bell Raj R Eapen, Norm Archer, Kamran Sartipi.","10.2196/18149","Dermatology; Digital imaging; LesionMap; LesionMapper; Machine learning","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107869804&doi=10.2196%2f18149&partnerID=40&md5=af72fd421be15b7a67a0d0e72c2b10de"
"Skin disease classification using neural network","Bajwa U.I.; Alam S.; Ul Haq N.; Ratyal N.I.; Anwar M.W.","2020","1","1","0","0","0","Unique","0","","","","","","","Background: In this study, a novel and fully automatic skin disease classification approach is proposed using statistical feature extraction and Artificial Neural Network (ANN) based classification using first and second order statistical moments, the entropy of different color channels and texture-based features. Aims: The basic aim of our study is to develop an automated system for skin disease classification that can help a general physician to automatically detect the lesion and classify it to disease types. Method: The performance of the proposed approach is corroborated by extensive experiments performed on a dataset of 588 images containing 6907 lesion regions. Results: The results show that the proposed methodology can be effectively used to construct a skin disease classification system. Conclusion: Our proposed method is designed for a specific skin tone. Future investigation is needed to analyze the impact of different skin tones on the performance of lesions detection and classification system. © 2020 Bentham Science Publishers.","10.2174/1573405615666190422152926","Artificial neural network; Classification; Lesion; Medical abnormalities; Skin disease; Ultraviolet (UV) rays","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086395513&doi=10.2174%2f1573405615666190422152926&partnerID=40&md5=934767eadac866926ed3840e091b304c"
"Applications of generative adversarial networks to dermatologic imaging","Furger F.; Amruthalingam L.; Navarini A.; Pouly M.","2020","0","1","0","0","0","First occurrence","0","","","","","","","While standard dermatological images are relatively easy to take, the availability and public release of such data sets for machine learning is notoriously limited due to medical data legal constraints, availability of field experts for annotation, numerous and sometimes rare diseases, large variance of skin pigmentation or the presence of identifying factors such as fingerprints or tattoos. With these generic issues in mind, we explore the application of Generative Adversarial Networks (GANs) to three different types of images showing full hands, skin lesions, and varying degrees of eczema. A first model generates realistic images of all three types with a focus on the technical application of data augmentation. A perceptual study conducted with laypeople confirms that generated skin images cannot be distinguished from real data. Next, we propose models to add eczema lesions to healthy skin, respectively to remove eczema from patient skin using segmentation masks in a supervised learning setting. Such models allow to leverage existing unrelated skin pictures and enable non-technical applications, e.g. in aesthetic dermatology. Finally, we combine both models for eczema addition and removal in an entirely unsupervised process based on CycleGAN without relying on ground truth annotations anymore. The source code of our experiments is available on https://github.com/furgerf/GAN-for-dermatologic-imaging. © Springer Nature Switzerland AG 2020.","10.1007/978-3-030-58309-5_15","Dermatology; Generative Adversarial Networks","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091270285&doi=10.1007%2f978-3-030-58309-5_15&partnerID=40&md5=2d5e636abc663081827a3edd70c56854"
"New local region based model for the segmentation of medical images","Badshah N.; Atta H.; Ali Shah S.I.; Attaullah S.; Minallah N.; Ullah M.","2020","0","1","0","0","0","First occurrence","0","","","","","","","Segmentation of images having inhomogeneous intensities is always challenging. In this paper, we propose a model based on new local data statistics using local means and variances for detection of region of interest in medical images suffered from intensity inhomogeneity. This is done by introducing a new probability density function based on coefficient of variation, which is a best measure for inhomogeneous data. The new energy functional in the proposed model is then expressed in terms of level set function and is minimized for optimal energy. Minimization of the energy will lead to a partial differential equation, which is solved by using well known explicit method. Results of the proposed model are compared with other state of the art models and found that the proposed model outperform other existing models. Comparison is given in both qualitative and quantitative way. Furthermore, the proposed model is tested on different type of medical images like MRI, CT, Mammogram and skin lesion etc. © 2021","10.1109/ACCESS.2020.3026143","Gaussian processes; Image segmentation; Intensity inhomogeneity; Level set method; Variational techniques","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102748507&doi=10.1109%2fACCESS.2020.3026143&partnerID=40&md5=6257e37603ce8761318d683d8cc8bd7e"
"Lung Cancer Diagnosis and Treatment Using AI and Mobile Applications","Rajesh P.; Murugan A.; Muruganantham B.; Ganesh Kumar S.","2020","0","1","0","0","0","Unique","0","","","","","","","Cancer has become very common in this evolving world. Technology advancements, increased radiations have made cancer a common syndrome. Various types of cancers like Skin Cancer, Breast Cancer, Prostate Cancer, Blood Cancer, Colorectal cancer, Kidney Cancer and Lung Cancer exits. Among these various types of cancers, the mortality rate is high in lung cancer which is tough to diagnose and can be diagnosed only in advanced stages. Small cell lung cancer and non-small cell lung cancer are the two types in which non-small cell lung cancer (NSCLC) is the most common type which makes up to 80 to 85 percent of all cases [1]. Digital Image Processing and Artificial Intelligence advancements has helped a lot in medical image analysis and Computer Aided Diagnosis (CAD). Numerous research is carried out in this field to improve the detection and prediction of the cancerous tissues. In current methods, traditional image processing techniques is applied for image processing, noise removal and feature extraction. There are few good approaches that applies Artificial Intelligence and produce better results. However, no research has achieved 100% accuracy in nodule detection, early detection of cancerous nodules nor faster processing methods. Application of Artificial Intelligence techniques like Machine Learning, Deep Learning is very minimal and limited. In this paper [Figure 1], we have applied Artificial intelligence techniques to process CT (Computed Tomography) Scan image for data collection and data model training. The DICOM image data is saved as numpy file with all medical information extracted from the files for training. With the trained data we apply deep learning for noise removal and feature extraction. We can process huge volume of medical images for data collection, image processing, detection and prediction of nodules. The patient is made well aware of the disease and enabled with their health tracking using various mobile applications made available in the online stores for iOS and Android mobile devices. © 2020. All Rights Reserved.","10.3991/ijim.v14i17.16607","Artificial intelligence; CAD; CNN; CT scan; K-means; Lung Cancer","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097441463&doi=10.3991%2fijim.v14i17.16607&partnerID=40&md5=330cae85460085751ead5da81b55d8c3"
"A Distance-Based Loss for Smooth and Continuous Skin Layer Segmentation in Optoacoustic Images","Gerl S.; Paetzold J.C.; He H.; Ezhov I.; Shit S.; Kofler F.; Bayat A.; Tetteh G.; Ntziachristos V.; Menze B.","2020","1","1","0","0","0","First occurrence","0","","","","","","","Raster-scan optoacoustic mesoscopy (RSOM) is a powerful, non-invasive optical imaging technique for functional, anatomical, and molecular skin and tissue analysis. However, both the manual and the automated analysis of such images are challenging, because the RSOM images have very low contrast, poor signal to noise ratio, and systematic overlaps between the absorption spectra of melanin and hemoglobin. Nonetheless, the segmentation of the epidermis layer is a crucial step for many downstream medical and diagnostic tasks, such as vessel segmentation or monitoring of cancer progression. We propose a novel, shape-specific loss function that overcomes discontinuous segmentations and achieves smooth segmentation surfaces while preserving the same volumetric Dice and IoU. Further, we validate our epidermis segmentation through the sensitivity of vessel segmentation. We found a 20% improvement in Dice for vessel segmentation tasks when the epidermis mask is provided as additional information to the vessel segmentation network. © 2020, Springer Nature Switzerland AG.","10.1007/978-3-030-59725-2_30","","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092792329&doi=10.1007%2f978-3-030-59725-2_30&partnerID=40&md5=3ec6956442d021b1e06ca73ebe2a43d9"
"Medical Image Recognition: An Explanation and Hands-On Example of Convolutional Networks","Ng D.; Feng M.","2020","0","1","0","0","0","First occurrence","0","","","","","","","This chapter consists of two sections. The first part covers a brief explanation of convolutional neural networks. We discuss the motivation behind using convolution in a neural network and present some of the common operations used in practice alongside with convolution. Then, we list some variations of the convolution layer and we set the guidelines as to when the types of CNN layer are used to manage certain tasks. In the latter section, we will demonstrate the application of a CNN on skin melanoma segmentation with the written approaches and steps to train our model. We provide succinct explanations and hopefully, this will give a better understanding of CNNs in the context of medical imaging. We encourage readers to follow along on their own and try the actual code available from the GitHub repository provided in the second section. © The Editor(s) (if applicable) and The Author(s) 2020.","10.1007/978-3-030-47994-7_16","CNNs; Convolutional networks; Image processing; Image segmentation; Neural networks; Skin melanoma","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151205906&doi=10.1007%2f978-3-030-47994-7_16&partnerID=40&md5=3e6005fd678b9d039cfe55d4f501645f"
"Semantic Segmentation of Histopathological Slides for the Classification of Cutaneous Lymphoma and Eczema","Scheurer J.; Ferrari C.; Berenguer Todo Bom L.; Beer M.; Kempf W.; Haug L.","2020","0","1","0","0","0","Unique","0","","","","","","","Mycosis fungoides (MF) is a rare, potentially life threatening skin disease, which in early stages clinically and histologically strongly resembles Eczema, a very common and benign skin condition. In order to increase the survival rate, one needs to provide the appropriate treatment early on. To this end, one crucial step for specialists is the evaluation of histopathological slides (glass slides), or Whole Slide Images (WSI), of the patients’ skin tissue. We introduce a deep learning aided diagnostics tool that brings a two-fold value to the decision process of pathologists. First, our algorithm accurately segments WSI into regions that are relevant for an accurate diagnosis, achieving a Mean-IoU of and a Matthews Correlation score of on a novel dataset. Additionally, we also show that our model is competitive with the state of the art on a reference dataset. Second, using the segmentation map and the original image, we are able to predict if a patient has MF or Eczema. We created two models that can be applied in different stages of the diagnostic pipeline, potentially eliminating life-threatening mistakes. The classification outcome is considerably more interpretable than using only the WSI as the input, since it is also based on the segmentation map. Our segmentation model, which we call EU-Net, extends a classical U-Net with an EfficientNet-B7 encoder which was pre-trained on the Imagenet dataset. © 2020, Springer Nature Switzerland AG.","10.1007/978-3-030-52791-4_3","Classification; Cutaneous lymphoma; Eczema; EfficientNet; Histopathological slides; Semantic segmentation; Transfer learning; U-Net","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088586858&doi=10.1007%2f978-3-030-52791-4_3&partnerID=40&md5=fe37ba0600072f016b5f6aa943c3b55e"
"3rd International Conference on Emerging Technology Trends in Electronics, Communication and Networking, ET2ECN 2020","","2020","0","1","0","0","0","Unique","0","","","","","","","The proceedings contain 23 papers. The special focus in this conference is on Emerging Technology Trends in Electronics, Communication and Networking. The topics include: A Comparative Evaluation of Low-Complexity LAS Detection Algorithm for Massive MIMO Systems; Evaluation of Gain and Noise Figure Spectrum of EDFA by Optimizing its Parameters with Different Pumping Schemes in the Scenario of WDM System; emerging Threats in Cloud Computing; reduction in Complexity of Anti-jamming with Interference Approximation and Classification Algorithm; Effect of EEG Dual-Channel Acquisition and Gender Specification Subjects on the Classification of Sleep Stages Using Machine Learning Techniques; hyperspectral Endmember Extraction Algorithm Using Convex Geometry and K-Means; Automatic Melanoma Detection System (AMDS): A State-of-the-Art Review; comparative Study of Sentiment Analysis and Text Summarization for Commercial Social Networks; an Approach for Fusion of Thermal and Visible Images; smart Automated Energy Meter; indian Sign Language Recognition Using Framework of Skin Color Detection, Viola- Jones Algorithm, Correlation-Coefficient Technique and Distance Based Neuro-Fuzzy Classification Approach; stroke Extraction of Handwritten Gujarati Consonant Using Structural Features; convolutional Neural Network Based Chest X-Ray Image Classification for Pneumonia Diagnosis; plant Leaf Disease Detection Using Machine Learning; A High Efficiency Six Phase Voltage Doubler Cell Using 180 nm CMOS Process; long Period Fiber Grating Sensors Design Optimization Using Jaya Algorithm; strategy for Designing Single Electron Transistors; experimental Study on Etching of Fiber Bragg Grating for Sensing Application; fabrication of Macro Porous Silicon Structures Using Pulsed Fiber Laser Technique for Capacitive Sensor Application; Target Tracking Using a Hybrid KF-PSO Tracking Model in WSN.","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089245005&partnerID=40&md5=db93dd47f5592c5872959fd243af724a"
"Imaging and quantifying drug delivery in skin – Part 2: Fluorescence andvibrational spectroscopic imaging methods","Pena A.-M.; Chen X.; Pence I.J.; Bornschlögl T.; Jeong S.; Grégoire S.; Luengo G.S.; Hallegot P.; Obeidy P.; Feizpour A.; Chan K.F.; Evans C.L.","2020","1","1","0","0","0","Unique","0","","","","","","","Understanding the delivery and diffusion of topically-applied drugs on human skin is of paramount importance in both pharmaceutical and cosmetics research. This information is critical in early stages of drug development and allows the identification of the most promising ingredients delivered at optimal concentrations to their target skin compartments. Different skin imaging methods, invasive and non-invasive, are available to characterize and quantify the spatiotemporal distribution of a drug within ex vivo and in vivo human skin. The first part of this review detailed invasive imaging methods (autoradiography, MALDI and SIMS). This second part reviews non-invasive imaging methods that can be applied in vivo: i) fluorescence (conventional, confocal, and multiphoton) and second harmonic generation microscopies and ii) vibrational spectroscopic imaging methods (infrared, confocal Raman, and coherent Raman scattering microscopies). Finally, a flow chart for the selection of imaging methods is presented to guide human skin ex vivo and in vivo drug delivery studies. © 2020 Elsevier B.V.","10.1016/j.addr.2020.03.003","2PEF; CARS; Confocal; Drug delivery; FLIM; Fluorescence; Human skin; IR; Multiphoton; Raman; SHG; SRS","50","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082649277&doi=10.1016%2fj.addr.2020.03.003&partnerID=40&md5=c4c1dc664d881766bb66bd3166d5f332"
"Simultaneous Estimation of X-Ray Back-Scatter and Forward-Scatter Using Multi-task Learning","Roser P.; Zhong X.; Birkhold A.; Preuhs A.; Syben C.; Hoppe E.; Strobel N.; Kowarschik M.; Fahrig R.; Maier A.","2020","0","1","0","0","0","Unique","0","","","","","","","Scattered radiation is a major concern impacting X-ray image-guided procedures in two ways. First, back-scatter significantly contributes to patient (skin) dose during complicated interventions. Second, forward-scattered radiation reduces contrast in projection images and introduces artifacts in 3-D reconstructions. While conventionally employed anti-scatter grids improve image quality by blocking X-rays, the additional attenuation due to the anti-scatter grid at the detector needs to be compensated for by a higher patient entrance dose. This also increases the room dose affecting the staff caring for the patient. For skin dose quantification, back-scatter is usually accounted for by applying pre-determined scalar back-scatter factors or linear point spread functions to a primary kerma forward projection onto a patient surface point. However, as patients come in different shapes, the generalization of conventional methods is limited. Here, we propose a novel approach combining conventional techniques with learning-based methods to simultaneously estimate the forward-scatter reaching the detector as well as the back-scatter affecting the patient skin dose. Knowing the forward-scatter, we can correct X-ray projections, while a good estimate of the back-scatter component facilitates an improved skin dose assessment. To simultaneously estimate forward-scatter as well as back-scatter, we propose a multi-task approach for joint back- and forward-scatter estimation by combining X-ray physics with neural networks. We show that, in theory, highly accurate scatter estimation in both cases is possible. In addition, we identify research directions for our multi-task framework and learning-based scatter estimation in general. © 2020, Springer Nature Switzerland AG.","10.1007/978-3-030-59713-9_20","Multi-task learning; Skin dose; X-ray scatter","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092701154&doi=10.1007%2f978-3-030-59713-9_20&partnerID=40&md5=cb7ebf502614d021cd6e6eec47c33510"
"Design of a multilayer neural network for the classification of skin ulcers' hyperspectral images: A proof of concept","Carmona Jaramillo D.; Escobar J.E.; Galeano J.; Torres-Madronero M.C.","2020","1","1","0","0","0","Unique","0","","","","","","","Cutaneous ulcer caused by Leishmaniasis is a neglected disease which is more common in low-income areas. The main challenge in this disease is its diagnosis; the lack of specialized physicians makes its diagnosis difficult since quite often it can be miss-diagnosed with other type of skin ulcers such us venous, diabetes, and others. Given the previous mentioned facts, cutaneous ulcers caused by cutaneous Leishmaniasis require for the creation of novel tools that could assist its diagnosis. Hyperspectral and multispectral images measure the radiance reflected and emitted by a surface in hundreds or tens of spectral bands along the electromagnetic spectrum. This type of systems has been used for the analysis of cutaneous pathologies such us cancer, vitiligo, melasma, among others. With a set of classified hyperspectral images of cutaneous ulcers caused by different pathologies, it is possible to create an algorithm based on a multilayer neural network in order to achieve a classification of different types of ulcers. In this article we present the design of a feed-forward artificial neural network for the classification of cutaneous ulcers' hyperspectral images in 4 kind of causes: occlusive vasculopathy, venous, Leishmaniasis, and diabetic. As result, a neural network structure is obtained that achieves a percentage of success higher than 72% in the classification of data. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","10.1117/12.2542277","Cutaneous ulcers; Diabetic ulcer; Feed-forward artificial neural network; Hyperspectral images; Leishmaniasis ulcer; Occlusive vasculopathy ulcer; Venous ulcer","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081138708&doi=10.1117%2f12.2542277&partnerID=40&md5=d8e54e7bc1cde562a1f8203fd3b9534c"
"A novel method for tissue segmentation in high-resolution H&E-stained histopathological whole-slide images","Kleczek P.; Jaworek-Korjakowska J.; Gorgon M.","2020","0","1","0","0","0","Unique","0","","","","","","","Tissue segmentation in whole-slide images is an important task in digital pathology, required for efficient and accurate computer-aided diagnostics. Precise tissue segmentation is particularly significant for a correct diagnosis in cases, when tissue structure of a specimen is very porous, such as skin specimens. In this paper, we addressed the problem of fore- and background segmentation in histopatological images of skin specimens stained with hematoxylin and eosin (H&E), which has not been solved yet, by a novel method based on a combination of statistical analysis, color thresholding, and binary morphology. We validated our algorithm on large extracts from 60 high-resolution whole slide images, with differing staining quality and captured under varying imaging conditions, from three laboratories. The size of extracts varies from 2000×1500 to 20000×30000 pixels and the number of images used in our study matches the number of H&E images used by other research teams. We compared our method to the published ones (GrabCut and FESI) and showed that our approach outperforms its counterparts (Jaccard index of 0.929 vs. 0.776 and 0.695). © 2019 The Authors","10.1016/j.compmedimag.2019.101686","hematoxylin-eosin; Histopathology; Image analysis; tissue segmentation","45","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076059979&doi=10.1016%2fj.compmedimag.2019.101686&partnerID=40&md5=b384674307558b556b0e9e62608c00c6"
"Multimodal Recognition System Based on High-Resolution Palmprints","Hussein I.S.; Sahibuddin S.B.; Nordin M.D.J.; Sjarif N.N.B.A.","2020","0","1","0","0","0","Unique","0","","","","","","","High-resolution palmprint recognition is a challenging problem due to deficiencies in images, such as poor quality, skin distortion, and unallocated images. Considering the importance of high-resolution palmprints in forensic applications, this study proposes a novel multimodal palmprint scheme that combines the left and right palmprints using feature-level fusion by exploiting the similarity between the left and right palmprints using high-resolution images. The proposed system accepts as input palmprints that were captured at 500 ppi, which is the standard in forensic applications. The system is implemented by employing a statistical gray-level co-occurrence matrix (GLCM) as the texture feature extraction algorithm. Then, the features are ranked based on their probability distribution functions (PDFs) to select the most significant features. Finally, an enhanced probabilistic neural network (PNN) is used to estimate the recognition system. The benchmark THUPALMLAB database is used to conduct experiments, the results of which demonstrate that the proposed method can yield satisfactory results. © 2013 IEEE.","10.1109/ACCESS.2020.2982048","GLCM; high-resolution palmprint; multimodal; PNN; ranking features","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082953914&doi=10.1109%2fACCESS.2020.2982048&partnerID=40&md5=e51ebddb2feac33fee13d4982d40c3d0"
"Curvelet and fast marching method-based technique for efficient artifact detection and removal in dermoscopic images","Choudhary P.; Singhai J.; Yadav J.S.","2021","0","1","0","0","0","Unique","0","","","","","","","Effective detection and removal of the artifacts from dermoscopic images require the analysis of structures within lesions for accurate cancer detection. But the dermoscopic images acquired may be affected by image acquisition noise, variation in texture, color, and irrelevant structure such as hairs, air bubbles, and contour blurring around the lesion. Hence preprocessing is very essential for accurate diagnosis. The proposed algorithm includes the preprocessing, to remove acquisition noise using curvelet transform, illumination correction using contrast limited adaptive histogram equalization (CLAHE) algorithm for image enhancement, Frangi vesselness algorithm is utilized for detection and removal of hairs and vessels like structures present in enhanced image, fast marching inpainting method is applied for repairing the information of lesion from removed hair pixels. The performance of the proposed algorithm is analyzed based on commonly used parameters such as diagnostic accuracy (DA), sensitivity (SE), specificity (SP), and precision (P). The performance is evaluated on PH2 and International Symposium on Biomedical Imaging (ISBI) datasets than compared with existing methods. The proposed algorithm segments the skin lesion with the highest diagnostic accuracy of 81.49% and sensitivity of 93.88% for the PH2 dataset and 75.39% and 79.34% respectively for the ISBI dataset. Results are better than existing methods. The proposed algorithm with improved preprocessing for artifact detection and removal is highly accurate and able to retrieve the hair occluded information. © 2021 Wiley Periodicals LLC.","10.1002/ima.22633","curvelet; fast marching method; Frangi vesselness; melanoma","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111348440&doi=10.1002%2fima.22633&partnerID=40&md5=e1e52464bf7c1dbb0e95ad784d72fa1e"
"Predicting the clinical management of skin lesions using deep learning","Abhishek K.; Kawahara J.; Hamarneh G.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Automated machine learning approaches to skin lesion diagnosis from images are approaching dermatologist-level performance. However, current machine learning approaches that suggest management decisions rely on predicting the underlying skin condition to infer a management decision without considering the variability of management decisions that may exist within a single condition. We present the first work to explore image-based prediction of clinical management decisions directly without explicitly predicting the diagnosis. In particular, we use clinical and dermoscopic images of skin lesions along with patient metadata from the Interactive Atlas of Dermoscopy dataset (1011 cases; 20 disease labels; 3 management decisions) and demonstrate that predicting management labels directly is more accurate than predicting the diagnosis and then inferring the management decision (13.73 ± 3.93 % and 6.59 ± 2.86 % improvement in overall accuracy and AUROC respectively), statistically significant at p< 0.001. Directly predicting management decisions also considerably reduces the over-excision rate as compared to management decisions inferred from diagnosis predictions (24.56% fewer cases wrongly predicted to be excised). Furthermore, we show that training a model to also simultaneously predict the seven-point criteria and the diagnosis of skin lesions yields an even higher accuracy (improvements of 4.68 ± 1.89 % and 2.24 ± 2.04 % in overall accuracy and AUROC respectively) of management predictions. Finally, we demonstrate our model’s generalizability by evaluating on the publicly available MClass-D dataset and show that our model agrees with the clinical management recommendations of 157 dermatologists as much as they agree amongst each other. © 2021, The Author(s).","10.1038/s41598-021-87064-7","","31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104089085&doi=10.1038%2fs41598-021-87064-7&partnerID=40&md5=963714c464a748b9f5b3c2afa35b42f1"
"Deep learning-based transfer learning for classification of skin cancer","Jain S.; Singhania U.; Tripathy B.; Nasr E.A.; Aboudaif M.K.; Kamrani A.K.","2021","1","1","0","0","0","First occurrence","0","","","","","","","One of the major health concerns for human society is skin cancer. When the pigments producing skin color turn carcinogenic, this disease gets contracted. A skin cancer diagnosis is a challenging process for dermatologists as many skin cancer pigments may appear similar in appearance. Hence, early detection of lesions (which form the base of skin cancer) is definitely critical and useful to completely cure the patients suffering from skin cancer. Significant progress has been made in developing automated tools for the diagnosis of skin cancer to assist dermatologists. The worldwide acceptance of artificial intelligence-supported tools has permitted usage of the enormous collection of images of lesions and benevolent sores approved by histopathology. This paper performs a comparative analysis of six different transfer learning nets for multi-class skin cancer classification by taking the HAM10000 dataset. We used replication of images of classes with low frequencies to counter the imbalance in the dataset. The transfer learning nets that were used in the analysis were VGG19, InceptionV3, InceptionResNetV2, ResNet50, Xception, and MobileNet. Results demonstrate that replication is suitable for this task, achieving high classification accuracies and F-measures with lower false negatives. It is inferred that Xception Net outperforms the rest of the transfer learning nets used for the study, with an accuracy of 90.48. It also has the highest recall, precision, and F-Measure values. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/s21238142","Artificial intelligence; CNN; Image classification; Skin lesion; Transfer learning","109","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120633708&doi=10.3390%2fs21238142&partnerID=40&md5=6e4aeb24262ff52418d95e8ef5b82a2c"
"Artificial intelligence techniques for enhanced skin lesion detection","Sengupta S.; Mittal N.; Modi M.","2021","1","1","0","0","0","First occurrence","0","","","","","","","The timely diagnosis of skin lesion diseases is highly difficult for people living in rural or far flung areas due to dearth of qualified dermatologists. However, the dermatologists can diagnose skin lesion diseases by carefully examining the high-quality images at their clinics or from a distance area. Further, the computerized automatic diagnostic system may assist primary health professionals for quick and accurate diagnosis of these skin diseases. Thus, there is a need for medical image processing and analysis of skin lesion images to enhance their visibility properties. An efficient and effective skin lesion detection and identification software tool will provide a better classification system and may enhance the automation of skin lesion diagnosis. In this work, detection of skin lesions from human skin images is conducted by utilizing three image processing segmentation methodologies namely—Edge Detection using Ant Colony Optimization, Color Space-based Thresholding, Genetic Algorithm-based Segmentation and FCM-Based Image Segmentation. In order to quantitatively collate the working of three techniques, the entropy values of skin lesion images are considered. Application of FCM-based Segmentation yields in far better attribute of skin lesion images as compared to Genetic Algorithm-based Segmentation, Edge Detection using Ant Colony Optimization and Color Space-based Thresholding. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","10.1007/s00500-021-06150-0","Ant colony optimization; Canny edge detector; Color space; Edge detection; Edge smoothing; FCM; Genetic algorithm (GA); Skin lesions; Threshold","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114052187&doi=10.1007%2fs00500-021-06150-0&partnerID=40&md5=ef5ef9a96cac433623c1c4bd165b01e5"
"Detection of malignant melanoma in H&E-stained images using deep learning techniques","Alheejawi S.; Berendt R.; Jha N.; Maity S.P.; Mandal M.","2021","0","1","0","0","0","Unique","0","","","","","","","Histopathological images are widely used to diagnose diseases including skin cancer. As digital histopathological images are typically of very large size, in the order of several billion pixels, automated identification of all abnormal cell nuclei and their distribution within multiple tissue sections would assist rapid comprehensive diagnostic assessment. In this paper, we propose a deep learning-based technique to segment the melanoma regions in Hematoxylin and Eosin (H&E) stained histopathological images. In this technique, the nuclei in the image are first segmented using a Convolutional Neural Network (CNN). The segmented nuclei are then used to generate melanoma region masks. Experimental results with a small melanoma dataset show that the proposed method can potentially segment the nuclei with more than 94 % accuracy and segment the melanoma regions with a Dice coefficient of around 85 %. The proposed technique also has a small execution time making it suitable for clinical diagnosis with a fast turnaround time. © 2021 Elsevier Ltd","10.1016/j.tice.2021.101659","Deep learning; Histopathological image analysis; Melanoma detection; Nuclear segmentation","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116903447&doi=10.1016%2fj.tice.2021.101659&partnerID=40&md5=fbac67cca07262edc2d5281fb4c61279"
"Universal adversarial attacks on deep neural networks for medical image classification","Hirano H.; Minagi A.; Takemoto K.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Background: Deep neural networks (DNNs) are widely investigated in medical image classification to achieve automated support for clinical diagnosis. It is necessary to evaluate the robustness of medical DNN tasks against adversarial attacks, as high-stake decision-making will be made based on the diagnosis. Several previous studies have considered simple adversarial attacks. However, the vulnerability of DNNs to more realistic and higher risk attacks, such as universal adversarial perturbation (UAP), which is a single perturbation that can induce DNN failure in most classification tasks has not been evaluated yet. Methods: We focus on three representative DNN-based medical image classification tasks (i.e., skin cancer, referable diabetic retinopathy, and pneumonia classifications) and investigate their vulnerability to the seven model architectures of UAPs. Results: We demonstrate that DNNs are vulnerable to both nontargeted UAPs, which cause a task failure resulting in an input being assigned an incorrect class, and to targeted UAPs, which cause the DNN to classify an input into a specific class. The almost imperceptible UAPs achieved > 80% success rates for nontargeted and targeted attacks. The vulnerability to UAPs depended very little on the model architecture. Moreover, we discovered that adversarial retraining, which is known to be an effective method for adversarial defenses, increased DNNs’ robustness against UAPs in only very few cases. Conclusion: Unlike previous assumptions, the results indicate that DNN-based clinical diagnosis is easier to deceive because of adversarial attacks. Adversaries can cause failed diagnoses at lower costs (e.g., without consideration of data distribution); moreover, they can affect the diagnosis. The effects of adversarial defenses may not be limited. Our findings emphasize that more careful consideration is required in developing DNNs for medical imaging and their practical applications. © 2020, The Author(s).","10.1186/s12880-020-00530-y","Adversarial attacks; Deep neural networks; Medical imaging; Security and privacy","123","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098887913&doi=10.1186%2fs12880-020-00530-y&partnerID=40&md5=1ef246fe2e61bc366714aa980e1eddde"
"Opportunities and Challenges: Classification of Skin Disease Based on Deep Learning","Zhang B.; Zhou X.; Luo Y.; Zhang H.; Yang H.; Ma J.; Ma L.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Deep learning has become an extremely popular method in recent years, and can be a powerful tool in complex, prior-knowledge-required areas, especially in the field of biomedicine, which is now facing the problem of inadequate medical resources. The application of deep learning in disease diagnosis has become a new research topic in dermatology. This paper aims to provide a quick review of the classification of skin disease using deep learning to summarize the characteristics of skin lesions and the status of image technology. We study the characteristics of skin disease and review the research on skin disease classification using deep learning. We analyze these studies using datasets, data processing, classification models, and evaluation criteria. We summarize the development of this field, illustrate the key steps and influencing factors of dermatological diagnosis, and identify the challenges and opportunities at this stage. Our research confirms that a skin disease recognition method based on deep learning can be superior to professional dermatologists in specific scenarios and has broad research prospects. © 2021, The Author(s).","10.1186/s10033-021-00629-5","Deep learning; Disease classification; Image method; Skin disease","53","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119847866&doi=10.1186%2fs10033-021-00629-5&partnerID=40&md5=3745885c82cd3bb5580cc10687718d34"
"AI outperformed every dermatologist in dermoscopic melanoma diagnosis, using an optimized deep-CNN architecture with custom mini-batch logic and loss function","Pham T.-C.; Luong C.-M.; Hoang V.-D.; Doucet A.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Melanoma, one of the most dangerous types of skin cancer, results in a very high mortality rate. Early detection and resection are two key points for a successful cure. Recent researches have used artificial intelligence to classify melanoma and nevus and to compare the assessment of these algorithms to that of dermatologists. However, training neural networks on an imbalanced dataset leads to imbalanced performance, the specificity is very high but the sensitivity is very low. This study proposes a method for improving melanoma prediction on an imbalanced dataset by reconstructed appropriate CNN architecture and optimized algorithms. The contributions involve three key features as custom loss function, custom mini-batch logic, and reformed fully connected layers. In the experiment, the training dataset is kept up to date including 17,302 images of melanoma and nevus which is the largest dataset by far. The model performance is compared to that of 157 dermatologists from 12 university hospitals in Germany based on the same dataset. The experimental results prove that our proposed approach outperforms all 157 dermatologists and achieves higher performance than the state-of-the-art approach with area under the curve of 94.4%, sensitivity of 85.0%, and specificity of 95.0%. Moreover, using the best threshold shows the most balanced measure compare to other researches, and is promisingly application to medical diagnosis, with sensitivity of 90.0% and specificity of 93.8%. To foster further research and allow for replicability, we made the source code and data splits of all our experiments publicly available. © 2021, The Author(s).","10.1038/s41598-021-96707-8","","69","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114166176&doi=10.1038%2fs41598-021-96707-8&partnerID=40&md5=db37c69b561df630cf1fd4074baaca7f"
"The mathematics of erythema: Development of machine learning models for artificial intelligence assisted measurement and severity scoring of radiation induced dermatitis","Ranjan R.; Partl R.; Erhart R.; Kurup N.; Schnidar H.","2021","0","1","0","0","0","Unique","0","","","","","","","Although significant advancements in computer-aided diagnostics using artificial intelligence (AI) have been made, to date, no viable method for radiation-induced skin reaction (RISR) analysis and classification is available. The objective of this single-center study was to develop machine learning and deep learning approaches using deep convolutional neural networks (CNNs) for automatic classification of RISRs according to the Common Terminology Criteria for Adverse Events (CTCAE) grading system. ScarletredⓇ Vision, a novel and state-of-the-art digital skin imaging method capable of remote monitoring and objective assessment of acute RISRs was used to convert 2D digital skin images using the CIELAB color space and conduct SEV* measurements. A set of different machine learning and deep convolutional neural network-based algorithms has been explored for the automatic classification of RISRs. A total of 2263 distinct images from 209 patients were analyzed for training and testing the machine learning and CNN algorithms. For a 2-class problem of healthy skin (grade 0) versus erythema (grade ≥ 1), all machine learning models produced an accuracy of above 70%, and the sensitivity and specificity of erythema recognition were 67–72% and 72–83%, respectively. The CNN produced a test accuracy of 74%, sensitivity of 66%, and specificity of 83% for predicting healthy and erythema cases. For the severity grade prediction of a 3-class problem (grade 0 versus 1 versus 2), the overall test accuracy was 60–67%, and the sensitivities were 56–82%, 35–59%, and 65–72%, respectively. For estimating the severity grade of each class, the CNN obtained an accuracy of 73%, 66%, and 82%, respectively. Ensemble learning combines several individual predictions to obtain a better generalization performance. Furthermore, we exploited ensemble learning by deploying a CNN model as a meta-learner. The ensemble CNN based on bagging and majority voting shows an accuracy, sensitivity and specificity of 87%, 90%, and 82% for a 2-class problem, respectively. For a 3-class problem, the ensemble CNN shows an overall accuracy of 66%, while for each grade (0, 1, and 2) accuracies were 76%, 69%, and 87%, sensitivities were 70%, 57%, and 71%, and specificities were 78%, 75%, and 95%, respectively. This study is the first to focus on erythema in radiation-dermatitis and produces benchmark results using machine learning models. The outcome of this study validates that the proposed system can act as a pre-screening and decision support tool for oncologists or patients to provide fast, reliable, and efficient assessment of erythema grading. © 2021 The Authors","10.1016/j.compbiomed.2021.104952","Artificial intelligence; Deep learning; eHealth; Erythema; Machine learning; Radiation dermatitis; Scarletred®Vision; Standardized erythema value (SEV)","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118495447&doi=10.1016%2fj.compbiomed.2021.104952&partnerID=40&md5=f90e674471ca72c649d9a1d6ca79c860"
"CMM-Net: Contextual multi-scale multi-level network for efficient biomedical image segmentation","Al-masni M.A.; Kim D.-H.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Medical image segmentation of tissue abnormalities, key organs, or blood vascular system is of great significance for any computerized diagnostic system. However, automatic segmentation in medical image analysis is a challenging task since it requires sophisticated knowledge of the target organ anatomy. This paper develops an end-to-end deep learning segmentation method called Contextual Multi-Scale Multi-Level Network (CMM-Net). The main idea is to fuse the global contextual features of multiple spatial scales at every contracting convolutional network level in the U-Net. Also, we re-exploit the dilated convolution module that enables an expansion of the receptive field with different rates depending on the size of feature maps throughout the networks. In addition, an augmented testing scheme referred to as Inversion Recovery (IR) which uses logical “OR” and “AND” operators is developed. The proposed segmentation network is evaluated on three medical imaging datasets, namely ISIC 2017 for skin lesions segmentation from dermoscopy images, DRIVE for retinal blood vessels segmentation from fundus images, and BraTS 2018 for brain gliomas segmentation from MR scans. The experimental results showed superior state-of-the-art performance with overall dice similarity coefficients of 85.78%, 80.27%, and 88.96% on the segmentation of skin lesions, retinal blood vessels, and brain tumors, respectively. The proposed CMM-Net is inherently general and could be efficiently applied as a robust tool for various medical image segmentations. © 2021, The Author(s).","10.1038/s41598-021-89686-3","","47","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105818264&doi=10.1038%2fs41598-021-89686-3&partnerID=40&md5=9bc1aaf6845cb07494d32981d29cea4c"
"Knowledge-aware deep framework for collaborative skin lesion segmentation and melanoma recognition","Wang X.; Jiang X.; Ding H.; Zhao Y.; Liu J.","2021","1","1","0","0","0","Unique","0","","","","","","","Deep learning techniques have shown their superior performance in dermatologist clinical inspection. Nevertheless, melanoma diagnosis is still a challenging task due to the difficulty of incorporating the useful dermatologist clinical knowledge into the learning process. In this paper, we propose a novel knowledge-aware deep framework that incorporates some clinical knowledge into collaborative learning of two important melanoma diagnosis tasks, i.e., skin lesion segmentation and melanoma recognition. Specifically, to exploit the knowledge of morphological expressions of the lesion region and also the periphery region for melanoma identification, a lesion-based pooling and shape extraction (LPSE) scheme is designed, which transfers the structure information obtained from skin lesion segmentation into melanoma recognition. Meanwhile, to pass the skin lesion diagnosis knowledge from melanoma recognition to skin lesion segmentation, an effective diagnosis guided feature fusion (DGFF) strategy is designed. Moreover, we propose a recursive mutual learning mechanism that further promotes the inter-task cooperation, and thus iteratively improves the joint learning capability of the model for both skin lesion segmentation and melanoma recognition. Experimental results on two publicly available skin lesion datasets show the effectiveness of the proposed method for melanoma analysis. © 2021 Elsevier Ltd","10.1016/j.patcog.2021.108075","Diagnosis guided feature fusion; Knowledge-aware deep framework; Lesion-based pooling and shape extraction; Melanoma diagnosis; Recursive mutual learning","47","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111176705&doi=10.1016%2fj.patcog.2021.108075&partnerID=40&md5=56158022afb5b1b38dcb20f5bf7e28a0"
"Bio-inspired computing-a dive into critical problems, potential architecture and techniques","Bale A.S.; Tiwari S.; Khatokar A.; Vinay N.; Kiran Mohan M.S.","2021","0","1","0","0","0","Unique","0","","","","","","","The integration and development of electronics in the recent years have impacted a major development on the world and humans, one among that is nanotechnology. Nanotechnology has achieved a greater progress in biomedical engineering in diagnosis and treatment, leading to the introduction of nanomaterials for drug delivery, prostheses and implanting. This work describes the Bio-Nano-tools that are developed based on iron oxide properties, automated tools used in the tumor detection, satin bowerbird optimization (SBO) technique employed in diagnosis of skin cancer. This work also highlights the post introduction development of nanomaterials like combination of nanotechnology with Artificial Intelligence (AI) and its impact, advancement of nanomaterials based on their operations, shapes and characteristics that leading to the growth of nanostructures with operations control properties. The paper also highlights the improvement of silicon neuromorphic photonic processors and parallel simulators in the development of bio inspired computing. We are hopeful that this review article provides future directions in Bio-Inspired Computing. © 2021, Walailak University. All rights reserved.","10.48048/tis.2021.703","Drug delivery; Efficiency; Nanomaterials; Optimization; SBO; Silicon neuromorphic photonic processors","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121599270&doi=10.48048%2ftis.2021.703&partnerID=40&md5=efef6cb77a10e055fafc527c21d0a4b6"
"Is computer-assisted tissue image analysis the future in minimally invasive surgery? A review on the current status of its applications","Tanos V.; Neofytou M.; Soliman A.S.A.; Tanos P.; Pattichis C.S.","2021","0","1","0","0","0","Unique","0","","","","","","","Purpose: Computer-assisted tissue image analysis (CATIA) enables an optical biopsy of human tissue during minimally invasive surgery and endoscopy. Thus far, it has been implemented in gastrointestinal, endometrial, and dermatologic examinations that use computational analysis and image texture feature systems. We review and evaluate the impact of in vivo optical biopsies performed by tissue image analysis on the surgeon’s diagnostic ability and sampling precision and investigate how operation complications could be minimized. Methods: We performed a literature search in PubMed, IEEE, Xplore, Elsevier, and Google Scholar, which yielded 28 relevant articles. Our literature review summarizes the available data on CATIA of human tissues and explores the possibilities of computer-assisted early disease diagnoses, including cancer. Results: Hysteroscopic image texture analysis of the endometrium successfully distinguished benign from malignant condi-tions up to 91% of the time. In dermatologic studies, the accuracy of distinguishing nevi melanoma from benign disease fluctuated from 73% to 81%. Skin biopsies of basal cell carcinoma and melanoma exhibited an accuracy of 92.4%, sensitivity of 99.1%, and specificity of 93.3% and distinguished nonmelanoma and normal lesions from benign precancerous lesions with 91.9% and 82.8% accuracy, respectively. Gastrointestinal and endometrial examinations are still at the experimental phase. Conclusions: CATIA is a promising application for distinguishing normal from abnormal tissues during endoscopic procedures and minimally invasive surgeries. However, the efficacy of computer-assisted diagnostics in distinguishing benign from malignant states is still not well documented. Prospective and randomized studies are needed before CATIA is implemented in clinical practice. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/jcm10245770","Computer-aided diagnosis l; Optical biopsies; Tissue image analysis; Tissue texture image analysis","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120809286&doi=10.3390%2fjcm10245770&partnerID=40&md5=ebcc2d399569309e17d8983e4b72547d"
"Apelin promotes blood and lymph vessel formation and the growth of melanoma lung metastasis","Berta J.; Török S.; Tárnoki-Zách J.; Drozdovszky O.; Tóvári J.; Paku S.; Kovács I.; Czirók A.; Masri B.; Megyesfalvi Z.; Oskolás H.; Malm J.; Ingvar C.; Markó-Varga G.; Döme B.; László V.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Apelin, a ligand of the APJ receptor, is overexpressed in several human cancers and plays an important role in tumor angiogenesis and growth in various experimental systems. We investigated the role of apelin signaling in the malignant behavior of cutaneous melanoma. Murine B16 and human A375 melanoma cell lines were stably transfected with apelin encoding or control vectors. Apelin overexpression significantly increased melanoma cell migration and invasion in vitro, but it had no impact on its proliferation. In our in vivo experiments, apelin significantly increased the number and size of lung metastases of murine melanoma cells. Melanoma cell proliferation rates and lymph and blood microvessel densities were significantly higher in the apelin-overexpressing pulmonary metastases. APJ inhibition by the competitive APJ antagonist MM54 significantly attenuated the in vivo pro-tumorigenic effects of apelin. Additionally, we detected significantly elevated circulating apelin and VEGF levels in patients with melanoma compared to healthy controls. Our results show that apelin promotes blood and lymphatic vascularization and the growth of pulmonary metastases of skin melanoma. Further studies are warranted to validate apelin signaling as a new potential therapeutic target in this malignancy. © 2021, The Author(s).","10.1038/s41598-021-85162-0","","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102358230&doi=10.1038%2fs41598-021-85162-0&partnerID=40&md5=8c221abeafb3cc9c525e05e4330f8e04"
"Automatic segmentation of skin cells in multiphoton data using multi-stage merging","Prinke P.; Haueisen J.; Klee S.; Rizqie M.Q.; Supriyanto E.; König K.; Breunig H.G.; Piątek Ł.","2021","1","1","0","0","0","First occurrence","0","","","","","","","We propose a novel automatic segmentation algorithm that separates the components of human skin cells from the rest of the tissue in fluorescence data of three-dimensional scans using non-invasive multiphoton tomography. The algorithm encompasses a multi-stage merging on preprocessed superpixel images to ensure independence from a single empirical global threshold. This leads to a high robustness of the segmentation considering the depth-dependent data characteristics, which include variable contrasts and cell sizes. The subsequent classification of cell cytoplasm and nuclei are based on a cell model described by a set of four features. Two novel features, a relationship between outer cell and inner nucleus (OCIN) and a stability index, were derived. The OCIN feature describes the topology of the model, while the stability index indicates segment quality in the multi-stage merging process. These two new features, combined with the local gradient magnitude and compactness, are used for the model-based fuzzy evaluation of the cell segments. We exemplify our approach on an image stack with 200 × 200 × 100 μm3, including the skin layers of the stratum spinosum and the stratum basale of a healthy volunteer. Our image processing pipeline contributes to the fully automated classification of human skin cells in multiphoton data and provides a basis for the detection of skin cancer using non-invasive optical biopsy. © 2021, The Author(s).","10.1038/s41598-021-93682-y","","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110705524&doi=10.1038%2fs41598-021-93682-y&partnerID=40&md5=0ee9f7a2a8b64dfcd4a8791bffe8804c"
"Machine learning and its application in skin cancer","Das K.; Cockerell C.J.; Patil A.; Pietkiewicz P.; Giulini M.; Grabbe S.; Goldust M.","2021","1","1","0","0","0","Unique","0","","","","","","","Artificial intelligence (AI) has wide applications in healthcare, including dermatology. Machine learning (ML) is a subfield of AI involving statistical models and algorithms that can progressively learn from data to predict the characteristics of new samples and perform a desired task. Although it has a significant role in the detection of skin cancer, dermatology skill lags behind radiology in terms of AI acceptance. With continuous spread, use, and emerging technologies, AI is becoming more widely available even to the general population. AI can be of use for the early detection of skin cancer. For example, the use of deep convolutional neural networks can help to develop a system to evaluate images of the skin to diagnose skin cancer. Early detection is key for the effective treatment and better outcomes of skin cancer. Specialists can accurately diagnose the cancer, however, considering their limited numbers, there is a need to develop automated systems that can diagnose the disease efficiently to save lives and reduce health and financial burdens on the patients. ML can be of significant use in this regard. In this article, we discuss the fundamentals of ML and its potential in assisting the diagnosis of skin cancer. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/ijerph182413409","Artificial intelligence; Machine learning; Skin cancer","115","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121400355&doi=10.3390%2fijerph182413409&partnerID=40&md5=41a4eca1a4ce77907b9ef6798ebb4d45"
"Simultaneous NAD(P)H and FAD fluorescence lifetime microscopy of long UVA–induced metabolic stress in reconstructed human skin","Ung T.P.L.; Lim S.; Solinas X.; Mahou P.; Chessel A.; Marionnet C.; Bornschlögl T.; Beaurepaire E.; Bernerd F.; Pena A.-M.; Stringari C.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Solar ultraviolet longwave UVA1 exposure of human skin has short-term consequences at cellular and molecular level, leading at long-term to photoaging. Following exposure, reactive oxygen species (ROS) are generated, inducing oxidative stress that might impair cellular metabolic activity. However, the dynamic of UVA1 impact on cellular metabolism remains unknown because of lacking adequate live imaging techniques. Here we assess the UVA1-induced metabolic stress response in reconstructed human skin with multicolor two-photon fluorescence lifetime microscopy (FLIM). Simultaneous imaging of nicotinamide adenine dinucleotide (NAD(P)H) and flavin adenine dinucleotide (FAD) by wavelength mixing allows quantifying cellular metabolism in function of NAD(P)+/NAD(P)H and FAD/FADH2 redox ratios. After UVA1 exposure, we observe an increase of fraction of bound NAD(P)H and decrease of fraction of bound FAD indicating a metabolic switch from glycolysis to oxidative phosphorylation or oxidative stress possibly correlated to ROS generation. NAD(P)H and FAD biomarkers have unique temporal dynamic and sensitivity to skin cell types and UVA1 dose. While the FAD biomarker is UVA1 dose-dependent in keratinocytes, the NAD(P)H biomarker shows no dose dependence in keratinocytes, but is directly affected after exposure in fibroblasts, thus reflecting different skin cells sensitivities to oxidative stress. Finally, we show that a sunscreen including a UVA1 filter prevents UVA1 metabolic stress response from occurring. © 2021, The Author(s).","10.1038/s41598-021-00126-8","","30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118978948&doi=10.1038%2fs41598-021-00126-8&partnerID=40&md5=2f44221ddae26fe7ce1273a1d2ab8177"
"Optimization of psoriasis assessment system based on patch images","Moon C.-I.; Lee J.; Yoo H.J.; Baek Y.S.; Lee O.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Psoriasis is a chronic inflammatory skin disease that occurs in various forms throughout the body and is associated with certain conditions such as heart disease, diabetes, and depression. The psoriasis area severity index (PASI) score, a tool used to evaluate the severity of psoriasis, is currently used in clinical trials and clinical research. The determination of severity is based on the subjective judgment of the clinician. Thus, the disease evaluation deviations are induced. Therefore, we propose optimal algorithms that can effectively segment the lesion area and classify the severity. In addition, a new dataset on psoriasis was built, including patch images of erythema and scaling. We performed psoriasis lesion segmentation and classified the disease severity. In addition, we evaluated the best-performing segmentation method and classifier and analyzed features that are highly related to the severity of psoriasis. In conclusion, we presented the optimal techniques for evaluating the severity of psoriasis. Our newly constructed dataset improved the generalization performance of psoriasis diagnosis and evaluation. It proposed an optimal system for specific evaluation indicators of the disease and a quantitative PASI scoring method. The proposed system can help to evaluate the severity of localized psoriasis more accurately. © 2021, The Author(s).","10.1038/s41598-021-97211-9","","19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114888689&doi=10.1038%2fs41598-021-97211-9&partnerID=40&md5=9929f200f3b65b40e8259e69ca55f4af"
"Lack of Transparency and Potential Bias in Artificial Intelligence Data Sets and Algorithms: A Scoping Review","Daneshjou R.; Smith M.P.; Sun M.D.; Rotemberg V.; Zou J.","2021","0","1","0","0","0","Unique","0","","","","","","","Importance: Clinical artificial intelligence (AI) algorithms have the potential to improve clinical care, but fair, generalizable algorithms depend on the clinical data on which they are trained and tested. Objective: To assess whether data sets used for training diagnostic AI algorithms addressing skin disease are adequately described and to identify potential sources of bias in these data sets. Data Sources: In this scoping review, PubMed was used to search for peer-reviewed research articles published between January 1, 2015, and November 1, 2020, with the following paired search terms: deep learning and dermatology, artificial intelligence and dermatology, deep learning and dermatologist, and artificial intelligence and dermatologist. Study Selection: Studies that developed or tested an existing deep learning algorithm for triage, diagnosis, or monitoring using clinical or dermoscopic images of skin disease were selected, and the articles were independently reviewed by 2 investigators to verify that they met selection criteria. Consensus Process: Data set audit criteria were determined by consensus of all authors after reviewing existing literature to highlight data set transparency and sources of bias. Results: A total of 70 unique studies were included. Among these studies, 1065291 images were used to develop or test AI algorithms, of which only 257372 (24.2%) were publicly available. Only 14 studies (20.0%) included descriptions of patient ethnicity or race in at least 1 data set used. Only 7 studies (10.0%) included any information about skin tone in at least 1 data set used. Thirty-six of the 56 studies developing new AI algorithms for cutaneous malignant neoplasms (64.3%) met the gold standard criteria for disease labeling. Public data sets were cited more often than private data sets, suggesting that public data sets contribute more to new development and benchmarks. Conclusions and Relevance: This scoping review identified 3 issues in data sets that are used to develop and test clinical AI algorithms for skin disease that should be addressed before clinical translation: (1) sparsity of data set characterization and lack of transparency, (2) nonstandard and unverified disease labels, and (3) inability to fully assess patient diversity used for algorithm development and testing. © 2021 American Medical Association. All rights reserved.","10.1001/jamadermatol.2021.3129","","225","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115829092&doi=10.1001%2fjamadermatol.2021.3129&partnerID=40&md5=4910fd9de52f970337634363b1897106"
"Machine learning based prediction of squamous cell carcinoma in ex vivo confocal laser scanning microscopy","Ruini C.; Schlingmann S.; Jonke Ž.; Avci P.; Padrón-Laso V.; Neumeier F.; Koveshazi I.; Ikeliani I.U.; Patzer K.; Kunrad E.; Kendziora B.; Sattler E.; French L.E.; Hartmann D.","2021","0","1","0","0","0","Unique","0","","","","","","","Image classification with convolutional neural networks (CNN) offers an unprecedented opportunity to medical imaging. Regulatory agencies in the USA and Europe have already cleared numerous deep learning/machine learning based medical devices and algorithms. While the field of radiology is on the forefront of artificial intelligence (AI) revolution, conventional pathology, which commonly relies on examination of tissue samples on a glass slide, is falling behind in leveraging this technology. On the other hand, ex vivo confocal laser scanning microscopy (ex vivo CLSM), owing to its digital workflow features, has a high potential to benefit from integrating AI tools into the assessment and decision-making process. Aim of this work was to explore a preliminary application of CNN in digitally stained ex vivo CLSM images of cutaneous squamous cell carcinoma (cSCC) for automated detection of tumor tissue. Thirty-four freshly excised tissue samples were prospectively collected and examined immediately after resection. After the histologically confirmed ex vivo CLSM diagnosis, the tumor tissue was annotated for segmentation by experts, in order to train the MobileNet CNN. The model was then trained and evaluated using cross validation. The overall sensitivity and specificity of the deep neural network for detecting cSCC and tumor free areas on ex vivo CLSM slides compared to expert evaluation were 0.76 and 0.91, respectively. The area under the ROC curve was equal to 0.90 and the area under the precision-recall curve was 0.85. The results demonstrate a high potential of deep learning models to detect cSCC regions on digitally stained ex vivo CLSM slides and to distinguish them from tumor-free skin. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/cancers13215522","Convolutional networks; Digital pathology; Digital staining; Ex vivo confocal laser scanning microscopy; Fluorescence confocal microscopy; Machine learning; Mohs surgery; Neural networks; Reflectance confocal microscopy; Squamous cell carcinoma","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118714670&doi=10.3390%2fcancers13215522&partnerID=40&md5=1129939ec44c849beecb276ef740c1a4"
"Detection of Circles as Structural Elements in Dermatoscopic Images of Skin Neoplasms in the Diagnosis of Melanoma","Nikitaev V.G.; Pronichev A.N.; Tamrazova O.B.; Sergeev V.Y.; Medvedeva O.A.; Kozlov V.S.; Solomatin M.A.","2021","1","1","0","0","0","First occurrence","0","","","","","","","A method for recognizing “circles”, significant structural elements of skin neoplasms, has been proposed. An RDS-2 dermatoscope has been used for imaging. Special software has been developed to implement the proposed method for circle recognition. The results of experimental detection of circles are presented. The developed method can be used in diagnostic systems for detecting skin melanoma, a dangerous form of cancer. © 2021, Springer Science+Business Media, LLC, part of Springer Nature.","10.1007/s10527-021-10113-y","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118651419&doi=10.1007%2fs10527-021-10113-y&partnerID=40&md5=3b9e087340c278357ed99d1898d2e004"
"Neural network classifier of hyperspectral images of skin pathologies","Vinokurov V.O.; Matveeva I.A.; Khristoforova Y.A.; Myakinin O.O.; Bratchenko I.A.; Bratchenko L.A.; Moryatov A.A.; Kozlov S.V.; Machikhin A.S.; Abdulhalim I.; Zakharov V.P.","2021","1","1","0","0","0","Unique","0","","","","","","","The paper presents results of using a neural network classifier to analyze images of malignant skin lesions obtained using a hyper-spectral camera. Using a three-block neural network of VGG architecture, we conducted the classification of a set of two-dimensional images of melanoma, papilloma and basal cell carcinoma, obtained in the range of 530 – 570 and 600 – 606 nm, characterized by the highest absorption of melanin and hemoglobin. The sufficiency of the inclusion in the training set of two-dimensional images of a limited spectral range is analyzed. The results obtained show significant prospects of using neural network algorithms for processing hyperspectral data for the classification of skin pathologies. With a relatively small set of training data used in the study, the classification accuracy for the three types of neoplasms was as high as 96 %. © 2021, Institution of Russian Academy of Sciences. All rights reserved.","10.18287/2412-6179-CO-832","Basal cell carcinoma; Hemoglobin; Hyperspectral imaging; Melanin; Melanoma; Neural network classifier; Oncopathology; VGG","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120825142&doi=10.18287%2f2412-6179-CO-832&partnerID=40&md5=39e4c2f36f824f47b8a3047457c20cb1"
"A deep-learning toolkit for visualization and interpretation of segmented medical images","Ghosal S.; Shah P.","2021","0","1","0","0","0","Unique","0","","","","","","","Generalizability of deep-learning (DL) model performance is not well understood and uses anecdotal assumptions for increasing training data to improve segmentation of medical images. We report statistical methods for visual interpretation of DL models trained using ImageNet initialization with natural-world (TII) and supervised learning with medical images (LMI) for binary segmentation of skin cancer, prostate tumors, and kidneys. An algorithm for computation of Dice scores from union and intersections of individual output masks was developed for synergistic segmentation by TII and LMI models. Stress testing with non-Gaussian distributions of infrequent clinical labels and images showed that sparsity of natural-world and domain medical images can counterintuitively reduce type I and type II errors of DL models. A toolkit of 30 TII and LMI models, code, and visual outputs of 59,967 images is shared to identify the target and non-target medical image pixels and clinical labels to explain the performance of DL models. © 2021 The Authors","10.1016/j.crmeth.2021.100107","binary segmentation; generalized deep learning; image processing; medical images; model explanation; statistics","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119341187&doi=10.1016%2fj.crmeth.2021.100107&partnerID=40&md5=9c0b90fd6fa4a60d3f0e66bdb1cf65db"
"Automatic image characterization of psoriasis lesions","Martínez-Torres J.; Piñeiro A.S.; Alesanco Á.; Pérez-Rey I.; García J.","2021","0","1","0","0","0","Unique","0","","","","","","","Psoriasis is a chronic skin disease that affects 125 million people worldwide and, par-ticularly, 2% of the Spanish population, characterized by the appearance of skin lesions due to a growth of the epidermis that is seven times larger than usual. Its diagnosis and monitoring are based on the use of methodologies for measuring the severity and extent of these spots, and this includes a large subjective component. For this reason, this paper presents an automatic method for characterizing psoriasis images that is divided into four parts: image preparation or pre-processing, feature extraction, classification of the lesions, and the obtaining of parameters. The methodology proposed in this work covers different digital-image processing techniques, namely, marker-based image delimitation, hair removal, nipple detection, lesion contour detection, areal-measurement-based lesion classification, as well as lesion characterization by means of red and white intensity. The results obtained were also endorsed by a professional dermatologist. This methodology provides professionals with a common software tool for monitoring the different existing typologies, which proved satisfactory in the cases analyzed for a set of 20 images corresponding to different types of lesions. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/math9222974","Classification; Image processing; OpenCV; Psoriasis","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119929017&doi=10.3390%2fmath9222974&partnerID=40&md5=0fedc14b3ef2d4b1f23f3608a1a0ad19"
"A Cross-Sectional Study of Nailfold Capillary Changes in Psoriasis","Santhosh P.; Riyaz N.; Bagde P.; Binitha M.P.; Sasidharanpillai S.","2021","0","1","0","0","0","Unique","0","","","","","","","Background: Microcirculation in the skin of psoriasis patients significantly differs from unaffected individuals. Vascular changes precede skin lesions and occur even in nonlesional skin. Aims: The primary aim of this work was to study the nailfold capillary changes in psoriasis patients, and to compare it with that of controls. The secondary aim of this work was to compare the nailfold capillary changes in psoriasis patients with and without nail changes. Methods: A comparative cross-sectional study of 40 psoriasis patients and 40 age and sex-matched controls analyzed the capillaries of the proximal nailfold of all fingers using a dermoscope. The mean capillary loop density/mm, tortuous capillaries, capillary hemorrhages, and avascular areas were assessed. Results: The mean nailfold capillary loop density in psoriasis (6.98 ± 0.54 per mm) was significantly less than that in controls (8.01 ± 0.61 per mm) (P < 0.001). Avascular areas in the nailfold of psoriasis patients (55%) were significantly more than the same in controls (22.5%) (P = 0.003). Of 40 psoriasis patients, 26 had nail psoriasis. Of this, 19 (73%) had avascular areas (P = 0.002). No significant association of nailfold capillary density or avascular areas with disease duration or severity was noted. An increase in tortuous capillaries and nailfold hemorrhages noted in psoriasis was not significant. Limitations: Small sample size, not having participants with psoriatic arthropathy, and lack of information on capillary diameter and capillary changes in hyponychium were the limitations. Conclusion: The reduced mean capillary loop density, and higher frequency of avascular areas noted in cases compared to controls, points to a pathogenic role for microvascular damage in psoriasis. Whether the lack of association of these changes with disease duration and severity suggests the possibility of these being early disease markers for psoriasis, needs further analysis in larger prospective studies. © 2021 Indian Dermatology Online Journal.","10.4103/idoj.IDOJ_793_20","Capillary density; Dermoscopy; Microscopic angioscopy; Nailfold capillaroscopy; Psoriasis","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122588936&doi=10.4103%2fidoj.IDOJ_793_20&partnerID=40&md5=823f2020077e86057004780dff3a7fbe"
"Design of a skin cancer diagnosing web application based on convolutional neural network model and chatterbot application programming interface","An Q.","2021","1","1","0","0","0","Unique","0","","","","","","","Skin cancer has become a great concern for people's wellness. With the popularization of machine learning, a considerable amount of data about skin cancer has been created. However, applications on the market featuring skin cancer diagnosis have barely utilized the data. In this paper, we have designed a web application to diagnose skin cancer with the CNN model and Chatterbot API. First, the application allows the user to upload an image of the user's skin. Next, a CNN model is trained with a huge amount of pre-taken images to make predictions about whether the skin is affected by skin cancer, and if the answer is yes, which kind of skin cancer the uploaded image can be classified. Last, a chatbot using the Chatterbot API is trained with hundreds of answers and questions asked and answered on the internet to interact with and give feedback to the user based on the information provided by the CNN model. The application has achieved significant performance in making classifications and has acquired the ability to interact with users. The CNN model has reached an accuracy of 0.95 in making classifications, and the chatbot can answer more than 100 questions about skin cancer. We have also done a great job on connecting the backend based on the CNN model as well as the Chatterbot API and the frontend based on the VUE Javascript framework. © 2021 Institute of Physics Publishing. All rights reserved.","10.1088/1742-6596/2078/1/012039","","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120460627&doi=10.1088%2f1742-6596%2f2078%2f1%2f012039&partnerID=40&md5=ee6cbf0e54b835fde9a27becd8246352"
"Toporesnet: A hybrid deep learning architecture and its application to skin lesion classification","Hu C.-S.; Lawson A.; Chen J.-S.; Chung Y.-M.; Smyth C.; Yang S.-M.","2021","1","1","0","0","0","Unique","0","","","","","","","The application of artificial intelligence (AI) to various medical subfields has been a popular topic of research in recent years. In particular, deep learning has been widely used and has proven effective in many cases. Topological data analysis (TDA)—a rising field at the intersection of mathematics, statistics, and computer science—offers new insights into data. In this work, we develop a novel deep learning architecture that we call TopoResNet that integrates topological information into the residual neural network architecture. To demonstrate TopoResNet, we apply it to a skin lesion classification problem. We find that TopoResNet improves the accuracy and the stability of the training process. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/math9222924","Deep learning; Hybrid models; Persistence curves; Persistence statistics; Persistent homology; Topological data analysis","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119662574&doi=10.3390%2fmath9222924&partnerID=40&md5=69e132e7bdd902cf23cc707eeb42f342"
"Multiclass skin cancer classification using ensemble of fine-tuned deep learning models","Kausar N.; Hameed A.; Sattar M.; Ashraf R.; Imran A.S.; Ul Abidin M.Z.; Ali A.","2021","1","1","0","0","0","Unique","0","","","","","","","Skin cancer is a widespread disease associated with eight diagnostic classes. The diagnosis of multiple types of skin cancer is a challenging task for dermatologists due to the similarity of skin cancer classes in phenotype. The average accuracy of multiclass skin cancer diagnosis is 62% to 80%. Therefore, the classification of skin cancer using machine learning can be beneficial in the diagnosis and treatment of the patients. Several researchers developed skin cancer classification models for binary class but could not extend the research to multiclass classification with better performance ratios. We have developed deep learning-based ensemble classification models for multiclass skin cancer classification. Experimental results proved that the individual deep learners perform better for skin cancer classification, but still the development of ensemble is a meaningful approach since it enhances the classification accuracy. Results show that the accuracy of individual learners of ResNet, InceptionV3, DenseNet, InceptionResNetV2, and VGG-19 are 72%, 91%, 91.4%, 91.7% and 91.8%, respectively. The accuracy of proposed majority voting and weighted majority voting ensemble models are 98% and 98.6%, respectively. The accuracy of proposed ensemble models is higher than the individual deep learners and the dermatologists’ diagnosis accuracy. The proposed ensemble models are compared with the recently developed skin cancer classification approaches. The results show that the proposed ensemble models outperform recently developed multiclass skin cancer classification models. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/app112210593","Classification model; Deep learning; Ensemble classifier; Ensemble models; Multiclass skin cancer; Skin cancer","56","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119257611&doi=10.3390%2fapp112210593&partnerID=40&md5=916141efd356644f96209af3105811a2"
"MBNM: Multi-branch network based on memory features for long-tailed medical image recognition","Zhang R.; E H.; Yuan L.; He J.; Zhang H.; Zhang S.; Wang Y.; Song M.; Wang L.","2021","0","1","0","0","0","Unique","0","","","","","","","Background and objectives: Deep learning algorithms show revolutionary potential in computer-aided diagnosis. These computer-aided diagnosis techniques often rely on large-scale, balanced standard datasets. However, there are many rare diseases in real clinical scenarios, which makes the medical datasets present a highly imbalanced long-tailed distribution, leading to the poor generalization ability of deep learning models. Currently, most algorithms to solve this problem involve more complex modules and loss functions. But for complicated tasks in the medical domain, usually suffer from issues such as increased inference time and unstable performance. Therefore, it is a great challenge to develop a computer-aided diagnosis algorithm for long-tailed medical data. Methods: We proposed the Multi-Branch Network based on Memory Features (MBNM) for Long-Tailed Medical Image Recognition. MBNM includes three branches, where each branch focuses on a different learning task: 1) the regular learning branch learns the generalizable feature representations; 2) the tail learning branch gains extra intra-class diversity for the tail classes through the feature memory module and the improved reverse sampler to improve the classification performance of the tail classes; 3) the fusion balance branch integrates various decision-making advantages and introduces an adaptive loss function to re-balance the classification performance of easy and difficult samples. Results: We conducted experiments on the multi-disease Ophthalmic OCT datasets with imbalance factors of 98.48 and skin image datasets Skin-7 with imbalance factors of 58.3. The Accuracy, MCR, F1-Score, Precision, and AUC of our model were significantly improved over the strong baselines in the auxiliary diagnosis scenario where the clinical medical data is extremely imbalanced. Furthermore, we demonstrated that MBNM outperforms the state-of-the-art models on the publicly available natural image datasets (CIFAR-10 and CIFAR-100). Conclusions: The proposed algorithm can solve the problem of imbalanced data distribution with little added cost. In addition, the memory module does not act in the inference phase, thereby saving inference time. And it shows outstanding performance on medical images and natural images with a variety of imbalance factors. © 2021","10.1016/j.cmpb.2021.106448","Deep learning; Fusion model; Imbalanced medical image; Memory features","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117201482&doi=10.1016%2fj.cmpb.2021.106448&partnerID=40&md5=7fb2f1f06bd41ab34a596697cd3d965f"
"Custom 3D-printed applicators for high dose-rate brachytherapy in skin cancer","Membrive Conejo I.; Pera Cegarra O.; Foro Arnalot P.; Reig Castillejo A.; Rodríguez de Dios N.; Sanz Latiesas X.; Pujol Vallverdú R.M.; Quera Jordana J.; Fernandez-Velilla Cepria E.; Algara Muñoz V.; Algara López M.","2021","1","1","0","0","0","Unique","0","","","","","","","PURPOSE: This paper describes the protocol for the development of 3D-printed custom applicators in treating skin carcinoma, the evaluation of the materials used, and the methods for segmentation and rendering of the applicators. MATERIAL AND METHODS: The segmentation and rendering process for the applicator had six phases: (i) determination of the volume of the lesion using a computed tomography (CT) scan; (ii) delineation of the patient surface, using the same CT images; (iii) creation of the applicator in the planner and segmentation of the mold; (iv) preliminary dosimetry and establishment of the route of the catheter from the brachytherapy unit; (v) creation of the 3D applicator using specialized software; and (vi) applicator printing. Following this process, the patient returned for a second CT to undergo the definitive dosimetry with the applicator in place. Radiation therapy was then administered. RESULTS: We made a total of 16 applicators. Only three applicators had to be remade, two due to an error in the infill and the other due to incorrect catheter geometry. In all cases, correct coverage of the planning target volume was achieved with the prescribed isodose. CONCLUSIONS: The creation of custom molds in plesiotherapy for skin cancer with 3D printing is feasible. Compared to manual methods, 3D printing increases precision in applicator geometry and optimization of the dosimetry. © 2021 American Brachytherapy Society","10.1016/j.brachy.2021.05.164","3D print; Brachytherapy; Plesiotherapy; Skin cancer","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113208804&doi=10.1016%2fj.brachy.2021.05.164&partnerID=40&md5=4c78b42e552ab0643ad44a05b992313e"
"Design and Assessment of Convolutional Neural Network Based Methods for Vitiligo Diagnosis","Zhang L.; Mishra S.; Zhang T.; Zhang Y.; Zhang D.; Lv Y.; Lv M.; Guan N.; Hu X.S.; Chen D.Z.; Han X.","2021","0","1","0","0","0","Unique","0","","","","","","","Background: Today's machine-learning based dermatologic research has largely focused on pigmented/non-pigmented lesions concerning skin cancers. However, studies on machine-learning-aided diagnosis of depigmented non-melanocytic lesions, which are more difficult to diagnose by unaided eye, are very few. Objective: We aim to assess the performance of deep learning methods for diagnosing vitiligo by deploying Convolutional Neural Networks (CNNs) and comparing their diagnosis accuracy with that of human raters with different levels of experience. Methods: A Chinese in-house dataset (2,876 images) and a world-wide public dataset (1,341 images) containing vitiligo and other depigmented/hypopigmented lesions were constructed. Three CNN models were trained on close-up images in both datasets. The results by the CNNs were compared with those by 14 human raters from four groups: expert raters (>10 years of experience), intermediate raters (5–10 years), dermatology residents, and general practitioners. F1 score, the area under the receiver operating characteristic curve (AUC), specificity, and sensitivity metrics were used to compare the performance of the CNNs with that of the raters. Results: For the in-house dataset, CNNs achieved a comparable F1 score (mean [standard deviation]) with expert raters (0.8864 [0.005] vs. 0.8933 [0.044]) and outperformed intermediate raters (0.7603 [0.029]), dermatology residents (0.6161 [0.068]) and general practitioners (0.4964 [0.139]). For the public dataset, CNNs achieved a higher F1 score (0.9684 [0.005]) compared to the diagnosis of expert raters (0.9221 [0.031]). Conclusion: Properly designed and trained CNNs are able to diagnose vitiligo without the aid of Wood's lamp images and outperform human raters in an experimental setting. © Copyright © 2021 Zhang, Mishra, Zhang, Zhang, Zhang, Lv, Lv, Guan, Hu, Chen and Han.","10.3389/fmed.2021.754202","deep learning; diagnosis; machine learning; skin pigmentation; vitiligo","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118346579&doi=10.3389%2ffmed.2021.754202&partnerID=40&md5=d5a1f69c0de26df9026526c200a25b74"
"A Comprehensive Survey of Deep Learning Models Based on Keras Framework","Chicho B.T.; Sallow A.B.","2021","0","1","0","0","0","Unique","0","","","","","","","Python is one of the most widely adopted programming languages, having replaced a number of those in the field. Python is popular with developers for a variety of reasons, one of which is because it has an incredibly diverse collection of libraries that users can run. The most compelling reasons for adopting Keras come from its guiding principles, particularly those related to usability. Aside from the simplicity of learning and model construction, Keras has a wide variety of production deployment options and robust support for multiple GPUs and distributed training. A strong and easy-to-use free, open-source Python library is the most important tool for developing and evaluating deep learning models. The aim of this paper is to provide the most current survey of Keras in different aspects, which is a Python-based deep learning Application Programming Interface (API) that runs on top of the machine learning framework, TensorFlow. The mentioned library is used in conjunction with TensorFlow, PyTorch, CODEEPNEATM, and Pygame to allow integration of deep learning models such as cardiovascular disease diagnostics, graph neural networks, identifying health issues, COVID-19 recognition, skin tumors, image detection, and so on, in the applied area. Furthermore, the author used Keras's details, goals, challenges, significant outcomes, and the findings obtained using this method. © Universiti Tun Hussein Onn Malaysia Publisher’s Office.","10.30880/jscdm.2021.02.02.005","Artificial Neural Network (ANN); Deep Learning (DL); Keras; Python; TensorFlow","39","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164347820&doi=10.30880%2fjscdm.2021.02.02.005&partnerID=40&md5=0134b8fba87f6a946e3a6d4ef67e7cba"
"Application of multi-classification method of skin cancer based on dermoscopic image","Chen Q.; Li M.; Chen C.; Chen C.; Lv X.","2021","1","1","0","0","0","Unique","0","","","","","","","As a kind of cancer with high incidence, skin cancer seriously threatens people's life and health. Early detection, early diagnosis, and early treatment are one of the effective ways to increase the survival rate of patients with skin diseases. Therefore, this paper used the ResNet50 model as a feature extractor based on deep learning, and combined machine learning algorithms to explore the heterogeneity among multi-type of skin cancer, and tried to construct the best performance computer-aided diagnosis model. The research first used preprocessing techniques such as hair noise removal and data enhancement, and then achieved a classification accuracy of 90.497% on the public data set of ISIC2019. The proposed model effectively relieves the huge work pressure of dermatologists, and provides a reference for the better use of dermoscopic images for intelligent diagnosis and classification of skin cancer. © 2021 ACM.","10.1145/3500931.3501005","hair noise removal; machine learning; residual network; Skin cancer","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122056598&doi=10.1145%2f3500931.3501005&partnerID=40&md5=9bab7a0bc011eb6b94a9a282040e06c7"
"Data-efficient sensor upgrade path using knowledge distillation","Van Molle P.; De Boom C.; Verbelen T.; Vankeirsbilck B.; De Vylder J.; Diricx B.; Simoens P.; Dhoedt B.","2021","0","1","0","0","0","Unique","0","","","","","","","Deep neural networks have achieved state-of-the-art performance in image classification. Due to this success, deep learning is now also being applied to other data modalities such as multispectral images, lidar and radar data. However, successfully training a deep neural network requires a large reddataset. Therefore, transitioning to a new sensor modality (e.g., from regular camera images to multispectral camera images) might result in a drop in performance, due to the limited availability of data in the new modality. This might hinder the adoption rate and time to market for new sensor technologies. In this paper, we present an approach to leverage the knowledge of a teacher network, that was trained using the original data modality, to improve the performance of a student network on a new data modality: a technique known in literature as knowledge distillation. By applying knowledge distillation to the problem of sensor transition, we can greatly speed up this process. We validate this approach using a multimodal version of the MNIST dataset. Especially when little data is available in the new modality (i.e., 10 images), training with additional teacher supervision results in increased performance, with the student network scoring a test set accuracy of 0.77, compared to an accuracy of 0.37 for the baseline. We also explore two extensions to the default method of knowledge distillation, which we evaluate on a multimodal version of the CIFAR-10 dataset: an annealing scheme for the hyperparameter α and selective knowledge distillation. Of these two, the first yields the best results. Choosing the optimal annealing scheme results in an increase in test set accuracy of 6%. Finally, we apply our method to the real-world use case of skin lesion classification. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/s21196523","Cross-modal distillation; Deep learning; Knowledge distillation; Multispectral imaging; Sensor upgrade; Skin lesion classification","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116041762&doi=10.3390%2fs21196523&partnerID=40&md5=a0d79c6dae19ed358ffdd54e2f62d303"
"Skin lesion detection algorithms in whole body images","Strzelecki M.H.; Strąkowska M.; Kozłowski M.; Urbańczyk T.; Wielowieyska-Szybińska D.; Kociołek M.","2021","1","1","0","0","0","Unique","0","","","","","","","Melanoma is one of the most lethal and rapidly growing cancers, causing many deaths each year. This cancer can be treated effectively if it is detected quickly. For this reason, many algorithms and systems have been developed to support automatic or semiautomatic detection of neo-plastic skin lesions based on the analysis of optical images of individual moles. Recently, full-body systems have gained attention because they enable the analysis of the patient’s entire body based on a set of photos. This paper presents a prototype of such a system, focusing mainly on assessing the effectiveness of algorithms developed for the detection and segmentation of lesions. Three detection algorithms (and their fusion) were analyzed, one implementing deep learning methods and two classic approaches, using local brightness distribution and a correlation method. For fusion of algorithms, detection sensitivity = 0.95 and precision = 0.94 were obtained. Moreover, the values of the selected geometric parameters of segmented lesions were calculated and compared for all algorithms. The obtained results showed a high accuracy of the evaluated parameters (error of area estimation < 10%), especially for lesions with dimensions greater than 3 mm, which are the most suspected of being neoplastic lesions. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/s21196639","Algorithm fusion; Skin lesion detection; Whole body system","27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116372068&doi=10.3390%2fs21196639&partnerID=40&md5=50dfb18c9853b294d624d6b7d8d6561f"
"Classification of squamous cell carcinoma from FF-OCT images: Data selection and progressive model construction","Ho C.-J.; Calderon-Delgado M.; Lin M.-Y.; Tjiu J.-W.; Huang S.-L.; Chen H.H.","2021","0","1","0","0","0","Unique","0","","","","","","","We investigate the speed and performance of squamous cell carcinoma (SCC) classification from full-field optical coherence tomography (FF-OCT) images based on the convolutional neural network (CNN). Due to the unique characteristics of SCC features, the high variety of CNN, and the high volume of our 3D FF-OCT dataset, progressive model construction is a time-consuming process. To address the issue, we develop a training strategy for data selection that makes model training 16 times faster by exploiting the dependency between images and the knowledge of SCC feature distribution. The speedup makes progressive model construction computationally feasible. Our approach further refines the regularization, channel attention, and optimization mechanism of SCC classifier and improves the accuracy of SCC classification to 87.12% at the image level and 90.10% at the tomogram level. The results are obtained by testing the proposed approach on an FF-OCT dataset with over one million mouse skin images. © 2021 Elsevier Ltd","10.1016/j.compmedimag.2021.101992","Convolutional neural network; Deep learning; Optical coherence tomography; Regularization; Squamous cell carcinoma; Training strategy","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116513776&doi=10.1016%2fj.compmedimag.2021.101992&partnerID=40&md5=aefaac39b7ab847e21268075e1a05a2d"
"Fuzzy segmentation and black widow–based optimal SVM for skin disease classification","Raju D.N.; Shanmugasundaram H.; Sasikumar R.","2021","1","1","0","0","0","First occurrence","0","","","","","","","The skin, which has seven layers, is the main human organ and external barrier. According to the World Health Organization (WHO), skin cancer is the fourth leading cause of non-fatal disease risk. In medicinal fields, skin disease classification is a major challenging issue due to inaccurate outputs, overfitting, larger computational cost, and so on. We presented a novel approach of support vector machine–based black widow optimization (SVM-BWO) for skin disease classification. Five different kinds of skin disease images are taken such as psoriasis, paederus, herpes, melanoma, and benign with healthy images which are chosen for this work. The pre-processing step is handled to remove the noises from the original input images. Thereafter, the novel fuzzy set segmentation algorithm subsequently segments the skin lesion region. From this, the color, gray-level co-occurrence matrix texture, and shape features are extracted for further process. Skin disease is classified with the usage of the SVM-BWO algorithm. The implementation works are handled in MATLAB-2018a, thereby the dataset images were collected from ISIC-2018 datasets. Experimentally, various kinds of performance analyses with state-of-the-art techniques are performed. Anyway, the proposed methodology outperforms better classification accuracy of 92% than other methods. Graphical abstract: [Figure not available: see fulltext.] © 2021, International Federation for Medical and Biological Engineering.","10.1007/s11517-021-02415-w","Black widow optimization; Features; Novel fuzzy set; Skin disease; Support vector machines","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113145560&doi=10.1007%2fs11517-021-02415-w&partnerID=40&md5=95ef0805e0ad7a679e1b2851c6430a55"
"A Clinical Perspective on the Automated Analysis of Reflectance Confocal Microscopy in Dermatology","Mehrabi J.N.; Baugh E.G.; Fast A.; Lentsch G.; Balu M.; Lee B.A.; Kelly K.M.","2021","0","1","0","0","0","Unique","0","","","","","","","Background and Objectives: Non-invasive optical imaging has the potential to provide a diagnosis without the need for biopsy. One such technology is reflectance confocal microscopy (RCM), which uses low power, near-infrared laser light to enable real-time in vivo visualization of superficial human skin from the epidermis down to the papillary dermis. Although RCM has great potential as a diagnostic tool, there is a need for the development of reliable image analysis programs, as acquired grayscale images can be difficult and time-consuming to visually assess. The purpose of this review is to provide a clinical perspective on the current state of artificial intelligence (AI) for the analysis and diagnostic utility of RCM imaging. Study Design/Materials and Methods: A systematic PubMed search was conducted with additional relevant literature obtained from reference lists. Results: Algorithms used for skin stratification, classification of pigmented lesions, and the quantification of photoaging were reviewed. Image segmentation, statistical methods, and machine learning techniques are among the most common methods used to analyze RCM image stacks. The poor visual contrast within RCM images and difficulty navigating image stacks were mediated by machine learning algorithms, which allowed the identification of specific skin layers. Conclusions: AI analysis of RCM images has the potential to increase the clinical utility of this emerging technology. A number of different techniques have been utilized but further refinements are necessary to allow consistent accurate assessments for diagnosis. The automated detection of skin cancers requires more development, but future applications are truly boundless, and it is compelling to envision the role that AI will have in the practice of dermatology. Lasers Surg. Med. © 2020 Wiley Periodicals LLC. © 2021 Wiley Periodicals LLC","10.1002/lsm.23376","artificial intelligence; machine learning; melanocytic lesions; photo-aging; pigmented lesions; reflectance confocal microscopy; skin stratification","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100186439&doi=10.1002%2flsm.23376&partnerID=40&md5=3ae1bb3b662463d7d83275bc388c409d"
"Skin cancer classification via convolutional neural networks: systematic review of studies involving human experts","Haggenmüller S.; Maron R.C.; Hekler A.; Utikal J.S.; Barata C.; Barnhill R.L.; Beltraminelli H.; Berking C.; Betz-Stablein B.; Blum A.; Braun S.A.; Carr R.; Combalia M.; Fernandez-Figueras M.-T.; Ferrara G.; Fraitag S.; French L.E.; Gellrich F.F.; Ghoreschi K.; Goebeler M.; Guitera P.; Haenssle H.A.; Haferkamp S.; Heinzerling L.; Heppt M.V.; Hilke F.J.; Hobelsberger S.; Krahl D.; Kutzner H.; Lallas A.; Liopyris K.; Llamas-Velasco M.; Malvehy J.; Meier F.; Müller C.S.L.; Navarini A.A.; Navarrete-Dechent C.; Perasole A.; Poch G.; Podlipnik S.; Requena L.; Rotemberg V.M.; Saggini A.; Sangueza O.P.; Santonja C.; Schadendorf D.; Schilling B.; Schlaak M.; Schlager J.G.; Sergon M.; Sondermann W.; Soyer H.P.; Starz H.; Stolz W.; Vale E.; Weyers W.; Zink A.; Krieghoff-Henning E.; Kather J.N.; von Kalle C.; Lipka D.B.; Fröhling S.; Hauschild A.; Kittler H.; Brinker T.J.","2021","1","1","0","0","0","Unique","0","","","","","","","Background: Multiple studies have compared the performance of artificial intelligence (AI)–based models for automated skin cancer classification to human experts, thus setting the cornerstone for a successful translation of AI-based tools into clinicopathological practice. Objective: The objective of the study was to systematically analyse the current state of research on reader studies involving melanoma and to assess their potential clinical relevance by evaluating three main aspects: test set characteristics (holdout/out-of-distribution data set, composition), test setting (experimental/clinical, inclusion of metadata) and representativeness of participating clinicians. Methods: PubMed, Medline and ScienceDirect were screened for peer-reviewed studies published between 2017 and 2021 and dealing with AI-based skin cancer classification involving melanoma. The search terms skin cancer classification, deep learning, convolutional neural network (CNN), melanoma (detection), digital biomarkers, histopathology and whole slide imaging were combined. Based on the search results, only studies that considered direct comparison of AI results with clinicians and had a diagnostic classification as their main objective were included. Results: A total of 19 reader studies fulfilled the inclusion criteria. Of these, 11 CNN-based approaches addressed the classification of dermoscopic images; 6 concentrated on the classification of clinical images, whereas 2 dermatopathological studies utilised digitised histopathological whole slide images. Conclusions: All 19 included studies demonstrated superior or at least equivalent performance of CNN-based classifiers compared with clinicians. However, almost all studies were conducted in highly artificial settings based exclusively on single images of the suspicious lesions. Moreover, test sets mainly consisted of holdout images and did not represent the full range of patient populations and melanoma subtypes encountered in clinical practice. © 2021 The Author(s)","10.1016/j.ejca.2021.06.049","Artificial intelligence; Convolutional neural network(s); Deep learning; Dermatology; Digital biomarkers; Machine learning; Malignant melanoma; Skin cancer classification","200","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110598997&doi=10.1016%2fj.ejca.2021.06.049&partnerID=40&md5=51cbe62048608fbf4401d8bd2c32d61a"
"Automated Extraction of Skin Wound Healing Biomarkers From In Vivo Label-Free Multiphoton Microscopy Using Convolutional Neural Networks","Jones J.D.; Rodriguez M.R.; Quinn K.P.","2021","1","1","0","0","0","Unique","0","","","","","","","Background and Objectives: Histological analysis is a gold standard technique for studying impaired skin wound healing. Label-free multiphoton microscopy (MPM) can provide natural image contrast similar to histological sections and quantitative metabolic information using NADH and FAD autofluorescence. However, MPM analysis requires time-intensive manual segmentation of specific wound tissue regions limiting the practicality and usage of the technology for monitoring wounds. The goal of this study was to train a series of convolutional neural networks (CNNs) to segment MPM images of skin wounds to automate image processing and quantification of wound geometry and metabolism. Study Design/Materials and Methods: Two CNNs with a 4-layer U-Net architecture were trained to segment unstained skin wound tissue sections and in vivo z-stacks of the wound edge. The wound section CNN used 380 distinct MPM images while the in vivo CNN used 5,848 with both image sets being randomly distributed to training, validation, and test sets following a 70%, 20%, and 10% split. The accuracy of each network was evaluated on the test set of images, and the effectiveness of automated measurement of wound geometry and optical redox ratio were compared with hand traced outputs of six unstained wound sections and 69 wound edge z-stacks from eight mice. Results: The MPM wound section CNN had an overall accuracy of 92.83%. Measurements of epidermal/dermal thickness, wound depth, wound width, and % re-epithelialization were within 10% error when evaluated on six full wound sections from days 3, 5, and 10 post-wounding that were not included in the training set. The in vivo wound z-stack CNN had an overall accuracy of 89.66% and was able to isolate the wound edge epithelium in z-stacks from eight mice across post-wound time points to quantify the optical redox ratio within 5% of what was recorded by manual segmentations. Conclusion: The CNNs trained and presented in this study can accurately segment MPM imaged wound sections and in vivo z-stacks to enable automated and rapid calculation of wound geometry and metabolism. Although MPM is a noninvasive imaging modality well suited to imaging living wound tissue, its use has been limited by time-intensive user segmentation. The use of CNNs for automated image segmentation demonstrate that it is possible for MPM to deliver near real-time quantitative readouts of tissue structure and function. Lasers Surg. Med. © 2021 Wiley Periodicals LLC. © 2021 Wiley Periodicals LLC","10.1002/lsm.23375","convolutional neural network; deep learning; in vivo; multiphoton microscopy; optical redox ratio; segmentation; wound healing","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099371131&doi=10.1002%2flsm.23375&partnerID=40&md5=e4192b726d186ccab44e511eeb85ab75"
"Imaging depth adaptive resolution enhancement for optical coherence tomography via deep neural network with external attention","Ren S.; Shen X.; Xu J.; Li L.; Qiu H.; Jia H.; Wu X.; Chen D.; Zhao S.; Yu B.; Gu Y.; Dong F.","2021","0","1","0","0","0","Unique","0","","","","","","","Optical coherence tomography (OCT) is a promising non-invasive imaging technique that owns many biomedical applications. In this paper, a deep neural network is proposed for enhancing the spatial resolution of OCT en face images. Different from the previous reports, the proposed can recover high-resolution en face images from low-resolution en face images at arbitrary imaging depth. This kind of imaging depth adaptive resolution enhancement is achieved through an external attention mechanism, which takes advantage of morphological similarity between the arbitrary-depth and full-depth en face images. Firstly, the deep feature maps are extracted by a feature extraction network from the arbitrary-depth and full-depth en face images. Secondly, the morphological similarity between the deep feature maps is extracted and utilized to emphasize the features strongly correlated to the vessel structures by using the external attention network. Finally, the SR image is recovered from the enhanced feature map through an up-sampling network. The proposed network is tested on a clinical skin OCT data set and an open-access retinal OCT dataset. The results show that the proposed external attention mechanism can suppress invalid features and enhance significant features in our tasks. For all tests, the proposed SR network outperformed the traditional image interpolation method, e.g. bi-cubic method, and the state-of-the-art image super-resolution networks, e.g. enhanced deep super-resolution network, residual channel attention network, and second-order attention network. The proposed method may increase the quantitative clinical assessment of micro-vascular diseases which is limited by OCT imaging device resolution. © 2021 Institute of Physics and Engineering in Medicine.","10.1088/1361-6560/ac2267","deep neural network; external attention; image super-resolution; optical coherence tomography; optical coherence tomography angiography","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116515919&doi=10.1088%2f1361-6560%2fac2267&partnerID=40&md5=ce458c1a1491e096120e373e62fc6017"
"Incorporating clinical knowledge with constrained classifier chain into a multimodal deep network for melanoma detection","Wang Y.; Cai J.; Louie D.C.; Wang Z.J.; Lee T.K.","2021","0","1","0","0","0","Unique","0","","","","","","","In recent years, vast developments in Computer-Aided Diagnosis (CAD) for skin diseases have generated much interest from clinicians and other eventual end-users of this technology. Introducing clinical domain knowledge to these machine learning strategies can help dispel the black box nature of these tools, strengthening clinician trust. Clinical domain knowledge also provides new information channels which can improve CAD diagnostic performance. In this paper, we propose a novel framework for malignant melanoma (MM) detection by fusing clinical images and dermoscopic images. The proposed method combines a multi-labeled deep feature extractor and clinically constrained classifier chain (CC). This allows the 7-point checklist, a clinician diagnostic algorithm, to be included in the decision level while maintaining the clinical importance of the major and minor criteria in the checklist. Our proposed framework achieved an average accuracy of 81.3% for detecting all criteria and melanoma when testing on a publicly available 7-point checklist dataset. This is the highest reported results, outperforming state-of-the-art methods in the literature by 6.4% or more. Analyses also show that the proposed system surpasses the single modality system of using either clinical images or dermoscopic images alone and the systems without adopting the approach of multi-label and clinically constrained classifier chain. Our carefully designed system demonstrates a substantial improvement over melanoma detection. By keeping the familiar major and minor criteria of the 7-point checklist and their corresponding weights, the proposed system may be more accepted by physicians as a human-interpretable CAD tool for automated melanoma detection. © 2021 Elsevier Ltd","10.1016/j.compbiomed.2021.104812","7-Point checklist; Constrained classifier chain; Melanoma detection; Multi-modality","36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114385803&doi=10.1016%2fj.compbiomed.2021.104812&partnerID=40&md5=6a2932b39351052453c79b93a311ea92"
"Variability in the histopathological diagnosis of non-melanocytic lesions excised to exclude melanoma","Katz I.; Azzi T.; Lilleyman A.; O'Brien B.; Schapiro B.; Thompson C.; Prow T.","2021","0","1","0","0","0","Unique","0","","","","","","","Introduction: The differential diagnosis of lesions excised to exclude melanoma include a variety of benign and malignant melanocytic and non-melanocytic lesions. Objectives: We examined the variability between pathologists in diagnosing non-melanocytic lesions. Methods. As part of a larger study prospectively examining the diagnosis of lesions excised to exclude melanoma in 198 patients at a primary care skin cancer clinic in Newcastle, Australia, we compared diagnosis made by 5 experienced dermatopathologists, of 44 non-melanocytic lesions in 44 patients aged 22-90. Results: Forty-four lesions (out of 217 in total) were non-melanocytic. Among the 5 pathologists who examined each case there was marked variability in the terminology used to diagnose each case. The most common variability was found between seborrheic keratosis, large cell acanthoma, solar lentigo, and lichenoid keratosis. The diagnosis made by the majority of the pathologists was deemed to be the reference diagnosis. Versus majority diagnosis, 4% of benign lesions were considered malignant, and 7% of malignant diagnoses were considered as benign. Conclusions: The different terminology adopted and lack of consensus in the diagnosis of these non-melanocytic lesions in this setting suggests that training AI systems using gold standards may be problematic. We propose a new management classification scheme called MOLEM (Management of Lesions Excised to exclude Melanoma) which expands the previously described MPATH-dx to include non-melanocytic lesions.  © 2021 Katz et al.","10.5826/dpc.1104a94","AI; Artificial intelligence; Diagnosis; Large cell acanthoma; Melanoma; Seborrheic keratosis","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119044008&doi=10.5826%2fdpc.1104a94&partnerID=40&md5=e07bae99da92465d0682f5ba04ed18d1"
"Skin lesion image retrieval using transfer learning-based approach for query-driven distance recommendation","Barhoumi W.; Khelifa A.","2021","1","1","0","0","0","Unique","0","","","","","","","Content-Based Dermatological Lesion Retrieval (CBDLR) systems retrieve similar skin lesion images, with a pathology-confirmed diagnosis, for a given query image of a skin lesion. By producing an intuitive support to both inexperienced and experienced dermatologists, the early diagnosis through CBDLR screening can significantly enhance the patients’ survival, while reducing the treatment cost. To deal with this issue, a CBDLR system is proposed in this study. This system integrates a similarity measure recommender which allows a dynamic selection of the adequate distance metric for each query image. The main contributions of this work reside in (i) the adoption of deep-learned features according to their performances for the classification of skin lesions into seven classes; and (ii) the automatic generation of ground truth that was investigated within the framework of transfer learning in order to recommend the most appropriate distance for any new query image. The proposed CBDLR system has been exhaustively evaluated using the challenging ISIC2018 and ISIC2019 datasets, and the obtained results show that the proposed system can provide a useful aided-decision while offering superior performances. Indeed, it outperforms similar CBDLR systems that adopt standard distances by at least 9% in terms of mAP@K. © 2021 Elsevier Ltd","10.1016/j.compbiomed.2021.104825","CBDLR; Deep-learned features; Similarity measure recommendation; Skin diseases; Transfer learning","29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114386623&doi=10.1016%2fj.compbiomed.2021.104825&partnerID=40&md5=0665e885fee27f81f1a9b3973abaa712"
"Artificial intelligence and obstetric ultrasound","Matsuoka R.","2021","0","1","0","0","0","Unique","0","","","","","","","Artificial intelligence (AI) technology is currently in its third era. Current AI technology is driven by machine learning (ML), particularly deep learning (DL). Deep learning is a computer technology that allows a computational model with multiple processing layers to learn the features of data. Convolutional neural networks have led to breakthroughs in the processing of images, videos, and audio. In medical imaging, computer-aided diagnosis algorithms for diabetic retinopathy, diabetic macular edema, tuberculosis, skin lesions, and colonoscopy classifiers are highly accurate and comparable to clinician performance. Although the application of AI technology in the field of ultrasound (US) has lagged behind other modalities such as radiography, computed tomography (CT), and magnetic resonance imaging (MRI), it has been rapidly applied in the field of obstetrics and gynecology in recent years. The results of AI processing of US images to determine the malignancy of ovarian tumors are comparable to the International Ovarian Tumor Analysis results, and it is now possible to identify each part of the body and calculate the estimated weight from fetal US movies. However, the application of AI to the central nervous system and especially to the fetal heart, which is the main part of fetal US morphological examination, is just beginning to progress. © Jaypee Brothers Medical Publishers. 2021 Open Access.","10.5005/jp-journals-10009-1702","Artificial intelligence; Computer-aided diagnosis; Convolutional neural network; Deep learning; Fetal ultrasound; Ovarian tumor","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116830757&doi=10.5005%2fjp-journals-10009-1702&partnerID=40&md5=2c3e1f8bef1c33709ce3141519d55f00"
"Hybrid of convolutional neural network algorithm and autoregressive integrated moving average model for skin cancer classification among Malaysian","Chin C.K.; Mat D.A.B.A.; Saleh A.Y.","2021","1","1","0","0","0","Unique","0","","","","","","","Skin cancer is a widely spreading cause of mortality among the people specifically living on or near the equatorial belt. Early detection of skin cancer significantly improves the recovery prevalence and the chance of surviving. Without the assist of computer-aided decision (CAD) system, skin cancer classification is the challenging task for the dermatologist to differentiate the type of skin cancer and provide the suitable treatment. Recently, the development of machine learning and pretrained deep neural network (DNN) shows the tremendous performance in image classification task which also provide the promising performance in medical field. However, these machine learning methods cannot get the deep features from network flow which resulting in low accuracy and the pretrained DNN has the complex network with a huge number of parameters causes the limited classification accuracy. This paper focuses on the classification of skin cancer to identify whether it is basal cell carcinoma, melanoma or squamous cell carcinoma by using the development of hybrid convolutional neural network algorithm and autoregressive integrated moving average model (CNN-ARIMA). The CNN-ARIMA model was trained and found to produce the best accuracy of 92.25%. © 2021, Institute of Advanced Engineering and Science. All rights reserved.","10.11591/ijai.v10.i3.pp707-716","ARIMA; Classification; Convolutional neural network; Deep neural network; Skin cancer","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114313617&doi=10.11591%2fijai.v10.i3.pp707-716&partnerID=40&md5=044eaf4c812eb1df99dae8341d29d2eb"
"Segmentation of dermoscopy images based on deformable 3D convolution and ResU-NeXt + +","Zhao C.; Shuai R.; Ma L.; Liu W.; Wu M.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Melanoma is one of the most dangerous skin cancers. The current melanoma segmentation is mainly based on FCNs (fully connected networks) and U-Net. Nevertheless, these two kinds of neural networks are prone to parameter redundancy, and the gradient of neural networks disappears that occurs when the neural network backpropagates as the neural network gets deeper, which will reduce the Jaccard index of the skin lesion image segmentation model. To solve the above problems and improve the survival rate of melanoma patients, an improved skin lesion segmentation model based on deformable 3D convolution and ResU-NeXt++ (D3DC- ResU-NeXt++) is proposed in this paper. The new modules in D3DC-ResU-NeXt++ can replace ordinary modules in the existing 2D convolutional neural networks (CNNs) that can be trained efficiently through standard backpropagation with high segmentation accuracy. In particular, we introduce a new data preprocessing method with dilation, crop operation, resizing, and hair removal (DCRH), which improves the Jaccard index of skin lesion image segmentation. Because rectified Adam (RAdam) does not easily fall into a local optimal solution and can converge quickly in segmentation model training, we also introduce RAdam as the training optimizer. The experiments show that our model has excellent performance on the segmentation of the ISIC2018 Task I dataset, and the Jaccard index achieves 86.84%. The proposed method improves the Jaccard index of segmentation of skin lesion images and can also assist dermatological doctors in determining and diagnosing the types of skin lesions and the boundary between lesions and normal skin, so as to improve the survival rate of skin cancer patients. Graphical abstract<!-- Query ID=""Q2"" Text="" Please check captured/presentation of ""Graphical Abstract"" caption if correct."" -->: [Figure not available: see fulltext.]. © 2021, International Federation for Medical and Biological Engineering.","10.1007/s11517-021-02397-9","Convolutional neural networks; Deformable 3D convolution; Dermoscopic images; Melanoma; ResNeXt; Skin lesion segmentation; U-Net++","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111111550&doi=10.1007%2fs11517-021-02397-9&partnerID=40&md5=20aba95c6e5380a999b91375c4f7ee39"
"Deep ensemble learning for skin lesions classification with convolutional neural network","Pratiwi R.A.; Nurmaini S.; Rini D.P.; Rachmatullah M.N.; Darmawahyuni A.","2021","1","1","0","0","0","Unique","0","","","","","","","One type of skin cancer that is considered a malignant tumor is melanoma. Such a dangerous disease can cause a lot of death in the world. The early detection of skin lesions becomes an important task in the diagnosis of skin cancer. Recently, a machine learning paradigm emerged known as deep learning (DL) utilized for skin lesions classification. However, in some previous studies by using seven class images diagnostic of skin lesions classification based on a single DL approach with CNNs architecture does not produce a satisfying performance. The DL approach allows the development of a medical image analysis system for improving performance, such as the deep convolutional neural networks (DCNNs) method. In this study, we propose an ensemble learning approach that combines three DCNNs architectures such as Inception V3, Inception ResNet V2 and DenseNet 201 for improving the performance in terms of accuracy, sensitivity, specificity, precision, and F1-score. Seven classes of dermoscopy image categories of skin lesions are utilized with 10015 dermoscopy images from well-known the HAM10000 dataset. The proposed model produces good classification performance with 97.23% accuracy, 90.12% sensitivity, 97.73% specificity, 82.01% precision, and 85.01% F1-Score. This method gives promising results in classifying skin lesions for cancer diagnosis. © 2021, Institute of Advanced Engineering and Science. All rights reserved.","10.11591/ijai.v10.i3.pp563-570","Deep convolutional neural; Ensemble learning; Melanoma; Network; Skin lesion","35","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108607392&doi=10.11591%2fijai.v10.i3.pp563-570&partnerID=40&md5=07699a930460c3adbf7dbee9c38c8015"
"Dermoscopic image classification using CNN with Handcrafted features","Sankar Raja Sekhar K.; Ranga Babu T.; Prathibha G.; Vijay K.; Chiau Ming L.","2021","0","1","0","0","0","Unique","0","","","","","","","Globally skin cancer is one of the main cause of death in humans. Early diagnosis plays a major role in increasing the prevention of death rate caused due to any kind of cancer. Conventional diagnosis of skin cancer is a tedious and time-consuming process. To overcome this an automated skin lesion classification must develop. Automated skin lesion classification is a challenging task due to the fine-grained variability in the visibility of skin lesions. In this work dermoscopic images are obtained from the International Skin Image Collaboration Archive 2016 (ISIC 2016). In the proposed method the analysis and classification of skin lesions is done with the help of a Convolution Neural Network (CNN) along with the hand crafted features of dermoscopic image using Scattered Wavelet Transform as additional input to the fully connected layer of CNN, which leads to an improvement in the accuracy for identifying Melanoma and different skin lesion classification when compared to the other state of the art methods. When raw dermoscopic image is given as an input to the CNN and feature values of segmented dermoscopic image as input to the fully connected layer as an additional information, the proposed method gives a classification accuracy of 98.13% for identification of Melanoma and the accuracy achieved for classification of skin lesions is 93.14% for Melanoma Vs Nevus, 95.4% for Seborrheic Keratosis (SK) vs Squamous Cell Carcinoma (SCC), 96.87% for Melanoma vs Seborrheic Keratosis (SK), 95.65% for Melanoma vs Basal Cell Carcinoma (BCC), 98.5% for Nevus vs Basal Cell Carcinoma(BCC). © 2021 The Authors","10.1016/j.jksus.2021.101550","Classification; CNN; Concatenation; Feature extraction; Fully connected layer; Scattered wavelet","30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112282428&doi=10.1016%2fj.jksus.2021.101550&partnerID=40&md5=be716491e9cfd9d8a73c1e99619942fc"
"Focal rank loss function with encoder-decoder network for skin lesion segmentation","Wang L.; Zhang L.; Shu X.","2021","1","1","0","0","0","Unique","0","","","","","","","Skin cancer is a major health problem as melanoma is one of the deadliest types of skin cancer and causes thousands of deaths worldwide each year. Automatic segmentation of skin lesions is considered an essential step in computer-aided diagnosis (CAD) systems for melanoma detection, which help the specialists better examine pigmented skin lesions. However, the segmentation is a challenging task due to the low contrast between each lesion and its surrounding skin tissue which makes the boundary pixels hard to classify. Besides, the class imbalance problem exists in skin lesion segmentation problem. Thus, a new hybrid loss function based on focal loss and rank loss is proposed to alleviate the class imbalance problem and the hard-easy classified pixels problem in skin lesion segmentation problem. The proposed method is evaluated on the ISIC 2017 dataset using the proposed encoder-decoder network, and the result shows the loss outperforms most methods in terms of the dice coefficient and especially the sensitivity. © Content from this work may be used under the terms of the Creative Commons Attribution 3.0 Licence.","10.1088/1742-6596/2010/1/012049","","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115062907&doi=10.1088%2f1742-6596%2f2010%2f1%2f012049&partnerID=40&md5=232e22a92a768bf60c19e7474faa1756"
"Full-Stack Application of Skin Cancer Diagnosis Based on CNN Model","Huo Y.","2021","1","1","0","0","0","Unique","0","","","","","","","Convolutional neural network (CNN) is a subset of deep neural networks, and it has commonly applied to analyze images. Skin cancer is a disease that can be observed without the help of expensive and professional instruments. At the same time, consulting a doctor in a hospital is not a cheap thing for many people. To tackle this issue, this paper introduced a skin cancer detection application based on CNN. In this application, the graphical user interface is implemented by Swift UI, and the backend is ExpressJs. It loads a keras CNN model through TensorFlow JS to detect and classify skin cancer. The CNN model used in the application is created through TensorFlow and trained with the HAM10000 skin cancer data set. It also integrated Natural Language Process (NLP) function, so that users can ask some questions and consult doctors online. The current version of this application can successfully operate in the IOS environment, and fully achieve those functions above. Also, the experimental result demonstrated that the accuracy of CNN model is around 75% for HAM10000 test set. © 2021 IEEE.","10.1109/CEI52496.2021.9574583","CNN model; IOS app; Skin cancer","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118923239&doi=10.1109%2fCEI52496.2021.9574583&partnerID=40&md5=2d0dffaa1f0c3ce87ebfcd89d0a506a0"
"Acne Vulgaris and Rosacea Skin Diseases Image Classification using Gray Level Co-Occurance Matrix and Convolutional Neural Network","Rahmad C.; Asmara R.A.; Agstriningtyas A.S.","2021","1","1","0","0","0","Unique","0","","","","","","","Teledermatology is one of the methods of dermatology treatment during the Covid-19 Pandemic which hit the world. Limiting physical contact between dermatologists and patients is a priority. This study aims to classify facial skin diseases with Rosacea and Acne Vulgaris. The disease is classified between Rosacea and three severity levels in Acne Vulgaris. The data used is taken from dermnet, kaggle and personal documentation. GLCM filters are used for feature extraction and are classified using Naïve Bayes and Convolutional Neural Network. Classification accuracy for GLCM is 45.30% and CNN Resnet-50 is 74,2424%.  © 2021 IEEE.","10.1109/IEIT53149.2021.9587363","Acne Vulgari; Classification; CNN; GLCM; Image Processing; Rosacea","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119089919&doi=10.1109%2fIEIT53149.2021.9587363&partnerID=40&md5=1a270f1eba8770fcff4608d6fc5cdbce"
"A benchmark for neural network robustness in skin cancer classification","Maron R.C.; Schlager J.G.; Haggenmüller S.; von Kalle C.; Utikal J.S.; Meier F.; Gellrich F.F.; Hobelsberger S.; Hauschild A.; French L.; Heinzerling L.; Schlaak M.; Ghoreschi K.; Hilke F.J.; Poch G.; Heppt M.V.; Berking C.; Haferkamp S.; Sondermann W.; Schadendorf D.; Schilling B.; Goebeler M.; Krieghoff-Henning E.; Hekler A.; Fröhling S.; Lipka D.B.; Kather J.N.; Brinker T.J.","2021","1","1","0","0","0","Unique","0","","","","","","","Background: One prominent application for deep learning–based classifiers is skin cancer classification on dermoscopic images. However, classifier evaluation is often limited to holdout data which can mask common shortcomings such as susceptibility to confounding factors. To increase clinical applicability, it is necessary to thoroughly evaluate such classifiers on out-of-distribution (OOD) data. Objective: The objective of the study was to establish a dermoscopic skin cancer benchmark in which classifier robustness to OOD data can be measured. Methods: Using a proprietary dermoscopic image database and a set of image transformations, we create an OOD robustness benchmark and evaluate the robustness of four different convolutional neural network (CNN) architectures on it. Results: The benchmark contains three data sets—Skin Archive Munich (SAM), SAM-corrupted (SAM-C) and SAM-perturbed (SAM-P)—and is publicly available for download. To maintain the benchmark's OOD status, ground truth labels are not provided and test results should be sent to us for assessment. The SAM data set contains 319 unmodified and biopsy-verified dermoscopic melanoma (n = 194) and nevus (n = 125) images. SAM-C and SAM-P contain images from SAM which were artificially modified to test a classifier against low-quality inputs and to measure its prediction stability over small image changes, respectively. All four CNNs showed susceptibility to corruptions and perturbations. Conclusions: This benchmark provides three data sets which allow for OOD testing of binary skin cancer classifiers. Our classifier performance confirms the shortcomings of CNNs and provides a frame of reference. Altogether, this benchmark should facilitate a more thorough evaluation process and thereby enable the development of more robust skin cancer classifiers. © 2021 The Author(s)","10.1016/j.ejca.2021.06.047","Artificial intelligence; Benchmarking; Deep learning; Dermatology; Melanoma; Nevus; Skin neoplasms","55","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110706464&doi=10.1016%2fj.ejca.2021.06.047&partnerID=40&md5=131225d3cb4e1d1b9e6635215ae8ced1"
"A study on multiple factors affecting the accuracy of multiclass skin disease classification","Fan J.; Kim J.; Jung I.; Lee Y.","2021","1","1","0","0","0","Unique","0","","","","","","","Diagnosis of skin diseases by human experts is a laborious task prone to subjective judgment. Aided by computer technology and machine learning, it is possible to improve the efficiency and robustness of skin disease classification. Deep transfer learning using off-the-shelf deep convolutional neural networks (CNNs) has huge potential in the automation of skin disease classification tasks. However, complicated architectures seem to be too heavy for the classification of only a few skin disease classes. In this paper, in order to study potential ways to improve the classification accuracy of skin diseases, multiple factors are investigated. First, two different off-the-shelf architectures, namely AlexNet and ResNet50, are evaluated. Then, approaches using either transfer learning or trained from scratch are compared. In order to reduce the complexity of the network, the effects of shortening the depths of deep CNNs are investigated. Furthermore, different data augmentation techniques based on basic image manipulation are compared. Finally, the choice of mini-batch size is studied. Experiments were carried out on the HAM10000 skin disease dataset. The results show that the ResNet50-based model is more accurate than the AlexNet-based model. The transferred knowledge from the ImageNet database helps to improve the accuracy of the model. The reduction in stages of the ResNet50-based model can reduce complexity while maintaining good accuracy. Additionally, the use of different types of data augmentation techniques and the choice of mini-batch size can also affect the classification accuracy of skin diseases. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/app11177929","Image classification; Skin diseases; Transfer learning","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114027037&doi=10.3390%2fapp11177929&partnerID=40&md5=ef0eb3bce16234f22e71c76dd44e98f2"
"Deep multi-scale attentional features for medical image segmentation","Poudel S.; Lee S.-W.","2021","0","1","0","0","0","Unique","0","","","","","","","Automatic segmentation of medical images is a difficult task in the field of computer vision owing to the various backgrounds, shapes, size, and colors of polyps or tumors. Despite the success of deep learning (DL)-based encoder–decoder architectures in medical image segmentation, these models have several disadvantages. First, an architecture such as U-Net cannot encode multi-scale semantic information at a different level on the decoder side. Second, it fails to reimpose the feature maps adeptly due to its limited capability on capturing long-range feature dependencies. In this study, we solve this problem by capturing multi-scale global feature maps, which forces the network to learn different semantic information at each scale. Further, we utilize the attention mechanism to suppress noise and the undesirable features, leading to a thorough restoration of contextual feature dependencies. Finally, we propose a novel method which leverages the compound scaled EfficientNet as a encoder backbone for efficient feature extraction and the UNet decoder to reconstruct the fine-grained details. We evaluated the proposed method using three different medical datasets: Kvasir-SEG, nuclei segmentation, and skin-lesion segmentation. The experimental results demonstrate that the proposed method takes an unassailable lead in terms of segmentation accuracy over the baseline models across different datasets and backbone architectures. Further, the proposed method strengthens the segmentation quality of varying shapes, object shapes, suppresses the noise, and leads to a better performance. © 2021 Elsevier B.V.","10.1016/j.asoc.2021.107445","Attention network; Convolutional neural networks; Image segmentation; Medical image segmentation; Multi-scale attention","49","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106282356&doi=10.1016%2fj.asoc.2021.107445&partnerID=40&md5=73034082a5eb894585995f82e603b310"
"Big transfer learning for automated skin cancer classification","Arkah Z.M.; Al-Dulaimi D.S.; Khekan A.R.","2021","1","1","0","0","0","Unique","0","","","","","","","Skin cancer is an example of the most dangerous disease. Early diagnosis of skin cancer can save many people's lives. Manual classification methods are time-consuming and costly. Deep learning has been proposed for the automated classification of skin cancer. Although deep learning showed impressive performance in several medical imaging tasks, it requires a big number of images to achieve a good performance. The skin cancer classification task suffers from providing deep learning with sufficient data due to the expensive annotation process and required experts. One of the most used solutions is transfer learning of pre-trained models of the ImageNet dataset. However, the learned features of pre-trained models are different from skin cancer image features. To end this, we introduce a novel approach of transfer learning by training the pre-trained models of the ImageNet (VGG, GoogleNet, and ResNet50) on a large number of unlabelled skin cancer images, first. We then train them on a small number of labeled skin images. Our experimental results proved that the proposed method is efficient by achieving an accuracy of 84% with ResNet50 when directly trained with a small number of labeled skin and 93.7% when trained with the proposed approach. © 2021 Institute of Advanced Engineering and Science. All rights reserved.","10.11591/ijeecs.v23.i3.pp1611-1619","CNN Deep learning Pre-trained models Skin cancer Transfer learning","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114380275&doi=10.11591%2fijeecs.v23.i3.pp1611-1619&partnerID=40&md5=1acda3cccbf6ad5eac5a9e92d2a0c91f"
"Skin characterizations by using contact capacitive imaging and high-resolution ultrasound imaging with machine learning algorithms","Chirikhina E.; Chirikhin A.; Dewsbury-Ennis S.; Bianconi F.; Xiao P.","2021","1","1","0","0","0","Unique","0","","","","","","","We present our latest research on skin characterizations by using Contact Capacitive Imaging and High-Resolution Ultrasound Imaging with Machine Learning algorithms. Contact Capacitive Imaging is a novel imaging technology based on the dielectric constant measurement principle, with which we have studied the skin water content of different skin sites and performed image classification by using pre-trained Deep Learning Neural Networks through Transfer Learning. The results show lips and nose have the lowest water content, whilst cheek, eye corner and under-eye have the highest water content. The classification yields up to 83.8% accuracy. High-Resolution Ultrasound Imaging is a state-of-the-art ultrasound technology, and can produce high-resolution images of the skin and superficial soft tissue to a vertical resolution of about 40 microns, with which we have studied the thickness of different skin layers, such as stratum corneum, epidermis and dermis, around different locations on the face and around different body parts. The results show the chin has the highest stratum corneum thickness, and the arm has the lowest stratum corneum thickness. We have also developed two feature-based image classification methods which yield promising results. The outcomes of this study could provide valuable guidelines for cosmetic/medical research, and methods developed in this study can also be extended for studying damaged skin or skin diseases. The combination of Contact Capacitive Imaging and High-Resolution Ultrasound Imaging could be a powerful tool for skin studies. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/app11188714","Capacitive imaging; High-resolution ultrasound; Machine learning; Skin image analysis; Skin texture; Skin thickness; Skin water content","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115312166&doi=10.3390%2fapp11188714&partnerID=40&md5=b864a08a1d6ef8077336101b2dcba9bb"
"Neural network classification system for pigmented skin neoplasms with preliminary hair removal in photographs","Lyakhov P.A.; Lyakhova U.A.","2021","1","1","0","0","0","Unique","0","","","","","","","The article proposes a neural network classification system for pigmented skin neoplasms with a preliminary processing stage to remove hair from the images. The main difference of the proposed system is the use of the stage of preliminary image processing to identify the location of the hair and their further removal. This stage allows you to prepare dermatoscopic images for further analysis in order to carry out automated classification and diagnosis of pigmented skin lesions. Modeling was carried out using the MatLAB R2020b software package on clinical dermatoscopic images from the international open archive ISIC Melanoma Project. The proposed system made it possible to increase the recognition accuracy of pigmented skin lesion images in 10 diagnostically important categories up to 80.81%. The use of the proposed system for the recognition and classification of images of dermatoscopic pigmented lesions by specialists will make it possible to increase the diagnostic efficiency in comparison with methods of visual diagnosis, and will also allow starting treatment at an earlier stage of the disease, which directly affects the survival and recovery rates for patients. © 2021, Institution of Russian Academy of Sciences. All rights reserved.","10.18287/2412-6179-CO-863","Convolutional neural networks; Dermatoscopic images; Digital image processing; Hair removal; Melanoma; Pigmented skin lesions","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115794416&doi=10.18287%2f2412-6179-CO-863&partnerID=40&md5=d337e052ce05333253ae6c69afab2448"
"Quantitative Assessment of Age-dependent Changes in Porphyrins from Fluorescence Images of Ultraviolet Photography by Image Processing","Wu Y.; Akimoto M.; Igarashi H.; Shibagaki Y.; Tanaka T.","2021","0","1","0","0","0","Unique","0","","","","","","","Background: Skin is the first line of defense against harmful external environmental factors. Skin flora living on the skin surface impact skin health and skin disease. Bacteria, form part of the unique and complex skin micro-ecological system. For example, Propionibacterium acnes (P. acnes) is a member of the anaerobic organisms and is involved in the induction of skin acne. It produces porphyrins that absorb ultraviolet light and emit red fluorescence in response. As a result, fluorescence surveillance of the skin can be important in both the diagnosis of skin acne and the evaluation of therapeutic effects. Many different measurement methods for single skin biophysical properties have been reported. This study focused on the age-dependent changes in porphyrins for normal skin, and developed a novel algorithm to evaluate porphyrins using the fluorescence images by image processing quantitatively. Materials and methods: An extraction algorithm was proposed for the segmentation of porphyrin fluorescence images in OpenCV. The algorithm consisted primarily of preprocessing, conversion from RGB color space to HSV color space, and classification of fluorescence. There are 3595 healthy Japanese aged 16–85 years enrolled in the study and fluorescence images were acquired from their cheek sites under 375 nm UV-LED excitation. Age-related fluorescence variation was conducted applying the algorithm implemented. Results: A new extraction algorithm has been proposed with fluorescence image input and three indexes output, including the number of fluorescence, area of fluorescence, and mean intensity of fluorescence. Proposed algorithm was verified by three parameters, the accuracy, sensitivity, and precision, which refer to the ability of algorithm to detect the number of fluorescence correctly and repeatedly. The verification results were 71%, 72%, and 88% respectively, taking a validly fundamental step for skin health record and analysis. Furthermore, large-scale fluorescence image segmentation results revealed that similar trends were coming out for all three indexes in cheek as people get older. All the fluorescence number, area and mean intensity arrived at the highest at 30 years old and fell off since then. Conclusion: The number, area, and fluorescence intensity of porphyrins can be extracted well from fluorescence images with the proposed algorithm in the study, which has the potential to aid in thediagnosis of skin acne and predict skin conditions as an assisted tool. It is implicated that fluorescence status is influenced by age, which rises to the peak around 30 years old for normal cheek's skin. © 2021 The Author(s)","10.1016/j.pdpdt.2021.102388","Age; HSV color model; Image processing; P. acnes; Porphyrin; Portable device","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108418635&doi=10.1016%2fj.pdpdt.2021.102388&partnerID=40&md5=60cea2107e66eab6178f5a120ba2e7ba"
"Skin Melanoma Detection in Microscopic Images Using HMM-Based Asymmetric Analysis and Expectation Maximization","Rastghalam R.; Danyali H.; Helfroush M.S.; Celebi M.E.; Mokhtari M.","2021","1","1","0","0","0","Unique","0","","","","","","","Melanoma is one of the deadliest types of skin cancer with increasing incidence. The most definitive diagnosis method is the histopathological examination of the tissue sample. In this paper, a melanoma detection algorithm is proposed based on decision-level fusion and a Hidden Markov Model (HMM), whose parameters are optimized using Expectation Maximization (EM) and asymmetric analysis. The texture heterogeneity of the samples is determined using asymmetric analysis. A fusion-based HMM classifier trained using EM is introduced. For this purpose, a novel texture feature is extracted based on two local binary patterns, namely local difference pattern (LDP) and statistical histogram features of the microscopic image. Extensive experiments demonstrate that the proposed melanoma detection algorithm yields a total error of less than 0.04%. © 2013 IEEE.","10.1109/JBHI.2021.3081185","Decision-level fusion; Hidden Markov Model-based EM; Local Binary Pattern; Melanoma","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107200036&doi=10.1109%2fJBHI.2021.3081185&partnerID=40&md5=2751ddb245b73b1a99cb27ddbb32200f"
"Assessment of Segmentation Impact on Melanoma Classification Using Convolutional Neural Networks","Deng Q.; Beltran J.C.C.; Lee D.","2021","0","1","0","0","0","Unique","0","","","","","","","Among the different types of skin cancer, melanoma is the one with the highest death rate. Therefore, the early detection of melanoma and the development of technologies that can assist in this task have become significantly important. Convolutional neural networks are one of the most popular skin cancer classification methods. However, most of the available skin cancer datasets include images with lesions that are hard to differentiate from healthy skin or with a high presence of hair that can occlude the lesion. This characteristics of the images makes it harder to extract lesion features. Therefore, utilizing segmentation to extract the lesion location is an important step to reduce hair noise and improve lesion analysis. In this paper, two combining methods for segmentation and classification were explored: concatenation and multiplication. By utilizing these methods, it was possible to improve the accuracy of different neural network architectures by around 1% when compared to unmodified models without segmentation. The best-performing model was selected for further training. This model in conjunction with the segmentation module allowed for the correct re-classification of around 10% of the total examples in the dataset, indicating that a segmentation phase leads to an overall accuracy improvement and suggested that by improving the segmentation, an improvement on the overall accuracy can be obtained. © 2021. The Korean Institute of Information Scientists and Engineers.","10.5626/JCSE.2021.15.3.115","Medical image segmentation; Melanoma classification; Skin cancer","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118673910&doi=10.5626%2fJCSE.2021.15.3.115&partnerID=40&md5=15149146b89af4028037c73801a93aff"
"Machine learning and deep learning methods for skin lesion classification and diagnosis: A systematic review","Kassem M.A.; Hosny K.M.; Damaševičius R.; Eltoukhy M.M.","2021","1","1","0","0","0","Unique","0","","","","","","","Computer-aided systems for skin lesion diagnosis is a growing area of research. Recently, researchers have shown an increasing interest in developing computer-aided diagnosis systems. This paper aims to review, synthesize and evaluate the quality of evidence for the diagnostic accuracy of computer-aided systems. This study discusses the papers published in the last five years in ScienceDirect, IEEE, and SpringerLink databases. It includes 53 articles using traditional machine learning methods and 49 articles using deep learning methods. The studies are compared based on their contributions, the methods used and the achieved results. The work identified the main challenges of evaluating skin lesion segmentation and classification methods such as small datasets, ad hoc image selection and racial bias. © 2021 by the authors.","10.3390/diagnostics11081390","Deep learning; Machine learning; Racial bias; Skin image segmentation; Skin lesion classification; Small data","188","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113216625&doi=10.3390%2fdiagnostics11081390&partnerID=40&md5=689e8435def586380b5de9a40b8d719e"
"Leveraging Latent Features for Local Explanations","Luss R.; Chen P.-Y.; Dhurandhar A.; Sattigeri P.; Zhang Y.; Shanmugam K.; Tu C.-C.","2021","0","1","0","0","0","First occurrence","0","","","","","","","As the application of deep neural networks proliferates in numerous areas such as medical imaging, video surveillance, and self driving cars, the need for explaining the decisions of these models has become a hot research topic, both at the global and local level. Locally, most explanation methods have focused on identifying relevance of features, limiting the types of explanations possible. In this paper, we investigate a new direction by leveraging latent features to generate contrastive explanations; predictions are explained not only by highlighting aspects that are in themselves sufficient to justify the classification, but also by new aspects which if added will change the classification. The key contribution of this paper lies in how we add features to rich data in a formal yet humanly interpretable way that leads to meaningful results. Our new definition of ""addition""uses latent features to move beyond the limitations of previous explanations and resolve an open question laid out in Dhurandhar, et. al. (2018), which creates local contrastive explanations but is limited to simple datasets such as grayscale images. The strength of our approach in creating intuitive explanations that are also quantitatively superior to other methods is demonstrated on three diverse image datasets (skin lesions, faces, and fashion apparel). A user study with 200 participants further exemplifies the benefits of contrastive information, which can be viewed as complementary to other state-of-the-art interpretability methods. © 2021 ACM.","10.1145/3447548.3467265","deep learning; explainability","30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113300033&doi=10.1145%2f3447548.3467265&partnerID=40&md5=f725669b54373d56a37d58b58cf67f6b"
"Disease detection platform using image processing through OpenCV","Faujdar N.; Sinha A.","2021","0","1","0","0","0","Unique","0","","","","","","","Presently, methods accessible for Glaucoma detection revolve around the usage of devices such as Digital Single-Lens Reflex (DSLR) camera, and these are extremely pricey. Same are the instances for eye and skin cancer. Apart from the fact that these are costly methods, they are also inaccessible to a majority of people. Thus, the main objective behind this chapter is to design useful and effective algorithms that, in turn, shall prove to be robust and cost-effective too. We strive to enroot algorithms that are capable of running on the required devices so that the disease detection platform can be widened, thereafter enabling us to take necessary actions. Taking into consideration cataract, the screening can be efficiently done using the proposed algorithm that focuses on analysis based on texture features like uniformity, standard deviation, and intensity. Similarly, retinoblastoma cancer can be detected via the automatized detection technique for immature cells in the retina. The idea is to encapsulate an image processing algorithm that, in turn, would be helpful for detection of white radius of retina with the help of image filtering, canny edge detection, and thresholding. These techniques of image processing have simplified the diagnosis of iris tumor. Melanoma is yet another disease that we aim to efficiently detect. Pre-processing of clinical images in order to deal with illumination and noise effects is an important step to achieve the goal. Thereafter, these enhanced images are served as input to image analysis algorithms for further identification and classification. © 2021 Scrivener Publishing LLC. All rights reserved.","10.1002/9781119785750.ch8","Cataract; Gaussian filter; Image processing; Melanoma; Pre-processing; Retinoblastoma; Segmenting; Standard deviation","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136960923&doi=10.1002%2f9781119785750.ch8&partnerID=40&md5=6dc3e978bac69ad86f0f9a8f630c6191"
"Artificial intelligence in diagnosing skin diseases; [Kunstig intelligens til diagnostik af hudsygdomme]","Thomsen K.; Pihl A.; Iversen L.; Winther O.; Lomholt H.B.; Thomsen S.F.","2021","1","1","0","0","0","Unique","0","","","","","","","Dermatology is a visual speciality suited for implementation of computer-aided diagnostic (CAD) systems as summarised in this review. There has been great progress in CAD melanoma detection, whereas the detection of multiple lesion skin diseases has proved more difficult. We need data on clinical implementation of CAD systems in order to know, how data from studies can be extrapolated to real-world clinical settings. Good clinical test designs and common standards for reporting and monitoring efficacy are needed. Implementation of CAD in the best possible way will be a challenge for health systems and clinicians in the coming years. © 2021","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126987085&partnerID=40&md5=ca54013c9c7535ba1ac11789f47e75c3"
"An Automated Hybrid Approach for Multimodal Tumor Segmentation","Sumathi R.; Venkatesulu M.","2021","0","1","0","0","0","Unique","0","","","","","","","For the past few years many people in the entire universe lost their lives due to cancer diseases like breast cancer, brain tumor, lung cancer and skin cancer etc. Many modalities like US, mammogram, CT are used to analyze the masses of cancer but its radiation effects the health for this reason MRI imaging is used for analyzing the anatomy behavior of tumors in terms of size of tumor, growth and location in detail. An automated hybrid approach with adaptive kernel fuzzy C Means with PSO is used to segment the tumor part in efficient manner. Using BRATS and RIDER MRI datasets are used for validation. Our proposed methods yields 97.1% segmentation accuracy and compared with various existing approaches like K Means and Adaptive K Means.  © Published under licence by IOP Publishing Ltd.","10.1088/1742-6596/1979/1/012047","Adaptive kernel fuzzy c means; Evaluation metrics; Image segmentation; Pso optimization","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112406065&doi=10.1088%2f1742-6596%2f1979%2f1%2f012047&partnerID=40&md5=35f6e95b6e8387b3fecca00c1a200f04"
"Multiscale ensemble of convolutional neural networks for skin lesion classification","Liu Y.-P.; Wang Z.; Li Z.; Li J.; Li T.; Chen P.; Liang R.","2021","1","1","0","0","0","Unique","0","","","","","","","Early detection and treatment of skin cancer can considerably reduce the patient mortality rates. Convolutional neural network (CNN) has been widely applied in the field of computer aided diagnosis. However, for skin lesions, the inconsistent size of lesion regions in dermatoscope images hinders the convolutional neural network precise discrimination. To solve this problem, multiscale ensemble of convolutional neural networks called MECNN is proposed, which involves three branches with different lesion scales as the model input. The first branch locates the lesion region outline by identifying the largest local response point. Then, MECNN reduces the search area of the lesion region and divides the outline into two scales used as the input for the other two branches. A global loss function is defined to control the learning objectives of the three branches and MECNN fuses the branches output as the final classification result. The proposed model is evaluated on the public HAM10000 dataset and achieves a higher classification accuracy than the comparative state-of-the-art methods. © 2021 The Authors. IET Image Processing published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology","10.1049/ipr2.12214","","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103961966&doi=10.1049%2fipr2.12214&partnerID=40&md5=15278b71c04c1e79366d4d618ad162fd"
"Computer-aided diagnosis algorithm for classification of malignant melanoma using deep neural networks","Kim C.-I.; Hwang S.-M.; Park E.-B.; Won C.-H.; Lee J.-H.","2021","0","1","0","0","0","Unique","0","","","","","","","Malignant melanoma accounts for about 1–3% of all malignancies in the West, especially in the United States. More than 9000 people die each year. In general, it is difficult to characterize a skin lesion from a photograph. In this paper, we propose a deep learning-based computer-aided diagnostic algorithm for the classification of malignant melanoma and benign skin tumors from RGB channel skin images. The proposed deep learning model constitutes a tumor lesion segmentation model and a classification model of malignant melanoma. First, U-Net was used to classify skin lesions in dermoscopy images. We implement an algorithm to classify malignant melanoma and benign tumors using skin lesion images and expert labeling results from convolutional neural networks. The U-Net model achieved a dice similarity coefficient of 81.1% compared to the expert labeling results. The classification accuracy of malignant melanoma reached 80.06%. As a result, the proposed AI algorithm is expected to be utilized as a computer-aided diagnostic algorithm to help early detection of malignant melanoma. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/s21165551","Computer aided diagnosis; Convolutional neural network; Malanoma","19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113151824&doi=10.3390%2fs21165551&partnerID=40&md5=7dfe818e247a96c6b5aa051523a44290"
"Generating Knowledge-Guided Discriminative Features Using Genetic Programming for Melanoma Detection","Ain Q.U.; Al-Sahaf H.; Xue B.; Zhang M.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Melanoma is the deadliest form of skin cancer that causes around 75% of deaths worldwide. However, most of the skin cancers can be cured, especially if detected and treated early. Existing approaches have employed various feature extraction methods, where different types of features are used individually for skin image classification which may not provide sufficient information to the classification algorithm necessary to discriminate between classes, leading to sub-optimal performance. This study develops a novel skin image classification method using multi-tree genetic programming (GP). To capture local information from gray and color skin images, Local Binary Pattern is used in this work. In addition, for capturing global information, variation in color within the lesion and the skin regions, and domain-specific lesion border shape features are extracted. GP with a multi-tree representation is employed to use multiple types of features. Genetic operators such as crossover and mutation are designed accordingly in order to select a single type of features at terminals in one tree of the GP individual. The performance of the proposed method is assessed using two skin image datasets having images captured from multiple modalities, and compared with six most commonly used classification algorithms as well as the standard (single-tree) wrapper and embedded GP methods. The results show that the proposed method has significantly outperformed all these classification methods. Being interpretable and fast in terms of the computation time, this method can help dermatologist identify prominent skin image features, specific to a type of skin cancer in real-time situations. © 2017 IEEE.","10.1109/TETCI.2020.2983426","feature construction; feature selection; Genetic programming; image classification; melanoma detection","46","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111140209&doi=10.1109%2fTETCI.2020.2983426&partnerID=40&md5=27d100b48481b35a640af667e8e511bc"
"Uncertainty quantification in skin cancer classification using three-way decision-based Bayesian deep learning","Abdar M.; Samami M.; Dehghani Mahmoodabad S.; Doan T.; Mazoure B.; Hashemifesharaki R.; Liu L.; Khosravi A.; Acharya U.R.; Makarenkov V.; Nahavandi S.","2021","1","1","0","0","0","Unique","0","","","","","","","Accurate automated medical image recognition, including classification and segmentation, is one of the most challenging tasks in medical image analysis. Recently, deep learning methods have achieved remarkable success in medical image classification and segmentation, clearly becoming the state-of-the-art methods. However, most of these methods are unable to provide uncertainty quantification (UQ) for their output, often being overconfident, which can lead to disastrous consequences. Bayesian Deep Learning (BDL) methods can be used to quantify uncertainty of traditional deep learning methods, and thus address this issue. We apply three uncertainty quantification methods to deal with uncertainty during skin cancer image classification. They are as follows: Monte Carlo (MC) dropout, Ensemble MC (EMC) dropout and Deep Ensemble (DE). To further resolve the remaining uncertainty after applying the MC, EMC and DE methods, we describe a novel hybrid dynamic BDL model, taking into account uncertainty, based on the Three-Way Decision (TWD) theory. The proposed dynamic model enables us to use different UQ methods and different deep neural networks in distinct classification phases. So, the elements of each phase can be adjusted according to the dataset under consideration. In this study, two best UQ methods (i.e., DE and EMC) are applied in two classification phases (the first and second phases) to analyze two well-known skin cancer datasets, preventing one from making overconfident decisions when it comes to diagnosing the disease. The accuracy and the F1-score of our final solution are, respectively, 88.95% and 89.00% for the first dataset, and 90.96% and 91.00% for the second dataset. Our results suggest that the proposed TWDBDL model can be used effectively at different stages of medical image analysis. © 2021 Elsevier Ltd","10.1016/j.compbiomed.2021.104418","Bayesian deep learning; Deep learning; Medical image classification; Monte Carlo dropout; Skin cancer; Uncertainty quantification (UQ)","197","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106889973&doi=10.1016%2fj.compbiomed.2021.104418&partnerID=40&md5=fe807bd2520050dcdbe20fde224f5ccb"
"Melanoma localization and classification through faster region-based convolutional neural network and SVM","Nawaz M.; Masood M.; Javed A.; Iqbal J.; Nazir T.; Mehmood A.; Ashraf R.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Melanoma is a lethal skin cancer disease affecting millions of people around the globe and has a high mortality rate. Dermatologists perform the manual inspection through visual analysis of pigmented skin lesions for melanoma identification at the early stage. However, manual inspection for melanoma detection is limited due to variable accuracy and lesser availability of dermatologists. Therefore, there exists an urgent need to develop automated melanoma detection methods that can effectively localize and classify skin lesions. Accurate localization and classification of the melanoma lesions is a challenging task due to the presence of low contrast information between the moles and skin part, the massive color similarity between the infected and non-infected skin portions, presence of noise, hairs, and tiny blood vessels, variations in color, texture, illumination, contrast, blurring, and melanoma size. To address these afore-mentioned challenges, we propose an effective and efficient melanoma detection method. The proposed method consists of three steps: i) image preprocessing, ii) employing Faster Region-based Convolutional Neural Network (Faster-RCNN) for melanoma localization, and iii) application of Support Vector Machine (SVM) for the classification of localized melanoma region into benign and malignant classes. Performance of the proposed method is evaluated on the benchmark ISIC-2016 dataset launched by ISBI challenge-2016 that is diverse in terms of variations in illumination, color, texture, and size of melanoma, and presence of blurring, noise, hairs, and tiny blood vessels, etc. Moreover, we have also performed a cross-dataset validation over the ISIC-2017 dataset to show the efficacy of our method in real-world scenarios. Our experimental results illustrate that the proposed framework is efficient and able to effectively localize and classify the melanoma lesion than state-of-the-art techniques. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","10.1007/s11042-021-11120-7","Deep-learning; Faster-RCNN; Medical imaging; Melanoma; Skin lesion; SVM","41","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107901552&doi=10.1007%2fs11042-021-11120-7&partnerID=40&md5=2480242344df9458a69f6f56bd9e6f76"
"Edge and neighborhood guidance network for 2D medical image segmentation","Cao W.; Zheng J.; Xiang D.; Ding S.; Sun H.; Yang X.; Liu Z.; Dai Y.","2021","0","1","0","0","0","Unique","0","","","","","","","Accurate automatic image segmentation is important in medical image analysis. A perfect segmentation using fully convolutional network (FCN) means an accurate classification of each pixel. However, it is still a great challenge to accurately differentiate edge pixels from neighborhood pixels in weak edge regions. Many previous segmentation methods have focused on edge information to mitigate weak edge problems, but the more important neighborhood information is undervalued. To tackle this problem, in this paper, we propose a novel yet effective Edge and Neighborhood Guidance Network (ENGNet). Specifically, instead of just utilizing the edge information as the shape constraints, the edge and neighborhood guidance (ENG) module is designed to exploit the edge information and fine-grained neighborhood spatial information simultaneously, so as to improve the ability of network to classify edge pixels and neighborhood pixels in weak edge regions. Moreover, the ENG modules are adopted in different scales to learn sufficient feature representations of edge and neighborhood. To extract complementary features more effectively in channel dimension, we also design a multi-scale adaptive selection (MAS) module at channel-wise to extract multi-scale context information and adaptively fuse different-scale features. Two 2D public segmentation datasets including skin lesion dataset and endoscopic polyp dataset are used to evaluate the performance of the proposed ENGNet. Experimental results demonstrated that by exploiting edge information and neighborhood spatial information in different scales simultaneously, the proposed ENGNet can effectively alleviate the misclassification in weak edge regions and achieve better performance than other state-of-the-art methods. © 2021 Elsevier Ltd","10.1016/j.bspc.2021.102856","Edge and neighborhood guidance module; Medical image segmentation; Multi-scale adaptive selection module; Weak edge","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109179906&doi=10.1016%2fj.bspc.2021.102856&partnerID=40&md5=f9228354fa71fd1ddd0345eee9403c54"
"Customized alexnet models for automatic classification of skin diseases","Huong A.K.C.; Tay K.G.; Ngu X.T.I.","2021","1","1","0","0","0","Unique","0","","","","","","","Most of the skin diseases exhibit complex, visually indiscernible features and characteristics, rendering traditional physical inspection technique fails. Meanwhile extraction of handcrafted features used in machine learning (ML) for prediction purposes may involve tedious manual labour. Different viable adaptations of deep convolutional neural network (CNN) system for automatic classification of skin diseases have not been extensively and systematically explored in the past. This could be due to the various degree of classification accuracy with complexity of the model, which also affects its modifiability, using the limited training data available. This work presents the use of AlexNet-SVM and Alex-KNN model trained with a limited data set for computer aided skin disease diagnosis. The performance of these models was also compared with that from transfer-learned AlexNet using images of skin disorders namely acne, eczema, psoriasis and rosacea. This work observed considerably consistent and good mean classification accuracy ranged in between 85 and 92 % produced by these customized models. Even though there is no correlation found between the models used in this research and their performance metrics using ANOVA t-test (ρ > 0.05), visual examination showed superiority of AlexNet-SVM over other models. In the concluding remark it is suggested that the highest adaptability of AlexNet-SVM to the considered task, combined with its robust and time effective advantages, make this approach an attractive tool for skin disease diagnosis. This model may be incorporated into skin health innovation as an added feature to allow accurate clinical decisions available rapidly and efficiently. © School of Engineering, Taylor’s University","","AlexNet; Computer Aided Diagnosis; KNN; Skin disease; SVM; Transfer-learned","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114360127&partnerID=40&md5=449fac5168efd10acc380f7b86bc8204"
"Automated segmentation of abnormal tissues in medical images","Homayoun H.; Ebrahimpour-Komleh H.","2021","0","1","0","0","0","Unique","0","","","","","","","Nowadays, medical image modalities are almost available everywhere. These modalities are bases of diagnosis of various diseases sensitive to specific tissue type. Usually physicians look for abnormalities in these modalities in diagnostic procedures. Count and volume of abnormalities are very important for optimal treatment of patients. Segmentation is a preliminary step for these measurements and also further analysis. Manual segmentation of abnormalities is cumbersome, error prone, and subjective. As a result, automated segmentation of abnormal tissue is a need. In this study, representative techniques for segmentation of abnormal tissues are reviewed. Main focus is on the segmentation of multiple sclerosis lesions, breast cancer masses, lung nodules, and skin lesions. As experimental results demonstrate, the methods based on deep learning techniques perform better than other methods that are usually based on handy feature engineering techniques. Finally, the most common measures to evaluate automated abnormal tissue segmentation methods are reported. © 2021, Shriaz University of Medical Sciences. All rights reserved.","10.31661/jbpe.v0i0.958","Abnormal Tissue Detection; Automatic Segmentation; Breast Cancer; Medical Imaging; Multiple Pulmonary Nodules; Multiple Sclerosis; Skin Abnormalities","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112159288&doi=10.31661%2fjbpe.v0i0.958&partnerID=40&md5=7faab7c5a77792212c82fe0eab0c299a"
"IBA-U-Net: Attentive BConvLSTM U-Net with Redesigned Inception for medical image segmentation","Chen S.; Zou Y.; Liu P.X.","2021","0","1","0","0","0","Unique","0","","","","","","","Accurate segmentation of medical images plays an essential role in their analysis and has a wide range of research and application values in fields of practice such as medical research, disease diagnosis, disease analysis, and auxiliary surgery. In recent years, deep convolutional neural networks have been developed that show strong performance in medical image segmentation. However, because of the inherent challenges of medical images, such as irregularities of the dataset and the existence of outliers, segmentation approaches have not demonstrated sufficiently accurate and reliable results for clinical employment. Our method is based on three key ideas: (1) integrating the BConvLSTM block and the Attention block to reduce the semantic gap between the encoder and decoder feature maps to make the two feature maps more homogeneous, (2) factorizing convolutions with a large filter size by Redesigned Inception, which uses a multiscale feature fusion method to significantly increase the effective receptive field, and (3) devising a deep convolutional neural network with multiscale feature fusion and a Attentive BConvLSTM mechanism, which integrates the Attentive BConvLSTM block and the Redesigned Inception block into an encoder-decoder model called Attentive BConvLSTM U-Net with Redesigned Inception (IBA-U-Net). Our proposed architecture, IBA-U-Net, has been compared with the U-Net and state-of-the-art segmentation methods on three publicly available datasets, the lung image segmentation dataset, skin lesion image dataset, and retinal blood vessel image segmentation dataset, each with their unique challenges, and it has improved the prediction performance even with slightly less calculation expense and fewer network parameters. By devising a deep convolutional neural network with a multiscale feature fusion and Attentive BConvLSTM mechanism, medical image segmentation of different tasks can be completed effectively and accurately with only 45% of U-Net parameters. © 2021 Elsevier Ltd","10.1016/j.compbiomed.2021.104551","Attentive BConvLSTM; Deep convolutional neural networks; Medical image segmentation; Multi-scale feature fusion","42","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109001932&doi=10.1016%2fj.compbiomed.2021.104551&partnerID=40&md5=04e99ba1e00636db64d04d06a228171f"
"Leveraging the Bhattacharyya coefficient for uncertainty quantification in deep neural networks","Van Molle P.; Verbelen T.; Vankeirsbilck B.; De Vylder J.; Diricx B.; Kimpe T.; Simoens P.; Dhoedt B.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Modern deep learning models achieve state-of-the-art results for many tasks in computer vision, such as image classification and segmentation. However, its adoption into high-risk applications, e.g. automated medical diagnosis systems, happens at a slow pace. One of the main reasons for this is that regular neural networks do not capture uncertainty. To assess uncertainty in classification, several techniques have been proposed casting neural network approaches in a Bayesian setting. Amongst these techniques, Monte Carlo dropout is by far the most popular. This particular technique estimates the moments of the output distribution through sampling with different dropout masks. The output uncertainty of a neural network is then approximated as the sample variance. In this paper, we highlight the limitations of such a variance-based uncertainty metric and propose an novel approach. Our approach is based on the overlap between output distributions of different classes. We show that our technique leads to a better approximation of the inter-class output confusion. We illustrate the advantages of our method using benchmark datasets. In addition, we apply our metric to skin lesion classification—a real-world use case—and show that this yields promising results. © 2021, The Author(s).","10.1007/s00521-021-05789-y","Bayesian networks; Deep learning; Dropout Monte Carlo; Uncertainty","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101912565&doi=10.1007%2fs00521-021-05789-y&partnerID=40&md5=810500b4bdad41fce94c5528577d46c4"
"A Multi-path CNN for Automated Skin Lesion Segmentation","Chauhan J.; Goyal P.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Automatic skin lesion segmentation in dermoscopic images is an essential requirement for making the computer-aided diagnosis (CADs) system, but efficiently segmenting skin lesions by using automated methods is not easy due to the factors such as color variations, illumination variations, presence of hair, etc. Researchers have recently been exploring deep convolutional neural networks (CNN) based methods in this domain. In this paper, we present a new and effective multi-path deep CNN method for automated skin lesion segmentation. The proposed network uses an encoder network in the first path and uses the learning representation from a pretrained base model's intermediate layers in its second path, for better learning of the features at different levels. Also, we use Instance Normalization that makes the network adaptive for each image and alleviates the problem that occurs due to different intensity images. Our method does not require any pre- or post- processing of the input dermoscopic images, except resizing in the beginning. The comparative performance evaluation of the proposed method is performed by considering two benchmark datasets: ISBI-2016 and ISBI-2017 and commonly used evaluation metrics including jaccard index and dice coefficient. The results analysis demonstrates the effectiveness of our approach, with our method achieving better performance in comparison to existing state-of-the-art methods overall and also on melanoma and non-melanoma images, across both the datasets. © 2021 IEEE.","10.1109/IJCNN52387.2021.9533787","Convolutional Neural Network; Instance Normalization; Jaccard Index; Skin Lesion Segmentation","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116490569&doi=10.1109%2fIJCNN52387.2021.9533787&partnerID=40&md5=1ab918d3addc129474779d5984e9ec95"
"Analysis of basic neural network types for automated skin cancer classification using Firefly optimization method","Balaji M.S.P.; Saravanan S.; Chandrasekar M.; Rajkumar G.; Kamalraj S.","2021","1","1","0","0","0","Unique","0","","","","","","","In recent days, cancer is a deadly disease because of its spreading nature to other cells, and this disease is not identified at an early detection stage. Generally, the cancer is detected with the help of a biopsy method, which is a painful approach. Due to the development of technology, nowadays, it is identified with the help of image processing methods. Here, the image processing approach is used for identifying and classifying the skin cancer types, namely melanoma, common and atypical nevi. The methods used earlier for the detection and classification are artificial skin leison merging, Raman spectroscopy and back-propagation networks. Cancer is classified into many types like blood cancer, bone, colon, and stomach and skin cancer. Among these cancer types, skin cancer can be a dreadful disease, which is detected and then treated at the starting stage of the disease. Hence, this paper proposed an optimized neural and fuzzy approach for skin cancer classification. The fuzzy c-means segmentation is used for the detection of the cancer region. Firefly optimization determines the dominant feature for the training of the neural network. The dominant feature is determined by reducing the error rate of the classifier. The overall process is evaluated with the help of evaluation metrics like accuracy, specificity and sensitivity. In this proposed method, the best result is achieved for the pattern net by improving its accuracy by 4.9% from its previous Moth-Flame Optimization based classification in its evaluation. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.","10.1007/s12652-020-02394-0","Accuracy; Cancer; Error rate; Firefly optimization; Fuzzy C means; Mean; Melanoma; Neural network types; Sensitivity","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092244031&doi=10.1007%2fs12652-020-02394-0&partnerID=40&md5=9aa0b16f5fbe08042c7384713f4b923a"
"Dermatoscopy using multi-layer perceptron, convolution neural network, and capsule network to differentiate malignant melanoma from benign nevus","Tiwari S.","2021","0","1","0","0","0","Unique","0","","","","","","","Epiluminescence microscopy, more simply, dermatoscopy, entails a process using imaging to examine skin lesions. Various sorts of skin ailments, for example, melanoma, may be differentiated via these skin images. With the adverse possibilities of malignant melanoma causing death, an early diagnosis of melanoma can impact on the survival, length, and quality of life of the affected victim. Image recognition-based detection of different tissue classes is significant to implementing computeraided diagnosis via histological images. Conventional image recognition require handcrafted feature extraction before the application of machine learning. Today, deep learning is offering significant choices with the progression of artificial learning to defeat the complications of the handcrafted feature extraction methods. A deep learning-based approach for the recognition of melanoma via the Capsule network is proposed here. The novel approach is compared with a multi-layer perceptron and convolution network with the Capsule network model yielding the classification accuracy at 98.9%. © 2021 IGI Global. All rights reserved.","10.4018/IJHISI.20210701.oa4","Capsule network; Convolution neural network; Dermatoscopy; Multi-layer perceptron","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098643099&doi=10.4018%2fIJHISI.20210701.oa4&partnerID=40&md5=af9a91b83cc744a9f6f2e42cf3fc684b"
"Dermatoscopic image melanoma recognition based on CFLDnet fusion network","Liu J.; Chen A.; Zhou G.; Chen W.; Peng N.; Yan N.","2021","0","1","0","0","0","First occurrence","0","","","","","","","As a common skin disease, malignant melanoma has attracted great attention in dermatology with high morbidity and mortality. Traditional medical diagnoses rely on clinical experience and have a certain subjective bias. Aiming at the problem of similarity between classes of melanoma dermoscopic images and the imbalance of lesion data set, we propose a CFLDnet-based dermoscopic image lesion classification model, it mainly uses the improved convolutional block attention (CBA) DenseNet algorithm to enhance beneficial features. To better integrate the attention module into DenseNet without increasing too many parameters and wasting the computing resources, we discussed three types of variant networks derived from the CFLDnet. Moreover, to balance the different categories of the data set, we also use the Sample Focal Loss (SFL) to calculate the effective sample size of the data set and smooth the focal loss function. Large numbers of comparative experiments were done based on the ISIC2018 task3 dataset, the average recognition accuracy of the CFLDnet network proposed in this paper is 86.89%, which is much higher than other similar methods (VGG16, ResNet50, InceptionV3 and DenseNet121 with cross-entropy loss function). © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","10.1007/s11042-021-10920-1","Convolutional block attention module; Densenet; Dermatoscopy image; Focal loss; Melanoma recognition","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104858451&doi=10.1007%2fs11042-021-10920-1&partnerID=40&md5=14854f3e9a343d3b04d83875517cdc6d"
"Towards accurate classification of skin cancer from dermatology images","Gautam A.; Raman B.","2021","1","1","0","0","0","Unique","0","","","","","","","Skin cancer is the most well-known disease found in the individuals who are exposed to the Sun's ultra-violet (UV) radiations. It is identified when skin tissues on the epidermis grow in an uncontrolled manner and appears to be of different colour than the normal skin tissues. This paper focuses on predicting the class of dermascopic images as benign and malignant. A new feature extraction method has been proposed to carry out this work which can extract relevant features from image texture. Local and gradient information from (Formula presented.) and (Formula presented.) directions of images has been utilized for feature extraction. After that images are classified using machine learning algorithms by using those extracted features. The efficacy of the proposed feature extraction method has been proved by conducting several experiments on the publicly available image dataset 2016 International Skin Imaging Collaboration (ISIC 2016). The classification results obtained by the method are also compared with state-of-the-art feature extraction methods which show that it performs better than others. The evaluation criteria used to obtain the results are accuracy, true positive rate (TPR) and false positive rate (FPR) where TPR and FPR are used for generating receiver operating characteristic curves. © 2021 The Authors. IET Image Processing published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology","10.1049/ipr2.12166","","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102172257&doi=10.1049%2fipr2.12166&partnerID=40&md5=154ad23c5b34c8d775f88b2a53c040c9"
"Skin disease classification using dermoscopy images through deep feature learning models and machine learning classifiers","Gupta S.; Panwar A.; Mishra K.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Skin is one of the very important and largest organs of the human body that helps in regulating the body temperature and is responsible for sensations such as feel, touch, hot and cold. These days, skin problems are very common in day-to-day life. There may be many reasons for skin diseases: unbalanced and impure diet, several types of pollutions, or maybe family heredity. However, if skin disease after a long treatment does not show any sign of improvement or the skin cells grow abnormally, this may lead to skin cancer. There are many forms of skin cancer. For early and timely diagnosis of skin cancer, an efficient technique is required at utmost importance. Many people across the globe lost their lives due to the late diagnosis. Therefore, a technique that is cost-effective, quicker, and easily accessible needs a higher demand. These days for the classification of images, machine learning, and deep learning techniques proved to be the most efficient approach. In this paper, the dataset of several images of a benign and malignant tumor was taken and pre-processed. Once all the images were pre-processed, they are ready to fed in several CNN models. These models extract the features and pass the images to several machine learning classifiers for the classification of moles as benign or malignant. The results verify by using the classification approach it becomes very much easy for the dermatologist to easily detect the lesions and provide the appropriate treatment to the patient to save the life. © 2021 IEEE.","10.1109/EUROCON52738.2021.9535552","Benign tumor; Classification; Machine Learning; Melanoma; Skin disease","48","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116230959&doi=10.1109%2fEUROCON52738.2021.9535552&partnerID=40&md5=53a7f718c06f63bd9f1376886d4f7b27"
"Medical Big Data Analysis with Attention and Large Margin Loss Model for Skin Lesion Application","Wu J.; Guo H.; Wen Y.; Hu W.; Li Y.N.; Liu T.Y.; Liu X.M.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Due to melanoma is one of the skin cancers with the highest mortality rate and have a large amount of data during the collection and diagnosis, there is an urgent need to improve the diagnostic efficiency and accuracy. However, there remain problems in analyzing medical big data for skin lesion application, such as the intra-class variation and inter-class similarity in skin lesion images and the lacks of ability to focus on the lesion area affecting the classification results of the model. To address these dilemmas, in this paper, we proposed a novel machine learning-based approach that builds on top of DenseNet. It combines the attention mechanism and large margin loss to enhance the classification accuracy in terms of intra-class compactness and inter-class separability. We evaluated our model on ISIC 2017 (International Skin Imaging Collaboration) dataset, which has achieved 92% of Mean AUC. The experimental results show the effectiveness of our solution outperforms the state-of-the-art significantly in classify skin lesion and can accurately classify malignant melanoma on medical images. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","10.1007/s11265-021-01664-0","Attention; Dermoscopy; DNNs; Large margin loss; Medical big data; Skin lesion","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106000796&doi=10.1007%2fs11265-021-01664-0&partnerID=40&md5=0f2441da9561eb9be1b277f53a35a05b"
"Computer-aided skin cancer diagnosis based on a New meta-heuristic algorithm combined with support vector method","Bi D.; Zhu D.; Sheykhahmad F.R.; Qiao M.","2021","1","1","0","0","0","Unique","0","","","","","","","Skin cancer has grown significantly over the past decades, and the importance of its initial treatment is increasing day by day. This study aims to use a computer-aided diagnosis automatic system for the exact diagnosis of cancerous cases. In the present study, after applying pre-processing operations including contrast enhancement, image thresholding, and mathematical morphology for highlighting the important areas, feature extraction based on 20 different features has been applied. Then, for decreasing the system complexity, a new improved version of the world cup optimization algorithm is utilized for the features pruning. After optimal selection of the features, the injected into a support vector machine as a classifier to determine the cancerous areas. Experimental results are compared by different new algorithms including the classic SVM method, hybrid optimized neural networks based on gray wolf optimizer and particle swarm optimization algorithm, and also convolutional neural network. Results obtained for skin lesions images from two different databases indicate that the proposed method has higher efficiency than other published methods, demonstrating even better performance than the well-known classification method, the convolutional neural networks. The proposed method presents the highest correct detection rate - 92.64 for ACS images and 87.5 for ISIC images with very low false acceptance rates (4.41 % and 9 % for ACS and ISIC images, respectively) and even less false rejection rates, this is, 2.94 % on ACS images and 3.5 % on ISIC images. These results prove that the proposed method may be reliably used to diagnose skin cancer through dermoscopy images. © 2021 Elsevier Ltd","10.1016/j.bspc.2021.102631","Chaotic world cup optimization algorithm; Computer-aided diagnosis; Feature classification; Feature extraction; Kapur image thresholding; Skin cancer; Support vector machine classifier","37","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104076330&doi=10.1016%2fj.bspc.2021.102631&partnerID=40&md5=b60a0efa9650ea1ec8332872afb15626"
"Semi-supervised medical image classification based on CamMix","Guo L.; Wang C.; Zhang D.; Xu K.; Huang Z.; Luo L.; Peng Y.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Collecting a large amount of labeled data is crutial for training deep neural network, which is a limitation for medical image classification because it necessarily involves expert knowledge. To mitigate this problem of insufficient labeled medical data, in this work, we propose a novel semi-supervised framework for medical image classification. For unlabeled data, we apply the consistency-based strategy to produce high-quality pseudo label, which encourages model to output the same predictions under different perturbations. In addition, we present a novel mixed sample data augmentation CamMix to effectively exploit the relation between samples, mixing pairs of input data and labels according to the class activation map mask. We have evaluated our proposed method on two public medical image datasets, interstitial lung disease dataset and ISIC 2018 skin lesion analysis dataset. The results demonstrate superior performance of our method over other existing methods on the two datasets. Meanwhile, our proposed CamMix performs better than the current mixed sample data augmentation methods. © 2021 IEEE.","10.1109/IJCNN52387.2021.9534222","CamMix; Medical image classification; Semi-supervised learning","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116456452&doi=10.1109%2fIJCNN52387.2021.9534222&partnerID=40&md5=70a4ca9dae0b33104b9023dbd5cd2539"
"Skin cancer classification through quantized color features and generative adversarial network","Maiti A.; Chatterjee B.; Santosh K.C.","2021","1","1","0","0","0","Unique","0","","","","","","","Early interpretation of skin cancer through computer-aided diagnosis (CAD) tools reduced the intricacy of the treatments as it can attain a 95% recovery rate. To frame up with computer-aided diagnosis system, scientists adopted various artificial intelligence (AI) designed to receive the best classifiers among these diverse features. This investigation covers traditional color-based texture, shape, and statistical features of melanoma skin lesion and contrasted with suggested methods and approaches. The quantized color feature set of 4992 traits were pre-processed before training the model. The experimental images have combined images of naevus (1500), melanoma (1000), and basal cell carcinoma (500). The proposed methods handled issues like class imbalanced with generative adversarial networks (GAN). The recommended color quantization method with synthetic data generation increased the accuracy of the popular machine learning models as it gives an accuracy of 97.08% in random forest. The proposed model preserves a decent accuracy with KNN, adaboost, and gradient boosting. Copyright © 2021, IGI Global.","10.4018/IJACI.2021070104","Adaboost; Classification; Color features; Computer-Aided diagnosis; Generative adversarial networks; Gradient boosting; KNN; Melanoma; Random forest; Skin cancer; Synthetic data","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106966287&doi=10.4018%2fIJACI.2021070104&partnerID=40&md5=7500ff0286fa7a0520dac6dbc0bf65b6"
"Artificial intelligence in dermatology for the clinician","Patel S.; Wang J.V.; Motaparthi K.; Lee J.B.","2021","0","1","0","0","0","Unique","0","","","","","","","As medicine enters the era of artificial intelligence (AI)–augmented practice, dermatology is beginning to witness the integration of AI into the daily practice, particularly in the areas of diagnosis, prognosis, and treatment of skin diseases. Many of the current electronic medical records that dermatologists have incorporated provide guidance in billing, a form of AI at work. The recent advances in visual recognition AI make application and integration of the technology particularly suited for perceptual specialties such as radiology and dermatology. In dermatology, AI is poised to improve the efficiency and accuracy of traditional diagnostic approaches, including visual examination, skin biopsy, and histopathologic examination. This review highlights the current progress of AI in dermatology and provides a basic overview of the technology. © 2021 Elsevier Ltd","10.1016/j.clindermatol.2021.03.012","","36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106587527&doi=10.1016%2fj.clindermatol.2021.03.012&partnerID=40&md5=36a42adab872072266c3ead51bedbdc8"
"Multi-class segmentation of skin lesions via joint dictionary learning","Moradi N.; Mahdavi-Amiri N.","2021","1","1","0","0","0","Unique","0","","","","","","","Melanoma is the deadliest type of human skin cancer. However, it is curable if diagnosed in an early stage. Recently, computer aided diagnosis (CAD) systems have drawn much interests. Segmentation is a crucial step of a CAD system. There are different types of skin lesions having high similarities in terms of color, shape, size and appearance. Most available works focus on a binary segmentation. Due to the huge variety of skin lesions and high similarities between different types of lesions, multi-class segmentation is still a challenging task. Here, we propose a method based on joint dictionary learning for multi-class segmentation of dermoscopic images. The key idea is based on combining data from different feature spaces to build a more informative structure. We consider training data from two different spaces. Then, two dictionaries are jointly learned using the K-SVD algorithm. The final segmentation is accomplished by a graph-cut method based on both the topological information of lesions and the learned dictionaries. We evaluate our proposed method on the ISIC 2107 dataset to segment three classes of lesions. Our method achieves better results, specially for challenging skin lesions, compared to the only available method for multi-class segmentation of dermoscopic images. We also evaluate the performance of our method for binary segmentation and lesion diagnosis and compared the results with the other state-of-the-art methods. Experimental results show the efficiency and effectiveness of the proposed method in producing results that are more reliable for clinical applications, even using limited amount of training data. © 2021","10.1016/j.bspc.2021.102787","Graph-cuts; Joint dictionary learning; Multi-class segmentation; Skin lesion; Sparse representation","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106388668&doi=10.1016%2fj.bspc.2021.102787&partnerID=40&md5=a54d8a86ac3c7ae9991f909c1316bc8d"
"Artificial Intelligence-Aided Recognition of Pathological Characteristics and Subtype Classification of Superficial Perivascular Dermatitis","Bao Y.; Zhang J.; Zhang Q.; Chang J.; Lu D.; Fu Y.","2021","0","1","0","0","0","Unique","0","","","","","","","Background: Superficial perivascular dermatitis, an important type of inflammatory dermatosis, comprises various skin diseases, which are difficult to distinguish by clinical manifestations and need pathological imaging observation. Coupled with its complex pathological characteristics, the subtype classification depends to a great extent on dermatopathologists. There is an urgent need to develop an efficient approach to recognize the pathological characteristics and classify the subtypes of superficial perivascular dermatitis. Methods: 3,954 pathological images (4 × and 10 ×) of three subtypes—psoriasiform, spongiotic and interface—of superficial perivascular dermatitis were captured from 327 cases diagnosed both clinically and pathologically. The control group comprised 1,337 pathological images of 85 normal skin tissue slides taken from the edge of benign epidermal cysts. First, senior dermatologists and dermatopathologists followed the structure–pattern analysis method to label the pathological characteristics that significantly contribute to classifying different subtypes on 4 × and 10 × images. A cascaded deep learning algorithm framework was then proposed to establish pixel-level pathological characteristics' masks and classify the subtypes by supervised learning. Results: 13 different pathological characteristics were recognized, and the accuracy of subtype classification was 85.24%. In contrast, the accuracy of the subtype classification model without recognition was 71.35%. Conclusion: Our cascaded deep learning model used small samples to deliver efficient recognition of pathological characteristics and subtype classification simultaneously. Moreover, the proposed method could be applied to both microscopic images and digital scanned images. © Copyright © 2021 Bao, Zhang, Zhang, Chang, Lu and Fu.","10.3389/fmed.2021.696305","multitask deep learning; pathological characteristics; skin histopathology images; subtype classification; superficial perivascular dermatitis","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111603216&doi=10.3389%2ffmed.2021.696305&partnerID=40&md5=7d1e466498a8964bffb0a2387da260d5"
"Automated Skin Cancer Detection: Where We Are and the Way to the Future","Goceri E.","2021","1","1","0","0","0","Unique","0","","","","","","","The most common and dreadful kinds of skin diseases is skin cancer. It can be caused by several factors such as prolonged exposure to sunlight, genetic defects and environmental factors. There are different kinds of skin cancer and the patients are usually not aware of recognizing the growth of skin lesions in the initial stage. For example, melanoma, which is a malignant lesion and one of the deadliest kinds. Skin cancer can be cured when it is detected early. Therefore, timely and accurate detection and treatment of the disease has a crucial role in the patients' survival. This paper aims to present an analysis of recent applications proposed for automated detection of skin cancer and future potentials to assist the investigators in developing efficient methods to achieve accurate, objective and early detection of the disease. © 2021 IEEE.","10.1109/TSP52935.2021.9522605","classification; deep learning; lesion detection; skin cancer; skin lesion","53","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115442883&doi=10.1109%2fTSP52935.2021.9522605&partnerID=40&md5=bb7de3b1374bd51f4a0b3a0b98ff5122"
"Optimized training for convolutional neural network using enhanced grey wolf optimization algorithm","Guernine A.; Kimour M.T.","2021","0","1","0","0","0","Unique","0","","","","","","","Convolutional Neural Networks (CNNs) are widely used in image classification tasks and have achieved significant performance. They have different applications with great success, especially in the medical field. The choice of architecture and hyperparameter settings of the CNN, highly influences both accuracy and its convergence speed. The empirical design and optimization of a new CNN architecture require a lot of expertise and can be very time-consuming. This paper proposes an enhanced Grey Wolf Optimization (GWO) algorithm to efficiently explore a defined space of potentially suitable CNN architectures, and simultaneously optimize their hyperparameters. Moreover, we introduce a spatial resolution reduction for a given image processing task, while taking skin cancer detection as a practical application. Through conducted experiments, we have shown that the obtained results are better than other classification methods in terms of accuracy and convergence speed. © 2021 Slovene Society Informatika. All rights reserved.","10.31449/inf.v45i5.3497","Convolutional neural network (CNN); Deep learning; Grey wolf optimization algorithm; Training algorithm","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112281110&doi=10.31449%2finf.v45i5.3497&partnerID=40&md5=95c3ce3ac093b1668831ec2cc5e1c6cd"
"Level set approach based on Parzen Window and floor of log for edge computing object segmentation in digital images","Rebouças E.D.S.; de Medeiros F.N.S.; Marques R.C.P.; Chagas J.V.S.; Guimarães M.T.; Santos L.O.; Medeiros A.G.; Peixoto S.A.","2021","0","1","0","0","0","Unique","0","","","","","","","Scientific research into methodologies and algorithms to improve support for medical diagnoses remains in high demand on the agenda. Computer-aided diagnostic systems that use the Internet of Things (IoT) enable greater accessibility and integration between patients and specialists. One of the steps covered by IoT systems is the segmentation of Regions of Interest (ROI) in digital images. The challenge to segment these ROI in IoT systems is to apply methods that have low computational and storage costs with reliable results. Thus this work proposes the use of edge computing with a new approach based on active contours to target the ROI in medical images called FLog Parzen Level Set (FPLS). The method can be divided into two stages. First is the initialization of the seed point using Parzen Window and clusterization using Floor of Log. Second the growth and refinement of the region with probabilistic estimates of the regional contour using the Parzen Window. The proposed method was evaluated using the metrics of Accuracy, Precision, Sensitivity, Specificity, Matthews Coefficient Correlation, Hausdorff distance, Dice, and Jaccard Similarity Coefficient. The stable and satisfactory results can be highlighted despite the low computational times and costs. The proposed method was submitted to stroke, lung, and skin disease datasets. The proposed method achieved the fastest mean segmentation time of 1.64s for the three datasets used in this work. The method obtained the highest values for Sensitivity (98.57%), Accuracy (98.77%) and MCC (94.73%) in the stroke dataset, the lowest value for Hausdorff distance (4.24) in the lung dataset, and the highest Dice Coefficient value (92.49%) in the skin dataset. In conclusion, the proposed method is a promising tool for an edge computing system that segments regions of interest with the high precision of a level set and a fast convergence rate. © 2021 Elsevier B.V.","10.1016/j.asoc.2021.107273","Active contour; Edge computing; Image segmentation; Medical imaging","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102972783&doi=10.1016%2fj.asoc.2021.107273&partnerID=40&md5=1a6663ab69b73e448e41540f2e99b692"
"Diagnosis of skin diseases in the era of deep learning and mobile technology","Goceri E.","2021","1","1","0","0","0","Unique","0","","","","","","","Efficient methods developed with deep learning in the last ten years have provided objectivity and high accuracy in the diagnosis of skin diseases. They also support accurate, cost-effective and timely treatment. In addition, they provide diagnoses without the need to touch patients, which is very desirable when the disease is contagious or the patients have another contagious disease. On the other hand, it is not possible to run deep networks on resource-constrained devices (e.g., mobile phones). Therefore, lightweight network architectures have been proposed in the literature. However, merely a few mobile applications have been developed for the diagnosis of skin diseases from colored photographs using lightweight networks. Moreover, only a few types of skin diseases have been addressed in those applications. Additionally, they do not perform as well as the deep network models, particularly for pattern recognition. Therefore, in this study, a novel model has been constructed using MobileNet. Also, a novel loss function has been developed and used. The main contributions of this study are: (i) proposing a novel hybrid loss function; (ii) proposing a modified-MobileNet architecture; (iii) designing and implementing a mobile phone application with the modified-MobileNet and a user-friendly interface. Results indicated that the proposed technique can diagnose skin diseases with 94.76% accuracy. © 2021 Elsevier Ltd","10.1016/j.compbiomed.2021.104458","Deep learning; Lesion classification; Lightweight network; Mobile application; MobileNet; Skin disease","116","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105759486&doi=10.1016%2fj.compbiomed.2021.104458&partnerID=40&md5=0678035f2d32718663120d7f5f798146"
"Skin detection in video under uncontrolled illumination","Chakraborty B.K.; Bhuyan M.K.; MacDorman K.F.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Many vision-based human-computer interaction (HCI) applications require skin detection. However, their performance relies on accuracy in detecting skin regions in video, which is difficult under uncontrolled illumination. The chromatic appearance of skin changes because of shading, often caused by body movement. To address this, we propose a dynamic adaptation method to detect skin regions affected by local color deformations. Static and dynamic skin regions are detected by a corresponding module. The static module includes a facial skin distribution model (FSDM) and a fusion-based background distribution model (FBDM). The FBDM is obtained from a local background distribution model (LBDM) and a global background distribution model (GBDM). The LBDM is obtained by comparing a frame pixel distribution model with the FSDM and GBDM. Next, the FBDM is derived from the LBDM and the GBDM. The dynamic module includes a moving skin distribution model (MSDM), derived from a set of moving skin samples. Initially, moving skin regions are detected using a modified double frame-difference method and then modeled using a Gaussian mixture model. To avoid misidentifying background regions as skin, the final MSDM is obtained by comparing the initial moving skin model to the FSDM and FBDM. Finally, the static and the dynamic models are fused by applying a maximization rule. Experimental results shows that the proposed method can detect skin regions more accurately than state-of-the-art methods. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC part of Springer Nature.","10.1007/s11042-021-10728-z","First keyword; More; Second keyword","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103627966&doi=10.1007%2fs11042-021-10728-z&partnerID=40&md5=70c9991f3287e30852d3b4b000afe2e9"
"Performance Analysis on Dermoscopic Images for Enhancing the Diagnostic Support System in Healthcare","Ayyappan S.","2021","0","1","0","0","0","Unique","0","","","","","","","Diagnostic support system plays a significant role in detecting skin cancer. Skin cancers cases are often misdiagnosed due to lack of experience and knowledge of different skin lesion types. Exploring the role of image processing in computer aided diagnosis system. To detect quantification of vascular structures towards skin lesions diagnosis. By taking a dermoscopic image split out the formation of the lesion by initially using independent component analysis into melanin and haemoglobin regions. Haemoglobin component is then clustered into three regions. Shaping filters are also used to erythema region for finding various measures. Hence, a vessel mask is created from global thresholding.12 vascular features are extracted towards lesion diagnosis fed into a classifier and achieves 94.1% accuracy. The proposed technique provides better accuracy and well suited for decision making in diagnostic support system.  © 2021 IEEE.","10.1109/ICOEI51242.2021.9452860","Dermoscopic image; Frangi filters; Independent Component Analysis; Region segmentation; Skin Cancer","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113454513&doi=10.1109%2fICOEI51242.2021.9452860&partnerID=40&md5=f0bb4ac551d27bb64fefdb1c87804877"
"Deep learning automated pathology in ex vivo microscopy","Combalia M.; Garcia S.; Malvehy J.; Puig S.; Mulberger A.G.; Browning J.; Garcet S.; Krueger J.G.; Lish S.R.; Lax R.; Ren J.; Stevenson M.; Doudican N.; Carucci J.A.; Jain M.; White K.; Rakos J.; Gareau D.S.","2021","0","1","0","0","0","Unique","0","","","","","","","Standard histopathology is currently the gold standard for assessment of margin status in Mohs surgical removal of skin cancer. Ex vivo confocal microscopy (XVM) is potentially faster, less costly and inherently 3D/digital compared to standard histopathology. Despite these advantages, XVM use is not widespread due, in part, to the need for pathologists to retrain to interpret XVM images. We developed artificial intelligence (AI)-driven XVM pathology by implementing algorithms that render intuitive XVM pathology images identical to standard histopathology and produce automated tumor positivity maps. XVM images have fluorescence labeling of cellular and nuclear biology on the background of endogenous (unstained) reflectance contrast as a grounding counter-contrast. XVM images of 26 surgical excision specimens discarded after Mohs micrographic surgery were used to develop an XVM data pipeline with 4 stages: flattening, colorizing, enhancement and automated diagnosis. The first two stages were novel, deterministic image processing algorithms, and the second two were AI algorithms. Diagnostic sensitivity and specificity were calculated for basal cell carcinoma detection as proof of principal for the XVM image processing pipeline. The resulting diagnostic readouts mimicked the appearance of histopathology and found tumor positivity that required first collapsing the confocal stack to a 2D image optimized for cellular fluorescence contrast, then a dark field-to-bright field colorizing transformation, then either an AI image transformation for visual inspection or an AI diagnostic binary image segmentation of tumor obtaining a diagnostic sensitivity and specificity of 88% and 91% respectively. These results show that video-assisted micrographic XVM pathology could feasibly aid margin status determination in micrographic surgery of skin cancer. © 2021 Optical Society of America under the terms of the OSA Open Access Publishing Agreement","10.1364/BOE.422168","","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106023700&doi=10.1364%2fBOE.422168&partnerID=40&md5=5de49dd2299fbcd68aa80057a0553c91"
"Melanoma Detection Using Convolutional Neural Networks and Group Normalization","Badlani S.; Aditya T.; Dave M.; Mulla N.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Melanoma is one of the most dangerous types of skin cancers. It is very difficult to detect even for experienced dermatologists. Thus, there is a need to develop artificial intelligence-based detection systems to aid in the early diagnosis and treatment of melanoma. The paper proposes a Convolutional Neural Network (CNN) based approach to classify benign and malignant melanoma. The proposed system includes a web application that can be used by the end user. The CNN is trained using a large number of benign and malignant melanoma images. The proposed CNN architecture uses data augmentation and Group Normalization techniques for improved results. The proposed model produces an accuracy of 89.82% with a sensitivity of 92.20% and a specificity of 87.27%. The proposed model is compared to two other experimental architectures and is found to produce the best results. The proposed architecture is also compared to pre-built CNN architectures like ResNet50, MobileNet and InceptionV3 which have been trained on the same dataset. The proposed model outperforms the pre-built architectures and produces appreciably better results.  © 2021 IEEE.","10.1109/ICOEI51242.2021.9453075","Batch Normalization; Convolutional Neural Networks; Data Augmentation; Group Normalization; Image Classification; Melanoma; ReLU; Skin Cancer","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113474656&doi=10.1109%2fICOEI51242.2021.9453075&partnerID=40&md5=81d93c52beb71511c5c5873511dadb78"
"D-LEMA: Deep learning ensembles from multiple annotations-application to skin lesion segmentation","Mirikharaji Z.; Abhishek K.; Izadi S.; Hamarneh G.","2021","1","0","0","0","0","Unique","0","","","","","","","Medical image segmentation annotations suffer from inter-and intra-observer variations even among experts due to intrinsic differences in human annotators and ambiguous boundaries. Leveraging a collection of annotators' opinions for an image is an interesting way of estimating a gold standard. Although training deep models in a supervised setting with a single annotation per image has been extensively studied, generalizing their training to work with datasets containing multiple annotations per image remains a fairly unexplored problem. In this paper, we propose an approach to handle annotators' disagreements when training a deep model. To this end, we propose an ensemble of Bayesian fully convolutional networks (FCNs) for the segmentation task by considering two major factors in the aggregation of multiple ground truth annotations: (1) handling contradictory annotations in the training data originating from inter-annotator disagreements and (2) improving confidence calibration through the fusion of base models' predictions. We demonstrate the superior performance of our approach on the ISIC Archive and explore the generalization performance of our proposed method by cross-dataset evaluation on the PH2 and DermoFit datasets. © 2021 IEEE.","10.1109/CVPRW53098.2021.00203","","27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116040542&doi=10.1109%2fCVPRW53098.2021.00203&partnerID=40&md5=a493469f0cd046f8c38b2cba05f56251"
"A novel melanoma detection model: Adapted K-means clustering-based segmentation process","Sukanya S.T.; Jerine","2021","0","1","0","0","0","Unique","0","","","","","","","The main intention of this paper is to propose a new Improved K-means clustering algorithm, by optimally tuning the centroids. This paper introduces a new melanoma detection model that includes three major phase's viz. segmentation, feature extraction and detection. For segmentation, this paper introduces a new Improved K-means clustering algorithm, where the initial centroids are optimally tuned by a new algorithm termed Lion Algorithm with New Mating Process (LANM), which is an improved version of standard LA. Moreover, the optimal selection is based on the consideration of multi-objective including intensity diverse centroid, spatial map, and frequency of occurrence, respectively. The subsequent phase is feature extraction, where the proposed Local Vector Pattern (LVP) and Grey-Level Co-Occurrence Matrix (GLCM)-based features are extracted. Further, these extracted features are fed as input to Deep Convolution Neural Network (DCNN) for melanoma detection. Finally, the performance of the proposed model is evaluated over other conventional models by determining both the positive as well as negative measures. From the analysis, it is observed that for the normal skin image, the accuracy of the presented work is 0.86379, which is 47.83% and 0.245% better than the traditional works like Conventional K-means and PA-MSA, respectively. From the overall analysis it can be observed that the proposed model is more robust in melanoma prediction, when compared over the state-of-Art models. © 2020 2020 Walter de Gruyter GmbH, Berlin/Boston.","10.1515/bams-2020-0040","GLCM; K-means clustering; melanoma detection; optimization; proposed LVP","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096496773&doi=10.1515%2fbams-2020-0040&partnerID=40&md5=2941d0b6da43060de3bebeeeb84a3aa4"
"Quantifying acceptable artefact ranges for dermatologic classification algorithms","Petrie T.C.; Larson C.; Heath M.; Samatham R.; Davis A.; Berry E.G.; Leachman S.A.","2021","0","1","0","0","0","Unique","0","","","","","","","Background: Many classifiers have been developed that can distinguish different types of skin lesions (e.g., benign nevi, melanoma) with varying degrees of success.1–5 However, even successfully trained classifiers may perform poorly on images that include artefacts. While problems created by hair and ink markings have been published, quantitative measurements of blur, colour and lighting variations on classification accuracy has not yet been reported to our knowledge. Objectives: We created a system that measures the impact of various artefacts on machine learning accuracy. Our objectives were to (1) quantitatively identify the most egregious artefacts and (2) demonstrate how to assess a classification algorithm's accuracy when input images include artefacts. Methods: We injected artefacts into dermatologic images using techniques that could be controlled with a single variable. This allows us to quantitatively evaluate the impact on the accuracy. We trained two convolutional neural networks on two different binary classification tasks and measured the impact on dermoscopy images over a range of parameter values. The area under the curve and specificity-at-a-given-sensitivity values were measured for each artefact induced at each parameter. Results: General blur had the strongest negative effect on the melanoma versus other task. Conversely, shifting the hue towards blue had a more pronounced effect on the suspicious versus follow task. Conclusions: Classifiers should either mitigate artefacts or detect them. Images should be excluded from diagnosis/recommendation when artefacts are present in amounts outside the machine perceived quality range. Failure to do so will reduce accuracy and impede approval from regulatory agencies. © 2021 The Authors. Skin Health and Disease published by John Wiley & Sons Ltd on behalf of British Association of Dermatologists.","10.1002/ski2.19","","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143211837&doi=10.1002%2fski2.19&partnerID=40&md5=fc2224f14be146f60e2b87f55b4ad472"
"Learning melanocytic proliferation segmentation in histopathology images from imperfect annotations","Liu K.; Mokhtari M.; Li B.; Nofallah S.; May C.; Chang O.; Knezevich S.; Elmore J.; Shapiro L.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Melanoma is the third most common type of skin cancer and is responsible for the most skin cancer deaths. A diagnosis of melanoma is made by the visual interpretation of tissue sections by a pathologist, a challenging task given the complexity and breadth of melanocytic lesions and the subjective nature of biopsy interpretation. We leverage advances in computer vision to aid melanoma diagnosis by segmenting potential regions of lesions on digital images of whole slide skin biopsies. In this study, we demonstrate a Mask-R-CNN-based segmentation framework for such a purpose. To alleviate the cost of data annotation, we leverage a sparse annotation pipeline. Our model can be trained on sparse and noisy labels and achieves state-of-the-art performance in identifying melanocytic proliferations, producing a segmentation with Dice score 0.719, mIOU 0.740 and overall pixel accuracy 0.927. © 2021 IEEE.","10.1109/CVPRW53098.2021.00417","","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116025864&doi=10.1109%2fCVPRW53098.2021.00417&partnerID=40&md5=031e47d0f78c82670ebea8fb093db58f"
"A Review on Multi-organ Cancer Detection Using Advanced Machine Learning Techniques","Sadad T.; Rehman A.; Hussain A.; Abbasi A.A.; Khan M.Q.","2021","0","1","0","0","0","Unique","0","","","","","","","Abnormal behaviors of tumors pose a risk to human survival. Thus, the detection of cancers at their initial stage is beneficial for patients and lowers the mortality rate. However, this can be difficult due to various factors related to imaging modalities, such as complex background, low contrast, brightness issues, poorly defined borders and the shape of the affected area. Recently, computer-aided diagnosis (CAD) models have been used to accurately diagnose tumors in different parts of the human body, especially breast, brain, lung, liver, skin and colon cancers. These cancers are diagnosed using various modalities, including computed tomography (CT), magnetic resonance imaging (MRI), colonoscopy, mammography, dermoscopy and histopathology. The aim of this review was to investigate existing approaches for the diagnosis of breast, brain, lung, liver, skin and colon tumors. The review focuses on decision-making systems, including handcrafted features and deep learning architectures for tumor detection. © 2021 Bentham Science Publishers.","10.2174/1573405616666201217112521","Classification; colonoscopy; CT; healthcare; mammography; MRI; public health","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100177557&doi=10.2174%2f1573405616666201217112521&partnerID=40&md5=962ae1de6ae3b2fd49cc840624b0db49"
"Can self-training identify suspicious ugly duckling lesions?","Mohseni M.; Yap J.; Yolland W.; Koochek A.; Atkins M.S.","2021","0","1","0","0","0","Unique","0","","","","","","","One commonly used clinical approach towards detecting melanomas recognises the existence of Ugly Duckling nevi, or skin lesions which look different to the other lesions on the same patient. An automatic method of detecting and analysing these lesions would help to standardize studies, compared with manual screening methods. However, it is difficult to obtain expertly-labelled images for ugly duckling lesions. We therefore propose to use self-supervised machine learning to automatically detect outlier lesions. We first automatically detect and extract all the lesions from a wide-field skin image, and calculate an embedding for each detected lesion in a patient image, based on automatically identified features. These embeddings are then used to calculate the L2 distances as a way to measure dissimilarity. Using this deep learning method, Ugly Ducklings are identified as outliers which should deserve more attention from the examining physician. We evaluate through comparison with dermatologists, and achieve a sensitivity rate of 72.1% and diagnostic accuracy of 94.2% on the held-out test set. © 2021 IEEE.","10.1109/CVPRW53098.2021.00202","","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116046828&doi=10.1109%2fCVPRW53098.2021.00202&partnerID=40&md5=a68c878ac933021e12cc79e73dedc995"
"Introducing frequency representation into convolution neural networks for medical image segmentation via twin-Kernel Fourier convolution","Tang X.; Peng J.; Zhong B.; Li J.; Yan Z.","2021","0","1","0","0","0","Unique","0","","","","","","","Background and objective: For medical image segmentation, deep learning-based methods have achieved state-of-the-art performance. However, the powerful spectral representation in the field of image processing is rarely considered in these models. Methods: In this work, we propose to introduce frequency representation into convolution neural networks (CNNs) and design a novel model, tKFC-Net, to combine powerful feature representation in both frequency and spatial domains. Through the Fast Fourier Transform (FFT) operation, frequency representation is employed on pooling, upsampling, and convolution without any adjustments to the network architecture. Furthermore, we replace original convolution with twin-Kernel Fourier Convolution (t-KFC), a new designed convolution layer, to specify the convolution kernels for particular functions and extract features from different frequency components. Results: We experimentally show that our method has an edge over other models in the task of medical image segmentation. Evaluated on four datasets—skin lesion segmentation (ISIC 2018), retinal blood vessel segmentation (DRIVE), lung segmentation (COVID-19-CT-Seg), and brain tumor segmentation (BraTS 2019), the proposed model achieves outstanding results: the metric F1-Score is 0.878 for ISIC 2018, 0.8185 for DRIVE, 0.9830 for COVID-19-CT-Seg, and 0.8457 for BraTS 2019. Conclusion: The introduction of spectral representation retains spectral features which result in more accurate segmentation. The proposed method is orthogonal to other topology improvement methods and very convenient to be combined. © 2021 Elsevier B.V.","10.1016/j.cmpb.2021.106110","Convolution neural networks; Frequency representation; Medical image segmentation; U-Net","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105689974&doi=10.1016%2fj.cmpb.2021.106110&partnerID=40&md5=a1ef6233e72b5d7b4b932bad1702278c"
"SegCaps: An efficient SegCaps network-based skin lesion segmentation in dermoscopic images","Kosgiker G.M.; Deshpande A.; Kauser A.","2021","1","1","0","0","0","Unique","0","","","","","","","This research aims to improve the efficiency of skin lesion segment locations for the given input image of skin cancer using a combination of recently modified segmentation algorithms. Skin lesion segmentation is still a challenging task in medical image analysis because of the low contrast and high noise produced by dermoscopic imaging. Previous works extracted spatially-oriented information but failed in terms of training. They were based on convolutional neural networks (CNNs), which require extensive training time. Current results show 91% to 93% efficiency in segmentation, but the proposed segmentation capsule network (SegCaps) in this research has improved it up to 98% by adding four pre-processing sequential processes in combinations with SegCaps algorithms. The performance of the proposed SegCaps model was evaluated on two different datasets—ISBI 2017 and PH2 and implemented on the MatlabR2017b software. The chosen metrics were Jaccard co-efficient, dice similarity co-efficient, accuracy, sensitivity, and specificity for validation. © 2021 Wiley Periodicals LLC.","10.1002/ima.22545","deep learning; dermoscopic images; multi-level preprocessing; SegCaps model; skin lesion segmentation","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099801529&doi=10.1002%2fima.22545&partnerID=40&md5=a375b725533f11da3da56acfc7360d65"
"Dark corner artefact and diagnostic performance of a market-approved neural network for skin cancer classification","Sies K.; Winkler J.K.; Fink C.; Bardehle F.; Toberer F.; Kommoss F.K.F.; Buhl T.; Enk A.; Rosenberger A.; Haenssle H.A.","2021","1","1","0","0","0","Unique","0","","","","","","","Background and objectives: Convolutional neural networks (CNN) have proven dermatologist-level performance in skin lesion classification. Prior to a broader clinical application, an assessment of limitations is crucial. Therefore, the influence of a dark tubular periphery in dermatoscopic images (also called dark corner artefact [DCA]) on the diagnostic performance of a market-approved CNN for skin lesion classification was investigated. Patients and methods: A prospective image set of 233 skin lesions (60 malignant, 173 benign) without DCA (control-set) was modified to show small, medium or large DCA. All 932 images were analyzed by a market-approved CNN (Moleanalyzer-Pro®, FotoFinder Systems), providing malignancy scores (range 0–1) with the cut-off > 0.5 indicating malignancy. Results: In the control-set the CNN achieved a sensitivity of 90.0 % (79.9 % – 95.3 %), a specificity of 96.5 % (92.6 % – 98.4 %), and an area under the curve (AUC) of receiver operating characteristics (ROC) of 0.961 (0.932 – 0.989). Comparable diagnostic performance was observed in the DCAsmall-set and DCAmedium-set. Conversely, in the DCAlarge-set significantly increased malignancy scores triggered a significantly decreased specificity (87.9 % [82.2 % – 91.9 %], P < 0.001), non-significantly increased sensitivity (96.7 % [88.6 % – 99.1 %]) and unchanged ROC-AUC of 0.962 (0.935 – 0.989). Conclusions: Convolutional neural network classification was robust in images with small and medium DCA, but impaired in images with large DCA. Physicians should be aware of this limitation when submitting images to CNN classification. © 2021 The Authors. Journal der Deutschen Dermatologischen Gesellschaft published by John Wiley & Sons Ltd on behalf of Deutsche Dermatologische Gesellschaft.","10.1111/ddg.14384","","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105490731&doi=10.1111%2fddg.14384&partnerID=40&md5=9cabfb7c6704ca378990d43844299831"
"FRACTAL MODEL FOR SKIN CANCER DIAGNOSIS USING PROBABILISTIC CLASSIFIERS","Jacob S.; Rosita J.D.","2021","1","1","0","0","0","Unique","0","","","","","","","The early detection of skin cancer can lead to high prognosis rate. Thus it is very important to identify abnormalities in skin as early as possible. However, the detection of abnormalities at their early stages is a challenging task since the shape and colour of the abnormalities vary with different persons. In this study, fractal model for skin cancer diagnosis is developed. Differential Box Counting (DBC) method is implemented to get the fractal dimension from the dermoscopic images from two databases; International Skin Imaging Collaboration (ISIC) and PH2 database. The fractal features are classified using a parametric and non-parametric classification approach. The system provides promising results for skin cancer diagnosis with 96.5% accuracy on PH2 images and 91.5% accuracy on ISIC database images using the non-parametric classifier whereas parametric classifier gives 95% (PH2) and 90% (ISIC) images. © 2021, XLESCIENCE. All rights reserved.","10.29284/ijasis.7.1.2021.21-29","fractal model; non-parametric classification; parametric classification; Skin cancer diagnosis","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121430532&doi=10.29284%2fijasis.7.1.2021.21-29&partnerID=40&md5=75612412bac6db104c726c1bed05cd65"
"Uncertainty-aware temporal self-learning (UATS): Semi-supervised learning for segmentation of prostate zones and beyond","Meyer A.; Ghosh S.; Schindele D.; Schostak M.; Stober S.; Hansen C.; Rak M.","2021","0","1","0","0","0","Unique","0","","","","","","","Various convolutional neural network (CNN) based concepts have been introduced for the prostate's automatic segmentation and its coarse subdivision into transition zone (TZ) and peripheral zone (PZ). However, when targeting a fine-grained segmentation of TZ, PZ, distal prostatic urethra (DPU) and the anterior fibromuscular stroma (AFS), the task becomes more challenging and has not yet been solved at the level of human performance. One reason might be the insufficient amount of labeled data for supervised training. Therefore, we propose to apply a semi-supervised learning (SSL) technique named uncertainty-aware temporal self-learning (UATS) to overcome the expensive and time-consuming manual ground truth labeling. We combine the SSL techniques temporal ensembling and uncertainty-guided self-learning to benefit from unlabeled images, which are often readily available. Our method significantly outperforms the supervised baseline and obtained a Dice coefficient (DC) of up to 78.9%, 87.3%, 75.3%, 50.6% for TZ, PZ, DPU and AFS, respectively. The obtained results are in the range of human inter-rater performance for all structures. Moreover, we investigate the method's robustness against noise and demonstrate the generalization capability for varying ratios of labeled data and on other challenging tasks, namely the hippocampus and skin lesion segmentation. UATS achieved superiority segmentation quality compared to the supervised baseline, particularly for minimal amounts of labeled data. © 2021 Elsevier B.V.","10.1016/j.artmed.2021.102073","Biomedical segmentation; Prostate zones; Semi-supervised deep learning","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104658608&doi=10.1016%2fj.artmed.2021.102073&partnerID=40&md5=feb5bd756dfad84d89ed3bfedb6018b4"
"Multi-Class Primary Morphology Lesions Classification Using Deep Convolutional Neural Network","Vakili N.; Krathu W.; Laomaneerattanaporn N.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Skin diseases are becoming the most prevalent health concern among all nations worldwide. Recognition of skin lesion, abnormal change usually caused by disease or infection in the skin is the first step in diagnosing skin diseases. In dermatology, morphology skin lesions occur due to the disease process's direct result and indicate categorizing a skin lesions' structure and appearance. In this work, we focus on primary skin lesion classification, particularly early-stage detection, and present a deep learning approach to classify images containing skin lesions, macule, nodule, papule, plaque pustule, wheal, and bulla. We applied deep learning techniques for classifying such images into seven classes covering the aforementioned types of lesion. In particular, we performed experiments on pre-trained deep convolutional neural network models to find the most accuracy one. The result shows that the pre-trained model ResNet-50 after the training and testing can achieve satisfactory accuracy of 85.95%. © 2021 ACM.","10.1145/3468784.3468887","Convolutional neural networks; Deep model; Detection; Keyword: Skin disease; Primary lesions; ResNet-50; Transfer learning","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112226985&doi=10.1145%2f3468784.3468887&partnerID=40&md5=ee27e01318c6b13ff637bf4f4fa9711d"
"Model learning analysis of 3D optoacoustic mesoscopy images for the classification of atopic dermatitis","Park S.; Saw S.N.E.E.; Li X.; Paknezhad M.; Coppola D.; Dinish U.S.; Ebrahim Attia A.B.; Yew Y.W.; Guan Thng S.T.; Lee H.K.; Olivo M.","2021","0","1","0","0","0","Unique","0","","","","","","","Atopic dermatitis (AD) is a skin inflammatory disease affecting 10% of the population worldwide. Raster-scanning optoacoustic mesoscopy (RSOM) has recently shown promise in dermatological imaging. We conducted a comprehensive analysis using three machine-learning models, random forest (RF), support vector machine (SVM), and convolutional neural network (CNN) for classifying healthy versus AD conditions, and sub-classifying different AD severities using RSOM images and clinical information. CNN model successfully differentiates healthy from AD patients with 97% accuracy. With limited data, RF achieved 65% accuracy in sub-classifying AD patients into mild versus moderate-severe cases. Identification of disease severities is vital in managing AD treatment. © 2021 Optical Society of America under the terms of the OSA Open Access Publishing Agreement.","10.1364/BOE.415105","","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107026310&doi=10.1364%2fBOE.415105&partnerID=40&md5=da04a94690938b6d6dd550e6ea285636"
"Whole-slide margin control through deep learning in Mohs micrographic surgery for basal cell carcinoma","van Zon M.C.M.; van der Waa J.D.; Veta M.; Krekels G.A.M.","2021","0","1","0","0","0","Unique","0","","","","","","","Background: Basal cell carcinoma (BCC) is the most common type of skin cancer with incidence rates rising each year. Mohs micrographic surgery (MMS) is most often chosen as treatment for BCC on the face for which each frozen section has to be histologically analysed to ensure complete tumor removal. This causes a heavy burden on health economics. Objectives: To develop and evaluate a deep learning model for the automated detection of BCC-negative slides and classification of BCC in histopathology slides of MMS based on whole-slide image (WSI). Methods: Two deep learning models were developed on the basis of 171 digitized H&E frozen slides from 70 different patients. The first model had a U-Net architecture and was used for the segmentation of BCC. A subsequent convolutional neural network used the segmentation to classify the whole slide as BCC or BCC-negative. Results: Quantitative evaluation over manually labelled ground truth data resulted in a Dice score of 0.66 for the segmentation of BCC and an area under the receiver operating characteristic curve (AUC) of 0.90 for the slide-level classification. Conclusions: This study demonstrates that through WSIs deep learning models may be a feasible option to improve the clinical workflow and reduce costs in histological analysis of BCC in MMS. © 2021 John Wiley & Sons A/S. Published by John Wiley & Sons Ltd","10.1111/exd.14306","basal cell carcinoma; deep learning; dermatopathology; digital pathology; Mohs micrographic surgery","29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101923354&doi=10.1111%2fexd.14306&partnerID=40&md5=52969d02aac79e7e4975b7930377a832"
"A Visually Interpretable Deep Learning Framework for Histopathological Image-Based Skin Cancer Diagnosis","Jiang S.; Li H.; Jin Z.","2021","1","1","0","0","0","Unique","0","","","","","","","Owing to the high incidence rate and the severe impact of skin cancer, the precise diagnosis of malignant skin tumors is a significant goal, especially considering treatment is normally effective if the tumor is detected early. Limited published histopathological image sets and the lack of an intuitive correspondence between the features of lesion areas and a certain type of skin cancer pose a challenge to the establishment of high-quality and interpretable computer-aided diagnostic (CAD) systems. To solve this problem, a light-weight attention mechanism-based deep learning framework, namely, DRANet, is proposed to differentiate 11 types of skin diseases based on a real histopathological image set collected by us during the last 10 years. The CAD system can output not only the name of a certain disease but also a visualized diagnostic report showing possible areas related to the disease. The experimental results demonstrate that the DRANet obtains significantly better performance than baseline models (i.e., InceptionV3, ResNet50, VGG16, and VGG19) with comparable parameter size and competitive accuracy with fewer model parameters. Visualized results produced by the hidden layers of the DRANet actually highlight part of the class-specific regions of diagnostic points and are valuable for decision making in the diagnosis of skin diseases. © 2013 IEEE.","10.1109/JBHI.2021.3052044","Attention mechanism; computer-aided diagnostic system; model visualization; skin histopathological image","94","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099724270&doi=10.1109%2fJBHI.2021.3052044&partnerID=40&md5=bc16eb40956e7b9944b0e992991f8d3b"
"Skin cancer detection: A review using deep learning techniques","Dildar M.; Akram S.; Irfan M.; Khan H.U.; Ramzan M.; Mahmood A.R.; Alsaiari S.A.; Saeed A.H.M.; Alraddadi M.O.; Mahnashi M.H.","2021","1","1","0","0","0","Unique","0","","","","","","","Skin cancer is one of the most dangerous forms of cancer. Skin cancer is caused by un-repaired deoxyribonucleic acid (DNA) in skin cells, which generate genetic defects or mutations on the skin. Skin cancer tends to gradually spread over other body parts, so it is more curable in initial stages, which is why it is best detected at early stages. The increasing rate of skin cancer cases, high mortality rate, and expensive medical treatment require that its symptoms be diagnosed early. Considering the seriousness of these issues, researchers have developed various early detection techniques for skin cancer. Lesion parameters such as symmetry, color, size, shape, etc. are used to detect skin cancer and to distinguish benign skin cancer from melanoma. This paper presents a detailed systematic review of deep learning techniques for the early detection of skin cancer. Research papers published in well-reputed journals, relevant to the topic of skin cancer diagnosis, were analyzed. Research findings are presented in tools, graphs, tables, techniques, and frameworks for better understanding. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/ijerph18105479","Deep learning; Deep neural network (DNN); Machine learning; Melanoma; Skin lesion; Support vector machine (SVM)","414","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106067977&doi=10.3390%2fijerph18105479&partnerID=40&md5=7dd189aa435681f27ee3364836446712"
"Retraction: Classification of Malignant Melanoma using Convolutional Neural Networks","Vijeya Kaveri V.; Meenakshi V.; Saran Karthik K.A.; Shri Raam S.","2021","0","1","0","0","0","Unique","0","","","","","","","Human cancer is one of the world's most deadly diseases caused due to genetic disruption of skin cells and several molecular mutations. Skin cancer remains the most predominant form of cancer in human beings. The major goal is to detect skin cancer in early stages by research and analyse it using various techniques such as segmentation and feature extraction. The diagnosis of malignant melanoma skin cancer is done by dermatologist by examining skin and physical biopsy to determine the accurate stage of melanoma. It is developed because of high accumulation of melanin in the dermis layer of the skin. ABCD law is used in along with dermoscopy technology to detect malignant melanoma skin cancer. Image Acquisition Technique, pre-processing, segmentation, distinguishing function for skin Feature Selection, which specifies lesion characterization and classification methods are all conducted in this project for melanoma skin lesion characterization. We used symmetry detection, border detection, colour and diameter detection, as well as feature extraction to remove texture based features using a digital image processing technique. The deep Neural Network was proposed here to characterize the benign or malignant stage. © Published under licence by IOP Publishing Ltd.","10.1088/1742-6596/1916/1/012070","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107348939&doi=10.1088%2f1742-6596%2f1916%2f1%2f012070&partnerID=40&md5=9bad6070a5d6981ec1324c04738e3689"
"Detection of stages of melanoma using deep learning","N. M. Saravana Kumar; K. Hariprasath; S. Tamilselvi; A. Kavinya; N. Kaviyavarshini","2021","0","1","0","0","0","First occurrence","0","","","","","","","Human Skin is the most utilized and largest organs next to blood acts as an outer protective covering of the entire body to protect the underlying internal organs from harmful UV rays, dust and pollution. One of the major concerns of such harmful rays is its ability that affects the human skin by mutating the DNA sequence of melanocytes cells which in turn stimulates an uncontrollable rapid growth of infelicitous cells as undesirable peripheral protuberances and in later progressive, prolonged and well-infected stages, it starts to grew inwards as well and reports majority of the deaths due to a skin cancer across the world. The premature detection of the melanoma enables the complete cure of the cancer and it significantly drags down the death rate. Though many research works concentrated on detecting the melanoma, this work narrow down the scope in finding the levels of skin carcinoma by using deep learning methodologies that boosts the accuracy in the detection of melanoma and can give an appropriate treatment with respect to the level of the cancer. In this work, state-of-art techniques like Random Forest, Support Vector Machine, Artificial Neural network along with the proposed fusion-based Deep learning methodology has been experimented. Various performance metric such as Mean Square Error, Peak Signal to Noise ratio for assessing the quality of the pre-processing strategy and Accuracy, Precision and Recall for evaluating the proposed methodology. With the experimental results, it is evident that the Deep learning using the feature-fusion methodology has the accuracy of 97% than other state-of-art techniques. On comparing with recent works done using same methodology, the proposed work has 11% more accuracy than the existing well-known works. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC part of Springer Nature.","10.1007/s11042-021-10572-1","Deep Learning; HAM10000; Levels of melanoma; Melanoma; Skin cancer","23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101230948&doi=10.1007%2fs11042-021-10572-1&partnerID=40&md5=f2b30bc64380d4c1a91591fcf249f019"
"Identification of risk of occurring skin cancer (Melanoma) using convolutional neural network (CNN)","Shawon M.; Majumder A.; Mahmud A.; Abedin K.F.; Mishu M.C.","2021","1","1","0","0","0","Unique","0","","","","","","","Skin cancer is one of the most common malignancy in human, has drawn attention from researchers around the world. As skin cancer can turn into fatal if not treated in its earliest stages, the necessity of devising automated skin cancer diagnosis system that can automatically detect skin cancer efficiently in its earliest stage in a faster process than traditional one is of crucial importance. In this paper, a computer aided skin cancer diagnosis system based Convolutional Neural Network method has been shown. Our proposed system consists of five stages namely image acquisition, image preprocessing, image segmentation, feature extraction and classification We remove hair any noise from the images using dull then use median filter to smoothen the images. Next, k-means algorithm was applied for image segmentation on the preprocessed images. Finally, the segmented images were fed into CNN model for feature extraction and classification. The developed system can classify benign and melanoma type skin cancers from Dermoscopic images as accurate as 80.47%. While developing the skin cancer detection system, we compare accuracy score of other models such as Artificial Neural Network (ANN), K-Nearest Neighbor (KNN) and Random Forest with our proposed system. The proposed method has been tested on 'ISIC Challenge 2016' test dataset and an accuracy rate of 80.47% was obtained for accurately classifying benign and malignant skin lesions by our proposed model. © 2021 AIUB Office of Research and Publication. All rights reserved.","10.53799/AJSE.V20I2.140","Accuracy; Convolutional neural network (CNN); Dermoscopy; K-means; Skin cancer","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112412714&doi=10.53799%2fAJSE.V20I2.140&partnerID=40&md5=4f458629e9ad60cda4e2ed9847bdc841"
"Method of Cleaning Hair Structures for Intellectual Image Classification of Skin Neoplasms","Lyakhova U.A.; Lyakhov P.A.","2021","1","1","0","0","0","First occurrence","0","","","","","","","The main problem in the application of artificial intelligence in the field of dermatology is the low level of accuracy of recognition and classification systems. This paper proposes a method for identifying and cleaning hair, as well as evaluating the effectiveness of the method using a pre-trained neural network. When examining pigmented lesions, the presence of hair in images can obscure important diagnostic information, reducing the effectiveness and quality of examination results. This method allows the preparation of dermatoscopic images for further automated classification and diagnosis of pigmented skin lesions. Modeling was carried out using the MatLab R2019b software package on clinical dermatoscopic images from the international open archive ISIC Melanoma Project. The proposed method made it possible to achieve the accuracy of recognition of images of pigmented skin lesions in 10 diagnostically important categories up to 80.81%. The use of neural network classification systems for dermatoscopic images of pigmented skin formations with a preliminary stage of hair removal will allow specialists to increase the efficiency and speed of diagnosis and start treatment of the disease at an earlier stage. © 2021 IEEE.","10.1109/USBEREIT51232.2021.9455057","convolutional neural networks; dermatoscopic images; digital image processing; hair removal; medical image processing; melanoma; pigmented skin lesions","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113730631&doi=10.1109%2fUSBEREIT51232.2021.9455057&partnerID=40&md5=56988765315f1b6c4405a16b1f2e153b"
"Artificial neural networks and pathologists recognize basal cell carcinomas based on different histological patterns","Kimeswenger S.; Tschandl P.; Noack P.; Hofmarcher M.; Rumetshofer E.; Kindermann H.; Silye R.; Hochreiter S.; Kaltenbrunner M.; Guenova E.; Klambauer G.; Hoetzenecker W.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Recent advances in artificial intelligence, particularly in the field of deep learning, have enabled researchers to create compelling algorithms for medical image analysis. Histological slides of basal cell carcinomas (BCCs), the most frequent skin tumor, are accessed by pathologists on a daily basis and are therefore well suited for automated prescreening by neural networks for the identification of cancerous regions and swift tumor classification. In this proof-of-concept study, we implemented an accurate and intuitively interpretable artificial neural network (ANN) for the detection of BCCs in histological whole-slide images (WSIs). Furthermore, we identified and compared differences in the diagnostic histological features and recognition patterns relevant for machine learning algorithms vs. expert pathologists. An attention-ANN was trained with WSIs of BCCs to identify tumor regions (n = 820). The diagnosis-relevant regions used by the ANN were compared to regions of interest for pathologists, detected by eye-tracking techniques. This ANN accurately identified BCC tumor regions on images of histologic slides (area under the ROC curve: 0.993, 95% CI: 0.990–0.995; sensitivity: 0.965, 95% CI: 0.951–0.979; specificity: 0.910, 95% CI: 0.859–0.960). The ANN implicitly calculated a weight matrix, indicating the regions of a histological image that are important for the prediction of the network. Interestingly, compared to pathologists’ eye-tracking results, machine learning algorithms rely on significantly different recognition patterns for tumor identification (p < 10−4). To conclude, we found on the example of BCC WSIs, that histopathological images can be efficiently and interpretably analyzed by state-of-the-art machine learning techniques. Neural networks and machine learning algorithms can potentially enhance diagnostic precision in digital pathology and uncover hitherto unused classification patterns. © 2020, The Author(s), under exclusive licence to United States & Canadian Academy of Pathology.","10.1038/s41379-020-00712-7","","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096019722&doi=10.1038%2fs41379-020-00712-7&partnerID=40&md5=2fb1a37cfc251f4a25a0fa7b461f49ad"
"Detection and Diagnosis of Skin Cancer Based on K-Means Cluster and Convolutional Neural Network","Shihab A.; Salah H.; Mocanu M.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Early detection of skin cancer can contribute significantly in preventing the exacerbation of the condition and its transformation into a benign tumor, reducing the number of deaths in skin cancer. This paper introduces the application of K-means cluster for detecting the skin tumor and the Convolutional Neural Network (CNN) for automatic diagnosis of skin tumor. The specific steps are as follows: The first step reads the skin cancer image, the second step 'preprocessing, which is achieved by applying the Gaussian filter, to improve the skin image and reduce noise, the third step: utilizing K-means cluster applied for segmentation image into two groups. The first group is represented by the background (largest area) and second group represents the skin tumor (least area). The last step (The fourth one): applying CNN to classify the skin tumor as benign or malignant. The results show that the proposed technique functions more efficiently by achieving 99.7% accuracy, obtained from the total of 22, 080 medical images based on DermQuest Digital Dataset.  © 2021 IEEE.","10.1109/CSCS52396.2021.00031","Automatic Thresholding; Convolutional Neural Network (CNN); Dermoscopy; Image Segmentation; K-Means Cluster; Melanoma; Skin Cancer","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112085799&doi=10.1109%2fCSCS52396.2021.00031&partnerID=40&md5=40c093c623e222deb1f885ce32e54043"
"Melanoma classification employing inter neighbor statistical color and mean order pattern texture feature","Seeja R.D.; Suresh A.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Automatic melanoma diagnosis is very important to lower the mortality rate by detecting the disease in earlier stages and accurate diagnosis. The main aim of this paper is to improve the classification accuracy of melanoma using a proposed novel color and texture feature descriptor. Initially, the skin lesion area of input dermoscopy image is segmented using a convolutional neural network-based U-Net algorithm. Then extract discriminate color, texture and combined color-texture features with the help of proposed Inter Neighbor Statistical Color Feature (INSCF), Inter Neighbor Mean Order Pattern (INMOP) and Inter Neighbor Statistical Color Mean Order Pattern (INSCMOP) by incorporating inter color channel values. This proposed feature descriptors are capable to discriminate the detailed information derived from spatial inter-chromatic texture patterns of different channels within a region. Finally, three classifiers namely, K-Nearest Neighbors (KNN), Random Forest (RF), and Support Vector Machine (SVM) are used to classify the skin lesion in a dermoscopic image as benign lesion or melanoma. Experimental results indicate that the proposed INSCMOP with Random Forest classifier achieves the highest classification performance based on accuracy of 93.27% for ISIC 2016 dataset, 86% for ISIC 2017 dataset and 92.31% for ISBI 2019 dataset. Moreover, comparing the proposed method with other systems shows that this approach has an excellent performance in melanoma classification. In this research, without any manual interaction, the classification process is performed in an automated way. It would set up a valuable assistance for dermatologist in clinical practice. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC part of Springer Nature.","10.1007/s11042-021-10685-7","Accuracy; Benign; Dermoscopy; Inter neighbor mean order pattern; Inter neighbor statistical color feature; Melanoma","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102186968&doi=10.1007%2fs11042-021-10685-7&partnerID=40&md5=4a16ce557bf8013131800befb23d6770"
"FRNet: an end-to-end feature refinement neural network for medical image segmentation","Wang D.; Hu G.; Lyu C.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Medical image segmentation is a crucial but challenging task for computer-aided diagnosis. In recent years, fully convolutional network-based methods have been widely applied to medical image segmentation. U-shape-based approaches are one of the most successful structures in this medical field. However, the consecutive down-sampling operations in the encoder lead to the loss of spatial information, which is important for medical image segmentation. In this paper, we present a novel lightweight end-to-end feature refinement network (FRNet) to address this issue. The structure of our model is simple and efficient. Specifically, the network adopts an encoder-decoder network as backbone, where two additional paths, spatial refinement path and semantic refinement path, are applied on the encoder and decoder, respectively, to improve the detailed representation ability and discriminative ability of our model. In addition, we introduce a feature adaptive fusion block (FAF block) that effectively combines features of different depths. The proposed FRNet can be trained in an end-to-end way. We have evaluated our method on three different medical image segmentation tasks. Experimental results show that FRNet has better performance than the state-of-the-art approaches. It achieves a high average accuracy without any post-processing of 0.968 and 0.936 for blood vessel segmentation and skin lesion segmentation, respectively. We further demonstrate that our method can be easily applied to other network structures to improve their performance. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.","10.1007/s00371-020-01855-z","Biomedical segmentation; Feature refinement path; Fully convolutional neural network; Retinal vessel segmentation; Skin lesion segmentation","41","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085618879&doi=10.1007%2fs00371-020-01855-z&partnerID=40&md5=202eb98eea811e921d3d003b9c2ec8b5"
"Retraction: Skin Cancer Classification Detection using CNN and SVM","Pushpalatha A.; Dharani P.; Dharini R.; Gowsalya J.","2021","1","1","0","0","0","Unique","0","","","","","","","Skin malignant growth is quite possibly the most commonly seen Malignancy type in people. Skin disease happens because of the un controllable developing of transformations occurring in DNAs developing to certain reasons. Perceiving the malignant growth in beginning phases could build the opportunity of an effective treatment. These days, PC helped finding applications are utilized nearly at each field. From the real dermo scopic images, the first-stage network aims for precise segmentation of the skin lesion. The second-stage network is a classification network that can predict the existence of Melanoma and Squamous Cell Carcinoma in a skin sample. Deep convolutional neural networks, such as Inception-v4, ResNet-152, and DenseNet-161, were trained for melanoma and squamous cell carcinoma detection and seborrheickeratosis classification. U-Net with VGG-16 Encoder was trained to create segmentation masks for lesion segmentation. Resnet engineering achieves the highest precision of 90 percent among the equations used in the proposed models. © Published under licence by IOP Publishing Ltd.","10.1088/1742-6596/1916/1/012148","convolutional neural network; deep learning; machine learning","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107357312&doi=10.1088%2f1742-6596%2f1916%2f1%2f012148&partnerID=40&md5=396298eadca98ebfb07c4f689eb85364"
"Facial Skin Monitoring System Based on Image Processing","Mu H.; Zhang J.; Xu T.","2021","1","1","0","0","0","Unique","0","","","","","","","The face skin quality tester can give reasonable skin care recommendations for the replication situation, so it has a broad market prospect. The current domestic testers have shortcomings such as single detection function, low detection accuracy, complicated operation, expensive price and large volume. This paper studies the image processing algorithm for skin quality index detection, including oil and pigment detection based on HSV color space, pore detection based on dual threshold segmentation and morphological operations, and roughness index detection based on gray-level co-occurrence matrix. And based on the CBS-1800 detection system as the standard, the skin quality index detection algorithm in this paper has been effectively verified. © Published under licence by IOP Publishing Ltd.","10.1088/1742-6596/1881/2/022014","Facial Skin; Oil Detection; Pigment Detection; Pore Detection","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105245623&doi=10.1088%2f1742-6596%2f1881%2f2%2f022014&partnerID=40&md5=644318a5c117f9074abdad9921a3cf4b"
"Matthews correlation coefficient loss for deep convolutional networks: Application to skin lesion segmentation","Abhishek K.; Hamarneh G.","2021","1","1","0","0","0","First occurrence","0","","","","","","","The segmentation of skin lesions is a crucial task in clinical decision support systems for the computer aided diagnosis of skin lesions. Although deep learning-based approaches have improved segmentation performance, these models are often susceptible to class imbalance in the data, particularly, the fraction of the image occupied by the background healthy skin. Despite variations of the popular Dice loss function being proposed to tackle the class imbalance problem, the Dice loss formulation does not penalize misclassifications of the background pixels. We propose a novel metric-based loss function using the Matthews correlation coefficient, a metric that has been shown to be efficient in scenarios with skewed class distributions, and use it to optimize deep segmentation models. Evaluations on three skin lesion image datasets: the ISBI ISIC 2017 Skin Lesion Segmentation Challenge dataset, the DermoFit Image Library, and the PH2 dataset, show that models trained using the proposed loss function outperform those trained using Dice loss by 11.25%, 4.87%, and 0.76% respectively in the mean Jaccard index. The code is available at https://github.com/kakumarabhishek/MCC-Loss.  © 2021 IEEE.","10.1109/ISBI48211.2021.9433782","Loss function; Matthews correlation coefficient; Segmentation; Skin lesion","36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107192299&doi=10.1109%2fISBI48211.2021.9433782&partnerID=40&md5=5e8fb78bc8038cf0e014288c895acb79"
"Development and Assessment of an Artificial Intelligence-Based Tool for Skin Condition Diagnosis by Primary Care Physicians and Nurse Practitioners in Teledermatology Practices","Jain A.; Way D.; Gupta V.; Gao Y.; De Oliveira Marinho G.; Hartford J.; Sayres R.; Kanada K.; Eng C.; Nagpal K.; Desalvo K.B.; Corrado G.S.; Peng L.; Webster D.R.; Dunn R.C.; Coz D.; Huang S.J.; Liu Y.; Bui P.; Liu Y.","2021","1","1","0","0","0","Unique","0","","","","","","","Importance: Most dermatologic cases are initially evaluated by nondermatologists such as primary care physicians (PCPs) or nurse practitioners (NPs). Objective: To evaluate an artificial intelligence (AI)-based tool that assists with diagnoses of dermatologic conditions. Design, Setting, and Participants: This multiple-reader, multiple-case diagnostic study developed an AI-based tool and evaluated its utility. Primary care physicians and NPs retrospectively reviewed an enriched set of cases representing 120 different skin conditions. Randomization was used to ensure each clinician reviewed each case either with or without AI assistance; each clinician alternated between batches of 50 cases in each modality. The reviews occurred from February 21 to April 28, 2020. Data were analyzed from May 26, 2020, to January 27, 2021. Exposures: An AI-based assistive tool for interpreting clinical images and associated medical history. Main Outcomes and Measures: The primary analysis evaluated agreement with reference diagnoses provided by a panel of 3 dermatologists for PCPs and NPs. Secondary analyses included diagnostic accuracy for biopsy-confirmed cases, biopsy and referral rates, review time, and diagnostic confidence. Results: Forty board-certified clinicians, including 20 PCPs (14 women [70.0%]; mean experience, 11.3 [range, 2-32] years) and 20 NPs (18 women [90.0%]; mean experience, 13.1 [range, 2-34] years) reviewed 1048 retrospective cases (672 female [64.2%]; median age, 43 [interquartile range, 30-56] years; 41920 total reviews) from a teledermatology practice serving 11 sites and provided 0 to 5 differential diagnoses per case (mean [SD], 1.6 [0.7]). The PCPs were located across 12 states, and the NPs practiced in primary care without physician supervision across 9 states. The NPs had a mean of 13.1 (range, 2-34) years of experience and practiced in primary care without physician supervision across 9 states. Artificial intelligence assistance was significantly associated with higher agreement with reference diagnoses. For PCPs, the increase in diagnostic agreement was 10% (95% CI, 8%-11%; P <.001), from 48% to 58%; for NPs, the increase was 12% (95% CI, 10%-14%; P <.001), from 46% to 58%. In secondary analyses, agreement with biopsy-obtained diagnosis categories of maglignant, precancerous, or benign increased by 3% (95% CI, -1% to 7%) for PCPs and by 8% (95% CI, 3%-13%) for NPs. Rates of desire for biopsies decreased by 1% (95% CI, 0-3%) for PCPs and 2% (95% CI, 1%-3%) for NPs; the rate of desire for referrals decreased by 3% (95% CI, 1%-4%) for PCPs and NPs. Diagnostic agreement on cases not indicated for a dermatologist referral increased by 10% (95% CI, 8%-12%) for PCPs and 12% (95% CI, 10%-14%) for NPs, and median review time increased slightly by 5 (95% CI, 0-8) seconds for PCPs and 7 (95% CI, 5-10) seconds for NPs per case. Conclusions and Relevance: Artificial intelligence assistance was associated with improved diagnoses by PCPs and NPs for 1 in every 8 to 10 cases, indicating potential for improving the quality of dermatologic care.. © 2021 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","10.1001/jamanetworkopen.2021.7249","","110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105042261&doi=10.1001%2fjamanetworkopen.2021.7249&partnerID=40&md5=79c5774a686c4e31ee9982ed849d8b7e"
"Automated detection and segmentation of brain metastases in malignant melanoma: Evaluation of a dedicated deep learning model","Pennig L.; Shahzad R.; Caldeira L.; Lennartz S.; Thiele F.; Goertz L.; Zopfs D.; Meißner A.-K.; Fürtjes G.; Perkuhn M.; Kabbasch C.; Grau S.; Borggrefe J.; Laukamp K.R.","2021","0","1","0","0","0","Unique","0","","","","","","","BACKGROUND AND PURPOSE: Malignant melanoma is an aggressive skin cancer in which brain metastases are common. Our aim was to establish and evaluate a deep learning model for fully automated detection and segmentation of brain metastases in patients with malignant melanoma using clinical routine MR imaging. MATERIALS AND METHODS: Sixty-nine patients with melanoma with a total of 135 brain metastases at initial diagnosis and available multiparametric MR imaging datasets (T1-/T2-weighted, T1-weighted gadolinium contrast-enhanced, FLAIR) were included. A previously established deep learning model architecture (3D convolutional neural network; DeepMedic) simultaneously operating on the aforementioned MR images was trained on a cohort of 55 patients with 103 metastases using 5-fold cross-validation. The efficacy of the deep learning model was evaluated using an independent test set consisting of 14 patients with 32 metastases. Manual segmentations of metastases in a voxelwise manner (T1-weighted gadolinium contrast-enhanced imaging) performed by 2 radiologists in consensus served as the ground truth. RESULTS: After training, the deep learning model detected 28 of 32 brain metastases (mean volume, 1.0 [SD, 2.4] cm3) in the test cohort correctly (sensitivity of 88%), while false-positive findings of 0.71 per scan were observed. Compared with the ground truth, automated segmentations achieved a median Dice similarity coefficient of 0.75. CONCLUSIONS: Deep learning-based automated detection and segmentation of brain metastases in malignant melanoma yields high detection and segmentation accuracy with false-positive findings of,1 per scan. © 2021 American Society of Neuroradiology. All rights reserved.","10.3174/AJNR.A6982","","32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104111654&doi=10.3174%2fAJNR.A6982&partnerID=40&md5=b78a94db392edeb48a0a080ef73a6d94"
"B-SegNet: Branched-SegMentor network for skin lesion segmentation","Saini S.; Jeon Y.S.; Feng M.","2021","1","1","0","0","0","Unique","0","","","","","","","Melanoma is the most common form of cancer in the world. Early diagnosis of the disease and an accurate estimation of its size and shape are crucial in preventing its spread to other body parts. Manual segmentation of these lesions by a radiologist however is time consuming and error-prone. It is clinically desirable to have an automatic tool to detect malignant skin lesions from dermoscopic skin images. We propose a novel end-to-end convolution neural network(CNN) for a precise and robust skin lesion localization and segmentation. The proposed network has 3 sub-encoders branching out from the main encoder. The 3 sub-encoders are inspired from Coordinate Convolution, Hourglass and Octave Convolutional blocks: Each sub-encoder summarizes different patterns and yet collectively aims to achieve a precise segmentation. We trained our segmentation model just on the ISIC 2018 dataset. To demonstrate the generalizability of our model, we evaluated our model on the ISIC 2018 and unseen datasets including ISIC 2017 and PH2. Our approach showed an average 5% improvement in performance over different datasets, while having less than half of the number of parameters when compared to other state-of-the-arts segmentation models.  © 2021 ACM.","10.1145/3450439.3451873","CNN; coordinate convolution; dermoscopy; melanoma; octave convolution; skin cancer; skin lesion segmentation","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104095656&doi=10.1145%2f3450439.3451873&partnerID=40&md5=8b36c442a0c902e0fc574195c5b64ba6"
"Target attack on biomedical image segmentation model based on multi-scale gradients","Shao M.; Zhang G.; Zuo W.; Meng D.","2021","0","1","0","0","0","Unique","0","","","","","","","Research shows that deep neural networks are vulnerable to adversarial examples due to the highly linear nature of deep neural networks (DNNs). Therefore, adversarial examples involve security of deep learning. However, there is a lack of research on the impact of adversarial examples on the biomedical segmentation model. Since a large part of medical image problems are segmentation problems, this paper analyzes the impact of adversarial examples on image segmentation models based on deep learning. We propose to fool the biomedical segmentation model and generate target segmentation masks with feature space perturbations and cross-entropy loss function. Different from the traditional gradient-based attack methods, which usually use the gradient of the final loss function, this paper adopts a Multi-scale Attack (MSA) method based on multi-scale gradients. Extensive experiments to attack U-Net on the ISIC skin lesion segmentation challenge dataset and the glaucoma optic disc segmentation dataset have proved that the predicted mask generated by this method has a high intersection over union(IoU) and pixel accuracy with the target mask. Besides, the L2 and L∞ distances between the adversarial and clean examples are reduced compared with the state-of-the-art method. © 2020 Elsevier Inc.","10.1016/j.ins.2020.12.013","Adversarial example; Biomedical image segmentation; Deep learning security; Multi-scale gradients; Target attack","24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098734517&doi=10.1016%2fj.ins.2020.12.013&partnerID=40&md5=9310e0aef31ee95fe1becdd1190a2110"
"Classification of skin disease using deep learning neural networks with mobilenet v2 and lstm","Srinivasu P.N.; Sivasai J.G.; Ijaz M.F.; Bhoi A.K.; Kim W.; Kang J.J.","2021","1","1","0","0","0","Unique","0","","","","","","","Deep learning models are efficient in learning the features that assist in understanding complex patterns precisely. This study proposed a computerized process of classifying skin disease through deep learning-based MobileNet V2 and Long Short Term Memory (LSTM). The MobileNet V2 model proved to be efficient with a better accuracy that can work on lightweight computational devices. The proposed model is efficient in maintaining stateful information for precise predictions. A grey-level co-occurrence matrix is used for assessing the progress of diseased growth. The performance has been compared against other state-of-the-art models such as Fine-Tuned Neural Networks (FTNN), Convolutional Neural Network (CNN), Very Deep Convolutional Networks for Large-Scale Image Recognition developed by Visual Geometry Group (VGG), and convolutional neural network architecture that expanded with few changes. The HAM10000 dataset is used and the proposed method has outperformed other methods with more than 85% accuracy. Its robustness in recognizing the affected region much faster with almost 2x lesser computations than the conven-tional MobileNet model results in minimal computational efforts. Furthermore, a mobile application is designed for instant and proper action. It helps the patient and dermatologists identify the type of disease from the affected region’s image at the initial stage of the skin disease. These findings suggest that the proposed system can help general practitioners efficiently and effectively diagnose skin conditions, thereby reducing further complications and morbidity. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/s21082852","Convolutional Neural Network (CNN); Deep Learning; Grey-level correlation; Long Short-Term Memory (LSTM); Mo-bileNet; Mobile platform; MobileNet V2; Neural network; Skin disease","595","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104346425&doi=10.3390%2fs21082852&partnerID=40&md5=b0eeacccf8915152034f85b273ef1496"
"Generation of augmented capillary network optical coherence tomography image data of human skin for deep learning and capillary segmentation","Mekonnen B.K.; Hsieh T.-H.; Tsai D.-F.; Liaw S.-K.; Yang F.-L.; Huang S.-L.","2021","1","1","0","0","0","Unique","0","","","","","","","The segmentation of capillaries in human skin in full-field optical coherence tomography (FF-OCT) images plays a vital role in clinical applications. Recent advances in deep learning techniques have demonstrated a state-of-the-art level of accuracy for the task of automatic medical image segmentation. However, a gigantic amount of annotated data is required for the successful training of deep learning models, which demands a great deal of effort and is costly. To overcome this fundamental problem, an automatic simulation algorithm to generate OCT-like skin image data with augmented capillary networks (ACNs) in a three-dimensional volume (which we called the ACN data) is presented. This algorithm simultaneously acquires augmented FF-OCT and corresponding ground truth images of capillary structures, in which potential functions are introduced to conduct the capillary pathways, and the two-dimensional Gaussian function is utilized to mimic the brightness reflected by capillary blood flow seen in real OCT data. To assess the quality of the ACN data, a U-Net deep learning model was trained by the ACN data and then tested on real in vivo FF-OCT human skin images for capillary segmentation. With properly designed data binarization for predicted image frames, the testing result of real FF-OCT data with respect to the ground truth achieved high scores in performance metrics. This demonstrates that the proposed algorithm is capable of generating ACN data that can imitate real FF-OCT skin images of capillary networks for use in research and deep learning, and that the model for capillary segmentation could be of wide benefit in clinical and biomedical applications. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/diagnostics11040685","Augmented dataset generation; Deep learning; Full-field optical coherence tomography; Image binarization; Skin capillary segmentation; U-Net","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109105646&doi=10.3390%2fdiagnostics11040685&partnerID=40&md5=264e512f49de6ed4a1b892fab86ffcf1"
"Dermatological expert system implementing the ABCD rule of dermoscopy for skin disease identification","Chatterjee S.; Dey D.; Munshi S.; Gorai S.","2021","1","1","0","0","0","Unique","0","","","","","","","Doctors and radiologists generally follow the standard ABCD rule of dermoscopy for differentiating the malignant and benign skin lesions. The estimation of the dermoscopic score by visual inspection only, may lead to the inaccurate diagnosis of the disease at an early stage. In this work, the ABCD attributes have been improvised and quantified in a dermatological expert system (DermESy) for the differentiation of malignant and benign lesions. DermESy, a rule based expert system has been developed by implementing dermatologist's knowledge with proper quantification of the dermoscopic findings. Using DermESy, the dermoscopic images have been categorized as malignant, benign and suspicious lesions based on the estimated total dermoscopic score (TDS), similar to the findings of an expert. To estimate the TDS, shape, brightness and color variations are considered to modify the ‘A’ score. The color information extraction algorithm is introduced to extract significant color regions to quantify the ‘C’ score. To find the appropriate ‘D’ score of a skin lesion, dermoscopic structures segmentation algorithms have been introduced. In this work, the ABCD rule of dermoscopy has been improvised by considering the spatial properties of dermoscopic structures for improved identification of malignant lesions. An explanatory subsystem is implemented in DermESy to assist the dermatologist with proper in-detail visualization. DermESy has differentiated the benign and malignant skin lesions with 97.69% sensitivity, 97.97% specificity and 97.86% accuracy. The TDS evaluated by DermESy is verified and compared against expert dermatologist's TDS scores of same dermoscopy images to establish the reliability and robustness of the proposed system. © 2020 Elsevier Ltd","10.1016/j.eswa.2020.114204","Benign; Dermoscopic images; Expert system; Malignant; Skin disease","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097005379&doi=10.1016%2fj.eswa.2020.114204&partnerID=40&md5=daa1aa535c176f6ce2de76809bafe24d"
"Instance segmentation based on deep convolutional neural networks and transfer learning for unconstrained psoriasis skin images","Lin G.-S.; Lai K.-T.; Syu J.-M.; Lin J.-Y.; Chai S.-K.","2021","1","1","0","0","0","Unique","0","","","","","","","In this paper, an efficient instance segmentation scheme based on deep convolutional neural networks is proposed to deal with unconstrained psoriasis images for computer-aided diagnosis. To achieve instance segmentation, the You Only Look At CoefficienTs (YOLACT) network composed of backbone, feature pyramid network (FPN), Protonet, and prediction head is used to deal with psoriasis images. The backbone network is used to extract feature maps from an image, and FPN is designed to generate multiscale feature maps for effectively classifying and localizing objects with multiple sizes. The prediction head is used to predict the classification information, bounding box information, and mask coefficients of objects. Some prototypes generated by Protonet are combined with mask coefficients to estimate the pixel-level shapes for objects. To achieve instance segmentation for unconstrained psoriasis images, YOLACT++ with a pretrained model is retrained via transfer learning. To evaluate the performance of the proposed scheme, unconstrained psoriasis images with different severity levels are collected for testing. As for subjective testing, the psoriasis regions and normal skin areas can be located and classified well. The four performance indices of the proposed scheme were higher than 93% after cross validation. About object localization, the Mean Average Precision (mAP) rates of the proposed scheme were at least 85.9% after cross validation. As for efficiency, the frames per second (FPS) rate of the proposed scheme reached up to 15. In addition, the F1_score and the execution speed of the proposed scheme were higher than those of the Mask Region- Based Convolutional Neural Networks (R-CNN)-based method. These results show that the proposed scheme based on YOLACT++ can not only detect psoriasis regions but also distinguish psoriasis pixels from background and normal skin pixels well. Furthermore, the proposed instance segmentation scheme outperforms the Mask R-CNN-based method for unconstrained psoriasis images. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/app11073155","Computer-aided diagnosis; Deep convolutional neural network; Instance segmentation; Mask R-CNN; YOLACT++","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104080178&doi=10.3390%2fapp11073155&partnerID=40&md5=22c79ea97cc42601a982e766df3b4341"
"Klasifikasi Citra Pigmen Kanker Kulit Menggunakan Convolutional Neural Network","Hakim L.; Sari Z.; Handhajani","2021","0","1","0","0","0","Unique","0","","","","","","","Skin cancer is a very common form of cancer that can be found in the United States with annual treatment costs exceeding $ 8 billion. New innovations in the classification and detection of skin cancer using artificial neural networks continue to develop to help the medical and medical world in analyzing images accurately and accurately. Researchers propose to classify skin cancer pigments by focusing on two classes, namely non-melanocytic malignant and benign, where the skin cancer category which is classified into the non-melanocytic class is Actinic keratoses, Basal cell carcinoma. While skin cancers that are classified into Benign are Benign keratosis like lesions, dermatofibrama, vascular lessions. The method used in this study is Convolutional Neural Network (CNN) with a model architecture using 8 Convolutional 2D layers which have filters (16, 16, 32, 32, 64, 64, 128, 128). The first input layers are (20,20). and the following layers (5,5 and 3,3), the types of pooling used in this study are MaxPooling and AveragePooling. The Fully Connected Layer used is (256, 128) and uses a Dropout (0.2). The dataset is obtained from the International Skin Imaging Collaboration (ISIC) 2018 with a total of 10015 images. Based on the results of the test and evaluation reports, an accuracy of 75% is obtained. with the highest precision and recall values found in the Benign class, namely 0.80 and 0.82 respectively and the f1_score value of 0.81. © 2021, Ikatan Ahli Informatika Indonesia. All rights reserved.","10.29207/resti.v5i2.3001","CNN; convolution; Deep Learning; Neural Network; skin cancer","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003023022&doi=10.29207%2fresti.v5i2.3001&partnerID=40&md5=844b886457bbce06052ec823c1991a6e"
"HOSMI-LBP-BASED FEATURE EXTRACTION for MELANOMA DETECTION USING HYBRID DEEP LEARNING MODELS","Kumar Tiwari A.; Kumar Mishra M.; Ranjan Panda A.; Panda B.","2021","0","1","0","0","0","Unique","0","","","","","","","""Melanoma is a serious form of skin cancer that begins in cells known as melanocytes and more dangerous due to its spreading ability to other organs more rapidly if it is not treated at an early stage"". This paper aims to propose a Melanoma detection methodology that includes four major phases: ""(i) pre-processing (ii) segmentation (iii) the proposed feature extraction and (iv) classification"". Initially, pre-processing is performed, where the input image is subjected to processing like resizing and edge smoothening. Subsequently, segmentation is carried out by the Otsu thresholding process. In the feature extraction phase, the proposed Higher-Order Standardized Moment Induced-Local Binary Patterns (HOSMI-LBP)-based features are extracted. These features are then subjected to a classification process for classifying the disease. For this, it is planned to use a hybrid classification framework, where the Convolutional Neural Network (CNN) and the Neural Network (NN) are deployed. Two-phase of classification gets processed: the extracted features are subjected to NN; the input image is directly classified using an optimized CNN framework. Finally, the classified outputs from NN and optimized CNN are averaged and the final output is considered as detected output. Particularly, the weight and initial rate of CNN is optimized using the proposed algorithm known as the Sea Lion Integrated Grey Wolf Algorithm (SLI-GWO) method that hybrid the concepts of both Sea Lion Optimization (SLnO) and Grey Wolf Optimization (GWO) algorithm. At last, the proposed work performance is computed with traditional systems in terms of various measures. © 2021 World Scientific Publishing Company.","10.1142/S0219519421500299","feature extraction; HOSMI-LBP; optimized NN; Segmentation; SLI-GWO method","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103290349&doi=10.1142%2fS0219519421500299&partnerID=40&md5=c74d32c8af4f6739eb48378994f6751a"
"A novel convolutional neural network for the diagnosis and classification of rosacea: Usability study","Zhao Z.; Wu C.-M.; Zhang S.; He F.; Liu F.; Wang B.; Huang Y.; Shi W.; Jian D.; Xie H.; Yeh C.-Y.; Li J.","2021","0","1","0","0","0","Unique","0","","","","","","","Background: Rosacea is a chronic inflammatory disease with variable clinical presentations, including transient flushing, fixed erythema, papules, pustules, and phymatous changes on the central face. Owing to the diversity in the clinical manifestations of rosacea, the lack of objective biochemical examinations, and nonspecificity in histopathological findings, accurate identification of rosacea is a big challenge. Artificial intelligence has emerged as a potential tool in the identification and evaluation of some skin diseases such as melanoma, basal cell carcinoma, and psoriasis. Objective: The objective of our study was to utilize a convolutional neural network (CNN) to differentiate the clinical photos of patients with rosacea (taken from 3 different angles) from those of patients with other skin diseases such as acne, seborrheic dermatitis, and eczema that could be easily confused with rosacea. Methods: In this study, 24,736 photos comprising of 18,647 photos of patients with rosacea and 6089 photos of patients with other skin diseases such as acne, facial seborrheic dermatitis, and eczema were included and analyzed by our CNN model based on ResNet-50. Results: The CNN in our study achieved an overall accuracy and precision of 0.914 and 0.898, with an area under the receiver operating characteristic curve of 0.972 for the detection of rosacea. The accuracy of classifying 3 subtypes of rosacea, that is, erythematotelangiectatic rosacea, papulopustular rosacea, and phymatous rosacea was 83.9%, 74.3%, and 80.0%, respectively. Moreover, the accuracy and precision of our CNN to distinguish rosacea from acne reached 0.931 and 0.893, respectively. For the differentiation between rosacea, seborrheic dermatitis, and eczema, the overall accuracy of our CNN was 0.757 and the precision was 0.667. Finally, by comparing the CNN diagnosis with the diagnoses by dermatologists of different expertise levels, we found that our CNN system is capable of identifying rosacea with a performance superior to that of resident doctors or attending physicians and comparable to that of experienced dermatologists. Conclusions: The findings of our study showed that by assessing clinical images, the CNN system in our study could identify rosacea with accuracy and precision comparable to that of an experienced dermatologist. © Zhixiang Zhao, Che-Ming Wu, Shuping Zhang, Fanping He, Fangfen Liu, Ben Wang, Yingxue Huang, Wei Shi, Dan Jian, Hongfu Xie, Chao-Yuan Yeh, Ji Li.","10.2196/23415","Artificial intelligence; Convolutional neural networks; Rosacea","37","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103617697&doi=10.2196%2f23415&partnerID=40&md5=373f42661f774f7a00100d582f2a7ef5"
"Diagnosis of Various Skin Cancer Lesions Based on Fine-Tuned ResNet50 Deep Network","ElGhany S.A.; Ibraheem M.R.; Alruwaili M.; Elmogy M.","2021","1","1","0","0","0","Unique","0","","","","","","","With the massive success of deep networks, there have been signi- cant efforts to analyze cancer diseases, especially skin cancer. For this purpose, this work investigates the capability of deep networks in diagnosing a variety of dermoscopic lesion images. This paper aims to develop and ne-tune a deep learning architecture to diagnose different skin cancer grades based on dermatoscopic images. Fine-tuning is a powerful method to obtain enhanced classication results by the customized pre-trained network. Regularization, batch normalization, and hyperparameter optimization are performed for ne-tuning the proposed deep network. The proposed ne-tuned ResNet50 model successfully classied 7-respective classes of dermoscopic lesions using the publicly available HAM10000 dataset. The developed deep model was compared against two powerful models, i.e., InceptionV3 and VGG16, using the Dice similarity coefcient (DSC) and the area under the curve (AUC). The evaluation results show that the proposed model achieved higher results than some recent and robust models. © 2021 Tech Science Press. All rights reserved.","10.32604/cmc.2021.016102","Deep learning model; dermatoscopic images analysis; multiclass diagnosis; ResNet50 network","39","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103668423&doi=10.32604%2fcmc.2021.016102&partnerID=40&md5=82e99b5143216d832f4ccf2eb7f4b9bc"
"Survey paper based critical reviews for Cosmetic Skin Diseases","Borade S.; Kalbande D.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Prediction and detection of skin diseases have always been a challenging and critical task for health care professionals. There are many clinics and skin practitioners who are offering their services at exorbitant costs. At the same time, skin condition prevails in our country in every part. In the current scenario majority of the skincare practitioners are using traditional methods to diagnose the disease which may take a considerable amount of time. Skin Diseases are serious problems in recent times as it is a matter of environmental factors, socioeconomic factors, lack of full diet, etc. This paper is a comparative study about understanding various skin diseases related to normal skin issues as well as cosmetology. A comparison between oily, dry, and normal skin is also projected in this study. A survey of different papers is done on basis of technologies used, results with accuracy, ethical conduct, number of diseases diagnosed, datasets, etc are done.  © 2021 IEEE.","10.1109/ICAIS50930.2021.9395803","Artificial Intelligence; Cosmetic; Cosmetology; Deep Learning; Diseases; Intelligent System; Skin; Survey","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105018820&doi=10.1109%2fICAIS50930.2021.9395803&partnerID=40&md5=97f387b1668b51b4c605541ead732724"
"The Importance of Incorporating Human Factors in the Design and Implementation of Artificial Intelligence for Skin Cancer Diagnosis in the Real World","Felmingham C.M.; Adler N.R.; Ge Z.; Morton R.L.; Janda M.; Mar V.J.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Artificial intelligence (AI) algorithms have been shown to diagnose skin lesions with impressive accuracy in experimental settings. The majority of the literature to date has compared AI and dermatologists as opponents in skin cancer diagnosis. However, in the real-world clinical setting, the clinician will work in collaboration with AI. Existing evidence regarding the integration of such AI diagnostic tools into clinical practice is limited. Human factors, such as cognitive style, personality, experience, preferences, and attitudes may influence clinicians’ use of AI. In this review, we consider these human factors and the potential cognitive errors, biases, and unintended consequences that could arise when using an AI skin cancer diagnostic tool in the real world. Integrating this knowledge in the design and implementation of AI technology will assist in ensuring that the end product can be used effectively. Dermatologist leadership in the development of these tools will further improve their clinical relevance and safety. © 2020, Springer Nature Switzerland AG.","10.1007/s40257-020-00574-4","","41","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097955721&doi=10.1007%2fs40257-020-00574-4&partnerID=40&md5=83dead13ee9e8ce0c97013513ec7495d"
"EfficientNet-Based Model with Test Time Augmentation for Cancer Detection","Jiahao Z.; Jiang Y.; Huang R.; Shi J.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Skin cancer is the most common type of cancer and among various kinds of skin cancer, melanoma causes the most deaths. In clinical practice, contextual information from every one of a patient's moles help dermatologists make better judgments about whether a particular one is a lesion. In this paper, we proposed an EfficientNet based deep learning method to identify melanoma in skin lesion images. Our method takes into consideration all skin lesion images from a patient and employs effective data augmentation during training and test time augmentation during inference to improve classification accuracy. On the SIIM-ISIC Melanoma Classification dataset, our method achieved 0.901 Auc-Roc scores, outperforming other deep learning models such as VGG16 or Resnet50. © 2021 IEEE.","10.1109/ICBAIE52039.2021.9389825","cancer detection; convolution neural network; image classification; ResNet network","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104411429&doi=10.1109%2fICBAIE52039.2021.9389825&partnerID=40&md5=3b3cb3dbe2ec65b482fc9178f2eba28e"
"A Hybrid Artificial Intelligence Model for Skin Cancer Diagnosis","Vidya Lakshmi V.; Leena Jasmine J.S.","2021","1","1","0","0","0","Unique","0","","","","","","","Melanoma or skin cancer is the most dangerous and deadliest disease. As the incidence and mortality rate of skin cancer increases worldwide, an automated skin cancer detection/classification system is required for early detection and prevention of skin cancer. In this study, a Hybrid Artificial Intelligence Model (HAIM) is designed for skin cancer classification. It uses diverse multi-directional representation systems for feature extraction and an efficient Exponentially Weighted and Heaped Multi-Layer Perceptron (EWHMLP) for the classification. Though the wavelet transform is a powerful tool for signal and image processing, it is unable to detect the intermediate dimensional structures of a medical image. Thus the proposed HAIM uses Curvelet (CurT), Contourlet (ConT) and Shearlet (SheT) transforms as feature extraction techniques. Though MLP is very flexible and well suitable for the classification problem, the learning of weights is a challenging task. Also, the optimization process does not converge, and the model may not be stable. To overcome these drawbacks, EWHMLP is developed. Results show that the combined qualities of each transform in a hybrid approach provides an accuracy of 98.33% in a multi-class approach on PH2 database. © 2021 CRL Publishing. All rights reserved.","10.32604/csse.2021.015700","contourlet; curvelet; multi-directional systems; multi-layer perceptron; shearlet; Skin cancer","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112605851&doi=10.32604%2fcsse.2021.015700&partnerID=40&md5=fb22c0b77ba3185f60adef000f22bfeb"
"SIIM-ISIC Melanoma Classification with DenseNet","Zhang Y.; Wang C.","2021","0","1","0","0","0","First occurrence","0","","","","","","","The mortality rate of melanoma is very high, but it can usually be cured by minor surgery. A Fast and accurate diagnosis can greatly benefit doctors and patients. In many medical fields, the performance of the recent deep-learning-based model is close to or even exceed the level of human experts. In this paper, to help dermatologists improve the efficiency of melanoma analysis, we employ the DenseNet model to complete the recognition of melanomas in skin lesion images. The proposed model is trained and evaluated with the ISIC2020 dataset. Besides, Experimental results show that our method achieves superior performance over the other deep-learning approaches. Our DenseNet model gains 0.925 with AUC metric, which is higher than approaches with VGG and ResNet backbone. © 2021 IEEE.","10.1109/ICBAIE52039.2021.9389983","Deep Learning; DenseNet; Image Classification; Melanoma recognition","27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104443886&doi=10.1109%2fICBAIE52039.2021.9389983&partnerID=40&md5=4122efb5991738d8c3251221c4ab792b"
"Data augmentation for skin lesion using self-attention based progressive generative adversarial network","Abdelhalim I.S.A.; Mohamed M.F.; Mahdy Y.B.","2021","1","1","0","0","0","Unique","0","","","","","","","While recent years have witnessed the remarkable success of deep learning methods in automated skin lesion detection systems, there still exists a gap between manual assessment of experts and automated evaluation of computers. The reason behind such a gap is the deep learning models demand considerable amounts of data, while the availability of annotated images is often limited. Data Augmentation (DA) is one way to mitigate the lack of labeled data; however, the augmented images intrinsically have a similar distribution to the original ones, leading to limited performance improvement. To satisfy the data lack in the real image distribution, we synthesize skin lesion images – realistic but completely different from the original ones – using Generative Adversarial Networks (GANs). In this paper, we propose the Self-attention Progressive Growing of GANs (SPGGANs) to generate fine-grained 256 × 256 skin lesion images for Convolutional Neural Network-based melanoma detection, which is challenging via conventional GANs; difficulties arise due to unstable GAN training with high resolution and a variety of skin lesions in size, shape, and location. In SPGGAN, details can be generated using aggregated information from all feature locations. Moreover, the discriminator can monitor that highly detailed features in distant portions of the image are consistent with each other. Furthermore, the Two-Timescale Update Rule (TTUR) is applied to SPGGAN (SPGGAN-TTUR) to improve stability while generating 256 × 256 skin lesion images. SPGGAN-TTUR is evaluated on data generation and classification tasks using the HAM10000 dataset. Our results confirm the importance of our proposed GAN-based DA approach for training skin lesion classifiers and indicate that it can lead to statistically significant improvements (p-value <0.05) in the sensitivity (recall) over non-augmented and augmented, with classical DA, counterparts. In general, in the case of all classes, The sensitivity improvements were 5.6% and 2.5% over non-augmented and augmented (with the best DA scheme) counterparts, respectively. Specifically, in the case of melanoma class, the sensitivity improvements were 13.8% and 8.6%. We believe that the proposed approach can be adopted in clinical practice to improve the sensitivity of automated skin lesion detection in dermoscopic images and thus support dermatologists’ efforts to improve melanoma diagnosis. © 2020 Elsevier Ltd","10.1016/j.eswa.2020.113922","Data augmentation; Data imbalance; Deep learning; Generative models; Skin cancer","114","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090417710&doi=10.1016%2fj.eswa.2020.113922&partnerID=40&md5=897b80d2bd7438f71195fd366bdb3bbd"
"Robustness of convolutional neural networks in recognition of pigmented skin lesions","Maron R.C.; Haggenmüller S.; von Kalle C.; Utikal J.S.; Meier F.; Gellrich F.F.; Hauschild A.; French L.E.; Schlaak M.; Ghoreschi K.; Kutzner H.; Heppt M.V.; Haferkamp S.; Sondermann W.; Schadendorf D.; Schilling B.; Hekler A.; Krieghoff-Henning E.; Kather J.N.; Fröhling S.; Lipka D.B.; Brinker T.J.","2021","1","1","0","0","0","Unique","0","","","","","","","Background: A basic requirement for artificial intelligence (AI)–based image analysis systems, which are to be integrated into clinical practice, is a high robustness. Minor changes in how those images are acquired, for example, during routine skin cancer screening, should not change the diagnosis of such assistance systems. Objective: To quantify to what extent minor image perturbations affect the convolutional neural network (CNN)–mediated skin lesion classification and to evaluate three possible solutions for this problem (additional data augmentation, test-time augmentation, anti-aliasing). Methods: We trained three commonly used CNN architectures to differentiate between dermoscopic melanoma and nevus images. Subsequently, their performance and susceptibility to minor changes (‘brittleness’) was tested on two distinct test sets with multiple images per lesion. For the first set, image changes, such as rotations or zooms, were generated artificially. The second set contained natural changes that stemmed from multiple photographs taken of the same lesions. Results: All architectures exhibited brittleness on the artificial and natural test set. The three reviewed methods were able to decrease brittleness to varying degrees while still maintaining performance. The observed improvement was greater for the artificial than for the natural test set, where enhancements were minor. Conclusions: Minor image changes, relatively inconspicuous for humans, can have an effect on the robustness of CNNs differentiating skin lesions. By the methods tested here, this effect can be reduced, but not fully eliminated. Thus, further research to sustain the performance of AI classifiers is needed to facilitate the translation of such systems into the clinic. © 2020 The Author(s)","10.1016/j.ejca.2020.11.020","Artificial intelligence; Deep learning; Dermatology; Machine learning; Melanoma; Neural networks; Nevus; Skin neoplasms","47","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099254625&doi=10.1016%2fj.ejca.2020.11.020&partnerID=40&md5=4283f2e2f95a457ded63d3ab03110933"
"A Brief Review of Feature Extraction Methods for Melanoma Detection","Saghir U.; Devendran V.","2021","0","1","0","0","0","Unique","0","","","","","","","One of the most deadly disease on the planet by which numerous individuals lost their lives is melanoma. In the last few decades, melanoma is growing rapidly around the world. In recent years, the fusion of dermoscopy techniques with the CAD system has become an important research field as it helps medical practitioners in gaining meaningful information from images. One of the main stages in any diagnostic system is feature extraction in which selection of the most appropriate feature is a very crucial step. In feature extraction from a single image hundred of features can be extracted. Though, all the extracted features are not suitable for the classification of the lesion. Many features which are not required make the classifier complex and require more computational time, which also reduces the classification accuracy. The best features should represent the characteristic of the region in skin cancer images. To extract the most suitable feature from an image some methods are used. In this paper, a brief review of feature extraction methods developed in the past is discussed. © 2021 IEEE.","10.1109/ICACCS51430.2021.9441787","CAD; Dermoscopy; Feature; Melanoma","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108022720&doi=10.1109%2fICACCS51430.2021.9441787&partnerID=40&md5=109fefbde395c675c28a6e280574e92d"
"Diagnosis of skin cancer using machine learning techniques","Murugan A.; Nair S.A.H.; Preethi A.A.P.; Kumar K.P.S.","2021","1","1","0","0","0","Unique","0","","","","","","","Generally, skin disease is a common one in human diseases. In computer vision application, the skin color is the powerful indication for this disease. This system identifies the skin cancer disease based on the images of skin. Initially, the skin is filtered using median filter and segmented using Mean shift segmentation. Segmented images are fed as input to feature extraction. GLCM, Moment Invariants and GLRLM features are extracted in this research work. The extracted features are classified by using classification techniques like Support vector machine, Probabilistic Neural Networks and Random forest and Combined SVM+ RF classifiers. Here combined SVM+RF classifier provided better results than other classifiers. © 2020","10.1016/j.micpro.2020.103727","GLCM; GLRLM; Moment invariants; Skin cancer; SVM","133","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098688050&doi=10.1016%2fj.micpro.2020.103727&partnerID=40&md5=18ed62bda10ba8130971ffda8c997a7e"
"Ascu-net: Attention gate, spatial and channel attention u-net for skin lesion segmentation","Tong X.; Wei J.; Sun B.; Su S.; Zuo Z.; Wu P.","2021","1","1","0","0","0","Unique","0","","","","","","","Segmentation of skin lesions is a challenging task because of the wide range of skin lesion shapes, sizes, colors, and texture types. In the past few years, deep learning networks such as U-Net have been successfully applied to medical image segmentation and exhibited faster and more accurate performance. In this paper, we propose an extended version of U-Net for the segmentation of skin lesions using the concept of the triple attention mechanism. We first selected regions using attention coefficients computed by the attention gate and contextual information. Second, a dual attention decoding module consisting of spatial attention and channel attention was used to capture the spatial correlation between features and improve segmentation performance. The combination of the three attentional mechanisms helped the network to focus on a more relevant field of view of the target. The proposed model was evaluated using three datasets, ISIC-2016, ISIC-2017, and PH2. The experimental results demonstrated the effectiveness of our method with strong robustness to the presence of irregular borders, lesion and skin smooth transitions, noise, and artifacts. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/diagnostics11030501","Attention mechanism; Deep convolutional neural networks; Skin lesion segmentation; U-Net","131","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108443257&doi=10.3390%2fdiagnostics11030501&partnerID=40&md5=ed69f9ee2cb89a2c708056fbac810297"
"Proposing a novel unsupervised stack ensemble of deep and conventional image segmentation (SEDCIS) method for localizing vitiligo lesions in skin images","Khatibi T.; Rezaei N.; Ataei Fashtami L.; Totonchi M.","2021","1","1","0","0","0","Unique","0","","","","","","","Background: Vitiligo is an acquired pigmentary skin disorder characterized by depigmented macules and patches which brings many challenges for the patients suffering from. For vitiligo severity assessment, several scoring methods have been proposed based on morphometry and colorimetry. But, all methods suffer from much inter- and intra-observer variations for estimating the depigmented area. For all mentioned assessment methods of vitiligo disorder, accurate segmentation of the skin images for lesion detection and localization is required. The image segmentation for localizing vitiligo skin lesions has many challenges because of illumination variation, different shapes and sizes of vitiligo lesions, vague lesion boundaries and skin hairs and vignette effects. The manual image segmentation is a tedious and time-consuming task. Therefore, using automatic image segmentation methods for lesion detection is necessarily required. Materials and methods: In this study, a novel unsupervised stack ensemble of deep and conventional image segmentation (SEDCIS) methods is proposed for localizing vitiligo lesions in skin images. Unsupervised segmentation methods do not require prior manual segmentation of vitiligo lesions which is a tedious and time-consuming task with intra- and inter-observer variations. Results: Our collected dataset includes 877 images taken from 21 patients with the resolution of 5760*3840 pixels suffering from vitiligo disorder. Experimental results show that SEDCIS outperforms the compared methods with accuracy of 97%, sensitivity of 98%, specificity of 96%, area overlapping of 94%, and Dice index of 97%. Conclusion: The proposed method can segment vitiligo lesions with highly reasonable performance and can be used for assessing the vitiligo lesion surface. © 2020 John Wiley & Sons A/S. Published by John Wiley & Sons Ltd","10.1111/srt.12920","depigmentation disorder; image segmentation; skin lesion localization; stacked ensemble method","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087770101&doi=10.1111%2fsrt.12920&partnerID=40&md5=5336b7213116ee9bf85a8a5b2858e1e1"
"Attributes based skin lesion detection and recognition: A mask RCNN and transfer learning-based deep learning framework","Khan M.A.; Akram T.; Zhang Y.-D.; Sharif M.","2021","1","1","0","0","0","Unique","0","","","","","","","Malignant melanoma is considered to be one of the deadliest types of skin cancers which is responsible for the massive number of deaths worldwide. According to the American Cancer Society (ACS), more than a million Americans are living with this melanoma. Since 2019, 192,310 new cases of melanoma are registered, where 95,380 are noninvasive, and 96,480 are invasive. The numbers of deaths due to melanoma in 2019 alone are 7,230, comprising 4,740 men and 2,490 women. Melanoma may be curable if diagnosed at the earlier stages; however, the manual diagnosis is time-consuming and also dependent on the expert dermatologist. In this work, a fully automated computerized aided diagnosis (CAD) system is proposed based on the deep learning framework. In the proposed scheme, the original dermoscopic images are initially pre-processed using the decorrelation formulation technique, which later passes the resultant images to the MASK-RCNN for the lesion segmentation. In this step, the MASK RCNN model is trained using the segmented RGB images generated from the ground truth images of ISBI2016 and ISIC2017 datasets. The resultant segmented images are later passed to the DenseNet deep model for feature extraction. Two different layers, average pool and fully connected, are used for feature extraction, which are later combined, and the resultant vector is forwarded to the feature selection block for down - sampling using proposed entropy-controlled least square SVM (LS-SVM). Three datasets are utilized for validation - ISBI2016, ISBI2017, and HAM10000 to achieve an accuracy of 96.3%, 94.8%, and 88.5% respectively. Further, the performance of MASK-RCNN is also validated on ISBI2016 and ISBI2017 to attain an accuracy of 93.6% and 92.7%. To further increase our confidence in the proposed framework, a fair comparison with other state-of-the-art is also provided. © 2021 Elsevier B.V.","10.1016/j.patrec.2020.12.015","ELM; Mask RCNN; Optimal features; Skin cancer; Transfer learning","213","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098599092&doi=10.1016%2fj.patrec.2020.12.015&partnerID=40&md5=9cb5634e71f97cc6c7f78562558ab098"
"Impact of pixel scaling on classification accuracy of dermatological skin disease detection","Adeyemo A.A.; Bashir S.A.; Mohammed A.D.; Abisoye O.O.","2021","1","1","0","0","0","Unique","0","","","","","","","Images are made up of many features on which the performance of the system used in processing them depends. Image pixel values are one of such important features which are often not considered. This study investigates the importance of image preprocessing using some calculated statistics on the pixels of skin images in classifying images using HAM10000 dataset. Image pixel values make a great impact on the classification performance of Convolutional Neural Network (CNN) based image classifiers. In this study, the 'original pixel values' of the skin images are used to train three carefully designed CNN architectures. The designed architectures are further trained with some calculated statistical values using 'global centering', 'local centering', 'dividing pixel values by the mean' and 'root of the division' techniques of data normalization. The results obtained have shown that, out of the five different forms of values used in training the architectures, the CNNs trained with the original (unscaled) image pixel values perform below those trained with calculated statistics that are computed on the image pixel values.  © 2021 IEEE.","10.1109/CYBERNIGERIA51635.2021.9428813","Classification accuracy; Dermatological skin diseases; Image pixel scaling; Image preprocessing","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107505275&doi=10.1109%2fCYBERNIGERIA51635.2021.9428813&partnerID=40&md5=01ed190b47b4217ad8b7f24c111d9db9"
"Using deep learning for dermatologist-level detection of suspicious pigmented skin lesions from wide-field images","Soenksen L.R.; Kassis T.; Conover S.T.; Marti-Fuster B.; Birkenfeld J.S.; Tucker-Schwartz J.; Naseem A.; Stavert R.R.; Kim C.C.; Senna M.M.; Avilés-Izquierdo J.; Collins J.J.; Barzilay R.; Gray M.L.","2021","1","1","0","0","0","Unique","0","","","","","","","A reported 96,480 people were diagnosed with melanoma in the United States in 2019, leading to 7230 reported deaths. Early-stage identification of suspicious pigmented lesions (SPLs) in primary care settings can lead to improved melanoma prognosis and a possible 20-fold reduction in treatment cost. Despite this clinical and economic value, efficient tools for SPL detection are mostly absent. To bridge this gap, we developed an SPL analysis system for wide-field images using deep convolutional neural networks (DCNNs) and applied it to a 38,283 dermatological dataset collected from 133 patients and publicly available images. These images were obtained from a variety of consumer-grade cameras (15,244 nondermoscopy) and classified by three board-certified dermatologists. Our system achieved more than 90.3% sensitivity (95% confidence interval, 90 to 90.6) and 89.9% specificity (89.6 to 90.2%) in distinguishing SPLs from nonsuspicious lesions, skin, and complex backgrounds, avoiding the need for cumbersome individual lesion imaging. We also present a new method to extract intrapatient lesion saliency (ugly duckling criteria) on the basis of DCNN features from detected lesions. This saliency ranking was validated against three board-certified dermatologists using a set of 135 individual wide-field images from 68 dermatological patients not included in the DCNN training set, exhibiting 82.96% (67.88 to 88.26%) agreement with at least one of the top three lesions in the dermatological consensus ranking. This method could allow for rapid and accurate assessments of pigmented lesion suspiciousness within a primary care visit and could enable improved patient triaging, utilization of resources, and earlier treatment of melanoma. Copyright © 2021 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works","10.1126/scitranslmed.abb3652","","116","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101698746&doi=10.1126%2fscitranslmed.abb3652&partnerID=40&md5=57c5efcec77b7a835206aee69138f440"
"Transformation-Consistent Self-Ensembling Model for Semisupervised Medical Image Segmentation","Li X.; Yu L.; Chen H.; Fu C.-W.; Xing L.; Heng P.-A.","2021","0","1","0","0","0","First occurrence","0","","","","","","","A common shortfall of supervised deep learning for medical imaging is the lack of labeled data, which is often expensive and time consuming to collect. This article presents a new semisupervised method for medical image segmentation, where the network is optimized by a weighted combination of a common supervised loss only for the labeled inputs and a regularization loss for both the labeled and unlabeled data. To utilize the unlabeled data, our method encourages consistent predictions of the network-in-training for the same input under different perturbations. With the semisupervised segmentation tasks, we introduce a transformation-consistent strategy in the self-ensembling model to enhance the regularization effect for pixel-level predictions. To further improve the regularization effects, we extend the transformation in a more generalized form including scaling and optimize the consistency loss with a teacher model, which is an averaging of the student model weights. We extensively validated the proposed semisupervised method on three typical yet challenging medical image segmentation tasks: 1) skin lesion segmentation from dermoscopy images in the International Skin Imaging Collaboration (ISIC) 2017 data set; 2) optic disk (OD) segmentation from fundus images in the Retinal Fundus Glaucoma Challenge (REFUGE) data set; and 3) liver segmentation from volumetric CT scans in the Liver Tumor Segmentation Challenge (LiTS) data set. Compared with state-of-the-art, our method shows superior performance on the challenging 2-D/3-D medical images, demonstrating the effectiveness of our semisupervised method for medical image segmentation.  © 2012 IEEE.","10.1109/TNNLS.2020.2995319","Liver segmentation; optic disk (OD) segmentation; self-ensembling; semisupervised learning; skin lesion segmentation","402","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100701697&doi=10.1109%2fTNNLS.2020.2995319&partnerID=40&md5=3560bf22dd3df5d017680bd14d75d303"
"Convolutional neural networks for malignant and benign cell classification using dermatoscopic images","Akash Kumar V.; Mishra V.; Arora M.","2021","0","1","0","0","0","Unique","0","","","","","","","In general, cancer is considered as the second most fatal disease across the globe. In the past decades, skin cancer is increasing at a high rate as it is a major type of cancer. Diagnosis of unknown pores and skin cancer is very significant for delivering proper treatment. Curable with early analysis, simplest extraordinarily trained dermatologists that capable of appropriately understand skin lesions as malignant or benign. Skin disease is analyzed by utilizing clinical screening, dermoscopic investigation, histopathological assessment and a biopsy. As number of biomedical images collected and stored are rapidly increasing so a need of a technology to meet the requirement. As understanding is in restrained supply, systems classify skin lesions automatically as of benign or malignant cancer are beneficial as preliminary screening gear. The proposed methodology presents a CNN model, trained on feature extracted from a highway CNN pretrained on images of dermoscopic of pores and skin lesions. Further, the model is optimized using two different optimizers i.e., RMSPROP and ADAM individually and then comparison of accuracies is done, and conclusion would be based on the good optimizer. Further, it doesn't price a good deal for computational energy in order to teach the model. It is a basic scratch model, in which this research work has worked only upon one DL algorithm and then in future, different DL algorithms will be analyzed to achieve a better accuracy. © 2021 IEEE.","10.1109/ICICV50876.2021.9388605","Benign; Convolution Neural Network; Dermatoscopic Images; Malignant; Optimizer; Scratch model; Skin Cancer","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104439446&doi=10.1109%2fICICV50876.2021.9388605&partnerID=40&md5=17558040c2bddcf64b0fa8b08cedb277"
"Semantic segmentation of lesions from dermoscopic images using yolo-deeplab networks","Bagheri F.; Tarokh M.J.; Ziaratban M.","2021","0","1","0","0","0","Unique","0","","","","","","","Accurate segmentation of lesions from dermoscopic images is very important for timely diagnosis and treatment of skin cancers. Due to the variety of shape, size, color, and location of lesions in dermoscopic images, automatic segmentation of skin lesions remains a challenge. In this study, a two-stage method is presented for the segmentation of skin lesions using Deep Learning. In the first stage, convolutional neural networks (CNNs) estimate the approximate size and location of the lesion. A sub-image around the estimated bounding box is cropped from the original image. The sub-image is resized to an image of a predefined size. In order to segment the exact area of the lesion from the normal image, other CNNs are used in the DeepLab structure. The accuracy of the normalization stage has a significant impact on the final performance. In order to increase the normalization accuracy, a combination of four networks in the structure of Yolov3 is used. Two approaches are proposed to combine the Yolov3 structures. The segmentation results of the two networks in the DeepLab v3+ structure are also combined to improve the performance of the second stage. Another challenge is the small number of training images. To overcome this problem, the data augmentation is used along with different modes of an image in each stage. In order to evaluate the proposed method, experiments are performed on the well-known ISBI 2017 dataset. Experimental results show that the proposed lesion segmentation method outperforms the state-of-the-art methods. © 2021 Materials and Energy Research Center. All rights reserved.","10.5829/IJE.2021.34.02B.18","Deep Learning; Deeplab3+; Semantic Segmentation; Skin Lesion; Yolov3","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101309009&doi=10.5829%2fIJE.2021.34.02B.18&partnerID=40&md5=a64a7b466827c429a20451c46d0241e5"
"Automated seeding for ultrasound skin lesion segmentation","Marosán P.; Szalai K.; Csabai D.; Csány G.; Horváth A.; Gyöngy M.","2021","1","1","0","0","0","Unique","0","","","","","","","The segmentation of cancer-suspicious skin lesions using ultrasound may help their differential diagnosis and treatment planning. Active contour models (ACM) require an initial seed, which when manually chosen may cause variations in segmentation accuracy. Fully-automated skin segmentation typically employs layer-by-layer segmentation using a combination of methods; however, such segmentation has not yet been applied on cancerous lesions. In the current work, fully automated segmentation is achieved in two steps: an automated seeding (AS) step using a layer-by-layer method followed by a growing step using an ACM. The method was tested on images of nevi, melanomas, and basal cell carcinomas from two ultrasound imaging systems (N=60), with all lesions being successfully located. For the seeding step, manual seeding (MS) was used as a reference. AS approached the accuracy of MS when the latter used an optimal bounding rectangle based on the ground truth (Sørensen–Dice coefficient (SDC) of 72.3 vs 74.6, respectively). The effect of varying the manual seed was also investigated; a 0.7 decrease in seed height and width caused a mean SDC of 54.6. The results show the robustness of automated seeding for skin lesion segmentation. © 2020 The Authors","10.1016/j.ultras.2020.106268","Automated layer segmentation; Automated lesion localization; Computer vision; Seed selection; Skin ultrasound","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092438714&doi=10.1016%2fj.ultras.2020.106268&partnerID=40&md5=4bd583e8ee5f6d1c13bc9524599140db"
"Deep convolutional neural strategy for detection and prediction of melanoma skin cancer","Dandu R.; Jayakameshwaraiah; Ravi Kumar Y.B.","2021","1","0","0","0","0","Unique","0","","","","","","","The research work has focused on detection and prediction of melanoma which is done by subjecting to features extraction, where the features of an image consisting of melanoma regions are detected by analysis and this analysis is done by considering the features like color and texture-based features learning strategy. These features are extracted by combining color and texture-based features extraction with deep convolutional features representation learning strategy. The colors of images are extracted by representing the colors of different channels into red, green and blue channel information. The combination of texture features extraction with color-based features extraction in addition to Alex net features extraction learning has made the system more robust and efficient toward the segmentation and classification of images. Further, the erected method involves convoluting the features of extracted information with color and texture-based method which has led our system to full convolution neural networks with images features extraction. The melanoma is detected and segmented with watershed segmentation, these segmented features are subjected to the proposed features extraction method, where the features are extracted by combining the methods of texture with color-based information. These colors are made available to the proposed method by analyzing the regions of melanoma images. The erected method does the task of features extraction by Weber law descriptors in combination with red, green, blue channels information extracted from features representation learning. The proposed method has yielded an accuracy of 94.12% of segmentation accuracy and a classification accuracy of 94.32% with respect to various other classification techniques.  © 2021 National Taiwan University.","10.4015/S1016237220500453","Color; Computer science; Features classification; Features extraction; Melanoma segmentation; Texture","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099668116&doi=10.4015%2fS1016237220500453&partnerID=40&md5=5c07e15215bd09f872017fed3af671b9"
"A review of human skin detection applications based on image processing","Al Naffakh H.A.H.; Ghazali R.; Abbadi N.K.E.; Razzaq A.N.","2021","1","1","0","0","0","Unique","0","","","","","","","In computer science, virtual image processing is the use of a digital computer to manipulate digital images through an algorithm for many applications. To begin with a new research topic, the must trend application that gets many requests to develop should know. Therefore, many applications based on human skin and human life are reviewed in this article, such as detection, classification, blocking, cryptography, identification, localization, steganography, segmentation, tracking, and recognition. In this article, the published articles with the topic of human skin-based image processing are investigated. The international publishers, such as Springer, IEEE, arXiv, and Elsevier are selected. The searching is implemented with the duration criteria of 2015-2019. It noted that human skin detection and recognition are the most repetitive articles with 43% and 28.5%, respectively of the total number of the investigated articles. The usage of human skin models is being widely used in the image processing of various applications. © 2021, Institute of Advanced Engineering and Science. All rights reserved.","10.11591/eei.v10i1.2497","Applications of human skin; Dataset; Skin color modeling; Skin detection","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091058991&doi=10.11591%2feei.v10i1.2497&partnerID=40&md5=dfa7312f913bd77f5b2139703d1af766"
"CA-Net: Comprehensive Attention Convolutional Neural Networks for Explainable Medical Image Segmentation","Gu R.; Wang G.; Song T.; Huang R.; Aertsen M.; Deprest J.; Ourselin S.; Vercauteren T.; Zhang S.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Accurate medical image segmentation is essential for diagnosis and treatment planning of diseases. Convolutional Neural Networks (CNNs) have achieved state-of-The-Art performance for automatic medical image segmentation. However, they are still challenged by complicated conditions where the segmentation target has large variations of position, shape and scale, and existing CNNs have a poor explainability that limits their application to clinical decisions. In this work, we make extensive use of multiple attentions in a CNN architecture and propose a comprehensive attention-based CNN (CA-Net) for more accurate and explainable medical image segmentation that is aware of the most important spatial positions, channels and scales at the same time. In particular, we first propose a joint spatial attention module to make the network focus more on the foreground region. Then, a novel channel attention module is proposed to adaptively recalibrate channel-wise feature responses and highlight the most relevant feature channels. Also, we propose a scale attention module implicitly emphasizing the most salient feature maps among multiple scales so that the CNN is adaptive to the size of an object. Extensive experiments on skin lesion segmentation from ISIC 2018 and multi-class segmentation of fetal MRI found that our proposed CA-Net significantly improved the average segmentation Dice score from 87.77% to 92.08% for skin lesion, 84.79% to 87.08% for the placenta and 93.20% to 95.88% for the fetal brain respectively compared with U-Net. It reduced the model size to around 15 times smaller with close or even better accuracy compared with state-of-The-Art DeepLabv3+. In addition, it has a much higher explainability than existing networks by visualizing the attention weight maps. Our code is available at https://github.com/HiLab-git/CA-Net. © 1982-2012 IEEE.","10.1109/TMI.2020.3035253","Attention; convolutional neural network; explainability; medical image segmentation","580","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100613336&doi=10.1109%2fTMI.2020.3035253&partnerID=40&md5=1ab2f2635a715da6152777ff24905981"
"A new deep learning approach integrated with clinical data for the dermoscopic differentiation of early melanomas from atypical nevi","Tognetti L.; Bonechi S.; Andreini P.; Bianchini M.; Scarselli F.; Cevenini G.; Moscarella E.; Farnetani F.; Longo C.; Lallas A.; Carrera C.; Puig S.; Tiodorovic D.; Perrot J.L.; Pellacani G.; Argenziano G.; Cinotti E.; Cataldo G.; Balistreri A.; Mecocci A.; Gori M.; Rubegni P.; Cartocci A.","2021","0","1","0","0","0","Unique","0","","","","","","","Background: Timely recognition of malignant melanoma (MM) is challenging for dermatologists worldwide and represents the main determinant for mortality. Dermoscopic examination is influenced by dermatologists’ experience and fails to achieve adequate accuracy and reproducibility in discriminating atypical nevi (AN) from early melanomas (EM). Objective: We aimed to develop a Deep Convolutional Neural Network (DCNN) model able to support dermatologists in the classification and management of atypical melanocytic skin lesions (aMSL). Methods: A training set (630 images), a validation set (135) and a testing set (214) were derived from the idScore dataset of 979 challenging aMSL cases in which the dermoscopic image is integrated with clinical data (age, sex, body site and diameter) and associated with histological data. A DCNN_aMSL architecture was designed and then trained on both dermoscopic images of aMSL and the clinical/anamnestic data, resulting in the integrated “iDCNN_aMSL” model. Responses of 111 dermatologists with different experience levels on both aMSL classification (intuitive diagnosis) and management decisions (no/long follow-up; short follow-up; excision/preventive excision) were compared with the DCNNs models. Results: In the lesion classification study, the iDCNN_aMSL achieved the best accuracy, reaching an AUC = 90.3 %, SE = 86.5 % and SP = 73.6 %, compared to DCNN_aMSL (SE = 89.2 %, SP = 65.7 %) and intuitive diagnosis of dermatologists (SE = 77.0 %; SP = 61.4 %). Conclusions: The iDCNN_aMSL proved to be the best support tool for management decisions reducing the ratio of inappropriate excision. The proposed iDCNN_aMSL model can represent a valid support for dermatologists in discriminating AN from EM with high accuracy and for medical decision making by reducing their rates of inappropriate excisions. © 2020 Japanese Society for Investigative Dermatology","10.1016/j.jdermsci.2020.11.009","Cutaneous melanoma; Deep convolutional neural network; Deep learning; Dermoscopy; Integrated diagnosis; Non-invasive imaging","34","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098080028&doi=10.1016%2fj.jdermsci.2020.11.009&partnerID=40&md5=7c2f1b2d2662a357c2fb41b0158e0a01"
"Curve‐based classification approach for hyperspectral dermatologic data processing","Uteng S.; Quevedo E.; Callico G.M.; Castaño I.; Carretero G.; Almeida P.; Garcia A.; Hernandez J.A.; Godtliebsen F.","2021","0","1","0","0","0","Unique","0","","","","","","","This paper shows new contributions in the detection of skin cancer, where we present the use of a customized hyperspectral system that captures images in the spectral range from 450 to 950 nm. By choosing a 7 × 7 sub‐image of each channel in the hyperspectral image (HSI) and then taking the mean and standard deviation of these sub‐images, we were able to make fits of the resulting curves. These fitted curves had certain characteristics, which then served as a basis of classification. The most distinct fit was for the melanoma pigmented skin lesions (PSLs), which is also the most aggressive malignant cancer. Furthermore, we were able to classify the other PSLs in malignant and benign classes. This gives us a rather complete classification method for PSLs with a novel perspective of the classification procedure by exploiting the variability of each channel in the HSI. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/s21030680","Benign; Curve fit; Hyperspectral; Malignant; Melanoma; Statistical discrimination","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099677035&doi=10.3390%2fs21030680&partnerID=40&md5=8182e81f6837866bbb8d023272fc52a3"
"A novel technique for automated concealed face detection in surveillance videos","Hosni Mahmoud H.A.; Mengash H.A.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Face detection perceives great importance in surveillance paradigm and security paradigm areas. Face recognition is the technique to identify a person identity after face detection. Extensive research has been done on these topics. Another important research problem is to detect concealed faces, especially in high-security places like airports or crowded places like concerts and shopping centres, for they may prevail security threat. Also, in order to help effectively in preventing the spread of Coronavirus, people should wear masks during the pandemic especially in the entrance to hospitals and medical facilities. Surveillance systems in medical facilities should issue warnings against unmasked people. This paper presents a novel technique for concealed face detection based on complexion detection to challenge a concealed face assumption. The proposed algorithm first determine of the existence of a human being in the surveillance scene. Head and shoulder contour will be detected. The face will be clustered to cluster patches. Then determination of presence or absent of human skin will be determined. We proposed a hybrid approach that combines normalized RGB (rgb) and the YCbCr space color. This technique is tested on two datasets; the first one contains 650 images of skin patches. The second dataset contains 800 face images. The algorithm achieves an average detection rate of 97.51% for concealed faces. Also, it achieved a run time comparable with existing state-of-the-art concealed face detection systems that run in real time. © 2020, Springer-Verlag London Ltd., part of Springer Nature.","10.1007/s00779-020-01419-x","Face detection; Human skin detection; Security; YCbCr space color","31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086455806&doi=10.1007%2fs00779-020-01419-x&partnerID=40&md5=41a6184baebcd6a8d5838cf9a765602b"
"Cutaneous Malignant Melanoma: A Review of Early Diagnosis and Management","Naik P.P.","2021","0","1","0","0","0","Unique","0","","","","","","","Cutaneous melanoma (CM) is a malignant tumor formed from pigment-producing cells called melanocytes. It is one of the most aggressive and fatal forms of skin malignancy. In the last decades, CM's incidence has gradually risen, with 351,880 new cases in 2015. Since the 1960s, its incidence has increased steadily, in 2019, with approximately 96,000 new cases. A greater understanding of early diagnosis and management of CM is urgently needed because of the high mortality rates due to metastatic melanoma. Timely detection of melanoma is crucial for successful treatment, but diagnosis with histopathology may also pose a significant challenge to this objective. Early diagnosis and management are essential and contribute to better survival rates of the patient. To better control this malignancy, such information is expected to be particularly useful in the early detection of possible metastatic lesions and the development of new therapeutic approaches. This article reviews the available information on the early diagnosis and management of CM and discusses such information's potential in facilitating the future prospective. © 2021. All Rights Reserved.","10.14740/wjon1349","Cutaneous melanoma; Early diagnosis; Malignant melanoma; Management; Mortality; Tumor","108","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105098143&doi=10.14740%2fwjon1349&partnerID=40&md5=27bef62c63a04b5398e042712a00284d"
"Automated melanoma skin cancer detection from digital images","Shalu; Rani R.; Kamboj A.","2021","1","1","0","0","0","Unique","0","","","","","","","In the early stages, diagnosis of melanoma is important for treating the illness and saving lives. This paper focuses on the development of a system for automatic detection of melanoma skin cancer. The objective of this study is to identify the importance of different colour spaces in melanoma skin cancer detection. Another objective is to compare the colour feature and texture feature to find out that which type of features have more discriminative power to correctly identify melanoma. The whole analysis is done by using the MED-NODE dataset of digital images. This dataset contains a total of 170 images (100 nevi and 70 melanoma). The results show that the combination of features extracted from the hue, saturation and value (HSV) and YCbCr (Y is Luma component and Cb and Cr are two chroma components) colour space give better performance than the features extracted from other colour spaces. Also, the performance of the system is enhanced with the colour features than the performance with texture features. By using features extracted from the HSV and YCbCr colour space, the system shows a more accurate result by giving an accuracy of 84.11% which is higher than the earlier approaches on this dataset. © 2021 Inderscience Enterprises Ltd.. All rights reserved.","10.1504/IJBET.2021.119928","Colour features; Digital image processing; Malignant melanoma; Medical imaging; Skin cancer detection; Skin cancer diagnosis; Texture features; The role of machine learning in skin cancer classification","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122829531&doi=10.1504%2fIJBET.2021.119928&partnerID=40&md5=e0d4f539d81fbf1966db55dd7b58d334"
"Useful features for computer-aided diagnosis systems for melanoma detection using dermoscopic images","Vocaturo E.; Zumpano E.","2021","0","1","0","0","0","First occurrence","0","","","","","","","The development of performing imaging techniques is favoring the spread of artificial vision systems as support tools for the early diagnosis of skin cancers. Epiluminescence microscopy (ELM) is currently the most adopted technique through which it is possible to obtain very detailed images of skin lesions. Over time, melanoma spreads quickly, invading the body's organs through the blood vessels: an early recognition is essential to ensure decisive intervention. There are many machine learning approaches proposed to implement artificial vision systems operating on datasets made up of dermatoscopic images obtained using ELM technique. These proposals are characterized by the use of various specific features that make understanding difficult: the problem of defining a set of features that can allows good classification performance arises. The aim of this work is to identify reference features that can be used by new researchers as a starting point for new proposals. © 2021, IGI Global.","10.4018/978-1-7998-6659-6.ch004","","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125194490&doi=10.4018%2f978-1-7998-6659-6.ch004&partnerID=40&md5=75af7beecf8fbe1b5564b8f54c41ba3c"
"Skin lesion classification by ensembles of deep convolutional networks and regularly spaced shifting","Thurnhofer-Hemsi K.; Lopez-Rubio E.; Dominguez E.; Elizondo D.A.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Skin lesions are caused due to multiple factors, like allergies, infections, exposition to the sun, etc. These skin diseases have become a challenge in medical diagnosis due to visual similarities, where image classification is an essential task to achieve an adequate diagnostic of different lesions. Melanoma is one of the best-known types of skin lesions due to the vast majority of skin cancer deaths. In this work, we propose an ensemble of improved convolutional neural networks combined with a test-time regularly spaced shifting technique for skin lesion classification. The shifting technique builds several versions of the test input image, which are shifted by displacement vectors that lie on a regular lattice in the plane of possible shifts. These shifted versions of the test image are subsequently passed on to each of the classifiers of an ensemble. Finally, all the outputs from the classifiers are combined to yield the final result. Experiment results show a significant improvement on the well-known HAM10000 dataset in terms of accuracy and F-score. In particular, it is demonstrated that our combination of ensembles with test-time regularly spaced shifting yields better performance than any of the two methods when applied alone.  © 2013 IEEE.","10.1109/ACCESS.2021.3103410","classification; deep learning; Image processing; skin lesion","75","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113260114&doi=10.1109%2fACCESS.2021.3103410&partnerID=40&md5=aefc8be23eb8606e2e3545c4b42bc047"
"Hybrid model of convolutional neural network and support vector machine to classify basal cell carcinoma","Rojas J.A.Á.; Calderón Vilca H.D.; Tumi Figueroa E.N.; Ramos K.J.C.; Matos Manguinuri S.S.; Calderón Vilca E.F.","2021","0","1","0","0","0","Unique","0","","","","","","","Skin cancer is one of the most common types of cancer in humans, it covers about one third of all neoplasms. Within skin cancer we find basal cell carcinoma (BCC), this being the most frequent type of cancer worldwide. Solutions with convolutional neural networks generally use the Softmax layer (classic model) to perform a BCC classification, however, in other similar fields such as image classification of microscopic bacteria they have replaced this Softmax layer with a support vector machine (SVM) achieving a better result. Given this, we propose a hybrid model of convolutional neural network and a support vector machine (CNN+SVM) to classify the BCC. Our model is composed of 4 convolution blocks with 32, 64 and 128 filters to carry out the extraction of characteristics and then pass it to the classifier, to which the L1-SVM loss function is implemented. The average results obtained for the CNN+SVM hybrid model were measured with the precision, accuracy, recall and F1-score metrics, obtaining 96.200%, 96.200%, 96.205% and 96.200% respectively compared to the classical model for the metrics of precision, accuracy, recall and F1-score where 95.661%, 95.673%, 95.661%, 95.660% respectively were obtained. The results show that the hybrid model achieves better results than the classic model to classify the BCC. © 2021 Instituto Politecnico Nacional. All rights reserved.","10.13053/CYS-25-1-3431","Basal cell carcinoma; Convolutional neural network; Deep learning; Support vector machine","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102520087&doi=10.13053%2fCYS-25-1-3431&partnerID=40&md5=74585252ecc2326bc9fa16a2dba9d5ed"
"Modified Attention Spatial Convolution Model for Skin Lesion Segmentation","Le T.-P.; Hsu Y.-C.; Wang J.-C.","2021","1","1","0","0","0","Unique","0","","","","","","","Melanoma is one of three skin cancer types and the main reason for almost all skin cancer deaths. The computer-aided diagnosis is the best method to automatically segment the skin lesion such as melanoma. In this paper, a modified attention spatial convolution (mASC) was designed to perform the skin lesion segmentation effectively. The superiority in skin lesion segmentation of the proposed mASC model was demonstrated by comparing with several recent models in the Skin Lesion Analysis Towards Melanoma Detection Challenge dataset.  © 2021 IEEE.","10.1109/ICCE-TW52618.2021.9602988","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123054950&doi=10.1109%2fICCE-TW52618.2021.9602988&partnerID=40&md5=347ea75713e47481607ab911e1bcb681"
"An Evolutionary Approach for the Enhancement of Dermatological Images and Their Classification Using Deep Learning Models","Chaahat; Kumar Gondhi N.; Kumar Lehana P.","2021","0","1","0","0","0","Unique","0","","","","","","","Dermatological problems are the most widely spread skin diseases amongst human beings. They can be infectious, chronic, and sometimes may also lead to serious health problems such as skin cancer. Generally, rural area clinics lack trained dermatologists and mostly rely on the analysis of remotely accessible experts through mobile-based networks for sharing the images and other related information. Under such circumstances, poor image quality introduced due to the capturing device results in misleading diagnosis. Here, a genetic-algorithm- (GA-) based approach used as an image enhancement technique has been explored to improve the low quality of the dermatological images received from the rural clinic. The diagnosis is performed on the enhanced images using convolutional neural network (CNN) classifier for the identification of the diseases. The scope of this paper is limited to only motion blurred images, which is the most prevalent problem in capturing of the images, specifically when any of the two (device or the object) may move unpredictably. Seven types of skin diseases, namely, melanoma, melanocytic nevus, basal cell carcinoma, actinic keratosis, benign keratosis, vascular lesion, and squamous cell carcinoma, have been investigated using ResNet-152 giving an overall accuracy of 87.40% for the blurred images. Use of GA-enhanced images increased the accuracy to 95.85%. The results were further analyzed using a confusion matrix and t-test-based statistical investigations. The advantage of the proposed technique is that it reduces the analysis time and errors due to manual diagnosis. Furthermore, speedy and reliable diagnosis at the earliest stage reduces the risk of developing more severe skin problems.  © 2021 Chaahat et al.","10.1155/2021/8113403","","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111548719&doi=10.1155%2f2021%2f8113403&partnerID=40&md5=42bac8ef9ee12ad185ab407b9d31c59f"
"Proposing a novel Cascade Ensemble Super Resolution Generative Adversarial Network (CESR-GAN) method for the reconstruction of super-resolution skin lesion images","Shahsavari A.; Ranjbari S.; Khatibi T.","2021","1","1","0","0","0","Unique","0","","","","","","","Background: Skin cancer is one of the most malignant cancers worldwide. Its early detection plays a prominent role in the patients' treatment. The quality of skin lesion images to ease the diagnosis of skin cancer is highly regarded. One of the most common technologies to take the skin lesion images is through a dermoscopy device. However, it is not accessible to all people. Capturing the images via other technologies such as mobile devices, is available everywhere, although they suffer from poor quality. Materials and methods: In this paper, a novel Cascade Ensemble Super Resolution Generative Adversarial Network (CESR-GAN) method is proposed to reconstruct super-resolution skin lesion images using low-resolution counterparts. Specifically, a novel feature-based measurement loss function is designed to obtain more details as much as possible and generate higher quality images. Results: Experimental results from quantitative and qualitative comparisons between our CESR-GAN model and other state-of-the-art methods show that our proposed method outperforms the compared methods on ISIC, and PH2 datasets, respectively. Conclusion: The CESR-GANs method can be used to generate super resolution skin images of skin lesions with highly notable performances. © 2021","10.1016/j.imu.2021.100628","Deep learning; Generative adversarial network; Medical image analysis; Skin cancer; Super resolution","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108179793&doi=10.1016%2fj.imu.2021.100628&partnerID=40&md5=8374f1b3b0242810f4ead603cf7863ef"
"Automated cad system for skin lesion diagnosis: A review","Singh L.; Janghel R.R.; Sahu S.P.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Skin cancer is deemed as the lethal type of cancer threatening worldwide with an increase in mortality rate per year. The growing incidences of melanoma skin cancer have introduced numerous treatment options. However, surgical treatment remains the basis for treating skin cancers. Automated skin cancer detection still remains a challenging task in the current scenario. Prior diagnosis of skin cancer requires computer-aided diagnosis. Computerized methods for analyzing images in dermoscopy are a subject of interest as dominant information regarding skin lesions can be retrieved. This paper has discussed the state of art techniques employed in CAD systems by providing domain facets of melanoma accompanied by efficient methods utilized in every phase. The phases comprise image preprocessing techniques, extraction, and selection of significant features, segmentation methods, and classification approaches for the identification of skin lesions. Inapplicability and future trends are discussed in the domain of research. © 2021, Springer Nature Singapore Pte Ltd.","10.1007/978-981-15-6329-4_26","CAD system; Melanoma; Segmentation","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092223875&doi=10.1007%2f978-981-15-6329-4_26&partnerID=40&md5=a0bfcc2683f0da016f564beb563a8edd"
"Intelligent Data Analytics for Diagnosing Melanoma Skin Lesions via Deep Learning in IoT System","Zhang S.; Huang S.; Wu H.; Yang Z.; Chen Y.","2021","1","1","0","0","0","Unique","0","","","","","","","Melanoma is considered to be one of the most dangerous human malignancy, which is diagnosed visually or by dermoscopic analysis and histopathological examination. However, as these traditional methods are based on human experience and implemented manually, there have been great limitations for general usability in current clinical practice. In this paper, a novel hybrid machine learning approach is proposed to identify melanoma for skin healthcare in various cases. The proposed approach consists of classic machine learning methods, including convolutional neural networks (CNNs), EfficientNet, and XGBoost supervised machine learning. In the proposed approach, a deep learning model is trained directly from raw pixels and image labels for classification of skin lesions. Then, solely based on modeling of various features from patients, an XGBoost model is adopted to predict skin cancer. Following that, a diagnostic system which composed of the deep learning model and XGBoost model is developed to further improve the prediction efficiency and accuracy. Different from experience-based methods and solely image-based machine learning methods, the proposed approach is developed based on the theory of deep learning and feature engineering. Experiments show that the hybrid model outperforms single model like the traditional deep learning model or XGBoost model. Moreover, the data-driven-based characteristics can help the proposed approach develop a guideline for image analysis in other medical applications. © 2021 Shixiang Zhang et al.","10.1155/2021/8700506","","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120624934&doi=10.1155%2f2021%2f8700506&partnerID=40&md5=3eaa8099cb34b759759152dca556fae3"
"Image Classification of Skin Cancer: Using Deep Learning as a Tool for Skin Self-examinations","Anderson K.; Hori S.S.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Skin cancer is the most common cancer in the United States, and studies indicate that its incidence is rapidly increasing. Regular skin self-examinations enable early cancer detection and intervention and are recommended in addition to clinician-based examinations. However, some patients struggle to identify high-risk skin lesions due to the presence of an overwhelming number of lesions, as well as the subtlety of changes to their skin over time. Artificial intelligence (AI) offers an at-home solution to filter low-risk lesions from a patient’s self-examination, thereby reducing the number of lesions requiring routine monitoring. This allows patients to triage lesions during their self-examinations, focus primarily on monitoring high-risk lesions between clinical visits, and become aware when clinical inspection or follow-up is needed. We used the HAM10000 skin cancer dataset from Harvard Dataverse to develop deep-learning algorithms that aid in skin self-examination. ResNet-50, DenseNet-121, and VGG-16 models were used to distinguish low-risk lesions (melanocytic nevi, dermatofibroma, and benign keratosis-like lesions) from high-risk lesions (melanoma, basal cell carcinoma, actinic keratoses, and vascular lesions). Each model generated a prediction score ranging from 0 to 1, where 1 was classified as high-risk and 0 was classified as low-risk. To minimize the number of high-risk lesions classified as low-risk, a threshold of 0.01 was selected for differentiating classes, ensuring only predictions with high-confidence remained in the low-risk bracket. Once the classification threshold between low-risk and high-risk was adjusted, the VGG-16 algorithm removed 50.7% of images from self-examination workload with a precision value in the low-risk category of 0.98 and a recall value of 0.96 for high-risk lesions. The VGG-16 neural net outperformed alternative ResNet-50 and DenseNet-121 models. This work has the potential to make the task of skin self-examination more manageable for patients by identifying which suspicious lesions require follow-up consultation with a clinician. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-91241-3_1","Convolutional neural network; Deep learning; Dermatology; Melanoma; Skin cancer","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121900976&doi=10.1007%2f978-3-030-91241-3_1&partnerID=40&md5=29998b87b5f16748932009dc4206a406"
"MLRNet: Skin Lesion Segmentation using Hybrid Gaussian Guided Filter with CNN","Krishna D.M.; Sahu S.K.; Srinivasa Raju G.R.L.V.N.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Recently, the worldwide population has been suffering with skin cancer issues due to the unpredictable radiation levels of environment, which may lead to cause of death. Therefore, the early detection of skin cancer through accurate skin lesion segmentation can save the human life all around the world. Deep Learning has demonstrated improved performance in several modalities of biological image analysis in recent years. This work adopted the multi-layer residual convolutional neural network (MLRNet) for skin cancer segmentation. Initially, the test skin lesion image is preprocessed by using hybrid gaussian guided image filter (HGGIF) in discrete wavelet transform (DWT) domain, which removes the noise and various artifacts from the skin lesion images. Further, the filtered image is applied to MLRNet, which generates the accurate segmentation map. The simulations are carried out on both ISIC-2019 and PH2 datasets. The proposed method outperformed in both subjective and objective performances as compared to conventional deep learning approaches. Keywords- Skin Lesion Segmentation, Deep learning, Multi-Layer Residual Convolutional Neural Network, Gaussian filter, Guided Image Filter  © 2021 IEEE.","10.1109/ICECA52323.2021.9676020","","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125406575&doi=10.1109%2fICECA52323.2021.9676020&partnerID=40&md5=778419a3a4ab93341774e60c8abc2657"
"Synthetic Images Generation Using Conditional Generative Adversarial Network for Skin Cancer Classification","Kaur R.; Gholamhosseini H.; Sinha R.","2021","1","1","0","0","0","Unique","0","","","","","","","Deep learning and computer vision have achieved remarkable success in many areas of machine learning and medical diagnostics. However, there is still a remarkable gap between dermatologists' skin cancer diagnosis and reliable computer-Aided melanoma detection. There are several reasons behind this gap, and the availability of insufficient data for training deep learning networks is one of them. Data augmen-Tation is a popular technique to increase training data manifolds to mitigate the lack of data. In this paper, a conditional generative adversarial network (CGAN) is proposed to produce high-resolution synthetic images to augment the training data and gain higher performance of skin cancer detection systems. The artificial generation of images resembling real images is a difficult task owing to unstable information present in the skin lesions such as irregular borders, diameter, shape, color, and texture. The generator module of CGAN is designed to aggregate the information from all feature layers and produce synthetic images. Additionally, the generator incorporates the auxiliary information along with image inputs to map latent feature components successfully. The network is trained on 10,015 skin cancer images taken from the International Skin Imaging Collaboration (ISIC 2018). It was concluded from the experiments that the proposed model obtained better classi-fication performance as compared to the imbalanced original dataset and other state-of-The-Art methods.  © 2021 IEEE.","10.1109/TENCON54134.2021.9707291","Data augmentation; Deep learning; Generative adversarial convolutional network; Skin cancer","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125967024&doi=10.1109%2fTENCON54134.2021.9707291&partnerID=40&md5=5e31246c74fe87f24994a5bc53a96718"
"Classification of skin lesion with hair and artifacts removal using black-hat morphology and total variation","Khan A.H.; Iskandar D.N.F.A.; Al-Asad J.F.; El-Nakla S.","2021","1","1","0","0","0","Unique","0","","","","","","","Automatic classification of skin lesion plays vital role in the diagnosis of actual skin cancer type. This classification process requires spatial features information of the skin lesion but dermoscopic images are usually occluded with hair and other artifacts such as shadows and markers etc. This occlusion can affect the classification process which may lead to erroneous diagnosis of skin cancer. In this research an efficient method to enhance dermoscopic images by removing hair and other artifacts using black-hat morphological processing and total variation inpainting technique is proposed. Additionally, to show the impact of proposed enhancement of dermoscopic images, a technique is proposed in an effort to achieve results for skin lesion classification comparable to deep neural networks with as low cost as in Conv 2D by performing two dimensional convolution on images. This system passes through three convolution streams to comprehensively cater information. The proposed model is evaluated on a public Skin Lesion dataset which contains 2000 images. Results depict the improvement in classification accuracy of three skin cancer classes which are Melanoma, Nevus and Seborrheic Keratosis (SK), when hair and artifacts are eliminated by proposed method. © 2021 University of Bahrain. All rights reserved.","10.12785/IJCDS/100157","Classification; Hair and Artifact Removal; Neural Networks; Skin Lesion","23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106571058&doi=10.12785%2fIJCDS%2f100157&partnerID=40&md5=5d6d1862ad9f1dbb468f41492350be36"
"A Review-Novel Approaches in Diagnosis of Melanoma Skin Lesion","Salian S.R.; Sawarkar S.D.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Automated and computerized image analysis systems for unbiased diagnosis of Melanoma skin lesions are primary requirement. It has gained a great interest of researchers in the last few decades on skin lesion analysis. Computer based diagnostic systems are reliable source for clinicians in early detection of melanoma and help to predict the stand alone warning and treat the patients before time thus increasing chances of survival. However, it is difficult to accurately recognize melanoma skin lesion. We present an review of novel approaches used in computer aided system by comprehending key features of melanoma along with discussing the prominent techniques used in following phases like preprocessing of image, skin lesion segmentation, feature extraction from images and classification of skin lesion. We discuss various methodologies and results acquired at each phase. In future, the inadequacies is expected to be worked on so as to build a reliable and accurate diagnostic systems. © 2021 IEEE.","10.1109/ICNTE51185.2021.9487686","classification; feature extraction; Melanoma; segmentation; Skin Lesion","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112371758&doi=10.1109%2fICNTE51185.2021.9487686&partnerID=40&md5=c95a25f4f20ede43aa0b5bb104015696"
"An Efficient Image Processing and Machine Learning based Technique for Skin Lesion Segmentation and Classification","Imtiaz I.; Ahmed I.; Jeon G.; Muramatsu S.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Skin cancer is one of the most lethal types of cancer that has grown extensively over the last decade and can lead to death if not treated on time. However, if skin cancer is diagnosed and treated at an early stage, it can be curable. Several image processing and machine learning methods have been considered to detect and classify skin cancer lesions (melanoma) accurately. However, a lower contrast of images also affects the segmentation efficiency and further increments classification error. Thus, in this work, a simple yet effective image processing and machine learning based technique has been proposed for skin lesion segmentation and classification to overcome this problem. The proposed technique increases the segmentation accuracy in its pre-processing stage, removing noise and hair and enhance image contrast by adjusting intensity values of RGB channels. Otsu thresholding and image subtraction methods are applied to extract the region of interest and segmented lesion area. Morphological operations are performed to remove noisy pixels and reshape the segmented image at the post-processing stage. For extraction of image features, color and ABCD features are applied. The PH2 dataset is used in this work, consisting of imbalanced classes; therefore, Synthetic Minority Over-sampling Technique (SMOTE) is used to balance the distribution of the dataset. A supervised machine learning classifier further uses the extracted image features to classify skin lesions. The proposed technique accurately segments the lesion with an accuracy of 90.25% and classifies them into melanoma and non-melanoma with an average accuracy of 98.13% using the Adaboost classifier.  © 2021 APSIPA.","","","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126701516&partnerID=40&md5=3da524066dae50989ec8da7f6cbcbba7"
"Efficacy of Deep Learning Approach for Automated Melanoma Detection","Renjith V.S.; Subha Heney Jose P.","2021","0","1","0","0","0","Unique","0","","","","","","","Melanoma is considered the most perilous type of skin cancer. However, differentiating lesions of melanoma from non-melanoma lesions has proven difficult. For this purpose, many Computer-Assisted Automatic Diagnosis Technologies are proposed in the past. Due to the complicated visual properties of images of skin lesions, which include inhomogeneous fuzzy boundaries and features, they have been limited in their performance. The use of computer-aided systems to diagnose skin lesions is becoming more common. Researchers have recently expressed a growing interest in developing computer-assisted diagnosis methods. In this research, a deep learning system for automated melanoma segmentation and lesion classification addresses these constraints. For effective learning and feature extraction, an upgraded encoder-decoder with sub-networks is interconnected, bringing the encoder feature maps relatively closer to the feature maps of the decoder. For pixel-wise categorization of melanoma lesions, the system uses a multi-scale and multi-stage technique, as well as a soft-max classifier. A novel approach called Lesion-classifier divides lesions of skin into non- melanoma and melanoma on the basis of the findings of pixel-wise classification. These studies are on the ISIC 2017 dataset, with dice coefficient and accuracy of 92 and 95 percent, respectively, while on the PH2 datasets, the dice coefficient and accuracies are as 93 and 95 percent.  © 2021 IEEE.","10.1109/DASA53625.2021.9682388","deep learning; encoding-decoding network; melanoma; pixel-wise classification; Segmentation; skin lesion","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125777640&doi=10.1109%2fDASA53625.2021.9682388&partnerID=40&md5=2a15c2ad85f322dfa8dfb8c083865ea8"
"Skin Lesions Detection via Convolutional Neural Networks","Wan Z.; Zhang T.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Cutaneous malignancies, or skin cancers, are a frequently diagnosed type of cancer worldwide. A late-stage diagnosis of cancer causes it to spread and metastasize to other nearby organs. As the disease progresses, it can decline the patient's immune system, eventually to death. The main challenge in skin cancer diagnosis is classifying Melanoma from benign pigmented skin lesions and treating Melanoma early to save the patient's life. There have been growing appeals for using convolutional neural networks (CNN) in image recognition and classification. Recent studies of skin cancers detection via CNN methods have stimulated related studies, including using the advanced Region-CNN (R-CNN) algorithm. This article examines papers on detecting skin cancers/lesions using classic CNN methods and Faster R-CNN and evaluates their performance and classification results in several currently available data sets.  © 2021 IEEE.","10.1109/AINIT54228.2021.00070","Convolutional neural networks; skin cancer; skin lesion classification","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127485037&doi=10.1109%2fAINIT54228.2021.00070&partnerID=40&md5=4c6a108a0daba568b6f2df47a2f791de"
"Evaluation of big data based cnn models in classification of skin lesions with melanoma","Naronglerdrit P.; Mporas I.","2021","1","1","0","0","0","First occurrence","0","","","","","","","That chapter presents a method regarding diagnosis of pigmented skin lesions using convolutional neural networks. The architecture is modeled over convolutional neural networks and it is evaluated using new CNN models as well as re-trained modification of pre-existing CNN models were used. The experimental results showed that CNN models pre-trained on big datasets for general purpose image classification when re-trained in order to identify skin lesion types offer more accurate results when compared to convolutional neural network models trained explicitly from the dermatoscopic images. The best performance was achieved by re-training a modified version of ResNet-50 convolutional neural network with accuracy equal to 93.89%. Analysis on skin lesion pathology type was also performed with classification accuracy for melanoma and basal cell carcinoma being equal to 79.13 and 82.88%, respectively. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2021.","10.1007/978-981-15-6321-8_5","","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090876351&doi=10.1007%2f978-981-15-6321-8_5&partnerID=40&md5=a6c07225ceb9d8fd4d7038f67eebe752"
"Developing a Recognition System for Diagnosing Melanoma Skin Lesions Using Artificial Intelligence Algorithms","Alsaade F.W.; Aldhyani T.H.H.; Al-Adhaileh M.H.","2021","1","1","0","0","0","Unique","0","","","","","","","In recent years, computerized biomedical imaging and analysis have become extremely promising, more interesting, and highly beneficial. They provide remarkable information in the diagnoses of skin lesions. There have been developments in modern diagnostic systems that can help detect melanoma in its early stages to save the lives of many people. There is also a significant growth in the design of computer-aided diagnosis (CAD) systems using advanced artificial intelligence. The purpose of the present research is to develop a system to diagnose skin cancer, one that will lead to a high level of detection of the skin cancer. The proposed system was developed using deep learning and traditional artificial intelligence machine learning algorithms. The dermoscopy images were collected from the PH2 and ISIC 2018 in order to examine the diagnose system. The developed system is divided into feature-based and deep leaning. The feature-based system was developed based on feature-extracting methods. In order to segment the lesion from dermoscopy images, the active contour method was proposed. These skin lesions were processed using hybrid feature extractions, namely, the Local Binary Pattern (LBP) and Gray Level Co-occurrence Matrix (GLCM) methods to extract the texture features. The obtained features were then processed using the artificial neural network (ANNs) algorithm. In the second system, the convolutional neural network (CNNs) algorithm was applied for the efficient classification of skin diseases; the CNNs were pretrained using large AlexNet and ResNet50 transfer learning models. The experimental results show that the proposed method outperformed the state-of-art methods for HP2 and ISIC 2018 datasets. Standard evaluation metrics like accuracy, specificity, sensitivity, precision, recall, and F-score were employed to evaluate the results of the two proposed systems. The ANN model achieved the highest accuracy for PH2 (97.50%) and ISIC 2018 (98.35%) compared with the CNN model. The evaluation and comparison, proposed systems for classification and detection of melanoma are presented.  © 2021 Fawaz Waselallah Alsaade et al.","10.1155/2021/9998379","","44","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107175102&doi=10.1155%2f2021%2f9998379&partnerID=40&md5=77fd5d112a8db69e57c4d04d501c0764"
"A robust method for skin cancer diagnosis based on interval analysis","Zhang H.; Wang Z.; Liang L.; Sheykhahmad F.R.","2021","1","1","0","0","0","Unique","0","","","","","","","Early diagnosis of skin cancer from dermoscopy images significantly reduces the mortality due to this cancer. However, several reasons impact the system diagnosis precision. One of the important problems in this process happens during image acquisition. Often, in medical photography, there are some uncertainties like noises and brightness variations, initial digitalization and sampling which affect the image quality. This study presents a new approach for border detection of the cancer area by considering the uncertainties. Interval analysis is utilized to extend the proposed edge detection method and the Hukuhara method is utilized for developing the differentiation formula for edge detection in the interval space. Simulation results are applied to two different skin cancer atlas and the results are compared with three popular methods by considering two types of noises including Gaussian noise and salt-and-pepper noise. The results showed that the introduced method gives better results than the compared methods. © 2020 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","10.1080/00051144.2020.1835108","computer-aided diagnosis; Edge detection; Gaussian noise; Hukuhara difference; interval analysis; skin cancer; Taylor inclusion functions; uncertainty","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094850201&doi=10.1080%2f00051144.2020.1835108&partnerID=40&md5=363ec9fe19c90a6dab2c4d63566671cd"
"Pre-trained CNN Based Deep Features with Hand-Crafted Features and Patient Data for Skin Lesion Classification","Yildirim-Yayilgan S.; Arifaj B.; Rahimpour M.; Hardeberg J.Y.; Ahmedi L.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Skin cancer is a major public health problem, with millions newly diagnosed cases each year. Melanoma is the deadliest form of skin cancer, responsible for the most over 6500 deaths each year in the US, and the rates have been rising rapidly over years. Because of this, a lot of research is being done in automated image-based systems for skin lesion classification. In our paper we propose an automated melanoma and seborrheic keratosis recognition system, which is based on pre-trained deep network combined with structural features. We compare using different pre-trained deep networks, analyze the impact of using patient data in our approach, and evaluate our system performance with different datasets. Our results shown us that patient data has impact on characteristic curve metric value with around 2–6% and different algorithm in final classification layer has impact with around 1–4%. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-71711-7_13","CNN; Deep networks; Handcrafted features; Image processing; Skin lesion classification and segmentation","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103504273&doi=10.1007%2f978-3-030-71711-7_13&partnerID=40&md5=699070ea45ecabd2c7c935be2b21b407"
"Convolutional Neural Networks Applied for Skin Lesion Segmentation","Araujo G.S.; Cámara-Chávez G.; Oliveira R.B.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Skin cancer is one of the cancers that most aggravates the problem in public health. Among the types of cancer, melanoma is the most aggressive type. Its early diagnosis is essential to increase the possibility of adequate treatment, aiming to reduce the mortality rate. Dermatologists generally use manual methods to diagnose skin lesions. These methods, in addition to being time-consuming, as they are performed manually, can present different results for the same lesion when analyzed by different specialists. Therefore, an automated diagnosis may be necessary to deal with this issue as well as avoid invasive tests. For this, the task of segmenting the skin lesion in the dermoscopic image can be fundamental, as it is a basic task in the image analysis process. In the present work, a Convolutional Neural Network (CNN) model, based on the U-Net, is used to segment the lesion in dermoscopic images. This proposal achieved an accuracy of 0.949 and Jaccard of 0.833 for the 2017 ISIC base, and an accuracy of 0.954 and Jaccard of 0.850 for the 2018 ISIC base. The proposed model has a simpler architecture, in addition to requiring less computational resources. The experiments made it possible to observe that the proposed model results are promising compared with other CNN models presented in the literature. ©2021 IEEE","10.1109/CLEI53233.2021.9640189","Image segmentation; Melanoma; Rede Neural Convolucional; Skin lesion; U-Net","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123852698&doi=10.1109%2fCLEI53233.2021.9640189&partnerID=40&md5=c25abf5c7b031f5bf9fc6bdf47c77d1c"
"Applied Deep learning for categorizing dermoscopic images","Avgoustis A.; Exarchos T.; Kermanidis K.L.; Mylonas P.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Melanoma is a serious form of skin cancer that begins in cells known as melanocytes. While it is less common than basal cell carcinoma (BCC) and squamous cell carcinoma (SCC), melanoma is more dangerous because of its ability to spread to other organs more rapidly if it is not treated at an early stage. The basic examination for melanoma is dermoscopy, an image modality of the skin part that is affected. In this work, we propose a new deep learning approach, based on convolutional neural networks, to classify dermoscopic images in one out of 32 categories. An existing dataset, containing 2013 images from different categories of melanoma [10] has been used for the training and validation of our approach.  © 2021 IEEE.","10.1109/SMAP53521.2021.9610798","classification; convolution neural network; dermoscopic images; Skin cancer","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123184177&doi=10.1109%2fSMAP53521.2021.9610798&partnerID=40&md5=380786ffde6a1e0d330d2f22a24880ea"
"CNN-NSVM Architecture for Skin Lesion Classification Using Non-Dermoscopic Digital Image","Kabir M.M.; Mehera P.; Saha A.K.; Mridha M.F.; Hamid M.A.; Monowar M.M.","2021","1","1","0","0","0","Unique","0","","","","","","","Skin cancer has become a severe problem for medical diagnosis. The adoption of Artificial Intelligence (AI) in pharmaceutical diagnosis is constantly improving. Lately, AI-based computer-aided diagnostics explications for the diagnosis of skin disease have been of prominent concern. Notwithstanding its importance, skin lesion segmentation inhabits an unresolved difficulty of variability in shade, texture, patterns, and obscure borders. Melanoma, precisely called malignant melanoma, is the deadliest kind of skin cancer. It is much more spread to other body organs if it remains undiagnosed and is not treated early. Hence, early screening has the utmost importance in enhancing the cure probability. The proposed algorithms significantly impacted skin cancer classification until today, but they decayed classification rates while using Non-Dermoscopic Digital Images. This paper presents a new approach of classifying skin lesions from non-dermoscopic digital images using Convolutional Neural Network and Neutrosophic Logic Support Vector Machine (CNN-NSVM) combined approach. CNN extracts the features from the images, and the neutrosophic logic employed with SVM classifies the skin lesion types. The proposed methodology is evaluated on the well-known malignant lesion image dataset from the digital image archive of the Department of Dermatology of the University Medical Center Groningen (UMCG). The obtained accuracy of the proposed algorithm is 91% which outperformed MED-NODE by 10% on a similar dataset. Contribution-The paper introduced a skin cancer classification method from non-dermoscopic digital images based on Convolutional Neural Network and Neutrosophic Logic SVM (CNN-NSVM) to classify skin lesions into two types: Melanoma and Naevus. © 2021 IEEE","10.1109/ICIEVICIVPR52578.2021.9564195","Convolutional Neural Network; Deep Learning; Machine Learning; Neutrosophic Logic Support Vector Machine; Skin Lesion Classification","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126204429&doi=10.1109%2fICIEVICIVPR52578.2021.9564195&partnerID=40&md5=820b33922fc5d3c491cf7830dbd6cf79"
"Melanoma Classification Approach with Deep Learning-Based Feature Extraction Models","dos Santos A.R.F.; Aires K.R.T.; das Filho F.C.I.; de Sousa L.P.; de Veras R.M.S.; de Neto L.S.B.; de Neto A.L.M.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Resumo—Melanoma is considered the worst type of skin cancer. The early diagnosis of this disease is still a complex task due to many variables that must be analyzed. Because of this, new methodologies are becoming common in the literature due to the good results obtained. Convolutional Neural Networks are Deep Learning techniques capable of providing effective solutions in the classification of medical images. In this sense, this work developed a disease detection system using AlexNet and VGG-F convolutional architectures, trained with images of skin lesions to create feature descriptors, not classifiers. Other conventional descriptors of skin lesions were used to assess the quality of data obtained from the last layers of convolutional architectures. Data from all feature extraction processes were submitted to the conventional classifiers Support Vector Machine, Multilayer Perceptron, and K-Nearest Neighbor. The results obtained in the approach show that the feature extracting models are viable and can offer a more accurate melanoma diagnosis possibility. The VGG-F architecture obtained the best result, with an accuracy of 91.54% and a precision of 91.64% given by the K-Nearest Neighbor. It is possible to see that this result highlights the quality of data in convolutional architectures and can provide a sense of further research. ©2021 IEEE","10.1109/CLEI53233.2021.9639944","Convolutional Neural Networks; Deep Learning; Feature Extraction Models; Melanoma","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123862844&doi=10.1109%2fCLEI53233.2021.9639944&partnerID=40&md5=e4db336fc2a2e961e46b0b8e1bb57b68"
"The Effect of Partial Fine Tuning on AlexNet for Skin Lesions Classification","Ngesthi S.O.; Setyawan I.; Timotius I.K.","2021","1","1","0","0","0","Unique","0","","","","","","","Melanoma is the deadliest form of skin cancer. The similarity between melanoma and nevus brings a challenge in identifying the presence of melanoma. Hence, automatic recognition will help dermatologists in identifying the lesion. Here, we implement transfer learning on AlexNet to classify skin lesions into melanoma and nevus. Additionally, we make a comparison between full and partial fine-tuning. Full fine-tuning is applied on all layers, while partial is applied on the 13th to 25th layers. Both models are tested using three different datasets, i.e. HAM10000, MSK, and UDA, each containing 400 skin images. The results show that the fully tuning was trained in 82 minutes and achieved 91 %, 75.75%, and 84.75% classification accuracy for the test with HAM 10000, MSK, and UDA datasets, respectively. Partial tuning was trained in 63 minutes and achieved 92.25%, 77.75%, and 85.75% of classification accuracy for with HAM10000, MSK, and UDA datasets, respectively. These results show that partial fine-tuning gives an insignificant improvement in terms of accuracy, but a quite significant boost in training time.  © 2021 IEEE.","10.1109/ICITEE53064.2021.9611885","fine-tuning; full; melanoma; nevus; partial","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123342366&doi=10.1109%2fICITEE53064.2021.9611885&partnerID=40&md5=a240fa0acbb9987dffc543135d7441c2"
"Convolutional neural networks for the automatic diagnosis of melanoma: An extensive experimental study","Pérez E.; Reyes O.; Ventura S.","2021","0","1","0","0","0","Unique","0","","","","","","","Melanoma is the type of skin cancer with the highest levels of mortality, and it is more dangerous because it can spread to other parts of the body if not caught and treated early. Melanoma diagnosis is a complex task, even for expert dermatologists, mainly due to the great variety of morphologies in moles of patients. Accordingly, the automatic diagnosis of melanoma is a task that poses the challenge of developing efficient computational methods that ease the diagnostic and, therefore, aid dermatologists in decision-making. In this work, an extensive analysis was conducted, aiming at assessing and illustrating the effectiveness of convolutional neural networks in coping with this complex task. To achieve this objective, twelve well-known convolutional network models were evaluated on eleven public image datasets. The experimental study comprised five phases, where first it was analyzed the sensitivity of the models regarding the optimization algorithm used for their training, and then it was analyzed the impact in performance when using different techniques such as cost-sensitive learning, data augmentation and transfer learning. The conducted study confirmed the usefulness, effectiveness and robustness of different convolutional architectures in solving melanoma diagnosis problem. Also, important guidelines to researchers working on this area were provided, easing the selection of both the proper convolutional model and technique according the characteristics of data. © 2020 Elsevier B.V.","10.1016/j.media.2020.101858","Convolutional neural networks; Data augmentation; Dermoscopy images; Melanoma diagnosis; Transfer learning; Weigth balancing","59","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093972761&doi=10.1016%2fj.media.2020.101858&partnerID=40&md5=a4e31fdb3a40b4d012b80989c148cc74"
"Ensembles of Deep Convolutional Neural Networks for Detecting Melanoma in Dermoscopy Images","Tziomaka M.; Maglogiannis I.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Malignant melanoma is the deadliest form of skin cancer and is one of the most rapidly increasing cancers in the world. In this paper, a methodology for the SIIM-ISIC Melanoma Classification Challenge, where the goal is to detect melanoma from dermoscopic images, is described. The EfficientNet family of convolutional neural networks is utilized and extended for identifying malignant melanoma on a dataset of 58,457 dermoscopic images of pigmented skin lesions. This binary classification problem comes with a severe class imbalance, which is tackled using a loss balancing approach. Furthermore, the dataset contains images with different resolution sizes. This property is addressed by considering different model input resolutions. Lastly, an ensembling strategy of models, trained with different activation functions is applied to increase the diversity of the ensembler and to further improve individual results. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-88081-1_39","Convolutional neural networks; Deep learning; Dermoscopy; EfficientNet; Ensemble models; Melanoma classification","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116881876&doi=10.1007%2f978-3-030-88081-1_39&partnerID=40&md5=c80c624e62695936f48b2d7921b0e890"
"End-to-end classification on basal-cell carcinoma histopathology whole-slides images","Geijs D.J.; Pinckaers H.; Amir A.L.; Litjens G.J.S.","2021","0","1","0","0","0","Unique","0","","","","","","","The high incidence of BCC skin cancer caused that the amount of work for pathologists has risen to unprecedented levels. Acquiring outlined annotations for training deep learning models classifying BCC is often tedious and time consuming. End-to-end learning provides relief in labelling data by using a single label to predict an clinical outcome. We compared multiple-instance-learning (MIL) and a streaming performance for detecting BCC in 420 slides collected from 72 BCC positive patients. This resulted in an ROC with AUC of 0.96 and 0.98 for respectively streaming and MIL. Saliency and probability maps showed that both methods were capable of classifying classifying BCC in an end-to-end way with single labels. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","10.1117/12.2581042","","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103294235&doi=10.1117%2f12.2581042&partnerID=40&md5=7d38ab49e36d2c8b001270986d0a5bee"
"Image Segmentation and Transfer Learning Approach for Skin Classification","Huynh H.X.; Phan C.A.; Truong L.T.T.; Nguyen H.T.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Skin problems are not only detrimental to physical health but also cause psychological. Especially for patients with damaged or even disfigured faces. In recent years, the incidence of skin diseases has increased rapidly. The medical examination of skin lesions is not a simple task. There are similarities among skin lesions where the doctor’s experience with a little inattention can give an inaccurate diagnosis. The automatic classification of skin lesions is expected to save effort, time, and human life. This work has deployed a method using the pre-trained MobileNet model on about 1,280,000 images from the 2014 ImageNet challenge and refined over 25,331 images of the International Skin Imaging Collaboration (ISIC) 2019 dataset. Transfer learning was applied, replacing the classifier with an active softmax layer with three or eight types of skin lesions. An accuracy measure is used to evaluate the performance of the proposed method. © 2021, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","10.1007/978-3-030-93179-7_14","Classification; Segmentation; Skin lesions; Transfer learning","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123273251&doi=10.1007%2f978-3-030-93179-7_14&partnerID=40&md5=fd920daf20631abc28afc8621ffbb435"
"Binary Classification of Melanoma Skin Cancer using SVM and CNN","Tanna R.; Sharma T.","2021","1","1","0","0","0","Unique","0","","","","","","","Skin cancer is seen as one of the most hazardous form of cancers found in humans. Malignant Melanoma is a deadly and a dangerous type of skin cancer. Most skin cancers either spread to other parts of the body and are fatal unless identified and treated early. Medical technology has shown advancement in computer aided diagnosis systems which can classify dermoscopic images. In this paper, we propose two methods for the detection of Skin Cancers particularly with image data taken for melanoma cancerous cells. One is using Convolutional Neural Networks with three layers and the second one is simple model of Support Vector Machines with the default RBF kernel. After applying the image processing techniques, the extracted feature parameters are used to classify the image as Benign or Malignant. The calculation metrics are accuracy, ROC curve and the AUC and confusion matrix. The classification accuracy obtained using SVM classifier is 79.39% and AUC is 0.81. CNN is computed for 100 epochs and the accuracy obtained is 84.39%. The CNN model is bought to deployment in form of a web app with the help of Streamlit.  © 2021 IEEE.","10.1109/AIMV53313.2021.9670894","Benign; Classification; CNN; Malignant; Melanoma; Skin cancer; SVM","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125013806&doi=10.1109%2fAIMV53313.2021.9670894&partnerID=40&md5=37719b13604da7af4e1054f025c67f64"
"A latent space exploration for microscopic skin lesion augmentations with VQ-VAE-2 and PixelSNAIL","Gallucci A.; Pezzotti N.; Znamenskiy D.; Petkovic M.","2021","1","1","0","0","0","Unique","0","","","","","","","Skin cancer affects more than 3 million people only in the US. Comprehensive microscopic databases include around 30 thousand samples, limiting the richness of patterns that can be presented to machine learning. To this end, generative models such as GANs have been proposed for creating realistic synthetic images but, despite their popularity, they are often difficult to train and control. Recently an autoregressive approach based on a quantized autoencoder showed state of the art performances while being simple to train and provide synthetic data generation opportunities. In the first part of this paper we evaluate the training of VQ-VAE-2 with different latent space configuration. In the second part, we show how to use a learned prior over the latent space with PixelSNAIL to generate and modify skin lesions. We show how this process can be used for powerful data augmentation and visualization for skin health, evaluating it on a downstream application that classifies malignant lesions  © 2021 SPIE.","10.1117/12.2580664","Autoencoders; Autoregressive generation; Dermatology; Image generation; Skin lesions","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103654129&doi=10.1117%2f12.2580664&partnerID=40&md5=582553ebf7e980378e947779ef3f79ca"
"Tmd-unet: Triple-unet with multi-scale input features and dense skip connection for medical image segmentation","Tran S.-T.; Cheng C.-H.; Nguyen T.-T.; Le M.-H.; Liu D.-G.","2021","0","1","0","0","0","Unique","0","","","","","","","Deep learning is one of the most effective approaches to medical image processing applica-tions. Network models are being studied more and more for medical image segmentation challenges. The encoder–decoder structure is achieving great success, in particular the Unet architecture, which is used as a baseline architecture for the medical image segmentation networks. Traditional Unet and Unet-based networks still have a limitation that is not able to fully exploit the output features of the convolutional units in the node. In this study, we proposed a new network model named TMD-Unet, which had three main enhancements in comparison with Unet: (1) modifying the inter-connection of the network node, (2) using dilated convolution instead of the standard convolution, and (3) integrating the multi-scale input features on the input side of the model and applying a dense skip connection instead of a regular skip connection. Our experiments were performed on seven datasets, including many different medical image modalities such as colonoscopy, electron microscopy (EM), dermoscopy, computed tomography (CT), and magnetic resonance imaging (MRI). The segmentation applications implemented in the paper include EM, nuclei, polyp, skin lesion, left atrium, spleen, and liver segmentation. The dice score of our proposed models achieved 96.43% for liver segmentation, 95.51% for spleen segmentation, 92.65% for polyp segmentation, 94.11% for EM segmentation, 92.49% for nuclei segmentation, 91.81% for left atrium segmentation, and 87.27% for skin lesion segmentation. The experimental results showed that the proposed model was superior to the popular models for all seven applications, which demonstrates the high generality of the proposed model. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/healthcare9010054","Electron microscopy segmentation; Left atrium segmentation; Liver segmentation; Medical image segmentation; Nuclei segmentation; Polyp segmenta-tion; Skin lesion segmentation; Spleen segmentation; Unet architecture","71","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103693448&doi=10.3390%2fhealthcare9010054&partnerID=40&md5=f88a3bec6ab416c0d0615038ff54cc22"
"Melanoma Detection and Classification in Digital Dermoscopic Images Using Machine Learning","Kumar K.S.; Varalakshmi S.; Kumar G.S.; Kosalai T.","2021","0","1","0","0","0","Unique","0","","","","","","","Melanoma is an exceptional disastrous variety of skin growth. This category of cancer is disconcerting due to its habit of causing metastasis. Nevertheless, it sometimes tough to discern it from nevus due to their alike ocular look and symptoms. There are various steps in computer-assisted interpretation systems of melanoma such as image segmentation, edge detection, feature extraction, and classification. Image segmentation on dermoscopic pictures plays an imperative part in discovering melanoma. The existing segmentation methods are K-means clustering, convolutional neural network, ROI clustering, histogram equalization, RA pooling method, RGB, HSV, GLCM, Cole–Cole model, multi-variant analysis of variant, fully convolutional neural networks, and mobile imaging system. A support vector machine (SVM) is applied for the analysis of sheath malignancy to identify melanoma or nevus. The goal is to evaluate the effectiveness of the proposed segmentation method, highlights the most appropriate options, and compares the classification methods. © 2021, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","10.1007/978-981-16-1395-1_36","Classification; Dermoscopic images; Hue value saturation; Image segmentation; Malignant detection; Melanoma; Skin cancer","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111377618&doi=10.1007%2f978-981-16-1395-1_36&partnerID=40&md5=fcb105414f465b3dc80649e1832c71ff"
"An Automated Deep Learning based Ensemble Approach for Malignant Melanoma Detection using Dermoscopy Images","Safdar K.; Akbar S.; Gull S.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Melanoma is categorized as an extremely lethal type of skin cancer. Its earlier and timely diagnosis is the only solution to minimize the fatality rate in patients. Various computer aided diagnosis (CAD) systems have been designed which show great advancement in lesion segmentation and classification. The Model Blending approach is the ensemble of multiple Convolutional Neural networks (CNNs) which results into lower variance in their output predictions, thus reducing the generalization error by many folds. This proposed study is designed to provide a fully automated deep learning based melanoma detection framework using multiple, standard skin lesion databases including PH2, Med-Node and ISIC-2020. Extensive pre-processing on dermoscopic images is performed to remove useless artefacts and preserve illumination effects. Semantic segmentation is carried out using a Fully Convolutional Network (FCN-8), followed by image augmentation methods. An ensemble of deep ResNet-50 and Inception-V3 has been designed to perform binary classification (benign or melanoma) of lesion images. The segmentation approach exhibited satisfactory performance with an accuracy score of 94%, Dice coefficient 88% and Jaccard similarity coefficient 89% In the classification task, the pre-trained CNN model successfully recorded an average accuracy of 93.4%, specificity 96.5%, ROC-AUC 98.8% and average precision 89.5% on augmented dermoscopy images. The classification results of the model are deeply analyzed and compared with other ultra-modern melanoma diagnosis frameworks which indicate that our proposed model successfully achieved better segmentation and classification results. This ensemble approach is fully practicable and can be deployed by dermatologists as their medical assistant/guide.  © 2021 IEEE.","10.1109/FIT53504.2021.00046","deep learning (DL); dermoscopy; image segmentation; melanoma; skin cancer detection","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126910452&doi=10.1109%2fFIT53504.2021.00046&partnerID=40&md5=81c54dd06ca5f1dd9b5f6144e4950827"
"Skin lesion segmentation and multiclass classification using deep learning features and improved moth flame optimization","Khan M.A.; Sharif M.; Akram T.; Damaševičius R.; Maskeliūnas R.","2021","1","1","0","0","0","Unique","0","","","","","","","Manual diagnosis of skin cancer is time-consuming and expensive; therefore, it is essential to develop automated diagnostics methods with the ability to classify multiclass skin lesions with greater accuracy. We propose a fully automated approach for multiclass skin lesion segmentation and classification by using the most discriminant deep features. First, the input images are initially enhanced using local color-controlled histogram intensity values (LCcHIV). Next, saliency is esti-mated using a novel Deep Saliency Segmentation method, which uses a custom convolutional neural network (CNN) of ten layers. The generated heat map is converted into a binary image using a thresholding function. Next, the segmented color lesion images are used for feature extraction by a deep pre-trained CNN model. To avoid the curse of dimensionality, we implement an improved moth flame optimization (IMFO) algorithm to select the most discriminant features. The resultant features are fused using a multiset maximum correlation analysis (MMCA) and classified using the Kernel Extreme Learning Machine (KELM) classifier. The segmentation performance of the proposed methodology is analyzed on ISBI 2016, ISBI 2017, ISIC 2018, and PH2 datasets, achieving an accuracy of 95.38%, 95.79%, 92.69%, and 98.70%, respectively. The classification performance is evaluated on the HAM10000 dataset and achieved an accuracy of 90.67%. To prove the effectiveness of the proposed methods, we present a comparison with the state-of-the-art techniques. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/diagnostics11050811","Deep features; Feature fusion; Heuristic feature optimization; Melanoma; Moth flame optimization; Skin cancer","232","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106302042&doi=10.3390%2fdiagnostics11050811&partnerID=40&md5=a3e3d4fa6ab1bbb3703a9d0379b5f3d2"
"A Concatenated Model with Deep Learning Technique for Skin Lesion Detection","Das A.; Mohapatra S.K.; Mohanty M.N.","2021","1","1","0","0","0","Unique","0","","","","","","","Unusual development of skin cells tends to the skin lesion problem. Early diagnosis may help to avoid some types of cancers like melanoma and focal cell carcinoma. The detection and classification of malignant growth in the skin at the beginning stage are challenging tasks for researchers, and medical professionals. For further improvement of the deep learning models, a concatenated model is proposed with a deep learning technique that uses an integration of non-statistical and statistical features. This offered model utilizes the Convolutional neural network (CNN) model to mine non-statistical image features and Multilayer Perceptron (MLP) to process statistical features as handcrafted features. It is shown that the accuracy of the proposed model is improved to 98.1%.  © 2021 IEEE.","10.1109/ISCON52037.2021.9702339","Classification; CNN; Deep Learning; Multilayer Perceptron; Skin Lesion; Statistical Features","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126431210&doi=10.1109%2fISCON52037.2021.9702339&partnerID=40&md5=770ac9059d298cecdd0a3f31018adc3e"
"SELECTED APPLICATIONS OF DEEP NEURAL NETWORKS IN SKIN LESION DIAGNOSTIC; [WYBRANE ZASTOSOWANIA GŁĘBOKICH SIECI NEURONOWYCH W DIAGNOZIE ZMIAN SKÓRNYCH]","Michalska-Ciekańska M.","2021","1","1","0","0","0","Unique","0","","","","","","","The article provides an overview of selected applications of deep neural networks in the diagnosis of skin lesions from human dermatoscopic images, including many dermatological diseases, including very dangerous malignant melanoma. The lesion segmentation process, features selection and classification was described. Application examples of binary and multiclass classification are given. The described algorithms have been widely used in the diagnosis of skin lesions. The effectiveness, specificity, and accuracy of classifiers were compared and analyzed based on available datasets. © 2021, Politechnika Lubelska. All rights reserved.","10.35784/iapgos.2804","dermatoscopic images; melanoma; neural networks; skin lesions","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147813867&doi=10.35784%2fiapgos.2804&partnerID=40&md5=cd78415775d5876fde1a52797c580d50"
"Optical technologies for the improvement of skin cancer diagnosis: A review","Rey-Barroso L.; Peña-Gutiérrez S.; Yáñez C.; Burgos-Fernández F.J.; Vilaseca M.; Royo S.","2021","1","1","0","0","0","Unique","0","","","","","","","The worldwide incidence of skin cancer has risen rapidly in the last decades, becoming one in three cancers nowadays. Currently, a person has a 4% chance of developing melanoma, the most aggressive form of skin cancer, which causes the greatest number of deaths. In the context of increasing incidence and mortality, skin cancer bears a heavy health and economic burden. Nevertheless, the 5-year survival rate for people with skin cancer significantly improves if the disease is detected and treated early. Accordingly, large research efforts have been devoted to achieve early detection and better understanding of the disease, with the aim of reversing the progressive trend of rising incidence and mortality, especially regarding melanoma. This paper reviews a variety of the optical modalities that have been used in the last years in order to improve non-invasive diagnosis of skin cancer, including confocal microscopy, multispectral imaging, threedimensional topography, optical coherence tomography, polarimetry, self-mixing interferometry, and machine learning algorithms. The basics of each of these technologies together with the most relevant achievements obtained are described, as well as some of the obstacles still to be resolved and milestones to be met. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/s21010252","3D topography; Confocal microscopy; Machine learning; Melanoma; Multispectral imaging; Optical coherence tomography; Optical feed-back interferometry; Polarimetry; Skin cancer","86","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098975598&doi=10.3390%2fs21010252&partnerID=40&md5=4cfdf442895669c8a913d03f706e72d4"
"Artificial Intelligence in Skin Cancer: Diagnosis and Therapy","Das T.; Kumar V.; Prakash A.; Lynn A.M.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Skin cancer is one of the major public health problems worldwide. Its early diagnosis and timely therapy are immensely important in improving patient health. Thus, the improved and accessible diagnostic systems for skin cancer are the most potent determinant of getting the right treatment at the right time. The last two decades have seen unprecedented growth in the application of artificial intelligence (AI) for skin cancer research. Recent advancement in the computational power, digitization of medical imaging, rise of -omics data have accumulated a new opportunity. The ability of AI methods to detect hidden or unknown patterns from such complex datasets reveals their importance. The AI approach in skin cancer has helped to improve the diagnostic and therapeutic strategies, from risk assessment using genomic sequences, accessible smartphone-based “apps” for diagnosis to predict the likelihood of therapy response amidst others. This technology holds a promising potential to automate and assist primary clinicians in improving patient health outcomes through effective diagnostic and therapy strategies using the complex healthcare data paving in the way for precision medicine. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2021.","10.1007/978-981-16-0364-8_9","Artificial intelligence; Convolutional neural network; Deep learning; Image analysis; Machine learning; Melanoma; Non-melanoma; Skin cancer; Targeted therapy","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124609595&doi=10.1007%2f978-981-16-0364-8_9&partnerID=40&md5=3955f2328aa84a1afceda83749d798a9"
"Ensemble Learning for Detection of Types of Melanoma","Patil R.; Bellary S.","2021","0","1","0","0","0","Unique","0","","","","","","","Melanoma is a potentially fatal type of skin cancer in these melanocytes develop uncontrollably. Malignant melanoma is another name for melanoma. Melanoma rates in Australia and New Zealand are the highest in the world. Melanoma is anticipated to strike one in every 15 white New Zealanders at some point in their lives. Invasive melanoma was the third most prevalent malignancy in both men and women in 2012. Melanoma can strike adults of any age, but it is extremely uncommon in youngsters. Melanoma is hypothesised to start as an uncontrolled proliferation of genetically transformed melanocytic stem cells. Early diagnosis of melanoma in Dermoscopy pictures boosts the survival percentage substantially. Melanoma detection, on the other hand, is extremely difficult. As a result, automatic identification of skin cancer is extremely beneficial to pathologists' accuracy. This paper offers an ensemble deep learning strategy for accurately classifying the kind of melanoma at an early stage. The proposed model distinguishes between lentigo maligna, superficial spreading and nodular melanoma, allowing for early detection of the virus and prompt isolation and treatment to prevent the disease from spreading further. The deep layer architectures of the convolutional neural network (CNN) and the shallow structure of the pixel-based multilayer perceptron (MLP) are neural network algorithms that represent deep learning (DL) technique and the classical non-parametric machine learning method. Two methods that have diverse behaviours, were combined in a simple and successful means for the classification of very fine melanoma type detection utilising a rule-based decision fusion methodology. On dataset retrieved from https://dermnetnz.org/, the efficiency of ensemble MLP-CNN classifier was examined. In compared to state-of-the-art approaches, experimental outcomes reveal that the proposed technique is worthier in terms of diagnostic accuracy  © 2021 IEEE.","10.1109/CCGE50943.2021.9776373","convolutional neural network; deep learning models; machine learning classification; multi-layer perceptron; types of melanoma","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131834922&doi=10.1109%2fCCGE50943.2021.9776373&partnerID=40&md5=50c463c1dea95927fd676ef47da8bf30"
"Internet of Medical Things (IoMT) Enabled Skin Lesion Detection and Classification Using Optimal Segmentation and Restricted Boltzmann Machines","Peter Soosai Anandaraj A.; Gomathy V.; Amali Angel Punitha A.; Abitha Kumari D.; Sheeba Rani S.; Sureshkumar S.","2021","1","1","0","0","0","First occurrence","0","","","","","","","In recent times, Internet of Medical Things (IoMT) and cloud enabled healthcare applications and services finds helpful for effective decision-making. Melanoma is the serious kind of skin cancer, results to high death rate. Earlier identification of skin cancer can leads to maximum survival rate. But the diagnosis process becomes difficult and expensive because of the need of medical experts and complex medical equipments. To overcome this issue, the latest developments in IoMT based decision making system with maximum performance can be used. This study introduces a new IoMT based skin lesion detection and classification model using Optimal Segmentation and Restricted Boltzmann Machines (RBM), named OS-RBM model. The proposed OS-RBM model involves a series of steps namely image acquisition, gaussian filtering (GF) based preprocessing, segmentation, feature extraction, and classification. Then, optimal segmentation using artificial bee colony (ABC) with kapur’s thresholding takes place. Besides, histogram and texture feature extraction will be carried out. Finally, RBM is applied as a classifier to detect and classify the existence of skin lesion in the dermoscopic images. A detailed simulation analysis takes place for ensuring the better outcome of the OS-RBM model and the results are assessed under diverse performance measures. The experimental outcome ensured the effective classification performance of the OS-RBM model with the maximum sensitivity of 96.43%, specificity of 97.95% and accuracy of 95.68%. © 2021, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-030-55833-8_12","Classification; Deep learning; Restricted Boltzmann machine; Segmentation; Skin lesion","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093840457&doi=10.1007%2f978-3-030-55833-8_12&partnerID=40&md5=df5e3bf84501a1387e425b7e25c0aa0f"
"Deep Learning and Transfer Learning for Skin Cancer Segmentation and Classification","Li L.; Seo W.","2021","1","1","0","0","0","First occurrence","0","","","","","","","According to Skin Cancer Foundation, skin cancer is by far the most common type of cancer in the United States and worldwide. Early diagnosis of skin cancer is critical because proper treatment at early stages can increase the chance of cure and recovery. However, visual inspection of dermoscopic images by dermatologists is error-prone and time-consuming. To ensure accurate diagnosis and faster treatment of skin cancer, deep learning techniques have been utilized to conduct automated skin lesion segmentation and classification. In this paper, after image processing, a Mask R-CNN model is built for lesion segmentation, where transfer learning is utilized by using the pre-trained weights from Microsoft COCO dataset. The weights of the trained Mask R-CNN model are saved and transferred to the next task - skin lesion classification, to train a Mask R-CNN model for classification. Our experiments are conducted on the benchmark datasets from the International Skin Imaging Collaboration 2018 (ISIC 2018) and evaluated by the same metrics used in ISIC 2018. The lesion boundary segmentation and lesion classification have achieved an accuracy of 96% and a balanced multiclass accuracy of 80%, respectively.  © 2021 IEEE.","10.1109/BIBE52308.2021.9635175","deep learning; dermoscopic images; lesion boundary segmentation; lesion classification; Mask R-CNN; skin cancer; transfer learning","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123711024&doi=10.1109%2fBIBE52308.2021.9635175&partnerID=40&md5=2141d3b7ba46dc6903fad21adbe60dea"
"Efficient skin cancer diagnosis based on deep learning approach using lesions skeleton","Filali Y.; Sabri M.A.; Aarab A.","2021","1","1","0","0","0","Unique","0","","","","","","","Skin cancer is one of the most threatening cancer all over the world. The early detection of this skin cancer could help dermatologists in saving patients' lives. For that, a computer-aided diagnosis is used for an early evaluation of this kind of cancer. Skeletons of the lesions are an effective representation making it possible to properly describe the shape and size of lesions and thus used to classify them effectively as melanoma or non-melanoma. Therefore, the proposed idea in this paper is to use the lesions skeleton as deep learning entry instead of the original images. Experimentation shows that this idea can both increase the classification rate, in comparison with recent approaches from the literature, and thus reduce the number of layers used to create the deep network. The accuracy of our proposed approach on the well-known ISIC challenge and dermoscopy datasets is 95%, showing the effectiveness of our system. Copyright © 2021 Inderscience Enterprises Ltd.","10.1504/IJCC.2021.120395","CNN; Convolutional neural network; Deep learning; Melanoma; Skeleton; Skin cancer","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123942286&doi=10.1504%2fIJCC.2021.120395&partnerID=40&md5=6f385b21a74b593e5299f2c4a9edc1c5"
"Classification of Dermoscopy Skin Images with the Application of Deep Learning Techniques","Minango Negrete P.D.; Iano Y.; Borges Monteiro A.C.; Padilha França R.; de Oliveira G.G.; Pajuelo D.","2021","1","1","0","0","0","First occurrence","0","","","","","","","The aid-computer assistant is important for the improvement in the diagnostic of skin lesions, principally to detect melanoma, which is the most dangerous skin cancer type. The principal goal of the aid-computer assistant is to detect melanoma in its initial stage because the probability of the five-year survival ratio is over 95%. With the purpose of diagnosed early, in this paper we propose an algorithm based on deep learning to classified dermoscopy images with two types of skin lesions, which are melanoma or malignant cancer and benign cancer. We use AlexNet architecture modified to attend our problem, which was trained twice times with 2000 and 3000 images, divide into three sets (training, validation, and test set). We analyze three types of optimizers in order to improve the process of learning, where the best result was obtained by SGD with an accuracy of 99.79% for the training set, 81.50% for the validation set, and 79.17% for the test set in the scenery of 4000 images. © 2021, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-030-57566-3_7","AlexNet; CNN; Deep learning; Dermoscopy images; Melanoma; Non-melanoma; Skin cancer","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098175518&doi=10.1007%2f978-3-030-57566-3_7&partnerID=40&md5=9073b0126a3ad7e50e70acd1c5f730b2"
"Melanoma Classification Method Based on Ensemble Convolutional Neural Network","Shen X.; Wei L.; Lu H.; Sheng X.","2021","0","1","0","0","0","Unique","0","","","","","","","Melanoma is the most serious form of skin cancer, with more than 123,000 new cases worldwide each year. Reliable automatic melanoma screening system will be a great help for clinicians to detect malignant skin lesions as soon as possible. To address this problem, a computer-assisted approach to detecting melanoma using convolutional neural networks will enable effective and faster treatment of the disease. Many attempts have been made to use convolutional neural networks to solve this problem, but so far the performance in this aspect is not good. In this project, Xception and VGG-16 models will be fine-tuned on the IEEE International Symposium on Biomedical Imaging (ISBI) Official Skin Data Set 2016 and combined into an integrated framework to predict whether skin disease images are benign or malignant. Our experimental results show that the ensemble model can achieve better classification results and the proposed method is competitive in this field. © 2021, Springer Nature Singapore Pte Ltd.","10.1007/978-981-16-7207-1_13","Convolutional neural network; Deep learning; Ensemble; Melanoma","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118126880&doi=10.1007%2f978-981-16-7207-1_13&partnerID=40&md5=4bf725c30a0fb3fbcba5822e0c876f7d"
"Achievements of neural network in skin lesions classification","Hameed N.; Shabut A.; Hameed F.; Cirstea S.; Hossain A.","2021","1","1","0","0","0","Unique","0","","","","","","","The gross mismatch of skin disease cases and the specialties to manage them is the main cause of a continuously increased disease burden. The skin disease burden contributes 1.79% toward the global disease burden. To lessen this burden, automated skin lesions classification schemes that can provide multiclass classification are highly demanded. This chapter presents an investigation into an automated classification scheme to classify multiple skin lesions (acne, eczema, psoriasis; benign, and malignant) using state-of-the-art machine learning techniques. In the proposed classification scheme, convolution neural network (CNN) is utilized using the transfer learning approach, and a pretrained CNN model “AlexNet” is used to retrain the classification model on the skin lesion dataset. The proposed classification scheme outperformed over existing classification schemes and obtained an accuracy of 96.65%. The multiclass classification scheme can be very beneficial in the limited resource areas as it can assist in the early diagnosis of multiple skin lesions. © 2021 Elsevier Inc. All rights reserved.","10.1016/B978-0-12-819740-0.00007-3","Acne classification; Automated skin diseases classification; Computer-aided diagnosis; Deep learning; Dermatological image classification; Eczema classification; Machine learning; Psoriasis classification; Skin cancer classification; Skin lesions classification; Transfer learning","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126802972&doi=10.1016%2fB978-0-12-819740-0.00007-3&partnerID=40&md5=357b77d9a93721d8c1a542503e0c93c7"
"A CNN-Based Model for Early Melanoma Detection","Sallam A.; Ba Alawi A.E.; Saeed A.Y.A.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Melanoma is a serious form of skin cancer that develops from pigment-producing cells known as melanocytes, which in turn produce melanin that gives your skin its color. Early detection of these symptoms will certainly help affected people to overcome their suffering and find appropriate solutions for their treatment methods. That is why researchers have tried in many studies to provide technical solutions to help early detection of skin cancer. In this paper, a smart pre-trained model based on deep learning techniques for the early detection of Melanoma and Nevus has been proposed. It is designed to track and divide the dynamic features of the dermoscopic ISIC dataset into two distinguished classes Melanoma and Nevus of epidermal pathologies. AlexNet and GoogLeNet are used to classify each cancer type according to their profile features. It was found that the average classification accuracy for the above-mentioned algorithms is 90.2% and 89% respectively, providing plausible results when comparing to other existing models. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-030-70713-2_5","AlexNet; CAD; Dermatologist; Dermoscopic; GoogLeNet; Melanoma; Skin diseases","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105507083&doi=10.1007%2f978-3-030-70713-2_5&partnerID=40&md5=798dd4a847f88425028a1d6ff825bc09"
"Deep Learning in Medical Applications: Lesion Segmentation in Skin Cancer Images Using Modified and Improved Encoder-Decoder Architecture","Kaur R.; GholamHosseini H.; Sinha R.","2021","1","1","0","0","0","First occurrence","0","","","","","","","The rise of deep learning techniques, such as a convolutional neural network (CNN) in solving medical image problems, offered fascinating results that motivated researchers to design automatic diagnostic systems. Image segmentation is one of the crucial and challenging steps in the design of a computer-aided diagnosis system owing to the presence of low contrast between skin lesion and background, noise artifacts, color variations, and irregular lesion boundaries. In this paper, we propose a modified and improved encoder-decoder architecture with a smaller network depth and a smaller number of kernels to enhance the segmentation process. The network performs segmentation for skin cancer images to obtain information about the infected area. The proposed model utilizes the power of the VGG19 network’s weight layers for calculating rich features. The deconvolutional layers were designed to regain spatial information of the image. In addition to this, optimized training parameters were adopted to further improve the network’s performance. The designed network was evaluated for two publicly available benchmarked datasets ISIC, and PH2 consists of dermoscopic skin cancer images. The experimental observations proved that the proposed network achieved the higher average values of segmentation accuracy 95.67%, IoU 96.70%, and BF-score of 89.20% on ISIC 2017 and accuracy 98.50%, IoU 93.25%, and BF-score 84.08% on PH2 datasets as compared to other state-of-the-art algorithms on the same datasets. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-72073-5_4","Deep learning; Image segmentation; Medical image analysis; Skin cancer","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104889412&doi=10.1007%2f978-3-030-72073-5_4&partnerID=40&md5=90615854c4336b867bbfd8fc98ddabe6"
"Multi-Scale Context Interaction Learning network for Medical Image Segmentation","Fang W.; Han X.-H.; Qiao X.; Jiang H.; Chen Y.-W.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Semantic segmentation methods based on deep learning have provided the state-of-the-art performance in recent years. Based on deep learning, many Convolutional Neural Network (CNN) models have been proposed. Among them, U-Net with the simple encoder and decoder structure, can learn multi-scale features with various context information and has become one of the most popular neural network architectures for medical image segmentation. To reuse the features with the detail image structure in the encoder path, U-Net utilizes a skip-connection structure to simply copy the low-level features in the encoder to the decoder, and cannot explore the correlations between two paths and different scales. This study proposes a multi-scale context interaction learning network (MCIU-net) for medical image segmentation. First, to effectively fuse the features with detail structure in the encoder path and more semantic information in the decoder path, we conduct interaction learning on the corresponding scale via the bi-directional ConvLSTM (BConvLSTM) unit. Second, the interaction learning among all blocks of the decoder path is also employed for dynamically merging multi-scale contexts. We validate our proposed interaction learning network on three medical image datasets: retinal blood vessel segmentation, skin lesion segmentation, and lung segmentation, and demonstrate promising results compared with the state-of-the-art methods. © 2021 IEEE.","10.1109/MIPR51284.2021.00036","CNN; Medical image; Semantic segmentation","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126215447&doi=10.1109%2fMIPR51284.2021.00036&partnerID=40&md5=8738c0d561d8bf55f30fe552c2b3fbee"
"Boundary-Aware Transformers for Skin Lesion Segmentation","Wang J.; Wei L.; Wang L.; Zhou Q.; Zhu L.; Qin J.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Skin lesion segmentation from dermoscopy images is of great importance for improving the quantitative analysis of skin cancer. However, the automatic segmentation of melanoma is a very challenging task owing to the large variation of melanoma and ambiguous boundaries of lesion areas. While convolutional neutral networks (CNNs) have achieved remarkable progress in this task, most of existing solutions are still incapable of effectively capturing global dependencies to counteract the inductive bias caused by limited receptive fields. Recently, transformers have been proposed as a promising tool for global context modeling by employing a powerful global attention mechanism, but one of their main shortcomings when applied to segmentation tasks is that they cannot effectively extract sufficient local details to tackle ambiguous boundaries. We propose a novel boundary-aware transformer (BAT) to comprehensively address the challenges of automatic skin lesion segmentation. Specifically, we integrate a new boundary-wise attention gate (BAG) into transformers to enable the whole network to not only effectively model global long-range dependencies via transformers but also, simultaneously, capture more local details by making full use of boundary-wise prior knowledge. Particularly, the auxiliary supervision of BAG is capable of assisting transformers to learn position embedding as it provides much spatial information. We conducted extensive experiments to evaluate the proposed BAT and experiments corroborate its effectiveness, consistently outperforming state-of-the-art methods in two famous datasets (Code is available at https://github.com/jcwang123/BA-Transformer ). © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-87193-2_20","Deep learning; Medical image segmentation; Transformer","169","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116438599&doi=10.1007%2f978-3-030-87193-2_20&partnerID=40&md5=0a059cb3b8aab5656f2088887f54940f"
"Efficient Unet with depth-aware gated fusion for automatic skin lesion segmentation","Ding X.; Wang S.","2021","1","1","0","0","0","Unique","0","","","","","","","Melanoma is a very serious disease. The segmentation of skin lesions is a critical step for diagnosing melanoma. However, skin lesions possess the characteristics of large size variations, irregular shapes, blurring borders, and complex background information, thus making the segmentation of skin lesions remain a challenging problem. Though deep learning models usually achieve good segmentation performance for skin lesion segmentation, they have a large number of parameters and FLOPs, which limits their application scenarios. These models also do not make good use of low-level feature maps, which are essential for predicting detailed information. The Proposed EUnet-DGF uses MBconv to implement its lightweight encoder and maintains a strong encoding ability. Moreover, the depth-aware gated fusion block designed by us can fuse feature maps of different depths and help predict pixels on small patterns. The experiments conducted on the ISIC 2017 dataset and PH2 dataset show the superiority of our model. In particular, EUnet-DGF only accounts for 19% and 6.8% of the original Unet in terms of the number of parameters and FLOPs. It possesses a great application potential in practical computer-aided diagnosis systems.  © 2021 - IOS Press. All rights reserved.","10.3233/JIFS-202566","deep learning; dermoscopic images; gated fusion; Skin lesion segmentation; Unet","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104940826&doi=10.3233%2fJIFS-202566&partnerID=40&md5=50e5bc81d07199ec743fc6f84799c193"
"A new approach to skin lesion classification with EnTransfer CNN","Soyuslu N.S.; Durusoy Y.; Kucukoner M.S.","2021","1","1","0","0","0","Unique","0","","","","","","","Skin cancers are common all over the world. It is expected that an increase will occur in the incidence of skin cancers due to the decrease of the ozone levels in the atmosphere. Early diagnosis of skin cancers increases the survival rate. Many studies have been published that detect skin cancer from dermatoscope images with deep learning algorithms so far. In this study, it is aimed to compare the success of transfer learning models and ensemble transfer learning models in the early diagnosis of skin cancers. 17,571 dermatoscope images containing 9 different skin lesions were used in the study. The data were divided into training, validation, and testing subsets. Then, 7 different transfer learning models were trained and evaluated with these data. Next, the best performing 2-to-7 models were assembled using our proposed ensemble method 'En Transfer' which is based on the stacked ensemble framework. Among the models evaluated with the test data (1760 images), the ensemble model created with the best 5 top-model achieved 93% accuracy (0.9316 weighted mean F1 score), and was the most successful. Among the non-combined models, InceptionResnetV2 achieved 89% accuracy (0.8947 weighted mean F1 score) and was the most successful. The data obtained showed that deep learning models can detect skin cancers with a high success rate. Also, it is shown that our ensemble models' success is much more than a single transfer learning model can achieve. Furthermore, by using the models trained in our study, new applications classifying 9 different lesions can be developed. © 2021 IEEE.","10.1109/ASYU52992.2021.9599051","cancer; deep learning; ensemble modeling; neural networks; skin lesion; transfer learning","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123173503&doi=10.1109%2fASYU52992.2021.9599051&partnerID=40&md5=ad0e7a030f290e597022631e39418791"
"A Computer-Aided Diagnosis System Using Deep Learning for Multiclass Skin Lesion Classification","Arshad M.; Khan M.A.; Tariq U.; Armghan A.; Alenezi F.; Younus Javed M.; Aslam S.M.; Kadry S.","2021","1","1","0","0","0","Unique","0","","","","","","","In the USA, each year, almost 5.4 million people are diagnosed with skin cancer. Melanoma is one of the most dangerous types of skin cancer, and its survival rate is 5%. The development of skin cancer has risen over the last couple of years. Early identification of skin cancer can help reduce the human mortality rate. Dermoscopy is a technology used for the acquisition of skin images. However, the manual inspection process consumes more time and required much cost. The recent development in the area of deep learning showed significant performance for classification tasks. In this research work, a new automated framework is proposed for multiclass skin lesion classification. The proposed framework consists of a series of steps. In the first step, augmentation is performed. For the augmentation process, three operations are performed: rotate 90, right-left flip, and up and down flip. In the second step, deep models are fine-tuned. Two models are opted, such as ResNet-50 and ResNet-101, and updated their layers. In the third step, transfer learning is applied to train both fine-tuned deep models on augmented datasets. In the succeeding stage, features are extracted and performed fusion using a modified serial-based approach. Finally, the fused vector is further enhanced by selecting the best features using the skewness-controlled SVR approach. The final selected features are classified using several machine learning algorithms and selected based on the accuracy value. In the experimental process, the augmented HAM10000 dataset is used and achieved an accuracy of 91.7%. Moreover, the performance of the augmented dataset is better as compared to the original imbalanced dataset. In addition, the proposed method is compared with some recent studies and shows improved performance.  © 2021 Mehak Arshad et al.","10.1155/2021/9619079","","50","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122228174&doi=10.1155%2f2021%2f9619079&partnerID=40&md5=eddc0af849e16fe1b0d402d87f56a637"
"A novel SEGCAP algorithm based enhanced segmentation of dermoscopic images of interest","Kosgiker G.M.; Deshpande A.","2021","0","1","0","0","0","Unique","0","","","","","","","Skin lesion segmentation helps in the early analysis of skin ailments and injuries such as skin lesion shape and border irregularity. It also provides a correct diagnosis of different skin-related diseases, such as skin cancer, by using a computerized system. The automatic segmentation of skin lesions in dermoscopic images is considered to be a difficult task as it faces issues related to artifacts in the stink boundaries, different sizes, low contrast, and varied shape of images. The main purpose of this paper is to provide an effective SEGCAP algorithm for segmentation of skin lesion. The research outcomes were obtained by analyzing the collected facts with Jaccard coefficient, Dice Similarity Coefficient, accuracy, sensitivity, and specificity. It outperformed all existing methods. © 2021 Elsevier Ltd. All rights reserved.","10.1016/j.matpr.2021.06.233","Convolutional neural networks; Dermoscopic images; Melanoma; SegCaps; Skin lesion","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126197784&doi=10.1016%2fj.matpr.2021.06.233&partnerID=40&md5=d91714b0ca0e2aeaa93a466f3b404d91"
"Melanoma Skin Cancer Detection Using EfficientNet and Channel Attention Module","Papiththira S.; Kokul T.","2021","1","1","0","0","0","Unique","0","","","","","","","Melanoma is the most dangerous type of skin cancer and hence early detection is crucial for survival. Classifying melanoma moles from non-melanoma moles is a challenging task since they are visually similar. In this study, we propose a deep transfer learning based approach for melanoma detection, which can able to detect from raw images without any pre-processing. The EfficientNet pre-trained model is utilized to transfer the learned knowledge with the fewer number of skin image samples and to achieve high detection speed. In addition, a channel attention module is included to boost the melanoma-specific features in the classification. Proposed approach is evaluated on UMGC and HAM10000 benchmark datasets with clinical and dermoscopic images, respectively. Experimental results demonstrate proposed work outperforms the state-of-the-art approaches with the classification accuracy of 84.12% and 96.32%, respectively.  © 2021 IEEE.","10.1109/ICIIS53135.2021.9660759","Channel Attention; Deep Transfer Learning; EfficientNet; Malignant Melanoma","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124702442&doi=10.1109%2fICIIS53135.2021.9660759&partnerID=40&md5=0f79fe410f69567cc80a5bffd4dd80f3"
"Dermal epidermal junction detection for full-field optical coherence tomography data of human skin by deep learning","Chou H.-Y.; Huang S.-L.; Tjiu J.-W.; Chen H.H.","2021","1","1","0","0","0","Unique","0","","","","","","","Full-field optical coherence tomography (FF-OCT) has been developed to obtain three-dimensional (3D) OCT data of human skin for early diagnosis of skin cancer. Detection of dermal epidermal junction (DEJ), where melanomas and basal cell carcinomas originate, is an essential step for skin cancer diagnosis. However, most existing DEJ detection methods consider each cross-sectional frame of the 3D OCT data independently, leaving the relationship between neighboring frames unexplored. In this paper, we exploit the continuity of 3D OCT data to enhance DEJ detection. In particular, we propose a method for noise reduction of the training data and a multi-directional convolutional neural network to predict the probability of epidermal pixels in the 3D OCT data, which is more stable than one-directional convolutional neural network for DEJ detection. Our crosscheck refinement method also exploits the domain knowledge to generate a smooth DEJ surface. The average mean error of the entire DEJ detection system is approximately 6 μm. © 2020 Elsevier Ltd","10.1016/j.compmedimag.2020.101833","Computer-aided diagnosis; Convolutional neural network; Deep learning; Dermal epidermal junction (DEJ); Human skin; Optical coherence tomography","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097756941&doi=10.1016%2fj.compmedimag.2020.101833&partnerID=40&md5=870940d224b190dea698ea3b102499b3"
"LRNet: Skin Cancer Classification using Low-Resolution Images","Shah M.","2021","1","1","0","0","0","Unique","0","","","","","","","Modern lifestyle and continuous depletion of the ozone layer have dramatically increased skin cancer cases worldwide. Detection of skin cancer at an early stage can increase the survival rate to 99%. Computer-aided skin cancer classification has various challenges due to the visual similarity between different skin cancer classes and model’s lack of generalization capability. Recent deep learning-based approaches have overcome these challenges and even outperform an expert dermatologist. However, these models are trained on a large number of high-resolution images which makes them computationally expensive. To elucidate this problem, we propose to train the neural networks on low-resolution images. We then propose a fast, scalable, and efficient Deep Convolutional Neural Network, LRNet for skin cancer classification on low-resolution images. LRNet is trained on 10015 pigmented lesion images belonging to the HAM10000 dataset. The proposed model is also deployed to a publicly available web application. The performance of LRNet is evaluated based on sensitivity, specificity, precision and accuracy, and the values obtained are 94%, 91.7%, 94.2%, and 90.6%, respectively. Our proposed approach outperforms all the pre-trained models and drastically reduces the training time. ©2021 IEEE","10.1109/ICCICT50803.2021.9510138","Convolutional Neural Network; Deep Learning; Dermatologist; HAM10000; Skin Cancer","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122838444&doi=10.1109%2fICCICT50803.2021.9510138&partnerID=40&md5=d1c92b3b26b3cd555f59df15098c5101"
"The Effects of Masking in Melanoma Image Classification with CNNs Towards International Standards for Image Preprocessing","Nunnari F.; Ezema A.; Sonntag D.","2021","0","1","0","0","0","First occurrence","0","","","","","","","The classification of skin lesion images is known to be biased by artifacts of the surrounding skin, but it is still not clear to what extent masking out healthy skin pixels influences classification performances, and why. To better understand this phenomenon, we apply different strategies of image masking (rectangular masks, circular masks, full masking, and image cropping) to three datasets of skin lesion images (ISIC2016, ISIC2018, and MedNode). We train CNN-based classifiers, provide performance metrics through a 10-fold cross-validation, and analyse the behaviour of Grad-CAM saliency maps through an automated visual inspection. Our experiments show that cropping is the best strategy to maintain classification performance and to significantly reduce training times as well. Our analysis through visual inspection shows that CNNs have the tendency to focus on pixels of healthy skin when no malignant features can be identified. This suggests that CNNs have the tendency of “eagerly” looking for pixel areas to justify a classification choice, potentially leading to biased discriminators. To mitigate this effect, and to standardize image preprocessing, we suggest to crop images during dataset construction or before the learning step. © 2021, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","10.1007/978-3-030-70569-5_16","AI standardization roadmap; Convolutional neural networks; Masking; Preprocessing; Reducing bias; Skin cancer","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104487178&doi=10.1007%2f978-3-030-70569-5_16&partnerID=40&md5=e5a3a9a3ea5008a51bb168adff04f300"
"Skin Cancer Detection Based on Extreme Learning Machine and a Developed Version of Thermal Exchange Optimization","Wang S.; Hamian M.","2021","1","1","0","0","0","Unique","0","","","","","","","Melanoma is defined as a disease that has been incurable in advanced stages, which shows the vital importance of timely diagnosis and treatment. To diagnose this type of cancer early, various methods and equipment have been used, almost all of which required a visit to the doctor and were not available to the public. In this study, an automated and accurate process to differentiate between benign skin pigmented lesions and malignant melanoma is presented, so that it can be used by the general public, and it does not require special equipment and special conditions in imaging. In this study, after preprocessing of the input images, the region of interest is segmented based on the Otsu method. Then, a new feature extraction is implemented on the segmented image to mine the beneficial characteristics. The process is then finalized by using an optimized Deep Believe Network (DBN) for categorization into 2 classes of normal and melanoma cases. The optimization process in DBN has been performed by a developed version of the newly introduced Thermal Exchange Optimization (dTEO) algorithm to obtain higher efficacy in different terms. To show the method’s superiority, its performance is compared with 7 different techniques from the literature. Copyright © 2021 Shi Wang and Melika Hamian. This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.","10.1155/2021/9528664","","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121990880&doi=10.1155%2f2021%2f9528664&partnerID=40&md5=df73ed306f0d3e4fbcb36eec240ab532"
"An artificial neural network based detection and classification of melanoma skin cancer using hybrid texture features","Tumpa P.P.; Kabir M.A.","2021","1","1","0","0","0","Unique","0","","","","","","","Melanoma being the most unpredictable and life-threating cancer, has been on the rise in recent times. In most of the cases being fatal, if treated early, the fatality rate might be lowered severely. Hands-on Melanoma detection at primary stages with the unassisted eye is error-prone and requires vast knowledge and experience. Number of expert dermatologists being inadequate, a computerized and automated approach is needed to accurately detect Melanoma. The following study tries to achieve this feat by developing a neural network that can effectively detect and classify Melanoma. The process begins with preprocessing of dermoscopic images to remove hairs with the Maximum Gradient Intensity algorithm and also enhancement of the images is done. Segmentation based on Otsu Thresholding algorithm is applied to separate skin lesions from the images. Multiple features like ABCD, GLCM, and LBP are then calculated from the segmented images which will be used to train a neural network. The network was successful to attain an accuracy of 97.7% on the combined dataset of ISIC archive the PH2 dermoscopic image database. The proposed method was found to be more accurate than existing methods and encorporates much more feature information from the images. © 2021 The Authors","10.1016/j.sintl.2021.100128","Hybrid texture features; Malignant; Maximum gradient intensity; Skin cancer","74","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120795550&doi=10.1016%2fj.sintl.2021.100128&partnerID=40&md5=bffc601c569da9212f0e1fe63a0732e8"
"Lightweight encoder-decoder model for automatic skin lesion segmentation","Wibowo A.; Purnama S.R.; Wirawan P.W.; Rasyidi H.","2021","1","1","0","0","0","Unique","0","","","","","","","Accurate skin lesion segmentation (SLS) is an important step in computer-aided diagnosis of melanoma. Automatic detection of skin lesions in dermoscopy images is challenging because of the presence of artifacts and as lesions can have heterogeneous texture, color, and shape with fuzzy or indistinct boundaries. In this study, automatic SLS was performed using a lightweight encoder-decoder, MobileNetV3-UNet, which can achieve high accuracy with low resources. A comprehensive analysis was performed to improve the accuracy of the method in SLS. The semantic segmentation method consists of an encoder-decoder architecture, data augmentation, learning schemes, and post-processing methods. To enhance the SLS, we modified the decoder with the bidirectional ConvLSTM layer from the BCDU-Net and separable blocks from the separable-UNet architecture. Random augmentation was used to improve image diversity in the training dataset to avoid overfitting. Furthermore, a learning scheme based on stochastic weight averaging (SWA) was used to obtain better generalization by averaging multiple local optima. Our method was evaluated using three publicly available datasets, such as ISIC-2017, ISIC-2018, and PH2. We obtained dice coefficient and Jaccard index of 87.74%, 80.25%; 91.01%, 83.44%; and 95.18%, 91.08% for ISIC-2017, ISIC-2018, and PH2, respectively. The experimental results proved that the modified MobileNetV3-UNet method can outperform several state-of-the-art methods. © 2021 The Authors","10.1016/j.imu.2021.100640","Encoder-decoder; MobileNet; Random augmentation; Skin lesion segmentation; Stochastic weight averaging; U-net","33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108422313&doi=10.1016%2fj.imu.2021.100640&partnerID=40&md5=13b84b6aa8278d695a2b4b18b49a55e1"
"Melanoma Classification Based on Three Different Very Deep Neural Networks","Minango P.; Iano Y.; Ruelas A.M.R.; de Oliveira G.G.; Alvarado M.C.L.; Minango J.; Arthur R.; Castro D.A.P.","2021","0","1","0","0","0","First occurrence","0","","","","","","","The present study proposes a methodology for classifying dermoscopic skin lesions images with melanoma and non-melanoma issues. Earlier diagnosis of melanoma gives the patient an estimate of a 5-year survival rate of 95%. Our main objective is to develop a computational tool that assists medical specialists in the task of recognizing melanoma in its initial stages. For this reason, our system is intended to generalize a prediction model, applying image processing techniques and very deep neural networks. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-030-75680-2_52","Convolutional networks; Melanoma classification; Very deep neural network","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111404006&doi=10.1007%2f978-3-030-75680-2_52&partnerID=40&md5=a8af93f5edb1dff45299769c6d9c94df"
"Diagnosis of Skin Cancer Using Feature Engineering Techniques","Sannigrahi A.; Singh V.; Gourisaria M.K.; Srivastava R.","2021","1","1","0","0","0","Unique","0","","","","","","","Major mortality rate among human beings is due to cancer. Early diagnosis of Skin cancer especially Melanoma is having the potentiality to reduce morbidity as the major reason behind the disastrous repercussions of three out four homo-sapiens is due to skin cancer. Detection of cancer using machine learning and deep learning algorithms makes it very much feasible and economical. The ultimate focus of this paper is for detecting skin cancer at an early stage and helping to combat the increasing cases in skin cancer patients. In this paper, we have implemented different types of CNNs of different configurations on categorical classification where architectures were trained on different input image size and selecting of best architecture was based on various metric evaluations like Maximum Accuracy, Precision, Recall, and F1 score and best architecture has achieved high accuracy and performed outstandingly in all the evaluation section. Architecture 4 performed overall excellent in terms of every field of metric evaluations. This architecture will be a helpful tool for diagnosing skin cancer at an early stage and will take the less computational cost for classifying the skin cancer disease.  © 2021 IEEE.","10.1109/ICAC3N53548.2021.9725420","Convolutional Neural Networks (CNNs); Deep learning; Machine learning; Medical Imaging; Skin Cancer","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126990570&doi=10.1109%2fICAC3N53548.2021.9725420&partnerID=40&md5=969d8a26135694f058af41699e453499"
"An efficient CNN based algorithm for detecting melanoma cancer regions in HE-stained images","Alheejawi S.; Berendt R.; Jha N.; Maity S.P.; Mandal M.","2021","0","1","0","0","0","Unique","0","","","","","","","Histopathological images are widely used to diagnose diseases such as skin cancer. As digital histopathological images are typically of very large size, in the order of several billion pixels, automated identification of abnormal cell nuclei and their distribution within multiple tissue sections would enable rapid comprehensive diagnostic assessment. In this paper, we propose a deep learning-based technique to segment the melanoma regions in Hematoxylin and Eosin-stained histopathological images. In this technique, the nuclei in an image are first segmented using a deep learning neural network. The segmented nuclei are then used to generate the melanoma region masks. Experimental results show that the proposed method can provide nuclei segmentation accuracy of around 90% and the melanoma region segmentation accuracy of around 98%. The proposed technique also has a low computational complexity. © 2021 IEEE.","10.1109/EMBC46164.2021.9630443","Deep learning; Histopathological image analysis; Melanoma detection; Nuclei segmentation","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122529084&doi=10.1109%2fEMBC46164.2021.9630443&partnerID=40&md5=bc882a54ba26341fc1687617757a1200"
"Segmentation and automatic classification of skin lesion using neural networks","Singh S.","2021","1","1","0","0","0","Unique","0","","","","","","","Melanoma is a lethal disease often impossible to cure if detected at later stages. To save a person, it is necessary to detect melanoma at earlier stages because melanoma treatment is detected at prior stages. Due to several reasons, there is a need for an automated system to detect melanoma. An automated system for the segmentation and the skin lesion classification is proposed using the artificial neural network. Image segmentation is carried out to bifurcate input image into different clusters. In this proposed methodology, the Fuzzy C Means algorithm is used for the pre-segmentation, and then Gaussian Mixture Model is used for the modeling. The results of the Gaussian mixture model are not as efficient up to the desired level. Artificial Neural Networks are used to achieve the highest accuracy, and their accuracy is checked by using the parameters of sensitivity and specificity. © 2021 Seventh Sense Research Group®","10.14445/22315381/IJETT-V69I1P218","Artificial Neural Network; Gaussian Mixture Model; Innovation; Melanoma; Skin Cancer","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100813699&doi=10.14445%2f22315381%2fIJETT-V69I1P218&partnerID=40&md5=1e9e8a7a79f70cfbf8142e11e0275aa2"
"RecU-Net++: Improved Utilization of Receptive Fields in U-Net++ for Skin Lesion Segmentation","Hussain R.; Basak H.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Recently skin cancer has emerged as one of the most threatening diseases with an alarming rate of fatality. Though the early detection of this disease is quite useful for proper treatment planning, the task is quite intimidating. Several factors such as obscure lesion boundaries, variable contrast, the difference in lesion shape, size and colours and the presence of undesirable artefacts (such as hair) make the segmentation task extremely challenging. To address those challenges and to augment the efforts of clinicians, in this paper we propose RecU-Net++, a novel segmentation framework that utilizes multiple Receptive Field Block (RFB) to extract spatial context information at multiple scales to preserve discriminative features of the lesion images. RecU-Net++ also introduces an extremely pliable feature fusion scheme by agglomerating features of multiple semantic scales with a redesigned skip connection. We also introduce dense blocks after every downsampling operation for effective reuse of features and strengthening feature flow, thus mitigating the problem of exploding gradient. Our proposed method is evaluated on two publicly available skin lesion segmentation datasets: HAM10000 and ISIC2017. Experimental results show that our proposed model outperforms the existing segmentation methods quite significantly. © 2021 IEEE.","10.1109/INDICON52576.2021.9691670","Deep learning; Dense block; Melanoma; RFB; Skin lesion segmentation; U-Net++","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126395725&doi=10.1109%2fINDICON52576.2021.9691670&partnerID=40&md5=6818535962176cced7790966db1e18b9"
"Channel Context and Dual-Domain Attention Based U-Net for Skin Lesion Attributes Segmentation","Mu X.L.; Pan H.W.; Zhang K.J.; Teng T.; Bian X.F.; Chen C.L.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Skin melanoma is one of the most common malignant tumors originating from melanocytes, and the incidence of the Chinese population is showing a continuous increasing trend. Early and accurate diagnosis of melanoma has great significance for guiding clinical treatment. However, the symptoms of malignant melanoma are not obvious in the early stage. It is difficult to be diagnosed with human observation. Meanwhile, it is easy to spread due to missed diagnosis. In order to accurately diagnose melanoma, end-to-end skin lesion attribute segmentation framework is presented in this paper. It is applied to facilitate the digitalization process of attributes segmentation. The framework was improved on the U-Net construction that use the channel context feature fusion module between the encoder and decoder to further merge context information. A dual-domain attention module is proposed to get more effective information from the feature map. It shows that the proposed method effectively segments the lesion attributes and achieves good result in the ISIC2018 task2 dataset. © 2021, Springer Nature Singapore Pte Ltd.","10.1007/978-981-16-5940-9_40","Channel context feature fusion; Dual-domain attention; Lesion attribute segmentation; Melanoma","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115366862&doi=10.1007%2f978-981-16-5940-9_40&partnerID=40&md5=b477a563156360712d215c1e54b3e528"
"Hair removal combining saliency, shape and color","Ramella G.","2021","0","1","0","0","0","Unique","0","","","","","","","In a computer-aided system for skin cancer diagnosis, hair removal is one of the main challenges to face before applying a process of automatic skin lesion segmentation and classification. In this paper, we propose a straightforward method to detect and remove hair from dermoscopic images. Preliminarily, the regions to consider as candidate hair regions and the border/corner components located on the image frame are automatically detected. Then, the hair regions are determined using information regarding the saliency, shape and image colors. Finally, the detected hair regions are restored by a simple inpainting method. The method is evaluated on a publicly available dataset, comprising 340 images in total, extracted from two commonly used public databases, and on an available specific dataset including 13 images already used by other authors for evaluation and comparison purposes. We propose also a method for qualitative and quantitative evaluation of a hair removal method. The results of the evaluation are promising as the detection of the hair regions is accurate, and the performance results are satisfactory in comparison to other existing hair removal methods. © 2021 by the author. Licensee MDPI, Basel, Switzerland.","10.3390/app11010447","Artifact removal; Color space; Dermoscopic image; Dermoscopy; Hair removal; Lesion segmentation; Pre-processing; Saliency; Shape; Skin lesion","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099848471&doi=10.3390%2fapp11010447&partnerID=40&md5=7ecf91b762de8c9e83429dd5e0b26765"
"TransFuse: Fusing Transformers and CNNs for Medical Image Segmentation","Zhang Y.; Liu H.; Hu Q.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Medical image segmentation - the prerequisite of numerous clinical needs - has been significantly prospered by recent advances in convolutional neural networks (CNNs). However, it exhibits general limitations on modeling explicit long-range relation, and existing cures, resorting to building deep encoders along with aggressive downsampling operations, leads to redundant deepened networks and loss of localized details. Hence, the segmentation task awaits a better solution to improve the efficiency of modeling global contexts while maintaining a strong grasp of low-level details. In this paper, we propose a novel parallel-in-branch architecture, TransFuse, to address this challenge. TransFuse combines Transformers and CNNs in a parallel style, where both global dependency and low-level spatial details can be efficiently captured in a much shallower manner. Besides, a novel fusion technique - BiFusion module is created to efficiently fuse the multi-level features from both branches. Extensive experiments demonstrate that TransFuse achieves the newest state-of-the-art results on both 2D and 3D medical image sets including polyp, skin lesion, hip, and prostate segmentation, with significant parameter decrease and inference speed improvement. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-87193-2_2","Convolutional neural networks; Fusion; Medical image segmentation; Transformers","1031","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116489333&doi=10.1007%2f978-3-030-87193-2_2&partnerID=40&md5=82d8b02a73ae31ea47e9487b493b641b"
"Large-scale Robust Deep AUC Maximization: A New Surrogate Loss and Empirical Studies on Medical Image Classification","Yuan Z.; Yan Y.; Sonka M.; Yang T.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Deep AUC Maximization (DAM) is a new paradigm for learning a deep neural network by maximizing the AUC score of the model on a dataset. Most previous works of AUC maximization focus on the perspective of optimization by designing efficient stochastic algorithms, and studies on generalization performance of large-scale DAM on difficult tasks are missing. In this work, we aim to make DAM more practical for interesting real-world applications (e.g., medical image classification). First, we propose a new margin-based min-max surrogate loss function for the AUC score (named as the AUC min-max-margin loss or simply AUC margin loss for short). It is more robust than the commonly used AUC square loss, while enjoying the same advantage in terms of large-scale stochastic optimization. Second, we conduct extensive empirical studies of our DAM method on four difficult medical image classification tasks, namely (i) classification of chest x-ray images for identifying many threatening diseases, (ii) classification of images of skin lesions for identifying melanoma, (iii) classification of mammogram for breast cancer screening, and (iv) classification of microscopic images for identifying tumor tissue. Our studies demonstrate that the proposed DAM method improves the performance of optimizing cross-entropy loss by a large margin, and also achieves better performance than optimizing the existing AUC square loss on these medical image classification tasks. Specifically, our DAM method has achieved the 1st place on Stanford CheXpert competition on Aug. 31, 2020. To the best of our knowledge, this is the first work that makes DAM succeed on large-scale medical image datasets. We also conduct extensive ablation studies to demonstrate the advantages of the new AUC margin loss over the AUC square loss on benchmark datasets. The proposed method is implemented in our open-sourced library LibAUC (www.libauc.org) whose github address is https://github.com/Optimization-AI/LibAUC. © 2021 IEEE","10.1109/ICCV48922.2021.00303","","91","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117145820&doi=10.1109%2fICCV48922.2021.00303&partnerID=40&md5=b3f15c9574b8772cde33bdf961556470"
"Anomaly Detection for Skin Lesion Images Using Replicator Neural Networks","Nunnari F.; Alam H.M.T.; Sonntag D.","2021","1","1","0","0","0","First occurrence","0","","","","","","","This paper presents an investigation on the task of anomaly detection for images of skin lesions. The goal is to provide a decision support system with an extra filtering layer to inform users if a classifier should not be used for a given sample. We tested anomaly detectors based on autoencoders and three discrimination methods: feature vector distance, replicator neural networks, and support vector data description fine-tuning. Results show that neural-based detectors can perfectly discriminate between skin lesions and open world images, but class discrimination cannot easily be accomplished and requires further investigation. © 2021, IFIP International Federation for Information Processing.","10.1007/978-3-030-84060-0_15","Anomaly detection; Autoencoders; Replicator neural networks; Skin cancer; SVDD","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115134065&doi=10.1007%2f978-3-030-84060-0_15&partnerID=40&md5=d5592c1b15ccb7817e9862a8cd08ed02"
"Robust Selective Classification of Skin Lesions with Asymmetric Costs","Carse J.; Süveges T.; Hogg S.; Trucco E.; Proby C.; Fleming C.; McKenna S.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Automated image analysis of skin lesions has potential to improve diagnostic decision making. A clinically useful system should be selective, rejecting images it is ill-equipped to classify, for example because they are of lesion types not represented well in training data. Furthermore, lesion classifiers should support cost-sensitive decision making. We investigate methods for selective, cost-sensitive classification of lesions as benign or malignant using test images of lesion types represented and not represented in training data. We propose EC-SelectiveNet, a modification to SelectiveNet that discards the selection head at test time, making decisions based on expected costs instead. Experiments show that training for full coverage is beneficial even when operating at lower coverage, and that EC-SelectiveNet outperforms standard cross-entropy training, whether or not temperature scaling or Monte Carlo dropout averaging are used, in both symmetric and asymmetric cost settings. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-87735-4_11","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117118967&doi=10.1007%2f978-3-030-87735-4_11&partnerID=40&md5=1391e2540c75f6580a0bd1be09333980"
"Method for the Recovery of Images in Databases of Skin Cancer","Viloria A.; Varela N.; Nuñez-Bravo N.; Lezama O.B.P.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Deep learning is widely used for the classification of images since the ImageNet competition in 2012 (Zaharia et al. in Common ACM 59(11):56–65, 2016, [1]; Tajbakhsh et al. in IEEE Trans Med Imaging 35(5):1299–1312, 2016, [2]). This image classification is very useful in the field of medicine, in which there is a growing interest in the use of data mining techniques in recent years. In this paper, a deep learning network was selected and trained for the analysis of a set of skin cancer data, obtaining very satisfactory results, as the model surpassed the classification results of trained dermatologists using a dermatoscope, other automatic learning techniques, and other deep learning techniques. © 2021, Springer Nature Singapore Pte Ltd.","10.1007/978-981-15-7234-0_94","Clinical data analysis; Deep learning; Medical images","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096423540&doi=10.1007%2f978-981-15-7234-0_94&partnerID=40&md5=1ca3351a4789980f2c157452b24926a0"
"Hair Segmentation and Removal in Dermoscopic Images Using Deep Learning","Talavera-Martinez L.; Bibiloni P.; Gonzalez-Hidalgo M.","2021","0","1","0","0","0","Unique","0","","","","","","","Melanoma and non-melanoma skin cancers have shown a rapidly increasing incidence rate, pointing to skin cancer as a major problem for public health. When analyzing these lesions in dermoscopic images, the hairs and their shadows on the skin may occlude relevant information about the lesion at the time of diagnosis, reducing the ability of automated classification and diagnosis systems. In this work, we present a new approach for the task of hair removal on dermoscopic images based on deep learning techniques. Our proposed model relies on an encoder-decoder architecture, with convolutional neural networks, for the detection and posterior restoration of hair's pixels from the images. Moreover, we introduce a new combined loss function in the network's training phase that combines the $L_{1}$ distance, the total variation loss, and a loss function based on the structural similarity index metric. Currently, there are no datasets that contain the same images with and without hair, which is necessary to quantitatively evaluate our model. Thus, we simulate the presence of hair in hairless images extracted from publicly known datasets. We compare our results with six state-of-the-art algorithms based on traditional computer vision techniques by means of similarity measures that compare the reference hairless image and the one with simulated hair. Finally, the Wilcoxon signed-rank test is used to compare the methods. The results, both qualitatively and quantitatively, demonstrate the effectiveness of our model and how our loss function improves the restoration ability of the proposed model.  © 2013 IEEE.","10.1109/ACCESS.2020.3047258","Deep neural networks; dermoscopy; hair removal; image processing; inpainting; skin lesion","47","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098802256&doi=10.1109%2fACCESS.2020.3047258&partnerID=40&md5=9bdcd1f4b914111f7123cf9c9060012a"
"Significant of multi-level pre-processing steps and its proper sequence in SegCaps skin lesion segmentation of dermoscopic images","Kosgiker G.M.; Deshpande A.; Anjum K.","2021","1","1","0","0","0","Unique","0","","","","","","","In computer-assisted diagnosis of dermoscopy images, skin lesion segmentation is a critical but difficult process. Many segmentation methods fail to extract correct lesion boundaries due to the lack of pre-processing steps or a very few number of pre-processing steps that aren't in the right order. This paper demonstrates the significant of Multi-level pre-processing steps and its proper sequence before SegCaps segmentation of Lesion images. In the proposed work author have planned four pre-processing steps before segmentation of skin lesion images in the sequence of first is a 2nd Order grey edge algorithm is used to achieve color consistency;. Second process consists of two sub-processes in the hair removal procedure. To get started, we use the Prewitt filter, which is adaptable to the hair pixel level. The following procedure is the Repairing Operation, which is carried out using the anisotropic Fast Marching Method. Third process is a noise filtering with the Improved Switching Bilateral Filter (ISBF), which uses the Sorted Quadrant Median Vector (SQMV) to determine best median value and the last process is The Directed Edge Enhancer algorithm is used to perform edge enhancement. The proposed model is tested Over MatlabR2017b, using the HAM10000 dataset. The proposed method's output is assessed by comparing segmentation effects with and without pre-processing, as well as visual appearances of pre-processed images from input images. From the results it has been concludes that when pre-processing steps are used in the correct order and proper sequence, segmentation accuracy is very high, as compared to segmentation without pre-processing steps. © 2021 Elsevier Ltd. All rights reserved.","10.1016/j.matpr.2021.05.016","Deep learning; Dermoscopic images; Multi-level preprocessing; SegCaps model; Skin lesion segmentation","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126190433&doi=10.1016%2fj.matpr.2021.05.016&partnerID=40&md5=ecf28738ba10ca6ecc4998c44d718f55"
"DEEP FEATURES FUSION WITH MUTUAL ATTENTION TRANSFORMER FOR SKIN LESION DIAGNOSIS","Zhou L.; Luo Y.","2021","1","1","0","0","0","Unique","0","","","","","","","Early skin lesion diagnosis is crucial to prevent skin cancer, and deep learning (DL) based methods are well exploited to support dermatologists’ diagnosis. The data for the diagnosis tasks include dermoscopic lesion images and textual information. It is a challenge to learn features from the multimodal data to improve diagnostic quality. Inspired by the vision and language integration models in Visual Question Answer (VQA), we present an end-to-end neural network model for skin lesion diagnosis using both images and textual information simultaneously. Specifically, we fine-grained features from the two modalities (image and text) of the dataset by the pre-trained DL models. We propose a novel approach named Mutual Attention Transformer (MAT), which consists of self-attention blocks and guided-attention blocks, to enable the interactions between the features from both modalities concurrently. We then develop a fusion mechanism to integrate the represented features before the final classification output layer. The experimental results on the HAM10000 dataset demonstrate that the proposed method outperforms the state-of-art methods for skin lesion diagnosis. © 2021 IEEE.","10.1109/ICIP42928.2021.9506211","Attention mechanism; Deep learning; Skin lesion classification; Transformer","27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125581230&doi=10.1109%2fICIP42928.2021.9506211&partnerID=40&md5=8951a260b60b6cc090a8c2cabb63a39c"
"A scaled-2D CNN for skin cancer diagnosis","Rafi T.H.; Shubair R.M.","2021","1","1","0","0","0","Unique","0","","","","","","","Every year, doctors diagnose skin cancer in around 3 million or more patients across the globe. Currently, it is one of the most widely recognized kinds of cancers for human health. Hence, we need an early diagnosis to prevail any critical condition of the infected patients. Apparently, it can treat with topical drugs, if it diagnoses in an early stage. Hence as an outcome, skin cancer is responsible for less than 1% of all cancer deaths. There are two types of tumors in the skin cancer diseases domain, such as benign and malignant. To develop a robust and early screening system to diagnose skin cancer, it requires an efficient algorithm for prediction, trained with a large dataset. The primary aim of this research is to develop an efficient skin cancer screening process using a robust deep neural network with a large dataset. In this paper, we intend to determine considerate and dangerous types of skin cancer tumors using dermoscopic images from a publicly available dataset. We proposed an efficient and fast scaled 2D-CNN based on EfficientNet-B7 deep neural architecture with image pre-processing. This paper also uses two different pre-trained deep neural architectures, such as VGG19, and ResNet-50 to compare the performance with the proposed architecture. The proposed architecture outperformed the other pre-trained CNN models whereas the proposed architecture achieved higher AUC and accuracy compared to other architectures. © 2021 IEEE.","10.1109/CIBCB49929.2021.9562888","2D-CNN; Benign; EfficientNet; Malignant; Skin Cancer; Transfer Learning","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126466191&doi=10.1109%2fCIBCB49929.2021.9562888&partnerID=40&md5=b71363c24028543bb4bbd28eb25c4f6e"
"Intelligent multiclass skin cancer detection using convolution neural networks","Alabduljabbar R.; Alshamlan H.","2021","1","0","0","0","0","Unique","0","","","","","","","The worldwide mortality rate due to cancer is second only to cardiovascular diseases. The discovery of image processing, latest artificial intelligence techniques, and upcoming algorithms can be used to effectively diagnose and prognose cancer faster and reduce the mortality rate. Efficiently applying these latest techniques has increased the survival chances during recent years. The research community is making significant continuous progress in developing automated tools to assist dermatologists in decision making. The datasets used for the experimentation and analysis are ISBI 2016, ISBI 2017, and HAM 10000. In this work pertained models are used to extract the efficient feature. The pertained models applied are ResNet, InceptionV3, and classical feature extraction techniques. Before that, efficient preprocessing is conducted on dermoscopic images by applying various data augmentation techniques. Further, for classification, convolution neural networks were implemented. To classify dermoscopic images on HAM 1000 Dataset, the maximum attained accuracy is 89.30% for the proposed technique. The other parameters for measuring the performance attained 87.34% (Sen), 86.33% (Pre), 88.44% (F1-S), and 11.30% false-negative rate (FNR). The class with the highest TP rate is 97.6% for Melanoma; whereas, the lowest TP rate was for the Dermatofibroma class. For dataset ISBI2016, the accuracy achieved is 97.0% with the proposed classifier, whereas the other parameters for validation are 96.12% (Sen), 97.01% (Pre), 96.3% (F1-S), and further 3.7% (FNR). For the experiment with the ISBI2017 dataset, Sen, Pre, F1-S, and FNR were 93.9%, 94.9%, 93.9%, and 5.2%, respectively. © 2021 Tech Science Press. All rights reserved.","10.32604/cmc.2021.018402","Artificial intelligence; Classification; Convolution neural networks; Dermoscopy; Feature extraction; Skin cancer","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107852396&doi=10.32604%2fcmc.2021.018402&partnerID=40&md5=05f675e006d18bb8378e3a4b65086fca"
"Exploring the Correlation Between Deep Learned and Clinical Features in Melanoma Detection","Chowdhury T.; Bajwa A.R.S.; Chakraborti T.; Rittscher J.; Pal U.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Despite the recent success of deep learning methods in automated medical image analysis tasks, their acceptance in the medical community is still questionable due to the lack of explainability in their decision-making process. The highly opaque feature learning process of deep models makes it difficult to rationalize their behavior and exploit the potential bottlenecks. Hence it is crucial to verify whether these deep features correlate with the clinical features, and whether their decision-making process can be backed by conventional medical knowledge. In this work, we attempt to bridge this gap by closely examining how the raw pixel-based neural architectures associate with the clinical feature based learning algorithms at both the decision level as well as feature level. We have adopted skin lesion classification as the test case and present the insight obtained in this pilot study. Three broad kinds of raw pixel-based learning algorithms based on convolution, spatial self-attention and attention as activation were analyzed and compared with the ABCD skin lesion clinical features based learning algorithms, with qualitative and quantitative interpretations. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-80432-9_1","Attention mechanisms; Deep machine learning; Digital dermatoscopy; Explainable artificial intelligence; Melanoma classification","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112145252&doi=10.1007%2f978-3-030-80432-9_1&partnerID=40&md5=543ddade81e1732a63cd0a644af1cb62"
"Culprit-Prune-Net: Efficient Continual Sequential Multi-domain Learning with Application to Skin Lesion Classification","Bayasi N.; Hamarneh G.; Garbi R.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Despite recent advances in deep learning based medical image computing, clinical implementations in patient-care settings have been limited with lack of sufficiently diverse data during training remaining a pivotal impediment to robust real-life model performance. Continual learning (CL) offers a desirable property of deep neural network models (DNNs), namely the ability to continually learn from new data to accumulate knowledge whilst retaining what has been previously learned. In this work we present a simple and effective CL approach for sequential multi-domain learning (MDL) and showcase its utility in the skin lesion image classification task. Specifically, we propose a new pruning criterion that allows for a fixed network to learn new data domains sequentially over time. Our MDL approach incrementally builds on knowledge gained from previously learned domains, without requiring access to their training data, while simultaneously avoiding catastrophic forgetting and maintaining accurate performance on all domain data learned. Our new pruning criterion detects culprit units associated with wrong classification in each domain and releases these units so they are dedicated for subsequent learning on new domains. To reduce the computational cost associated with retraining the network post pruning, we implement MergePrune, which efficiently merges the pruning and training stages into one step. Furthermore, at inference time, instead of using a test-time oracle, we design a smart gate using Siamese networks to assign a test image to the most appropriate domain and its corresponding learned model. We present extensive experiments on 6 skin lesion image databases, representing different domains with varying levels of data bias and class imbalance, including quantitative comparisons against multiple baselines and state-of-the-art methods, which demonstrate superior performance and efficient computations of our proposed method. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-87234-2_16","Deep learning; Dermatology; Multi-domain learning; Sequential learning; Unit pruning","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116413188&doi=10.1007%2f978-3-030-87234-2_16&partnerID=40&md5=ba92fdbe4e32dd79053f2547f3cd1b80"
"OVERVIEW OF FEATURE SELECTION METHODS USED IN MALIGNANT MELANOMA DIAGNOSTICS; [PRZEGLĄD METOD SELEKCJI CECH UŻYWANYCH W DIAGNOSTYCE CZERNIAKA]","Michalska M.","2021","0","1","0","0","0","Unique","0","","","","","","","Currently, a large number of trait selection methods are used. They are becoming more and more of interest among researchers. Some of the methods are of course used more frequently. The article describes the basics of selection-based algorithms. FS methods fall into three categories: filter wrappers, embedded methods. Particular attention was paid to finding examples of applications of the described methods in the diagnosis of skin melanoma. © 2021, Politechnika Lubelska. All rights reserved.","10.35784/iapgos.2455","embedded methods; feature selection methods; filter methods; wrappers methods","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178304694&doi=10.35784%2fiapgos.2455&partnerID=40&md5=d75d096472663e04de082cd158d664e4"
"Deep Learning Approach for Medical Image Analysis","Adegun A.A.; Viriri S.; Ogundokun R.O.","2021","0","1","0","0","0","Unique","0","","","","","","","Localization of region of interest (ROI) is paramount to the analysis of medical images to assist in the identification and detection of diseases. In this research, we explore the application of a deep learning approach in the analysis of some medical images. Traditional methods have been restricted due to the coarse and granulated appearance of most of these images. Recently, deep learning techniques have produced promising results in the segmentation of medical images for the diagnosis of diseases. This research experiments on medical images using a robust deep learning architecture based on the Fully Convolutional Network-(FCN-) UNET method for the segmentation of three samples of medical images such as skin lesion, retinal images, and brain Magnetic Resonance Imaging (MRI) images. The proposed method can efficiently identify the ROI on these images to assist in the diagnosis of diseases such as skin cancer, eye defects and diabetes, and brain tumor. This system was evaluated on publicly available databases such as the International Symposium on Biomedical Imaging (ISBI) skin lesion images, retina images, and brain tumor datasets with over 90% accuracy and dice coefficient.  © 2021 Adekanmi Adeyinka Adegun et al.","10.1155/2021/6215281","","38","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106376551&doi=10.1155%2f2021%2f6215281&partnerID=40&md5=08ede9996c416d056ee0657fce210044"
"An auxiliary tool for preliminary tests of skin cancer : A self-modifying meta-learning method for clean and noisy data","Cao Y.; Wu Y.; Tian Z.; Yu X.","2021","1","1","0","0","0","Unique","0","","","","","","","Deep learning is a popular method when it comes to disease detection problems. As for skin cancer, a rather common kind of disease, however, unexpected rare cases often occur with few written records and referential materials, resulting in a disadvantageous situation for a usual neural network to learn. Hence, J in this paper, we propose a self-modifying meta-learning model which combines the idea of meta-learning with curriculum learning. Applying this mechanism, our model will first train on data of common diseases and then adapt the model to rare disease classification. Moreover, despite the existence of natural noise in data, like manually mistaken labels, our model can still handle which. We evaluate our algorithm on ISIC 2018 skin lesion classification dataset. Employing only 5 samples from each class, we achieve our accuracy up to 79.2%. Apart from that, when predicting data with a 20% noisy rate, our model can also adapt to classify unseen classes by accuracy of 76.2%. The further utilization for our model can be limited to skin cancer detection and diagnosis and extend to be applied to all kinds of diseases, serving as helpful assistants for medical workers, which would be a win-win for both patients and doctors.  © 2021 IEEE.Allrights reserved","10.1109/ICBASE53849.2021.00040","Deep Learning; Meta Learning; Noise Robustness; Skin-cancer","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126446420&doi=10.1109%2fICBASE53849.2021.00040&partnerID=40&md5=3fcd7467589f195808e0a117fb93f830"
"Pooling and Convolution Layer Strategy on CNN for Melanoma Detection","Sheng M.; Zeng H.; Li J.; Sun W.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Melanoma is the most lethal skin cancer nowadays, but an early diagnosis can considerably boost the survival rate and cure rate. Convolutional neural network (CNN) can be implied on medical image classification and can help the early melanoma detection. Our study mainly focuses on the influence of the CNN model on the melanoma detection. AlexNet and VGG are used as the network and the size of the pooling layer and the number of convolution layers are adjusted. According to the changes of parameters, the metrics of different models are compared. After training the models, the results illustrated that the pooling size of 3 contributed to better performance than that of 2, and the VGG model with 5 convolutional layers, max pooling, and pooling size of 3 is discovered to reach the lowest loss value of about 0.38. In conclusion, the specific recognition performance varies depending on the CNN structure, and what causes this variation also includes the number of convolutional layers and the pooling kernel size. Our main contribution also includes the identification of the best structure for detecting melanoma by comparing the model performance. © 2021 IEEE.","10.1109/MLBDBI54094.2021.00038","AlexNet; convolution layer; medical image classification; Melanoma; pooling layer; VGG","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128224723&doi=10.1109%2fMLBDBI54094.2021.00038&partnerID=40&md5=13058013a5bd5f9dd3327e40197c38d3"
"Measurement of Skin Test Wheals Using Image Segmentation Approaches","Parihar G.; Christopher J.; Joyce Y.S.; Bakthasingh Lazarus Y.; Dayalan J.","2021","1","1","0","0","0","Unique","0","","","","","","","Medical image segmentation is a widely used approach for skin image analysis ranging from detection of skin wheals, characterization of skin lesions and measurement of tumor-size. The segmentation approaches used in this work focus on the outcome of the tuberculin skin test or Mantaux test. In a skin test, the outcome is a wheal (localized swelling), which usually has a particular shape such as a circle or an ellipse. Automatic wheal detection and measurement is an important step to precisely estimate the wheal dimensions, and thereby estimate the extent and intensity of infection. This work presents an analysis of segmentation approaches on images captured using simple photography for estimating the wheal area and perimeter in terms of number of pixels. Four segmentation approaches are used; namely, Otsu's, region-growing, watershed and region watershed. From the experimental results, it is observed that the average relative error in computing the area and perimeter using the four approaches is found to be 50.77% and 56.35%, 24% and 12.19%, 23.34% and 16.15%, and 30.61% and 20.42% respectively. These automatic wheal detection methods work sufficiently well as compared to the manual selection method. The approach presented in this work minimizes the errors and inconsistencies involved in the reading and interpretation of skin test outcomes; moreover, using computer aided diagnosis would enhance automation of healthcare informatics at clinics and hospitals.  © 2021 IEEE.","10.1109/ICCCA52192.2021.9666435","Feature Extraction; Image segmentation; Intradermal skin test; Medical Image Processing","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124806941&doi=10.1109%2fICCCA52192.2021.9666435&partnerID=40&md5=41ad0af4ebdbb8561f7adb8f96c9cc9b"
"BEA-SegNet: Body and Edge Aware Network for Medical Image Segmentation","Kuang H.; Liang Y.; Liu N.; Liu J.; Wang J.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Medical image segmentation is a fundamental step for diagnosis and prognosis. This study proposes a new body and edge aware network for automated 2D medical image segmentation (called BEA-SegNet). The proposed BEA-SegNet consists of a shared encoder, a body and edge decouple (BEdecouple) module, two parallel decoders for body and edge segmentation. In the encoder and decoders, short-term multi-scale concatenation (STMSC) modules are utilized to implement multi-scale representation. We design a BEdecouple module to decouple the convolutional features into the body and edge features, making the proposed method be body and edge aware. The body and edge decoders utilize Bedecouple modules in each level to learn more effective features for the body and edge segmentation respectively, and their outputs are fused to generate the final segmentation. Besides, the body and edge supervision are applied to improve the final segmentation. The proposed BEA-SegNet is trained and evaluated on the International Skin Imaging Collaboration challenge 2018 dataset (ISIC2018). Experimental results show that the proposed BEA-SegNet achieves an average Dice similarity coefficient of 90.3% and an average Hausdorff distance of 15.9 for the skin lesion segmentation task and outperforms five benchmarks for skin lesion segmentation.  © 2021 IEEE.","10.1109/BIBM52615.2021.9669545","Body and edge decouple; Convolutional neural network; Deep supervision; Medical image segmentation; Multi-scale representation","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125166928&doi=10.1109%2fBIBM52615.2021.9669545&partnerID=40&md5=2cd025701340a487add07b3ef3b3470d"
"Haar Wavelet Pyramid-Based Melanoma Skin Cancer Identification With Ensemble of Machine Learning Algorithms","Thepade S.D.; Ramnani G.","2021","1","1","0","0","0","Unique","0","","","","","","","Melanoma is a mortal type of skin cancer. Early detection of melanoma significantly improves the patient’s chances of survival. Detection of melanoma at an early juncture demands expert doctors. The scarcity of such expert doctors is a major issue with healthcare systems globally. Computer-assisted diagnostics may prove helpful in this case. This paper proposes a health informatics system for melanoma identification using machine learning with dermoscopy skin images. In the proposed method, the features of dermoscopy skin images are extracted using the Haar wavelet pyramid various levels. These features are employed to train machine learning algorithms and ensembles for melanoma identification. The consideration of higher levels of Haar wavelet pyramid helps speed up the identification process. It is observed that the performance gradually improves from the Haar wavelet pyramid level 4x4 to 16x16 and shows marginal improvement further. The ensembles of machine learning algorithms have shown a boost in performance metrics compared to the use of individual machine learning algorithms. © 2021 IGI Global. All rights reserved.","10.4018/IJHISI.20211001.oa24","Computer-Assisted Diagnostics; Haar Wavelet; Machine Learning; Melanoma Skin Cancer","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163902583&doi=10.4018%2fIJHISI.20211001.oa24&partnerID=40&md5=a73fe5e8e9b61fc131c62f02387690db"
"Identification of Melanoma from Hyperspectral Pathology Image Using 3D Convolutional Networks","Wang Q.; Sun L.; Wang Y.; Zhou M.; Hu M.; Chen J.; Wen Y.; Li Q.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Skin biopsy histopathological analysis is one of the primary methods used for pathologists to assess the presence and deterioration of melanoma in clinical. A comprehensive and reliable pathological analysis is the result of correctly segmented melanoma and its interaction with benign tissues, and therefore providing accurate therapy. In this study, we applied the deep convolution network on the hyperspectral pathology images to perform the segmentation of melanoma. To make the best use of spectral properties of three dimensional hyperspectral data, we proposed a 3D fully convolutional network named Hyper-net to segment melanoma from hyperspectral pathology images. In order to enhance the sensitivity of the model, we made a specific modification to the loss function with caution of false negative in diagnosis. The performance of Hyper-net surpassed the 2D model with the accuracy over 92%. The false negative rate decreased by nearly 66% using Hyper-net with the modified loss function. These findings demonstrated the ability of the Hyper-net for assisting pathologists in diagnosis of melanoma based on hyperspectral pathology images.  © 1982-2012 IEEE.","10.1109/TMI.2020.3024923","Microscopy; optical imaging; quantification and estimation; segmentation; skin","106","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098885732&doi=10.1109%2fTMI.2020.3024923&partnerID=40&md5=0d18e06f2688fb31a439f3a9e5b4cf1d"
"Using CNN model to diagnose skin cancer","Wu Z.; Liu H.","2021","1","1","0","0","0","Unique","0","","","","","","","The main idea of the project is to utilize machine learning to try to make a diagnose of potential skin cancer. We used a traditional CNN model and later a ResNet Model to solve the problem. The model takes an image of the skin sample as input and tries to predict whether the abnormality on the surface of the skin is malignant or benign. The traditional CNN model resulted in an accuracy of 81.3% while the ResNet model resulted in an accuracy of 87.7%, which is a great leap due to the advancement in ResNet model compared to a traditional CNN model. However, we concluded that the accuracy of the model can still be increased by updating come factors of the model like the size of the dataset, the computing ability, and the structure of the model itself. Besides, the researchers implemented a GUI so that the users can utilize our research more conveniently. © 2021 SPIE","10.1117/12.2623115","CNN; Convolutional neural network; Image classifier; ResNet50; Skin cancer diagnose","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123248722&doi=10.1117%2f12.2623115&partnerID=40&md5=26a6523a850798ed6bf85657934dc9b4"
"Decision Support System for Detection and Classification of Skin Cancer Using CNN","Garg R.; Maheshwari S.; Shukla A.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Skin cancer is one of the most deathful of all the cancers. It is bound to spread to different parts of the body on the off chance that it is not analyzed and treated at the beginning time. It is mostly because of the abnormal growth of skin cells, often develops when the body is exposed to sunlight. Furthermore, the characterization of skin malignant growth in the beginning time is a costly and challenging procedure. It is classified where it develops and its cell type. High Precision and recall are required for the classification of lesions. The paper aims to use MNIST HAM-10,000 dataset containing dermoscopy images. The objective is to propose a system that detects skin cancer and classifies it in different classes by using the convolution neural network. The diagnosing methodology uses image processing and deep learning model. The dermoscopy image of skin cancer undergone various techniques to remove the noise and picture resolution. The image count is also increased by using various image augmentation techniques. In the end, the transfer learning method is used to increase the classification accuracy of the images further. Our CNN model gave a weighted average precision of 0.88, a weighted recall average of 0.74, and a weighted F1 score of 0.77. The transfer learning approach applied using ResNet model yielded an accuracy of 90.51% © 2021, Springer Nature Singapore Pte Ltd.","10.1007/978-981-15-6067-5_65","CNN; Deep learning; Skin cancer; Skin lesion","73","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092159496&doi=10.1007%2f978-981-15-6067-5_65&partnerID=40&md5=7966a2fd0dbc123e9b3994d869a4db5d"
"Bio-medical Image Analysis for Diagnosis and Healthcare Detection System of Skin Cancer","Yu C.-J.; Chen C.-A.; Chen S.-L.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Diagnosis of melanoma not only requires specialized equipment, but melanoma is also the deadliest. Because of a lack of medical resources, patients living in remote areas normally cannot use such facilities for skin detecting. To overcome these problems, this paper discusses opportunities in remote and melanoma detection system, a called telemedicine for the consumer electronics industry. In this research, the proposed melanoma detection system will use a variety of image processing methods, and present the discrimination results on the interface, and help doctors diagnose melanoma, and early detection of melanoma can increase the survival rate of the patients.  © 2021 IEEE.","10.1109/ICCE-TW52618.2021.9603067","Dermoscopy; Image Compression; Image Processing; Lesion Segmentation; Melanoma; Remote Healthcare","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123059266&doi=10.1109%2fICCE-TW52618.2021.9603067&partnerID=40&md5=e6ee9ad598af7792229222d8e61a3996"
"kCBAC-Net: Deeply Supervised Complete Bipartite Networks with Asymmetric Convolutions for Medical Image Segmentation","Gu P.; Zheng H.; Zhang Y.; Wang C.; Chen D.Z.","2021","0","1","0","0","0","Unique","0","","","","","","","Accurate and automatic medical image segmentation is challenging due to significant size and shape variations of objects (e.g., in multi-scales) and missing/blurring object borders. In this paper, we propose a new deeply supervised k-complete-bipartite network with asymmetric convolutions (kCBAC-Net) to exploit multi-scale features and improve the capability of standard convolutions for segmentation. (1) We leverage a generalized complete bipartite network to reuse multi-scale features, consolidate feature hierarchies at different scales, and preserve maximum information flow between encoder and decoder layers. (2) To further capture multi-scale information, we sequentially connect k complete bipartite network modules together to facilitate their processing in different image scales. (3) We replace the standard convolution by asymmetric convolution block to strengthen the central skeleton parts of standard convolution, enhancing the model’s robustness on exploiting more discriminative features. (4) We employ auxiliary deep supervisions to boost information flow in the network and extract highly discriminative features. We evaluate our kCBAC-Net on three datasets (ultrasound lymph node segmentation (2D), 2017 ISIC Skin Lesion segmentation (2D), and MM-WHS CT (3D)), achieving state-of-the-art performance. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-87193-2_32","","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116472657&doi=10.1007%2f978-3-030-87193-2_32&partnerID=40&md5=4f3a95beef6f43fcd2b29078f166f865"
"A Deep Learning Model for Skin Lesion Analysis Using Gaussian Adversarial Networks","Ergin F.; Parlak I.B.","2021","1","1","0","0","0","Unique","0","","","","","","","Computer assisted radiology becomes an interdisciplinary domain between mathematics, medicine and engineering. Tumor detection, analysis, classification are main problems in digital radiology for diagnosis and follow-up. A physician or an oncologist involves in the care of patients by regarding detailed reports of carcinoma in situ that analyze the pathology of suspicious lesions. Deep learning applied to several fields in medicine is considered as an intervention for oncology. Even if the final treatment of the lesion is decided by the oncologists or the surgeons in a case of resection, image based analysis of lesions (benign or malign) promises automated decision making for radiology. Skin lesion detection and classification are current challenges in medical image analysis. Dermatologic image processing benefits from the evaluation scores of neural nets. Gaussian Adversarial Networks (GAN) bring a new architecture in machine learning by adding generator and discriminator steps in data analysis. In this article, GAN architecture has been implemented on two dimensional skin lesion images. After the preprocessing, colored images have been trained in GAN. The experiment setup has been enriched by adding incremental noise on tumor images before GAN training. The evaluation has been tested through accuracy, sensitivity, specificity, Dice coefficient and Jaccard coefficient parameters. In conclusion, test results showed that GAN architecture provides a robust approach in skin lesion analysis. © 2021, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-030-51156-2_118","Deep neural networks; Histology; Image processing; Image segmentation; Tumor detection","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088753489&doi=10.1007%2f978-3-030-51156-2_118&partnerID=40&md5=aa63d1e5731b365902f27807213a62b7"
"Functional Networks for Image Segmentation of Cutaneous Lesions with Rational Curves","Gálvez A.; Fister I.; Fister I., Jr.; Iglesias A.","2021","0","1","0","0","0","First occurrence","0","","","","","","","This paper considers the problem of image segmentation for medical images, in particular, cutaneous lesions. Given a digital image of a skin lesion, our goal is to compute the border curve separating the lesion from the image background. This problem can be formulated as an optimization problem, where the border curve is computed through data fitting from a set of points lying on the lesion boundary. Some recent papers have applied artificial intelligence techniques to tackle this issue. However, they usually focus on the polynomial case, ignoring the more powerful (but also more difficult) case of rational curves. In this paper, we address this problem with rational Bézier curves by applying functional networks, a powerful extension of the classical neural networks. Experimental results on some benchmark medical images show that this method performs well and can be successfully applied to this problem. © 2021, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-030-57802-2_75","Cutaneous lesion; Data fitting; Functional networks; Image segmentation; Rational curves","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091319734&doi=10.1007%2f978-3-030-57802-2_75&partnerID=40&md5=6ea9760fd0e25e1cfcc3b87ff13715a1"
"An Efficient Approach for Skin Disease Detection using Deep Learning","Alam J.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Skin diseases are mostly caused by fungal infection, bacteria, allergy, or viruses, etc. The lasers advancement and photonics based medical technology is used in diagnosis of the skin diseases quickly and accurately. But the medical equipment for such diagnosis is limited and mostly expensive. However, using an image-based diagnosis system can help in reducing both time and cost. Image processing and Deep learning techniques can be combined together which helps in detection of skin disease at an initial stage. On the other hand, feature extraction plays a key role in classification of skin diseases. We propose an efficient approach for detecting skin disease using deep learning. The proposed system enables detecting skin disease with 85.14% accuracy which is higher than that of the existing models.  © IEEE 2022.","10.1109/CSDE53843.2021.9718427","Classification; Convolution Neural Network; Cross Validation; Image segmentation; Machine Learning; Prediction; Skin Cancer Detection; Skin Disease Detection","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127874042&doi=10.1109%2fCSDE53843.2021.9718427&partnerID=40&md5=6e566f4416e06de47f9cdd8b2681671c"
"Don’t Tear Your Hair Out: Analysis of the Impact of Skin Hair on the Diagnosis of Microscopic Skin Lesions","Gallucci A.; Znamenskiy D.; Pezzotti N.; Petkovic M.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Recent work on the classification of microscopic skin lesions does not consider how the presence of skin hair may affect diagnosis. In this work, we investigate how deep-learning models can handle a varying amount of skin hair during their predictions. We present an automated processing pipeline that tests the performance of the classification model. We conclude that, under realistic conditions, modern day classification models are robust to the presence of skin hair and we investigate three architectural choices (Resnet50, InceptionV3, Densenet121) that make them so. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-68763-2_31","Augmentations; Deep learning; Dermatology; Hair detection; Imaging; Melanoma; Skin lesion","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104325768&doi=10.1007%2f978-3-030-68763-2_31&partnerID=40&md5=12658a8a606b18e402ca1456390926a9"
"Intelligent Dermatologist Tool for Classifying Multiple Skin Cancer Subtypes by Incorporating Manifold Radiomics Features Categories","Attallah O.; Sharkas M.","2021","1","1","0","0","0","Unique","0","","","","","","","The rates of skin cancer (SC) are rising every year and becoming a critical health issue worldwide. SC's early and accurate diagnosis is the key procedure to reduce these rates and improve survivability. However, the manual diagnosis is exhausting, complicated, expensive, prone to diagnostic error, and highly dependent on the dermatologist's experience and abilities. Thus, there is a vital need to create automated dermatologist tools that are capable of accurately classifying SC subclasses. Recently, artificial intelligence (AI) techniques including machine learning (ML) and deep learning (DL) have verified the success of computer-assisted dermatologist tools in the automatic diagnosis and detection of SC diseases. Previous AI-based dermatologist tools are based on features which are either high-level features based on DL methods or low-level features based on handcrafted operations. Most of them were constructed for binary classification of SC. This study proposes an intelligent dermatologist tool to accurately diagnose multiple skin lesions automatically. This tool incorporates manifold radiomics features categories involving high-level features such as ResNet-50, DenseNet-201, and DarkNet-53 and low-level features including discrete wavelet transform (DWT) and local binary pattern (LBP). The results of the proposed intelligent tool prove that merging manifold features of different categories has a high influence on the classification accuracy. Moreover, these results are superior to those obtained by other related AI-based dermatologist tools. Therefore, the proposed intelligent tool can be used by dermatologists to help them in the accurate diagnosis of the SC subcategory. It can also overcome manual diagnosis limitations, reduce the rates of infection, and enhance survival rates.  © 2021 Omneya Attallah and Maha Sharkas.","10.1155/2021/7192016","","19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116265092&doi=10.1155%2f2021%2f7192016&partnerID=40&md5=126d0243956828e8191802e5b1db1d7e"
"A Majority Voting based Ensemble Approach of Deep Learning Classifiers for Automated Melanoma Detection","Safdar K.; Akbar S.; Shoukat A.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Melanoma is one of the most threatening types of skin cancer with a large-scale mortality rate. The early-stage diagnosis of melanoma can help prevent its proliferation to other body organs. In this regard, several Computer aided Diagnosis (CAD) approaches have been proposed by researchers which serve as a milestone in combatting this ugly disease. In this research work, we have proposed a Model Blending technique which is an ensemble of two pre-trained deep Convolutional Neural Networks (CNNs) namely DenseNet-201 and ResNet-50. The proposed ensemble approach plays a key role in accurate melanoma classification with reduced generalization error of the two Neural Networks (NNs). Region of Interest (ROI) segmentation and lesion classification are performed using multiple, standardized dermoscopy datasets accessed from PH2, Med-Node and DermIs archives. We have applied advanced data purification techniques to remove occlusions, unwanted artifacts and to adjust low contrast or illumination effects. ROI (lesion) segmentation is done using the K-means clustering algorithm which precisely separates the foreground and background pixels of the images. Affine Image Transformation and Color Space Transformation approaches are applied to augment our image datasets. The ensemble model of ResNet-50 and DenseNet-201 performed binary lesion classification (benign or malignant) using a Majority Voting technique. Our proposed segmentation method displayed satisfactory results with a precision of 91%, AUC 89%, specificity 95.7% and sensitivity score of 94%. In the classification task, the pre-trained ensemble model recorded superior results as compared to other ultra-modern melanoma diagnosis approaches and achieved an accuracy of 95.2%, specificity 96.7%, sensitivity 92.8% and AUC 98.5% on multiple dermoscopy image datasets. The evaluation results are carefully analyzed and compared with other existing melanoma detection approaches which indicate the reliability and robustness of our model.  © 2021 IEEE.","10.1109/ICIC53490.2021.9692915","benign; deep learning; dermoscopy; image classification; melanoma","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126677866&doi=10.1109%2fICIC53490.2021.9692915&partnerID=40&md5=ee1fb7cd221ee22ed7f98c9eba40d0d2"
"Predicting Melanoma Tumor Size through Machine Learning Approaches","Chadha D.; Jain N.; Gupta V.","2021","0","1","0","0","0","Unique","0","","","","","","","Melanoma is a kind of skin cancer that arises from melanocytes, pigment-producing cells. Melanoma is more harmful than other cancers because it can spread to other organs more quickly if not treated early. As a result, it is important to detect melanoma early. Existing research has focused on predicting whether or not a tumor is present, but no such methodology has been used to predict tumor size. This chapter focuses on measuring the tumor's size based on the various features provided. The size of a tumor has been predicted using a number of machine learning methods. RMSE, MAE, R2 score, and MBE were used to assess the prediction's accuracy. Based on the results obtained, combined model of XGBoost, LightGBM, Extra Tree Regressor, Catboost, and Bagging Regressor outperforms all approaches. © 2022 selection and editorial matter Dharmender Saini, Gopal Chaudhary, and Vedika Gupta; individual chapters, the contributors.","10.1201/9781003134138-11","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196585493&doi=10.1201%2f9781003134138-11&partnerID=40&md5=de0a0586f8c314baa84857a68270f38b"
"DC-Net: Dual Context Network for 2D Medical Image Segmentation","Xu R.; Wang C.; Xu S.; Meng W.; Zhang X.","2021","0","1","0","0","0","Unique","0","","","","","","","Medical image segmentation is essential for disease diagnosis analysis. There are many variants of U-Net that are based on attention mechanism and dense connections have made progress. However, CNN-based U-Net lacks the ability to capture the global context, and the context information of different scales is not effectively integrated. These limitations lead to the loss of potential context information. In this work, we propose a Dual Context Network (DC-Net) to aggregate global context and fuse multi-scale context for 2D medical image segmentation. In order to aggregate the global context, we present the Global Context Transformer Encoder (GCTE), which reshapes the original image and the multi-scale feature maps into a sequence of image patches, and combines the advantages of Transformer Encoder on global context aggregation to improve the performance of encoder. For the fusion of multi-scale context, we propose the Adaptive Context Fusion Module (ACFM) to adaptively fuse context information by learning Adaptive Spatial Weights and Adaptive Channel Weights to improve the performance of decoder. We apply our DC-Net with GCTE and ACFM to skin lesion segmentation and cell contour segmentation tasks, experimental results show that our method can outperform other advanced methods and get state-of-the-art performance. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-87193-2_48","Medical image segmentation; Multi-scale context fusion; Visual transformer","31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116454442&doi=10.1007%2f978-3-030-87193-2_48&partnerID=40&md5=e65497c2457eb91ecb2b39dbe8453924"
"A Novel Image Segmentation Algorithm Based on Hesitant Neutrosophic and Level Set","Zheng Y.; Zhang L.","2021","0","1","0","0","0","First occurrence","0","","","","","","","The first step of dermoscopy image analysis technology is image segmentation, the segmentation result will directly affect the subsequent processing process, aiming at the background noise, blurred edge and gray uneven dermoscopy image, a new image segmentation method combining the hesitant neutrosophic set with level set is proposed. Firstly, the image is transformed into the hesitant neutrosophic image by using the hesitant neutrosophic set theory. The hesitant neutrosophic set image is composed of three subsets (T, I, F), and the hesitant neutrosophic image is used to highlight the target information and edge information of the image. Then, we improved the traditional DRLSE level set, constructed a new edge stop function, and added a gray energy term. Finally, we used the improved DRLSE level set to test the ISIC(2018) dermoscopy image. The Jaccard Index values of the experimental results are all greater than 95%, and the mean square error (MSE), peak signal-to-noise ratio (PNSR) and structural similarity Index (SSIM) all perform well, indicating that the proposed method can accurately and effectively segment the skin mirror images with fuzzy edges and uneven gray scales. It's a foundation for the processing and diagnosis of the subsequent dermoscopy image.  © 2021 IEEE.","10.1109/ICEITSA54226.2021.00077","dermoscopy images; Hesitant Neutrosophic; Image segmentation; Level set","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126871858&doi=10.1109%2fICEITSA54226.2021.00077&partnerID=40&md5=554dc72c8902488900e24ea899e941bd"
"Tacotron Model and CNN in Virtual Reality for Cancer Diagnosis and Communication between Doctors and Patients","Jin S.; Li J.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Virtual reality is widely used in various fields, such as military, industrial and medical fields. CNN is prevalent when solving problems about image classification. NLP is the most useful model to realize speech synthesis. However, image classification is seldom combined with speech synthesis to be used in a realistic scene. In order to tackle this issue, this paper proposed a system, which combines image classification with speech synthesis organically. There are three steps used to build this system in this paper. First, this paper devises a model to classify whether the patients have skin cancer. It designs a CNN model to deal with the classification of images of skin, diagnosing whether the patient suffers from Melanoma. Second, the Tacotron model is included in this paper to implement speech synthesis, telling the diagnostic results obtained from image classification to the patients. Finally, a virtual reality environment is built to display a scene when a patient entering the hospital and then being diagnosed and getting treatment.  © 2021 IEEE.","10.1109/AINIT54228.2021.00093","Cancer Diagnosis; CNN Model; DenseNet; Tacotron Model; Virtual Reality","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127498512&doi=10.1109%2fAINIT54228.2021.00093&partnerID=40&md5=478560b0cf9b426701dab35dd62dbf87"
"Convolutional Neural Network Based Skin Cancer Detection (Malignant vs Benign)","Hossain M.; Sadik K.; Rahman M.M.; Ahmed F.; Bhuiyan M.N.H.; Khan M.M.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Skin cancer is very dangerous and deadly diseases in today's world. Between Malignant and Benign skin cancers, Malignant is the deadliest and Benign is curable. Due to the significant growth rate of Malignant and Benign skin cancer, its high treatment costs, and the mortality rate, the need for early detection of skin cancer has been increased. In most cases, these cells are manually identified and it takes time to cure them. In this paper it has been addressed the requirement for a cheap and fast detection of skin disease (Malignant and Benign) applying more effective CNN, PyTorch and to increase the accuracy four different ResNet models has been used. In this method, a pre-trained model named ResNet is used for image classification. It has been used four different version of ResNet model (ResNet18, ResNet50, ResNet101 and ResNet152) to increase the accuracy of our project. ResNet model is a specific type and advance version of deep convolutional neural network. It is better and faster than previously used VGG-16 per-trained model for image classification. Dataset used in this project is collected from Kaggle.com which contains almost 6,599 images to train the model and measure the accuracy. By using different version of ResNet model respectively observed different test result (86.34% for ResNet18 model, 88.78% for ResNet50, 89.09% for ResNet101 and 89.65% for ResNet152). It has been compared the accuracy from our proposed method with the existing method and obtained better accuracy rather than the existing method. The existing system gave an accuracy which is about 83.02% and this system gives more than 89.65% accuracy and it's higher than previously done on skin cancer detection project.  © 2021 IEEE.","10.1109/IEMCON53756.2021.9623192","Accuracy; Benign; Convolutional Neural Network (CNN); Dataset; Image Classification; Malignant; PyTorch; ResNet Model; Skin Cancer; VGG-16 model","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123590022&doi=10.1109%2fIEMCON53756.2021.9623192&partnerID=40&md5=6fce39800fbaf62a1b7258859007d535"
"Performance Analysis of Segmentor Adversarial Network (SegAN) on Bio-Medical Images for Image Segmentation","Sachin Saj T.K.; Sowmya V.; Soman K.P.","2021","0","1","0","0","0","Unique","0","","","","","","","Cancer is termed as one of the deadliest disease, and it is becoming a major health problem in the world. This deadly disease can be cured, if it is found at earlier stages. Medical imaging plays an important role in finding this type of diseases and helps in treatment planning. Automated lesion/tumor segmentation is an important and challenging clinical diagnostic task because of tumor’s different shape, volume, contrast, and locations. Since deep learning is promising in many applications, thus motivating us to apply in this important task. In this paper, we propose to do automated tumor segmentation with two challenge dataset named as BraTs 2017 brain tumor and ISIC 2018 skin lesion by using Segmentor Adversarial Network (SegAN), inspired from classical GAN. © 2021, Springer Nature Singapore Pte Ltd.","10.1007/978-981-15-8221-9_69","GAN; Image segmentation; SegAN","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103442651&doi=10.1007%2f978-981-15-8221-9_69&partnerID=40&md5=f367eca6ba84c62824ca170822cc5c79"
"Development and validation of two artificial intelligence models for diagnosing benign, pigmented facial skin lesions","Yang Y.; Ge Y.; Guo L.; Wu Q.; Peng L.; Zhang E.; Xie J.; Li Y.; Lin T.","2021","1","1","0","0","0","Unique","0","","","","","","","Objective: This study used deep learning for diagnosing common, benign hyperpigmentation. Method: In this study, two convolutional neural networks were used to identify six pigmentary diseases, and a disease diagnosis model was established. Because the distribution of lesions in the original training picture is very complex, we cropped the image around the lesions, trained the network on the extracted lesion images, and fused the verification results of the overall picture and the extracted picture to assess the model performance in identifying hyperpigmented dermatitis pictures. Finally, we evaluated the image recognition performance of the two convolutional neural networks and the converged networks in the test set through a comparison of the converged network and the physicians’ assessments. Results: The AUC of DenseNet-96 for the overall picture was 0.98, whereas the AUC of ResNet-152 was 0.96; therefore, we concluded that DenseNet-96 performed better than ResNet-152. From the AUC, the converged network has the best performance. The converged network model achieved a comprehensive classification performance comparable to that of the doctors. Conclusions: The diagnostic model for benign, pigmented skin lesions based on convolutional neural networks had a slightly higher overall performance than the skin specialists. © 2020 John Wiley & Sons A/S. Published by John Wiley & Sons Ltd","10.1111/srt.12911","artificial intelligence; benign facial skin lesions; diagnostic model; Pigmented skin lesion","29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089090180&doi=10.1111%2fsrt.12911&partnerID=40&md5=3faf4fe21c49c867e8d621b710b1630a"
"24th International Conference on Medical Image Computing and Computer Assisted Intervention, MICCAI 2021","","2021","0","1","0","0","0","First occurrence","0","","","","","","","The proceedings contain 531 papers. The special focus in this conference is on Medical Image Computing and Computer Assisted Intervention. The topics include: TransBTS: Multimodal Brain Tumor Segmentation Using Transformer; automatic Polyp Segmentation via Multi-scale Subtraction Network; patch-Free 3D Medical Image Segmentation Driven by Super-Resolution Technique and Self-Supervised Guidance; progressively Normalized Self-Attention Network for Video Polyp Segmentation; SGNet: Structure-Aware Graph-Based Network for Airway Semantic Segmentation; NucMM Dataset: 3D Neuronal Nuclei Instance Segmentation at Sub-Cubic Millimeter Scale; AxonEM Dataset: 3D Axon Instance Segmentation of Brain Cortical Regions; improved Brain Lesion Segmentation with Anatomical Priors from Healthy Subjects; carveMix: A Simple Data Augmentation Method for Brain Lesion Segmentation; TransFuse: Fusing Transformers and CNNs for Medical Image Segmentation; boundary-Aware Transformers for Skin Lesion Segmentation; A Topological-Attention ConvLSTM Network and Its Application to EM Images; BiX-NAS: Searching Efficient Bi-directional Architecture for Medical Image Segmentation; multi-task, Multi-domain Deep Segmentation with Shared Representations and Contrastive Regularization for Sparse Pediatric Datasets; TEDS-Net: Enforcing Diffeomorphisms in Spatial Transformers to Guarantee Topology Preservation in Segmentations; learning Consistency- and Discrepancy-Context for 2D Organ Segmentation; partially-Supervised Learning for Vessel Segmentation in Ocular Images; unsupervised Network Learning for Cell Segmentation; MT-UDA: Towards Unsupervised Cross-modality Medical Image Segmentation with Limited Source Labels; context-Aware Virtual Adversarial Training for Anatomically-Plausible Segmentation; Pancreas CT Segmentation by Predictive Phenotyping; interactive Segmentation via Deep Learning and B-Spline Explicit Active Surfaces; multi-compound Transformer for Accurate Biomedical Image Segmentation; kCBAC-Net: Deeply Supervised Complete Bipartite Networks with Asymmetric Convolutions for Medical Image Segmentation; Refined Local-imbalance-based Weight for Airway Segmentation in CT.","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116449682&partnerID=40&md5=a936522a42c5fb2669e4c78d144da38a"
"Identification of skin melanoma based on microscopic hyperspectral imaging technology","Fan T.; Long Y.; Zhang X.; Peng Z.; Li Q.","2021","1","0","0","0","0","Unique","0","","","","","","","Screening and diagnosing of the melanoma are crucial for the early diagnosis. As the deterioration of melanoma, it can be easily separated from the other materials based on the spectral features and spatial features. With the image of microscopic hyperspectral, this paper applies spectral math to preprocess the image firstly and the utilizes three traditional supervised classifications-maximum likelihood classification (MLC), convolution neural networks (CNN) and support vector machine (SVM) to make the segmentation after preprocess. Finally, we evaluate the accuracy of results generated by three to get the best segmentation method among them. This experiment shows practical value in pathological diagnosis. © 2021 SPIE.","10.1117/12.2588969","convolution neural networks (CNN); maximum likelihood classification; melanoma; microscopic hyperspectral; segmentation; support vector machine (SVM)","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100025615&doi=10.1117%2f12.2588969&partnerID=40&md5=9e429500da3725483d4f7ccfa454eb2e"
"Melanoma Prevention","Orrin E.J.R.; Cassidy P.B.; Kulkarni R.P.; Berry E.G.; Leachman S.A.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Primary prevention measures are used with the intent to decrease or ameliorate the effects of pro-tumorgenic damage to normal tissue. Secondary prevention consists of interventions that decrease morbidity and mortality from melanoma for patients whose skin harbors initiating mutations and/or early-stage melanomas. The most important secondary prevention modality is early detection and removal of melanoma before it attains metastatic or lethal potential. Secondary prevention can also involve halting the progression of transformed cells to lethal cancers by other means such as therapeutic prevention. Tailoring prevention strategies to different populations and specific patients starts with assessments of phenotypic, environmental, and genetic risk factors for melanoma. Our discussions of primary prevention focus on the effects of ultraviolet radiation (UV) and methods for decreasing risk by the use of sunscreen, and avoiding exposure to UV from the sun and tanning beds. We then discuss secondary prevention modalities and identify those that are most appropriate for patients and populations at each level of risk for melanoma. Secondary prevention strategies include education, skin self-examination, use of mobile applications, provider screenings, total body skin examinations by dermatologists, and genetic testing. We also discuss population-level interventions and additional public health issues surrounding melanoma prevention. Primary and secondary prevention, Therapeutic prevention, Antioxidants Ultraviolet radiation, Sunscreens, Risk factors, Genetic testing, Education, Skin awareness, Population-level interventions","10.1007/978-3-030-82639-0_1","Antioxidants Ultraviolet radiation; Education; Genetic testing; Population-level interventions; Primary and secondary prevention; Risk factors; Skin awareness; Sunscreens; Therapeutic prevention","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156222926&doi=10.1007%2f978-3-030-82639-0_1&partnerID=40&md5=505e4e65b25fa898b68af80494658aad"
"A Novel Region-Extreme Convolutional Neural Network for Melanoma Malignancy Recognition","Nida N.; Irtaza A.; Yousaf M.H.","2021","0","1","0","0","0","Unique","0","","","","","","","Melanoma malignancy recognition is a challenging task due to the existence of intraclass similarity, natural or clinical artefacts, skin contrast variation, and higher visual similarity among the normal or melanoma-affected skin. To overcome these problems, we propose a novel solution by leveraging ""region-extreme convolutional neural network""for melanoma malignancy recognition as malignant or benign. Recent works on melanoma malignancy recognition employed the traditional machine learning techniques based on various handcrafted features or the recently introduced CNN network. However, the efficient training of these models is possible, if they localize the melanoma affected region and learn high-level feature representation from melanoma lesion to predict melanoma malignancy. In this paper, we incorporate this observation and propose a novel ""region-extreme convolutional neural network""for melanoma malignancy recognition. Our proposed region-extreme convolutional neural network refines dermoscopy images to eliminate natural or clinical artefacts, localizes melanoma affected region, and defines precise boundary around the melanoma lesion. The defined melanoma lesion is used to generate deep feature maps for model learning using the extreme learning machine (ELM) classifier. The proposed model is evaluated on two challenge datasets (ISIC-2016 and ISIC-2017) and performs better than ISIC challenge winners. Our region-extreme convolutional neural network recognizes the melanoma malignancy 85% on ISIC-2016 and 93% on ISIC-2017 datasets. Our region-extreme convolutional neural network precisely segments the melanoma lesion with an average Jaccard index of 0.93 and Dice score of 0.94. The region-extreme convolutional neural network has several advantages: it eliminates the clinical and natural artefacts from dermoscopic images, precisely localizes and segments the melanoma lesion, and improves the melanoma malignancy recognition through feedforward model learning. The region-extreme convolutional neural network achieves significant performance improvement over existing methods that makes it adaptable for solving complex medical image analysis problems. © 2021 Nudrat Nida et al.","10.1155/2021/6671498","","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111512286&doi=10.1155%2f2021%2f6671498&partnerID=40&md5=5d3f9208272800eb4a8f39947fd35057"
"Deep Learning Models of Melonoma Image Texture Pattern Recognition","Samraj J.; Pavithra R.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Melanoma is treated as one of the most hazardous skin disease, which must be identified in earlier for a proper treatment and diagnosing. The Computer Aided Diagnosis (CAD) system is more helpful to exactly detect and classify the disease based on its features. This paper aims to conduct a detailed review on different types of image processing techniques used for detecting the skin disease with improved efficiency and accuracy measures. There are several models of image feature analysis and prediction methods based on the neural network to enhance the classification rate. In this paper, the techniques related to the neural network based classification models are analyzed and reviewed with its benefits and demerits. Also, this work aims to investigate the performance of each technique based on several evaluation measures. Based on this study, the most suitable technique is identified for the Melanoma skin disease detection with high detection efficiency. © 2021 IEEE.","10.1109/ICMNWC52512.2021.9688345","cellular automata; computer aided diagnosis (cad); deep learning and melanoma image classification; image texture pattern","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125694620&doi=10.1109%2fICMNWC52512.2021.9688345&partnerID=40&md5=94618bf48840f329f1bffdabff1895cb"
"Image assisted assessment of cancer segment from dermoscopy images","Santhosh M.; Rubin Silas Raj R.; Rajinikanth V.; Satapathy S.C.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Previous research confirms the accessibility of an assortment of picture assessment schemes for the skin melanoma appraisal. Skin Melanoma (SM) is also one of the deadliest diseases, and the unnoticed SM may direct to casualty. In this study, the SM image assessment is based on the Bat Algorithm (BA) and Kapur’s threshold. Active Contour Segmentation (ACS) is employed to mine and study the melanoma tainted skin fragment. In this work, the dermoscopy images of the benchmark data, like DermIS and Dermquest are considered for the inspection. Primarily, all the pictures are transformed into 256 × 256 pixels together with the ground truth (GT) slice, and these pictures are then used in the inspection. The efficacy of the projected procedure is then validated using a comparative examination among the mined skin segment and GT. The experimental result substantiates that this procedure helps to achieve a better Jaccard-Index and Dice value for the considered datasets; hence this procedure is appropriate to inspect the SM pictures. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2021.","10.1007/978-981-15-5679-1_68","Bat algorithm; Dermoscopy picture; Kapur’s-function; Melanoma; Segmentation","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091100044&doi=10.1007%2f978-981-15-5679-1_68&partnerID=40&md5=f289d5e98c3b9328af13dd78d028ca55"
"Skin Cancer Classification Based on Convolutional Neural Network","Li J.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Skin cancer is a kind of cancer that is usually diagnosed by images from dermoscopy. In recent years, researchers have attempted to utilize deep learning technology, especially convolution neural networks (CNN), in the recognition of skin cancer images. Many CNN models have already performed great applicability, like DenseNet, Inception, and Xception. This paper carried a comparative experiment on ISIC 2019 challenge dataset which includes 25,331 skin cancer images of 8 different kinds. On the classification task on the ISIC 2019, it introduced 6 models, VGGNet19, ResNet50, ResNet152, DenseNet201, Inception-v3, and Xception, then conducted a comparative analysis of their performance involving 2 methods (data enhance and transfer learning) and 2 optimizers (Adam and SGD), aiming to explore the impact of different methods and structures on the accuracy, in order to find traits for potential models of higher accuracy. In the 24 groups of results, Xception with data enhance, transfer learning (pretraining) and Adam optimizer had the highest accuracy of 83.8%, while VGGNet19 without transfer learning had the lowest of 66.67%. The influence of transfer leaning is positive on all models, both on accuracy and training time; similar to Adam optimizer, except for a noticeable enhancement effect on Inception-v3 and Xception. The data enhance method applied in this paper had a weak, non-directed impact. Possible reasons for this phenomenon are discussed in depth in the study. © 2021 IEEE.","10.1109/ICAICE54393.2021.00108","convolution neural network; data enhance; deep learning; ISIC 2019; medical image classification; Skin cancer; transfer learning","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133974275&doi=10.1109%2fICAICE54393.2021.00108&partnerID=40&md5=3d55f05d544dae7173bcdcefd4d07675"
"5th IFIP TC 5, TC 12, WG 8.4, WG 8.9, WG 12.9 International Cross-Domain Conference on Machine Learning and Knowledge Extraction, CD-MAKE 2021","","2021","0","1","0","0","0","Unique","0","","","","","","","The proceedings contain 22 papers. The special focus in this conference is on Machine Learning and Knowledge Extraction. The topics include: Airbnb Price Prediction Using Machine Learning and Sentiment Analysis; towards Financial Sentiment Analysis in a South African Landscape; weighted Utility: A Utility Metric Based on the Case-Wise Raters’ Perceptions; Deep Convolutional Neural Network (CNN) Design for Pathology Detection of COVID-19 in Chest X-Ray Images; anomaly Detection for Skin Lesion Images Using Replicator Neural Networks; On the Overlap Between Grad-CAM Saliency Maps and Explainable Visual Features in Skin Cancer Images; from Explainable to Reliable Artificial Intelligence; Explanatory Pluralism in Explainable AI; on the Trustworthiness of Tree Ensemble Explainability Methods; when in Doubt, Ask: Generating Answerable and Unanswerable Questions, Unsupervised; human-in-the-Loop Model Explanation via Verbatim Boundary Identification in Generated Neighborhoods; MAIRE - A Model-Agnostic Interpretable Rule Extraction Procedure for Explaining Classifiers; transparent Ensembles for Covid-19 Prognosis; self-propagating Malware Containment via Reinforcement Learning; text2PyCode: Machine Translation of Natural Language Intent to Python Source Code; automated Short Answer Grading Using Deep Learning: A Survey; fair and Adequate Explanations; mining Causal Hypotheses in Categorical Time Series by Iterating on Binary Correlations; active Finite Reward Automaton Inference and Reinforcement Learning Using Queries and Counterexamples; rice Seed Image-to-Image Translation Using Generative Adversarial Networks to Improve Weedy Rice Image Classification.","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115135405&partnerID=40&md5=b4a06571b78f247a85455a2d14edc462"
"Evaluation of a smartphone application for diagnosis of skin diseases","Mikołajczyk M.; Patrzyk S.; Nieniewski M.; Woźniacka A.","2021","1","1","0","0","0","Unique","0","","","","","","","Introduction: Artificial intelligence (AI) could offer equal, or even more accurate, diagnoses of melanoma than most dermatologists. However, the value of popular smartphone applications for diagnosing unpigmented skin lesions remains unclear. Aim: To compare the diagnostic accuracy of a popular, free-to-use web application for automatic dermatosis diagnosis against expert diagnosis of selected skin diseases. Material and methods: Skin lesion images of patients with verified diagnosis were collected using a smartphone and were diagnosed by the application. The AI provided five diagnoses of varying probability. For each patient, accuracy of the diagnosis was evaluated by three criteria, i.e. whether the expert diagnosis was matched by the most probable automated diagnosis, one of the top three diagnoses or one of the top five diagnoses. Reliability was analysed using intraclass correlation coefficients. Results: The chance of a correct diagnosis increased when more outcomes were considered and more samples of a skin condition were included. However, the probability of a diagnosis repeating for the same patient was below 25%. Reliability, sensitivity and specificity were insufficient for clinical purposes. Conclusions: Although AI diagnostics are encouraging, there is also a large margin for improvement, and AI is not yet an adequate replacement for medical professionals. © 2021 Termedia Publishing House Ltd.. All rights reserved.","10.5114/ada.2020.101258","Artificial intelligence; New technology; Psoriasis; Skin diseases diagnosis; Smartphone application; Web application","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119020372&doi=10.5114%2fada.2020.101258&partnerID=40&md5=3a25a0b1b4102d6aebca32b7e7bcf17e"
"A Multitasking Learning Framework for Dermoscopic Image Analysis","Talavera-Martínez L.; Bibiloni P.; González-Hidalgo M.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Multitasking learning improves a model’s ability to generalize by learning multiple tasks in parallel. However, it is difficult to know how each task influences the others’ learning. In this work, we study in-depth the behavior of the tasks of skin lesion segmentation, hair mask segmentation, and the inpainting of those hairs, in a multitasking framework to discover how they influence each other. The experiments are performed using an encoder-decoder convolutional neural network and images from five public databases: PH2, dermquest, dermis, EDRA2002, and the ISIC Data Archive. To evaluate the tasks’ performance, we use a series of metrics on which we apply a statistical test to check the superiority of each task in a multitasking model with respect to their individual performance. We also check, in a three-task model, whether there is a task that dominates the learning stage. Finally, we conclude that while the inpainting task does not benefit from this type of learning, the rest of the tasks improve their performance when compared to that obtained by their corresponding single-task model. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-93420-0_4","Deep neural networks; Dermoscopy; Hair removal; Inpainting; Multitasking; Skin lesion segmentation","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124330676&doi=10.1007%2f978-3-030-93420-0_4&partnerID=40&md5=4153712df1d9affa7db36625ca2fb573"
"A Simple Generic Method for Effective Boundary Extraction in Medical Image Segmentation","Kim M.; Lee B.-D.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Accurate identification of the shape and position of organs and abnormal objects (e.g., tumors) in medical images plays an important role in surgical planning as well as in the diagnosis and prognosis of diseases. However, this is difficult to achieve from two-dimensional medical images as these images present inaccurate and ambiguous organ boundaries. Further, traditional image processing-based boundary detection methods such as the Canny edge detector and Sobel operator exhibit poor boundary detection performance for images with substantial noise. Recently, the use of deep learning has resulted in improvements in semantic segmentation in medical images. In this paper, we propose a generic boundary-aware loss function to facilitate the effective discernment of the boundaries of organs and abnormal objects in medical images. Specifically, the proposed loss function introduces a boundary area and assigns higher weights to the loss of pixels located in the boundary area than to those in the non-boundary areas, thereby promoting effective learning in the boundary area. The results of experiments conducted using public medical datasets comprising colon polyp, skin lesion, and chest X-ray data indicate that the standard loss functions, such as cross-entropy loss and Dice loss, combined with the proposed boundary-aware loss function, achieve comparable or better performance than those without the boundary-aware loss function.  © 2013 IEEE.","10.1109/ACCESS.2021.3099936","Boundary extraction; deep learning; loss function; medical image analysis; segmentation","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111937958&doi=10.1109%2fACCESS.2021.3099936&partnerID=40&md5=af254712496edaf3e1d3823b6c5a71b6"
"Recent Trends in Computer-Aided Diagnostic Systems for Skin Diseases: Theory, Implementation, and Analysis","Chatterjee S.; Dey D.; Munshi S.","2021","1","1","0","0","0","Unique","0","","","","","","","Recent Trends in Computer-aided Diagnostic Systems for Skin Diseases: Theory, Implementation, and Analysis provides comprehensive coverage on the development of computer-aided diagnostic (CAD) systems employing image processing and machine learning tools for improved, uniform evaluation and diagnosis (avoiding subjective judgment) of skin disorders. The methods and tools are described in a general way so that these tools can be applied not only for skin diseases but also for a wide range of analogous problems in the domain of biomedical systems. Moreover, quantification of clinically relevant information that can associate the findings of physicians/experts is the most challenging task of any CAD system. This book gives all the details in a step-by-step form for different modules so that the readers can develop each of the modules like preprocessing, feature extraction/learning, disease classification, as well as an entire expert diagnosis system themselves for their own applications. © 2022 Elsevier Inc. All rights reserved.","10.1016/B978-0-323-91211-2.00010-X","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129641544&doi=10.1016%2fB978-0-323-91211-2.00010-X&partnerID=40&md5=0952045868a325354f89e6ef9c2818e9"
"A Survey on a Skin Disease Detection System","Mamun Md.A.; Uddin M.S.","2021","1","1","0","0","0","Unique","0","","","","","","","Skin diseases are frequent and quite perennial in the world, and in some cases, these lead to cancer. These are curable if detected earlier and treated appropriately. An automated image-based detection system consisting of four main modules—image enhancement, region of interest segmentation, feature extraction, and detection—can facilitate early identification of these diseases. Diverse image-based methods incorporating machine learning techniques are developed to diagnose different types of skin diseases. This article focuses on the review of the tools and techniques used in the diagnosis of 28 common skin diseases. Furthermore, it has discussed the available image databases and the evaluation metrics for the performance analysis of various diagnosis systems. This is vital for figuring out the implementation framework as well as the efficacy of the diagnosis methods for the neophyte. Based on the performance accuracy, the state-of-the-art method for the diagnosis of a particular disease is figured out. It also highlights challenges and shows future research directions. © 2021 IGI Global. All rights reserved.","10.4018/IJHISI.20211001.oa35","Feature Extraction; Melanoma; Segmentation; Skin-Disease Diagnosis","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135839826&doi=10.4018%2fIJHISI.20211001.oa35&partnerID=40&md5=1bae7669d3892dc4f682c730ef72a97b"
"Clinical Skin Disease Detection and Classification: Ensembled VGG","Saikiran G.; Surya Narayana G.; Porika D.; Vinit Kumar G.","2021","1","1","0","0","0","Unique","0","","","","","","","Our research work has succeeded in integrating ensembles into VGG image classification technique aiming higher accuracy and performance than existing models. The convolutional layers are apt for feature extraction from images. In VGG classifier three fully connected dense layers are used for classification of class from these outputted features. But we have integrated ensemble methods immediately after convolutional layers for purpose of better classification output. Thus, the output (features of image) of convolutional layers is passed as a separate input to both ensemble methods and fully connected layers of VGG for obtaining the class of image. Final class of image is determined by specific strategy after analyzing outputs of ensemble and VGG fully connected layers. All earlier works focused on skin disease classification. Here, we have also experimented with yolo for detection of location and class of diseases. Skin is considered as the most significant part of the body. But this most significant part of the body is easily subjected to various kinds of diseases that spread throughout skin at a faster pace. Early detection and prevention are needed. Our research work aimed at detecting top 10 common skin diseases with higher accuracy. User can upload a pic in a mobile or cloud application and inbuilt AI algorithms will detect the type of skin disease with higher accuracy and thus offering prevention suggestions at an early stage without doctor intervention. © 2021, Springer Nature Singapore Pte Ltd.","10.1007/978-981-15-7234-0_78","Bagging; Boosting; Object detection; Random forest; VGG; XGBOOST; Yolo","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096410366&doi=10.1007%2f978-981-15-7234-0_78&partnerID=40&md5=e67bc9a105fb06e68ab9e696e4fb5d56"
"A comparative study among segmentation techniques for skin disease detection systems","Al Mamun M.; Uddin M.S.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Skin disorders are serious health problems for people. An automatic mobile-oriented skin disease detection system with offline or online is extremely essential for detecting skin diseases and serving patient treatment plans. For any image-based detection as well as recognition task, useful features are playing an important role. But the extraction of essential features is seriously dependent on the segmentation of disease-affected region, which ultimately hampers the detection accuracy sensitivity and specificity. In this paper, we have described a comparative study on various segmentation algorithms that are applied to extract the lesion part from the skin images for detecting diseases. Available methods are evaluated based on both qualitative and quantitative perspectives. Besides, we have pointed out some challenges of skin disease detection which need special attention of researchers, such as the availability of extensive datasets, well-defined efficient segmentation algorithms, and mobile-friendly computation environment. © 2021, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","10.1007/978-981-33-4673-4_14","Dermoscopy; Edge; Skin lesion segmentation; Texture; Wavelet","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098247889&doi=10.1007%2f978-981-33-4673-4_14&partnerID=40&md5=936a120cbc3f795818e707208fb1909d"
"Digital Diagnosis of Hand, Foot, and Mouth Disease Using Hybrid Deep Neural Networks","Verma S.; Razzaque M.A.; Sangtongdee U.; Arpnikanondt C.; Tassaneetrithep B.; Hossain A.","2021","0","1","0","0","0","First occurrence","0","","","","","","","Hand, Foot and Mouth Disease (HFMD) is a highly contagious paediatric disease showing up symptoms like fever, diarrhoea, oral ulcers and rashes on the hands and foot, and even in the mouth. This disease has become an epidemic with several outbreaks in many Asian-Pacific countries with the basic reproduction number $R_{0} > 1$. HFMD's diagnosis is very challenging as its lesion pattern may appear quite similar to other skin diseases such as herpangina, aseptic meningitis, and poliomyelitis. Therefore, clinical symptoms are essential besides skin lesion's pattern and position for precise diagnose of this disease. A deep learning-based HFMD detection system can play a significant role in the digital diagnosis of this disease. Various machine learning and deep learning architectures have been proposed for skin disease diagnosis and classification. However, these models are limited to the image classification problem. The diagnosis of similar appearing skin diseases using the image classification approach may result in misclassification or misdiagnosis of the disease. Parallel integration of clinical symptoms and images can improve disease diagnosis and classification performance. However, no deep learning architecture has been developed to diagnose HFMD disease from images and clinical data. This paper has proposed a novel Hybrid Deep Neural Networks integrating Multi-Layer Perceptron (MLP) network and Convolutional Neural Network into a single framework for the diagnosis of HFMD using the integrated features from clinical and image data. The proposed Hybrid Deep Neural Networks is particularly a multi branched model comprising of Multi-Layer Perceptron (MLP) network in the first branch to extract the clinical features and the modified pre-trained CNN architecture: MobileNet or NasNetMobile in the second branch to extract the features from skin disease lesion images. The features learnt from both the branches are merged to form an integrated feature from clinical data and images, which is fed to the subsequent classification network. We conducted several experiments employing image data only, clinical data only and both sources of data. The analyses compared and evaluated the performance of a typical MLP model and CNN model with our proposed Hybrid Deep Neural Networks. The novel approach promotes the existing image classification model and clinical symptoms based disease classification model, particularly the MLP model. From the cross-validated experiments, the results reveal that the proposed Hybrid Deep Neural Networks can diagnose the disease 99%-100% accurately. © 2013 IEEE.","10.1109/ACCESS.2021.3120199","CNN; convolution neural network; hand foot mouth and disease; HFMD; hybrid deep neural network; image classification; mobilenet; NasNetMobile; Thailand","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117840474&doi=10.1109%2fACCESS.2021.3120199&partnerID=40&md5=fff67e694292b13397ccee29ec5e8900"
"Skin Cancer Identification","Tejasree A.D.; Neeharika B.; Prince Mary S.","2021","1","1","0","0","0","Unique","0","","","","","","","One of the most well-known and enlarging medical issues on the planet is identified with skin. The most capricious and one of the most troublesome elements to naturally recognize and assess is the human skin infection considering complexities of surface, tone, nearness of hair, and other highlights. PC supported the conclusion of injuries in ultrasound images is essential to the anticipation of bosom disease. Numerous methodologies handle this issue through a few component extraction procedures. Be that as it may, most of them miss the mark regarding adaptability in the recovery organize, and their symptomatic exactness is, in this manner, limited. To defeat this downside, we propose a reasonable strategy for the analysis of influenced injuries. For an inquiry image region of interest (ROI) and Gabor, highlights are removed. Utilizing in this manner includes that would be painstakingly separated, the motivation behind this investigation could be essential to demonstrate and to exhibit the plausibility of looking over decisively the changing qualities of a skin malignant growth sore inside a thought about images’ arrangement. © 2021, Springer Nature Singapore Pte Ltd.","10.1007/978-981-15-7504-4_49","Artificial neural network; Diagnosis; Framework; Image processing; Skin disease","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101748211&doi=10.1007%2f978-981-15-7504-4_49&partnerID=40&md5=689aa884be2f499d14b52e3b72cefb10"
"Unsupervised Representation Learning Meets Pseudo-Label Supervised Self-Distillation: A New Approach to Rare Disease Classification","Sun J.; Wei D.; Ma K.; Wang L.; Zheng Y.","2021","0","1","0","0","0","Unique","0","","","","","","","Rare diseases are characterized by low prevalence and are often chronically debilitating or life-threatening. Imaging-based classification of rare diseases is challenging due to the severe shortage in training examples. Few-shot learning (FSL) methods tackle this challenge by extracting generalizable prior knowledge from a large base dataset of common diseases and normal controls, and transferring the knowledge to rare diseases. Yet, most existing methods require the base dataset to be labeled and do not make full use of the precious examples of the rare diseases. To this end, we propose in this work a novel hybrid approach to rare disease classification, featuring two key novelties targeted at the above drawbacks. First, we adopt the unsupervised representation learning (URL) based on self-supervising contrastive loss, whereby to eliminate the overhead in labeling the base dataset. Second, we integrate the URL with pseudo-label supervised classification for effective self-distillation of the knowledge about the rare diseases, composing a hybrid approach taking advantages of both unsupervised and (pseudo-) supervised learning on the base dataset. Experimental results on classification of rare skin lesions show that our hybrid approach substantially outperforms existing FSL methods (including those using fully supervised base dataset) for rare disease classification via effective integration of the URL and pseudo-label driven self-distillation, thus establishing a new state of the art. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-87240-3_50","Pseudo-label supervised self-distillation; Rare disease classification; Unsupervised representation learning","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116433713&doi=10.1007%2f978-3-030-87240-3_50&partnerID=40&md5=622286a993fdaaf072c72c310a079ccc"
"Medical and organizational approaches to early diagnosis of skin melanoma","Neretin E.Yu.; Kozlov S.V.; Zolotareva T.G.","2021","1","1","0","0","0","Unique","0","","","","","","","Introduction. The most significant problem is the early diagnosis of skin melanoma (SM). In many countries of the world, there is a constant increase in the incidence rate, and the organization of population screening can help solve this problem. Purpose of the study. Evaluation of the use of multi-agent technology in the diagnosis of SM. Material and methods. Study design: at the 1st stage, primary medical documentation was studied — Charts No. 090/y; 027-2/y, statistical reports of the Samara Regional Clinical Oncological Dispensary — Charts No. 7, No. 35, according to the results revealed at stage 2. There was developed and implemented multiagent technology for SM diagnostics, including various agents of both qualified and specialized levels, these were both individuals and teams of departments who worked in close contact: a public relations agent; artificial intelligence secondary prevention planning agent; agent for training doctors and nurses, patients in the basics of early diagnosis and assessing their level of training; an agent for evaluating performance indicators. Results. After introducing the multi-agent system, the indicator of the share of 1–2 stages of MC in 2010–2019. increased by 48.3% compared to the period 2000–2009 and outpaced the growth in the total number of patients with SM by 6.96%; from 2010 to 2019 the proportion of patients with SM who were actively identified began to increase; one-year mortality rate from 2010 to 2019 decreased in waves (y = 0.0003x5 – 0.0104x4 – 0.2647x3 + 1.4818x2 – 1.8942x + 10.585; R2 = 0.554). Conclusion. The use of multi-agent technology makes it possible to reduce the one-year mortality rate, to achieve a faster growth rate of the newly detected number of patients with an early stage of SM (stage 1–2) compared to the increase in the number of cases, to improve the indicators of early diagnosis, active detection of skin melanoma, which is a positive result. © AUTHORS, 2021.","10.47470/0044-197X-2021-65-6-557-564","Early diagnosis; Expert system; Multi-agent technology for the diagnosis; Skin melanoma; Skin melanoma database","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123791294&doi=10.47470%2f0044-197X-2021-65-6-557-564&partnerID=40&md5=5661890f970c3f47edea8422dd4b5909"
"International Conference on Computer Graphics, Visualization, Computer Vision and Image Processing 2021, CGVCVIP 2021, Connected Smart Cities 2021, CSC 2021 and Big Data Analytics, Data Mining and Computational Intelligence 2021, BIGDACI 2021 - Held at the 15th Multi-Conference on Computer Science and Information Systems, MCCSIS 2021","","2021","0","1","0","0","0","Unique","0","","","","","","","The proceedings contain 24 papers. The topics discussed include: using fast multidimensional projections to reveal band and circumplex patterns in reorderable matrices; a 3D spectral-spatial classification of hyperspectral remote sensing imagery using inception based network; 3D face reconstruction from hard blended edges; capsule neural networks in classification of skin lesions; a single RGB image based 3D object reconstruction system; face features-based personality assessment; analysis of capsule networks for image classification; analysis and visual exploration of prediction algorithms for public bicycle sharing systems; and hello, my name is smarttram, human factors is on board, enjoy the ride! developing a human factors program for automatic trams.","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117711021&partnerID=40&md5=baf8b45965f4a77648fa6acd7f2838ca"
"Semi-supervised Learning Regularized by Adversarial Perturbation and Diversity Maximization","Liu P.; Zheng G.","2021","0","1","0","0","0","Unique","0","","","","","","","In many clinical settings, a lot of medical image datasets suffer from the imbalance problem, which makes the predictions of the trained models to be biased toward majority classes. Semi-supervised Learning (SSL) algorithms trained with such imbalanced datasets become more problematic since pseudo-labels of unlabeled data are generated from the model’s biased predictions. Towards addressing this challenge, we propose a SSL framework which can effectively leverage unlabeled data for improving the performance of deep convolutional neural networks. It is a consistency-based method which exploits the unlabeled data by encouraging the prediction consistency of given input under adversarial perturbation and diversity maximization. We additionally propose to use uncertainty estimation to filter out low-quality consistency targets for the unlabeled data. We conduct comprehensive experiments to evaluate the performance of our method on two publicly available datasets, i.e., the ISIC 2018 challenge dataset for skin lesion classification and the ChestX-ray14 dataset for thorax disease classification. The experimental results demonstrated the efficacy of the present method. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-87589-3_21","Adversarial perturbation; Diversity maximization; Semi-supervised learning; Uncertainty estimation","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116508657&doi=10.1007%2f978-3-030-87589-3_21&partnerID=40&md5=e5d2ce1a31e9d21a6b645f26508ba374"
"10th International Workshop on Clinical Image-Based Procedures, CLIP 2021, 2nd MICCAI Workshop on Distributed and Collaborative Learning, DCL 2021, 1st MICCAI Workshop, LL-COVID19, 1st Secure and Privacy-Preserving Machine Learning for Medical Imaging Workshop and Tutorial, PPML 2021, held in conjunction with 24th International Conference on Medical Image Computing and Computer Assisted Intervention, MICCAI 2021","","2021","0","1","0","0","0","Unique","0","","","","","","","The proceedings contain 17 papers. The special focus in this conference is on Clinical Image-Based Procedures. The topics include: DCL preface; LL-COVID-19 preface; PPML preface; intestine Segmentation with Small Computational Cost for Diagnosis Assistance of Ileus and Intestinal Obstruction; multi-task Federated Learning for Heterogeneous Pancreas Segmentation; federated Learning in the Cloud for Analysis of Medical Images - Experience with Open Source Frameworks; on the Fairness of Swarm Learning in Skin Lesion Classification; Lessons Learned from the Development and Application of Medical Imaging-Based AI Technologies for Combating COVID-19: Why Discuss, What Next; The Role of Pleura and Adipose in Lung Ultrasound AI; DuCN: Dual-Children Network for Medical Diagnosis and Similar Case Recommendation Towards COVID-19; data Imputation and Reconstruction of Distributed Parkinson’s Disease Clinical Assessments: A Comparative Evaluation of Two Aggregation Algorithms; defending Medical Image Diagnostics Against Privacy Attacks Using Generative Methods: Application to Retinal Diagnostics; generation of Patient-Specific, Ligamentoskeletal, Finite Element Meshes for Scoliosis Correction Planning; Bayesian Graph Neural Networks for EEG-Based Emotion Recognition; ViTBIS: Vision Transformer for Biomedical Image Segmentation; Attention-Guided Pancreatic Duct Segmentation from Abdominal CT Volumes; development of the Next Generation Hand-Held Doppler with Waveform Phasicity Predictive Capabilities Using Deep Learning; learning from Mistakes: An Error-Driven Mechanism to Improve Segmentation Performance Based on Expert Feedback.","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120670667&partnerID=40&md5=d2d8d0fe0bacf848b549c7c0113ca065"
"Real-time diagnosis of multi-category skin diseases based on IR-VGG","Tan L.; Rong S.; Xia J.; Sajib S.; Ma W.","2021","1","1","0","0","0","Unique","0","","","","","","","Malignant skin lesions have a very high cure rate in the early stage. In recent years, dermatological diagnosis research based on deep learning has been continuously promoted, with high diagnostic accuracy. However, computational resource consumption is huge and it relies on large computing equipment in hospitals. In order to realize rapid and accu- rate diagnosis of skin diseases on Internet of things (IoT) mobile devices, a real-time diagnosis system of multiple catego- ries of skin diseases based on inverted residual visual geometry group (IR-VGG) was proposed. The contour detection algo- rithm was used to segment the lesion area of skin image. The convolutional block of the first layer of VGG16 was replaced with reverse residual block to reduce the network parameter weight and memory overhead. The original image and the seg- mented lesion image was inputed into IR-VGG network, and the dermatological diagnosis results after global and local fea- ture extraction were outputed. The experimental results show that the IR-VGG network structure can achieve 94.71% and 85.28% accuracy in Skindata-1 and Skindata-2 skin diseases data sets respectively, and can effectively reduce complexity, making it easier for the diagnostic system to make real-time skin diseases diagnosis on IoT mobile devices. © 2021, Beijing Xintong Media Co., Ltd.. All rights reserved.","10.11959/j.issn.2096-3750.2021.00217","Deep learning; Edge detection segmentation; Internet of things mobile devices; Inverted residual; Skin lesions","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130690737&doi=10.11959%2fj.issn.2096-3750.2021.00217&partnerID=40&md5=cbdb476ee5cbc5adb607c1b2b0751b1a"
"Optical coherence tomography-guided confocal Raman microspectroscopy for rapid measurements in tissues","Ren X.; Lin K.; Hsieh C.-M.; Liu L.; Ge X.; Liu Q.","2021","0","1","0","0","0","Unique","0","","","","","","","We report a joint system with both confocal Raman spectroscopy (CRS) and optical coherence tomography (OCT) modules capable of quickly addressing the region of interest in a tissue for targeted Raman measurements from OCT. By using an electrically tunable lens in the Raman module, the focus of the module can be adjusted to address any specific depth indicated in an OCT image in a few milliseconds. We demonstrate the performance of the joint system in the depth dependent measurements of an ex vivo swine tissue and in vivo human skin. This system can be useful in measuring samples embedded with small targets, for example, to identify tumors in skin in vivo and assessment of tumor margins, in which OCT can be used to perform initial real-time screening with high throughput based on morphological features to identify suspicious targets then CRS is guided to address the targets in real time and fully characterize their biochemical fingerprints for confirmation. © 2021 Optical Society of America under the terms of the OSA Open Access Publishing Agreement","10.1364/BOE.441058","","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122003960&doi=10.1364%2fBOE.441058&partnerID=40&md5=f260efa786303bd1d868dc87c9a8dc3e"
"HFMD Skin Rash Detection Using Convolutional Neural Networks","Vakili N.; Phattarakijtham N.; Chan J.H.; Krathu W.","2021","1","1","0","0","0","First occurrence","0","","","","","","","Skin rash problems are common and often temporary if they can be treated in time. Hand-Foot-Mouth disease (HFMD) is an extremely contagious viral infection common in infants, and can quickly develop into a severe problem. The infection can spread quickly through close contact with an infected person. HFMD usually involves the hands, feet and mouth, but sometimes can be detected elsewhere. To assist in diagnosing HFMD, we built a dataset of various skin conditions from readily available web sources. We propose the use of a deep convolutional neural networks (CNN) to distinguish HFMD rash from other skin conditions and normal skin. This study presents a promising application of CNN with a precision rate of 0.92%, 0.96%, and 0.88 for HFMD, non-HFMD, and normal skin, respectively. Our proposed model can facilitate a proper and early detection of HFMD rash to assist in containing HFMD outbreaks regionally. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-030-79757-7_16","Convolutional Neural Network; Deep Learning; Hand, Foot and Mouth Disease; HFMD; Multiclass Classification","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111448049&doi=10.1007%2f978-3-030-79757-7_16&partnerID=40&md5=602fef0f2f33e83ce666b6687b9d3069"
"Artificial intelligence in medical image processing : Progress and prospect; [人工智能在医学图像处理中的研究进展与展望]","Wu Y.; Zhang X.","2021","0","1","0","0","0","Unique","0","","","","","","","At present, our world has entered an aging society, with more and more people suffering from various diseases, hut the limited medical resources are difficult to meet the medical needs of today' s society.Artificial intelligence has been used in medical care in the early stage, including medical information consultation and electronic medical records, and in the later stage, it is applied into intelligent diagnosis of skin cancer and pulmonary nodule based on medical imaging and pathological data.Such researches and products concerning artificial intelligence have developed rapidly, and can save medical resources and reduce medical burden.This paper analyzes the research and application of artificial intelligence in medical image processing in recent years, in the aspects of intelligent segmentation, intelligent diagnosis and intelligent prognostic assessment.Moreover, this article discusses the research progress and prospects of medical artificial intelligence, and provides references for future research in order to accelerate the digitization of medical resources, save medical costs, and improve medical efficiency. Copyright © 2021,.","10.16016/j.1000-5404.202106194","artificial intelligence; intelligent diagnosis; intelligent prognostic assessment; medical image segmentation","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127321368&doi=10.16016%2fj.1000-5404.202106194&partnerID=40&md5=a2670e1bab6dcccbd7ebebc226d9a3b2"
"Measles Rash Identification Using Transfer Learning and Deep Convolutional Neural Networks","Glock K.; Napier C.; Gary T.; Gupta V.; Gigante J.; Schaffner W.; Wang Q.","2021","0","1","0","0","0","Unique","0","","","","","","","Measles is a highly contagious disease, one of the largest vaccine-preventable illnesses and leading causes of death in developing countries, claiming more than 140,000 lives each year. Measles was declared eliminated in the United States in the year 2000 due to decades of successful vaccination but it resurged in 2019 with 1,282 confirmed cases. Due to rapid spread of this disease among people in contact, rapid and automated diagnostic systems are required for early prevention. In this work, we employed transfer learning to build deep convolutional neural networks (CNNs) to distinguish measles rash from other skin conditions. Experiments with ResNet-50 model, trained on our diverse and curated skin rash image dataset, produce classification accuracy of 95.2%, sensitivity of 81.7%, and specificity of 97.1%, respectively. This indicates that our technique is effective in facilitating an accurate detection of measles to help contain outbreaks. The performance of a small CNN model MobileNet-V2 on our image data set is also discussed. Our work will facilitate healthcare professionals to effectively diagnose measles and accelerate the development of automated diagnostic tools to prevent the measles spread at various public venues. © 2021 IEEE.","10.1109/BigData52589.2021.9671333","CNN; Convolutional Neural Network; Deep Learning; Image Recognition; Measles; Measles rash; MobileNet; Residual Network; Transfer Learning","31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125340902&doi=10.1109%2fBigData52589.2021.9671333&partnerID=40&md5=ab9b10a1ffcf9c9c9c0d761189faf134"
"Data-Efficient Training of High-Resolution Images in Medical Domain","Pandit A.; Mahajan K.; Kunde S.; Sharma M.; Singhal R.; Vig L.","2021","0","1","0","0","0","Unique","0","","","","","","","The ability of Graphical Processor Units (GPUs) to quickly train data- and compute-intensive deep networks has led to rapid advancements across diverse domains such as robotics, medical imaging and autonomous driving. However, memory constraints with GPU-based training for memory-intensive deep networks have forced researchers to adopt various workarounds: 1) resize the input image, 2) divide input image into smaller patches, or use smaller batch-sizes in order to fit both the model and batch training data into GPU memory.While these alternatives perform well when dealing with natural images, they suffer from 1) loss of high-resolution information, 2) loss of global context and 3) sub-optimal batch sizes. Such issues will likely to become more pressing for domains like medical imaging, where data is scarce and images are often of very high resolution with subtle features. Therefore, in this paper, we demonstrate that training can be made more data-efficient by using a distributed training setup with high-resolution images and larger effective batch sizes, with batches being distributed across multiple nodes. The distributed GPU training framework, which partitions the data and only shares model parameters across different GPUs, gets around the memory constraints of single GPU training. We conduct a study in which experiments are performed for different image resolutions (ranging from 112 × 112 to 1024 × 1024) and different number of images per class to determine the effect of image resolutions on network performance. We illustrate our findings on two medical imaging datasets namely, SD-198 skin-lesion and NIH Chest X-rays. © 2021 ESANN Intelligence and Machine Learning. All rights reserved.","10.14428/esann/2021.ES2021-57","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129288037&doi=10.14428%2fesann%2f2021.ES2021-57&partnerID=40&md5=2b49d5800cae4339bc4542b0402ea041"
"Machine learning techniques for mitoses classification","Nofallah S.; Mehta S.; Mercan E.; Knezevich S.; May C.J.; Weaver D.; Witten D.; Elmore J.G.; Shapiro L.","2021","0","1","0","0","0","Unique","0","","","","","","","Background: Pathologists analyze biopsy material at both the cellular and structural level to determine diagnosis and cancer stage. Mitotic figures are surrogate biomarkers of cellular proliferation that can provide prognostic information; thus, their precise detection is an important factor for clinical care. Convolutional Neural Networks (CNNs) have shown remarkable performance on several recognition tasks. Utilizing CNNs for mitosis classification may aid pathologists to improve the detection accuracy. Methods: We studied two state-of-the-art CNN-based models, ESPNet and DenseNet, for mitosis classification on six whole slide images of skin biopsies and compared their quantitative performance in terms of sensitivity, specificity, and F-score. We used raw RGB images of mitosis and non-mitosis samples with their corresponding labels as training input. In order to compare with other work, we studied the performance of these classifiers and two other architectures, ResNet and ShuffleNet, on the publicly available MITOS breast biopsy dataset and compared the performance of all four in terms of precision, recall, and F-score (which are standard for this data set), architecture, training time and inference time. Results: The ESPNet and DenseNet results on our primary melanoma dataset had a sensitivity of 0.976 and 0.968, and a specificity of 0.987 and 0.995, respectively, with F-scores of.968 and.976, respectively. On the MITOS dataset, ESPNet and DenseNet showed a sensitivity of 0.866 and 0.916, and a specificity of 0.973 and 0.980, respectively. The MITOS results using DenseNet had a precision of 0.939, recall of 0.916, and F-score of 0.927. The best published result on MITOS (Saha et al. 2018) reported precision of 0.92, recall of 0.88, and F-score of 0.90. In our architecture comparisons on MITOS, we found that DenseNet beats the others in terms of F-Score (DenseNet 0.927, ESPNet 0.890, ResNet 0.865, ShuffleNet 0.847) and especially Recall (DenseNet 0.916, ESPNet 0.866, ResNet 0.807, ShuffleNet 0.753), while ResNet and ESPNet have much faster inference times (ResNet 6 s, ESPNet 8 s, DenseNet 31 s). ResNet is faster than ESPNet, but ESPNet has a higher F-Score and Recall than ResNet, making it a good compromise solution. Conclusion: We studied several state-of-the-art CNNs for detecting mitotic figures in whole slide biopsy images. We evaluated two CNNs on a melanoma cancer dataset and then compared four CNNs on a public breast cancer data set, using the same methodology on both. Our methodology and architecture for mitosis finding in both melanoma and breast cancer whole slide images has been thoroughly tested and is likely to be useful for finding mitoses in any whole slide biopsy images. © 2020 Elsevier Ltd","10.1016/j.compmedimag.2020.101832","Convolutional neural networks; Machine learning; Melanoma; Mitoses; Pathology","24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097453946&doi=10.1016%2fj.compmedimag.2020.101832&partnerID=40&md5=fa677c252bff3be428129299255301fd"
"Skin Disease Classification Using Machine Learning Techniques","Abir M.A.H.; Anik G.K.; Riam S.H.; Karim M.A.; Tareq A.H.; Rahman R.M.","2021","1","1","0","0","0","Unique","0","","","","","","","According to the Global Burden of Disease project, skin diseases are the fourth leading cause of benign sickness throughout the world. Diagnosis of dermatological diseases presents a challenge alongside the absence of trained dermatologists and access to formal medical care. This presents a critical challenge, especially in countries with a large rural population and minimal development. The aim of this paper is to study machine learning based classifiers for predicting skin infections for three classes from a clinical dataset. Convolutional neural network (CNN) has been proved to perform well in image classification. The performance of the neural network is compared with a benchmark multiclass SVM classifier. The result analysis and possible future works are also discussed in this paper. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-85030-2_49","CNN; Image classification; Neural network; SVM","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115198544&doi=10.1007%2f978-3-030-85030-2_49&partnerID=40&md5=1a8948808195143bacf924a32e5136c4"
"1st International Symposium on Geometry and Vision, ISGV 2021","","2021","0","1","0","0","0","Unique","0","","","","","","","The proceedings contain 29 papers. The special focus in this conference is on Geometry and Vision. The topics include: Coverless Video Steganography Based on Inter Frame Combination; character Photo Selection for Mobile Platform; close Euclidean Shortest Path Crossing an Ordered 3D Skew Segment Sequence; a Lane Line Detection Algorithm Based on Convolutional Neural Network; segment- and Arc-Based Vectorizations by Multi-scale/Irregular Tangential Covering; algorithms for Computing Topological Invariants in Digital Spaces; discrete Linear Geometry on Non-square Grid; electric Scooter and Its Rider Detection Framework Based on Deep Learning for Supporting Scooter-Related Injury Emergency Services; tracking Livestock Using a Fully Connected Network and Kalman Filter; traffic-Sign Recognition Using Deep Learning; a Comparison of Approaches for Synchronizing Events in Video Streams Using Audio; union-Retire: A New Paradigm for Single-Pass Connected Component Analysis; improving Object Detection in Real-World Traffic Scenes; comparison of Red versus Blue Laser Light for Accurate 3D Measurement of Highly Specular Surfaces in Ambient Lighting Conditions; fruit Detection from Digital Images Using CenterNet; a Graph-Regularized Non-local Hyperspectral Image Denoising Method; random Convolutional Network for Hyperspectral Image Classification; mamboNet: Adversarial Semantic Segmentation for Autonomous Driving; effective Pavement Crack Delineation Using a Cascaded Dilation Module and Fully Convolutional Networks; d-GaussianNet: Adaptive Distorted Gaussian Matched Filter with Convolutional Neural Network for Retinal Vessel Segmentation; tree Leaves Detection Based on Deep Learning; deep Learning in Medical Applications: Lesion Segmentation in Skin Cancer Images Using Modified and Improved Encoder-Decoder Architecture; apple Ripeness Identification Using Deep Learning; a Hand-Held Sensor System for Exploration and Thermal Mapping of Volcanic Fumarole Fields.","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104869502&partnerID=40&md5=b4389a1043f289f768d0eacb94ba0719"
"Recognition of Skin Diseases Using Curvelet Transforms and Law’s Texture Energy Measures","Chaki J.; Dey N.; Rajinikanth V.; Ashour A.S.; Shi F.","2021","1","1","0","0","0","First occurrence","0","","","","","","","This work presents an automated system to recognize human skin disease. In many computer vision and pattern recognition problems, such as our case, considering only a single descriptor to mine one sort of feature vector is not enough to attain the entire relevant information from the input data. Therefore, it is required to apply more than one descriptor to extract more than one feature vector categories with different dimensions. In this paper, for the purpose of skin disease classification, we propose a new hybrid method which is the combination of two methods to proficiently classify different types of feature vectors in their original form, dimensionality. The first one uses the Curvelet transform method in spatial and frequency viewpoint and the second one uses the set of energy measures to define textures had been formulated by Law’s texture energy measure. Minimum euclidean distance of the Law’s texure energy measures between different species are calculated for discrimination. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-52190-5_4","Curvelet; Law’s texture; Skin disease classification; Texture","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097994195&doi=10.1007%2f978-3-030-52190-5_4&partnerID=40&md5=08bdb4138e4789dc16996339113c1c87"
"Computer aided diagnosis of obesity based on thermal imaging using various convolutional neural networks","U S.; Palani Thanaraj K.; K S.","2021","0","1","0","0","0","Unique","0","","","","","","","Objectives: The study aims at the following: i) To construct a custom Deep Learning Network for classifying the thermal images of abdomen, forearm and shank regions into obese and normal cases ii) To compare the performance of the proposed CNN with some of the state-of-the-art pre-trained CNN and Machine Learning models in detection of obesity. Methods: Fifty healthy subjects along with fifty other age cum sex matched obese subjects were included in the study. The mean skin surface temperature was measured in abdomen, shank and forearm region for normal and obese subjects. After data augmentation, the images are fed to the proposed CNN and pre-trained networks for training, validation and classification of normal and obese thermograms. Results: Among the ROI studied, the abdomen region exhibited a high temperature difference of 4.703 % between the normal and obese compared to other regions. The proposed custom network-2 provided an overall accuracy of 92 %, area under the curve (AUC) value of 0.948 whereas the pre-trained model VGG16 net produced an accuracy of 79 % and AUC value of 0.90 for discrimination into obese and normal thermograms. Conclusions: Hence, the deep learning system based on custom CNN provided a reliable classification performance to identify the occurrence of obesity in test subjects. The experimental analysis showed that custom CNN network-2 provided a commendable degree of accuracy in classification of normal and obese subjects from the thermal images. Thus, the trained Custom-2 CNN model can be used for computer aided screening of test subjects for obesity detection. © 2020 Elsevier Ltd","10.1016/j.bspc.2020.102233","Computer aided diagnosis; Convolution neural network; Obesity; Thermal imaging","25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091760880&doi=10.1016%2fj.bspc.2020.102233&partnerID=40&md5=c7b86deef33025395809f6be22ad71a4"
"Automatic layer segmentation in H&E images of mice skin based on colour deconvolution and fuzzy C-mean clustering","Hussein S.","2021","1","1","0","0","0","Unique","0","","","","","","","Skin is by far the largest organ in the mammalian body. It has a complex structure of multiple layers consisting of various distinguishable cells and other features. Dermatology specialists have long associated many diseases with changes in different skin layers. However, manually quantifying and analysing large volumes of images is an error-prone, time-consuming and costly endeavour in terms of the resources and staff training required. This paper presents an automated high-throughput solution for segmenting mice skin layers from images into epidermis, dermis, and adipose layers and further segmenting the epidermis into cornified and basal layers. Such segmentation can be considered the first step in automatically quantifying cutaneous features in different skin layers. The proposed method combines a colour deconvolution method with fuzzy C-mean (FCM) clustering to segment skin layers. A dataset of 7,000 mice skin images was used to evaluate the effectiveness of the proposed method. The images were hematoxylin and eosin (H&E) microscopic images taken at 20X magnification by the Mouse Genetics Project. A segmentation accuracy rate of 96% was achieved using the hybrid solution, and accuracy rates of 80% and 92% were achieved using colour deconvolution and FCM, respectively. The experimental results were then examined by domain experts who confirmed the viability of the hybrid solution. © 2021","10.1016/j.imu.2021.100692","Colour deconvolution; Fuzzy cluster; Segmentation of H&E images","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112106077&doi=10.1016%2fj.imu.2021.100692&partnerID=40&md5=88b26064865f3a63a343b6d33541dcc1"
"Adam Optimized Pruning Method for Few-Shot Learning with GAN Data Augmentation","Shi Q.; Che H.; Chen J.; Wen Q.","2021","0","1","0","0","0","Unique","0","","","","","","","Weight pruning is widely used for model compression and acceleration. In this work, a novel Adam optimization method for few-shot learning with GAN data augmentation is proposed. The first-order Taylor series is implemented to evaluate parameters' importance toward the loss function. And with the given compression ratio, parameters with importance above the threshold are updated by the Adam optimizer with momentum-accelerated weight decay, while others have negative updates as the penalization. After continuous iterations, the model enables to achieve corresponding sparsity ratio, with the influence of the redundant parameters reducing to a low extent. Experiments demonstrate that this method is effective on ResNet with CUB and ISIC-2018 datasets. Note that CUB and ISIC-2018 are datasets about birds and skin deceases, respectively, which represents the generalization of our method on cross-domain classification issues. As a result, the pruned model is able to retain the accuracy with high model sparse ratios. And in some specific compress ratio, like 10× for CUB dataset and 3 × for ISIC-2018 dataset, the pruned model even outperforms the origin model by 3.15% and 1.16%, respectively.  © 2021 IEEE.","10.1109/ICCWAMTIP53232.2021.9674082","Adam optimization algorithm; Data augmentation; Few-shot learning; GAN; Image classification; Image fusion","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125992277&doi=10.1109%2fICCWAMTIP53232.2021.9674082&partnerID=40&md5=2a14f319a0ee3af424c377b44379b5b8"
"Mobile System for Personal Support to Psoriatic Patients","Moreira R.S.; Carvalho P.; Catarino R.; Lopes T.; Soares C.; Torres J.M.; Sobral P.; Teixeira A.; Almeida I.F.; Almeida V.","2021","0","1","0","0","0","Unique","0","","","","","","","Psoriasis is a chronic inflammatory skin disease with a high worldwide incidence that in worst cases reaches 4.6%. This dermatosis can be associated with other comorbidities and has a significant negative impact on labor productivity and the quality of life of affected people. During day-to-day lives, psoriasis patients come across several practical clinical difficulties, e.g. to i) easily register a time evolution of affected skin areas (for later analysis by health carers); ii) daily evaluate the size of each affected skin area, to be able to iii) calculate the amount of medication to be applied on those affected body areas. In such a context, this paper proposes the Follow-App mobile system aiming to support people with psoriasis, by alleviating and managing their daily life with the disease. More precisely, the goals of the system are: to allow individual photographic registration of body parts affected by psoriasis; in addition, cataloging each image according to its body segment location and sampling date; then, on those photos, automatically detect and segment the affected skin surface, to posteriorly be able to calculate the area of the lesions; finally, based on the area and prescribed medicine, dynamically accounting the amount of topical medicine to use. These were the requirements addressed by the proposed system prototype. The evaluation tests on the ability to detect and quantify the area of the skin lesions were performed on a data-set with 22 images. The proposed segmentation algorithm for detecting the area of redness lesions reached an IoU rate over 81%. Therefore, the proposed Follow-App mobile system may become an important asset for people with psoriasis since the extent and redness of affected areas are major evaluation factors for the disease severity. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-030-72660-7_46","Computer vision; Image processing; Psoriasis follow-app mobile system; Psoriasis lesion segmentation area and time evolution","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107324370&doi=10.1007%2f978-3-030-72660-7_46&partnerID=40&md5=d4e8674d61e5ad3a1afd4172ef90a7c7"
"Envisaging Variance Amid Indian Floras Owed To Contaminates Via SSIM Technique","Aggarwal S.; Bhatia M.; Pandey H.M.; Madaan R.","2021","0","1","0","0","0","Unique","0","","","","","","","Earth's atmosphere contains 20.9% of oxygen among all components (nitrogen, argon and other gases). But due to several factors, such as pollution, global warming, fuel burning, etc., the level of oxygen is degrading. Several researchers have reported that pollution is the main cause for degradation of oxygen levels. People are struggling with several health issues, like asthma, lung cancer and skin problems, like atopic dermatitis, eczema, psoriasis or acne, skin cancer, etc. Due to pollution plants are also getting affected in addition to human beings. Henceforth, numerous researches are in an improvement to overcome the existing challenges. In order to detect the changes in plants due to pollution the current research proposed a structural similarity index methodology (SSIM). All the samples (Ocimum tenuiflorum, Sansevieria trifasciata, Chlorophytum comosum, Azadirachta indica, aloe vera) were stipulated from the Indian species of plants that are rich in oxygen. The structural similarity index (SSIM) is calculated from the input sample images with the help of image processing by using MATLAB 2019a. Further, we have shown the effect on plants due to pollution by contrasting the structural similarity index (SSIM) value with the pollution index. This pollution index was measured from the air quality checker system situated near the target site at the time when the sample images were collected. Many analyses are done and the results were evaluated by plotting graph. This graph depicts that when structural similarity index value increases with respect to pollution index, the image quality of the sample decreases and vice versa. © 2021 - Kalpana Corporation","","Air quality index; Image processing; Oxygen; Plants; Pollution; Structural similarity index methodology","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125074366&partnerID=40&md5=c910b4586d793c5779be93156e96747f"
"Deep learning approach to subepidermal low echogenic band segmentation in high frequency ultrasound","Czajkowska J.; Dziurowicz W.; Badura P.; Korzekwa S.","2021","0","1","0","0","0","Unique","0","","","","","","","Atopic dermatitis is a chronic, pruritic, inflammatory cutaneous disease, which mainly occurrs in children and has a tendency to regress during childhood. The accurate therapy requires an objective method to examine the skin condition. However, there is a lack of standardization of diagnostic criteria using high-resolution, non-invasive methods. Therefore, we are faced with a need for accurate assessment and monitoring of treatment results. The newest clinical research mention the benefit of using high frequency ultrasound in skin condition analysis. With the use of high frequency ultrasound it is possible to segment and then measure the hypoechoic band below the echo entry (subepidermal low echogenic band), characteristic for atopic dermatitis. In this study we developed a two-step methodology consisting of the region of interest detection and segmentation based on convolutional neural network with a U-net architecture. The accuracy of the proposed framework was verified using 47 clinical images annotated by an expert, yielding mean Dice index value of 0.86±0.04 and mean error of the hypoechoic band thickness estimation at 12.0±9.3 μm. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2021.","10.1007/978-3-030-49666-1_1","Atopic dermatitis; Deep learning; High frequency ultrasound; SLEB segmentation","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090999799&doi=10.1007%2f978-3-030-49666-1_1&partnerID=40&md5=0b0f690c462441bd738e22d9180bacbc"
"Generating digital images of skin diseases based on deep learning","Ahmed H.M.; Kashmola M.Y.","2021","1","1","0","0","0","Unique","0","","","","","","","Data generation systems and architectures seek to create new and valuable data with specific sizes and characteristics which are similar to the original data that fit the mechanism of the application used. GANs (generative adversarial network architectures) are a type of generative modeling that uses deep learning methods like convolutional neural networks to generate data, particularly digital images which are used in scientific applications. The goal of this paper is to design and build three architectures of Generative adversarial network (based on convolutional neural networks) to generate three types of digital images of skin diseases by defining two supervised models, the generator model that is trained to generate new digital images and the discrimination model that classifies digital images as real or fake from the field. An intelligent architecture for training the generative model was created, where the two models are trained together in a zero-sum field. Each digital image that was generated differs in its accuracy, size, and dimensions. After applying all the architectures, obtaining and comparing digital images, it turns out that the fewer dimensions of the resulting digital images, the faster the generation processes and the lower the memory costs, but their accuracy is low. The importance of building architecture lies in increasing the images of skin diseases to be used in the data set to perform classification operations for these diseases, as digital images were generated in different sizes, which are 64×64, 128×128, and 512×512, and the new images were obtained with accuracy commensurate with the requirements of this paper. The generated digital images with dimensions 128×128 gave the best results in the accuracy of the resulted images. At the same time, they do not consume much memory, which leads to their processing speed.  © 2021 IEEE.","10.1109/ICCITM53167.2021.9677769","Convolutional Neural Network; Deep Learning; Digital Images; Generative adversarial networks; Skin Diseases","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125414408&doi=10.1109%2fICCITM53167.2021.9677769&partnerID=40&md5=7e2d01af7b9608cecca91ebb44189ced"
"Multi-modal Sensor and Data Processing for Comprehensive Skin Evaluation","Wang S.; Xi N.","2021","1","1","0","0","0","Unique","0","","","","","","","This paper presents a novel skin testing device, called the skin sensor, which can realize multi-modal sensing of optical and mechanical skin properties. The sensor structure and operating cycle are described in detail. Based on the calibration result and physical model of the skin sensor, the algorithms to extract optical and mechanical skin properties from skin sensor data are established, which are simple, efficient, and moreover, self-decoupling for different sensing modes. Experiments are conducted with testee to verify the comprehensive skin evaluation ability of the skin sensor, which shows positive results. This skin sensor has great potential in cosmetic usage due to its portability and strong skin state monitoring ability. © 2021 IEEE.","10.1109/SENSORS47087.2021.9639790","calibration; FTIR; mechanical properties; optical properties; skin sensor","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123585360&doi=10.1109%2fSENSORS47087.2021.9639790&partnerID=40&md5=21c97819c7164fd08126ecfb8d202b42"
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              