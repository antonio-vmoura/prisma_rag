"Document Title","Authors","Publication Year","Title: Skin","Abstract: Skin","First Removal","Abstract: Traditional ML","Second Removal","Duplication Status","Third Removal","Accepted or not","Proposed Model","Tasks (Objectives)","Used Databases"," Proposed Methodology"," Evaluation Metrics and Results","Abstract","DOI","Author Keywords","Article Citation Count","PDF Link"
"Super-Resolution of Medical Images Using Real ESRGAN","Nandal P.; Pahal S.; Khanna A.; Rogerio Pinheiro P.","2024","0","1","0","0","0","First occurrence","0","","","","","","","Rich details in an image are constantly vital for medical image analysis to detect a broad extent of medical ailments. The diagnosis will be best served if the image is accessible in high resolution and the small details are preserved. Image super-resolution techniques based on deep learning can assist us in extracting spatial features from a low-resolution image captured with current technologies. The updated variant of the super-resolution technique known as Real Enhanced Super-Resolution Generative Adversarial Networks (Real-ESRGAN), which produces 2D real-world images with excellent perceptual quality, is used in the present work. We investigate the suggested approach using four distinct medical image types: 1) brain MRI images from the BraTS dataset; 2) dermoscopy images from the ISIC skin cancer dataset; 3) cardiac ultrasound images from the CAMUS dataset; and 4) chest x-rays images from the MIMIC-CXR dataset. The employed architecture achieves improved visual results in comparison to the alternative innovative techniques for super-resolution. The observed findings are evaluated and contrasted both qualitatively and quantitatively with conventional approaches in terms of PSNR, SSIM, and MSE, and an improvement of up to 12% is obtained. © 2013 IEEE.","10.1109/ACCESS.2024.3497002","Deep learning; generative adversarial network; medical image enhancement; Real-ESRGAN","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209664749&doi=10.1109%2fACCESS.2024.3497002&partnerID=40&md5=d79764a5f556d7e59aa897709e7e3d4a"
"Dual residual learning of frequency fingerprints in detecting synthesized biomedical imagery","Sharafudeen M.; S.S. V.C.","2025","0","1","0","0","0","Unique","0","","","","","","","Artificial synthesis of biomedical imagery is an evolving threat yet under-addressed. The integrity of medical imaging is important for accurate diagnosis and treatment. This study addresses the potential threat of fabricated biomedical imagery, focusing on synthetic dermatological lesions and CT nodules. The Representation Similarity Matrix measured the quantitative authenticity to account for similarities of synthesized data with authentic data. The study explores traces of manipulation from frequency signatures of synthesized imagery. We propose a novel combinatorial architecture, the Dual Residual Network (DRN), capturing hidden residual traces from low-frequency fingerprints of synthetic data and exposing hidden forgeries. DRN achieves near-perfect detection rates with an accuracy of 98.80% for CT nodules and 98.97% for lesions. Equal Error Rates of the model on the two datasets exhibited a marginal improvement of 57.87% in the CT nodules compared to the skin lesions. Sensitivity and specificity play a significant role in medical diagnostics. The model achieved sensitivities of 99.31% and 98.45% and specificity of 98.80% and 99.60% for each dataset, respectively. Further verification of the frequency traces was performed by analyzing gradients in the target concepts that led to decision-making. This study equips the medical field with a powerful tool to combat the evolving threat of synthetic fraud, safeguarding patient and client safety. The potential of the technique extends beyond healthcare, offering a blueprint for tackling synthetic data across diverse domains. © 2025 Elsevier B.V.","10.1016/j.asoc.2025.112930","Biomedical imaging; Frequency fingerprinting; Gradient mapping; Residual Networks; Synthesized imagery","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219528261&doi=10.1016%2fj.asoc.2025.112930&partnerID=40&md5=705ca61d90f4754f76b579fa5bbd8561"
"Segmentation and Classification of Skin Cancer Diseases Based on Deep Learning: Challenges and Future Directions","Khalaf A.D.; Hamdan H.; Abdul Halin A.; Manshor N.","2025","1","1","0","0","0","First occurrence","0","","","","","","","Deep Learning (DL) techniques have significantly improved the diagnostic accuracy in healthcare, particularly for detecting and classifying skin cancer. Such technological advancements will assist healthcare professionals in delivering more accurate, efficient, and timely diagnoses, ultimately improving patient outcomes and facilitating early detection and treatment. Medical imaging technologies such as magnetic resonance imaging (MRI) and computed tomography (CT) are critical for diagnosing dermatological conditions. However, interpreting these images can be challenging due to overlapping structures and varying image quality. This study explores the application of DL in skin cancer diagnosis, focusing on advances in image segmentation and classification. DL-based models are reviewed specifically by convolutional neural networks (CNNs), and evaluations on their effectiveness for skin lesion detection are provided. This study also examines the critical challenges of deploying DL models in clinical practice, covering issues including dataset diversity, model interpretability, and real-world implementation feasibility. It further explores the selection of network architectures and data preprocessing techniques, emphasizing their influence on model performance. In summary, this study identifies research gaps and suggests future directions for enhancing DL models for dermatological applications.  © 2013 IEEE.","10.1109/ACCESS.2025.3569170","Augmentation; classification; convolutional neural networks; deep learning; detection; segmentation; skin cancer; understandable artificial intelligence","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005363551&doi=10.1109%2fACCESS.2025.3569170&partnerID=40&md5=17ff7a53dec5a1cd6eddcb12759c5436"
"Ensemble Fusion: Skin Cancer Detection using ResNet, EfficientNet, and VGG Architectures","S. Thakur; S. Sharma","2024","1","1","0","0","0","Unique","0","Accepted","Ensemble model (ResNet, EfficientNet, VGG16)","classify skin lesions as malignant or benign with high accuracy.","HAM10000","Rigorous preprocessing was applied to images, followed by training an ensemble model that combines ResNet, EfficientNet, and VGG16 architectures.","Accuracy: 99.1% on the test dataset.","Skin cancer detection is crucial for timely intervention and improved patient outcomes. This study addresses the challenge of early detection accuracy through the utilization of advanced machine learning techniques. Leveraging the HAM1000 dataset, comprising high-resolution dermatoscopic images, rigorous preprocessing techniques were applied to enhance image quality and feature extraction. Our methodology involved training an ensemble model incorporating state-of-the-art architectures such as ResNet, EfficientNet, and VGG16. This ensemble approach harnesses the diverse capabilities of these models, leveraging their strengths in feature representation and learning.Experimental results demonstrate outstanding performance, with the ensemble model achieving a remarkable accuracy of $99.1\%$ on test dataset in classifying skin lesions as malignant or benign. This achievement under-scores the effectiveness of ensemble modeling in skin cancer detection, particularly when integrating powerful architectures like ResNet, EfficientNet, and VGG16.Furthermore, our study highlights the importance of robust preprocessing techniques in optimizing model performance and ensuring reliable diagnostic outcomes. The findings of this research have significant implications for clinical practice, offering a promising avenue for improving early detection rates and ultimately enhancing patient outcomes.Future research endeavors may explore the integration of additional datasets and validation on diverse populations to further validate the efficacy and generalizability of the proposed ensemble approach.","10.1109/ICCCNT61001.2024.10726235","Skin cancer detection;Machine learning;Ensemble modeling;HAM1000 dataset;Preprocessing techniques;Diagnostic accuracy;ResNet50;EfficientNet;VGG16","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10726235"
"GAN-Alz: Synthetic Data Generation for Multiclass Alzheimer’s Classification","R. R. Nair; T. Babu; G. Ramasamy; T. Singh; X. Yuan","2024","0","1","0","0","0","Unique","0","","","","","","","Accurate detection of skin cancer, particularly melanoma, is crucial for effective treatment and patient survival. This study explores the use of Convolutional Neural Networks (CNNs) enhanced by Generative Adversarial Networks (GANs) for skin cancer detection. CNNs have shown remarkable performance in image classification tasks but often require extensive labeled datasets, which are scarce in medical domains. To address this, GANs are employed to generate synthetic skin lesion images, augmenting the dataset and improving the model’s generalization capability. The proposed approach integrates a pre-trained CNN architecture fine-tuned with a combination of real and GANgenerated images, enhancing the network’s ability to distinguish between benign and malignant lesions. Experimental results demonstrate that the inclusion of GAN-augmented data improves the model’s accuracy by $7 \%$, achieving an overall accuracy of $94 \%$, with precision and recall rates of $92 \%$ and $93 \%$, respectively. These findings suggest that the GAN-augmented CNN model offers a promising solution for automated skin cancer screening","10.1109/SPARC61891.2024.10828935","Generative Adversarial Network(GAN);Over Sampling;Vgg16;Efficient Net;Resnet;Inception Net","1","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10828935"
"Computing rational border curves of melanoma and other skin lesions from medical images with bat algorithm","G\'alvez, Akemi and Fister, Iztok and Osaba, Eneko and Fister, Iztok and Ser, Javier Del and Iglesias, Andr\'es","2019","1","1","0","0","0","Unique","0","","","","","","","Border detection of melanoma and other skin lesions from images is an important step in the medical image processing pipeline. Although this task is typically carried out manually by the dermatologists, some recent papers have applied evolutionary computation techniques to automate this process. However, these works are only focused on the polynomial case, ignoring the more powerful (but also more difficult) case of rational curves. In this paper, we address this problem with rational B\'ezier curves by applying the bat algorithm, a popular bio-inspired swarm intelligence technique for optimization. Experimental results on two examples of medical images of melanomas show that this method is promising, as it outperforms the polynomial approach and can be applied to medical images without further pre/post-processing.","10.1145/3319619.3326873","","","https://doi.org/10.1145/3319619.3326873"
"On Image Prefiltering for Skin Lesion Characterization Utilizing Deep Transfer Learning","Delibasis, K.; Georgakopoulos, S. V.; Tasoulis, S. K.; Maglogiannis, I.; Plagianakos, V. P.","2020","1","1","0","0","0","Unique","0","","","","","","","Skin cancer is one of the most diagnosed cancers according to the World Health Organization and one of the most malignant. Unfortunately, still the available annotated data are in most cases not enough to successfully train deep learning algorithms that would allow highly accurate predictions. In this paper, we propose the utilization of transfer learning to fine-tune the parameters at the very last layers of a pre-trained a deep learning neural network. We expect that a limited number of skin lesion images is enough to affect significantly the later data-specific layers. Furthermore, we propose a pre-process step for skin lesion images that segments and crops the lesion, whereas smooths the effect of image masking, thus enhancing the network’s classification capabilities. The reported results are very promising, since the overall accuracy, as well as the accuracy of individual class classification improved in 7 out of the 8 classes, suggesting future developments in medical diagnosis through pre-trained deep learning models and specialized image prefiltering.","10.1007/978-3-030-48791-1_29","Convolutional Neural Networks (CNN); Skin Lesion Classification; Cancer detection; Image pre-processing","","http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-030-48791-1_29"
