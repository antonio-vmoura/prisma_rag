"Document Title","Authors","Publication Year","Title: Skin","Abstract: Skin","First Removal","Abstract: Traditional ML","Second Removal","Duplication Status","Third Removal","Accepted or not","Proposed Model","Tasks (Objectives)","Used Databases"," Proposed Methodology"," Evaluation Metrics and Results","Abstract","DOI","Author Keywords","Article Citation Count","PDF Link"
"Melanoma lesion detection and segmentation using deep region based convolutional neural network and fuzzy C-means clustering","Nida N.; Irtaza A.; Javed A.; Yousaf M.H.; Mahmood M.T.","2019","0","1","0","0","0","Unique","0","","","","","","","Objective: Melanoma is a dangerous form of the skin cancer responsible for thousands of deaths every year. Early detection of melanoma is possible through visual inspection of pigmented lesions over the skin, treated with simple excision of the cancerous cells. However, due to the limited availability of dermatologists, the visual inspection alone has the limited and variable accuracy that leads the patient to undergo a series of biopsies and complicates the treatment. In this work, a deep learning method is proposed for automated Melanoma region segmentation using dermoscopic images to overcome the challenges of automated Melanoma region segmentation within dermoscopic images. Materials and methods: A deep region based convolutional neural network (RCNN) precisely detects the multiple affected regions in the form of bounding boxes that simplify localization through Fuzzy C-mean (FCM) clustering. Our method constitutes of three step process: skin refinement, localization of Melanoma region, and finally segmentation of Melanoma. We applied the proposed method on benchmark dataset ISIC-2016 by International Symposium on biomedical images (ISBI) having 900 training and 376 testing Melanoma dermatological images. Main findings: The performance is evaluated for Melanoma segmentation using various quantitative measures. Our method achieved average values of pixel level specificity (SP) as 0.9417, pixel level sensitivity (SE) as 0.9781, F1 _ s core as 0.9589, pixel level accuracy (Ac) as 0.948. In addition, average dice score (Di) of segmentation was recorded as 0.94, which represents good segmentation performance. Moreover, Jaccard coefficient (Jc) averaged value on entire testing images was 0.93. Comparative analysis with the state of art methods and the results have demonstrated the superiority of the proposed method. Conclusion: In contrast with state of the art systems, the RCNN is capable to compute deep features with amen representation of Melanoma, and hence improves the segmentation performance. The RCNN can detect features for multiple skin diseases of the same patient as well as various diseases of different patients with efficient training mechanism. Series of experiments towards Melanoma detection and segmentation validates the effectiveness of our method. © 2019 Elsevier B.V.","10.1016/j.ijmedinf.2019.01.005","CAD tool; Fuzzy C-Means; Melanoma segmentation; RCNN; Region proposal","182","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060342436&doi=10.1016%2fj.ijmedinf.2019.01.005&partnerID=40&md5=c9b53545517b14eee55108dfd539fc98"
"Automatic skin lesion segmentation by coupling deep fully convolutional networks and shallow network with textons","Zhang L.; Yang G.; Ye X.","2019","1","1","0","0","0","Unique","0","","","","","","","Segmentation of skin lesions is an important step in computer-aided diagnosis of melanoma; it is also a very challenging task due to fuzzy lesion boundaries and heterogeneous lesion textures. We present a fully automatic method for skin lesion segmentation based on deep fully convolutional networks (FCNs). We investigate a shallow encoding network to model clinically valuable prior knowledge, in which spatial filters simulating simple cell receptive fields function in the primary visual cortex (V1) is considered. An effective fusing strategy using skip connections and convolution operators is then leveraged to couple prior knowledge encoded via shallow network with hierarchical data-driven features learned from the FCNs for detailed segmentation of the skin lesions. To our best knowledge, this is the first time the domain-specific hand craft features have been built into a deep network trained in an end-to-end manner for skin lesion segmentation. The method has been evaluated on both ISBI 2016 and ISBI 2017 skin lesion challenge datasets. We provide comparative evidence to demonstrate that our newly designed network can gain accuracy for lesion segmentation by coupling the prior knowledge encoded by the shallow network with the deep FCNs. Our method is robust without the need for data augmentation or comprehensive parameter tuning, and the experimental results show great promise of the method with effective model generalization compared to other state-of-the-art-methods. © 2019 Society of Photo-Optical Instrumentation Engineers (SPIE).","10.1117/1.JMI.6.2.024001","fully convolutional networks; melanoma; skin lesion segmentation; textons","49","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065472375&doi=10.1117%2f1.JMI.6.2.024001&partnerID=40&md5=19dc9d79de4eb6cc60d01042cee42bd5"
