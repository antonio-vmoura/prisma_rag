Document Title,Authors,Publication Year,Title: Skin,Abstract: Skin,First Removal,Abstract: Traditional ML,Second Removal,Duplication Status,Third Removal,Accepted or not,Proposed Model,Tasks (Objectives),Used Databases, Proposed Methodology, Evaluation Metrics and Results,Abstract,DOI,Author Keywords,Article Citation Count,PDF Link
Skin lesion detection using adaptive regularized kernel based fuzzy algorithm,Tamije Selvy P.; Shabarish N.; Anitha M.,2019,1,1,0,0,0,Unique,0,,,,,,,"Skin cancer is found to be the worst type of cancer which is generally difficult to predict in early stages. In recent days, it has been proved that Computer Aided Diagnosis (CAD) System provides best result in automatic diagnosis of lesions in skin. The purpose of this research paper is early and automatic diagnosis of lesions in skin. Preprocessing, Segmentation by Adaptive Regularized Kernel Based Fuzzy and feature extraction is done in order to achieve a rapid and reliable diagnosis. This proposed work is implemented on 232 images obtained from International Skin Imaging Collaboration (ISIC) archive. © IJSTR 2019.",,Adaptive Regularized Kernel Based Fuzzy; Computer Aided Diagnosis; Melanoma; Region of Interest; Skin Cancer,0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077341582&partnerID=40&md5=f5192b42cef65464ec50527c9c1ed4c9
Depthwise Separable Convolutional Neural Network for Skin Lesion Classification,Kassani S.H.; Kassani P.H.; Wesolowski M.J.; Schneider K.A.; Deters R.,2019,1,1,0,0,0,Unique,0,,,,,,,"Melanoma is one of the deadliest skin cancers. Early diagnosis plays an essential role in effective treatment planning and reducing the mortality rate of skin cancer. In this study, we propose a compact deep learning-based classification model with a separable convolutional neural network for melanoma detection. The proposed architecture is aimed to minimize the need for task-specific data pre-processing methods such as noise reduction, artifact removal, and low contrast adjustment to support a better generalization ability for unseen / test data. We validated the performance of the proposed method on the ISIC 2018 dataset. Our results show that the proposed architecture achieves comparable accuracy to the widely-used architectures presented in the literature while being more compact and simpler. The proposed methodology achieves 87.24% accuracy, 95.94% sensitivity and 98.47% specificity. © 2019 IEEE.",10.1109/ISSPIT47144.2019.9001790,Deep learning; Medical imaging; Melanoma detection; Separable convolution; Skin cancer classification,12,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081285729&doi=10.1109%2fISSPIT47144.2019.9001790&partnerID=40&md5=ae9b3d6763ec96b4e515c5dbc98d19e3
Dense pooling layers in fully convolutional network for skin lesion segmentation,Nasr-Esfahani E.; Rafiei S.; Jafari M.H.; Karimi N.; Wrobel J.S.; Samavi S.; Reza Soroushmehr S.M.,2019,1,1,0,0,0,Unique,0,,,,,,,"One of the essential tasks in medical image analysis is segmentation and accurate detection of borders. Lesion segmentation in skin images is an essential step in the computerized detection of skin cancer. However, many of the state-of-the-art segmentation methods have deficiencies in their border detection phase. In this paper, a new class of fully convolutional network is proposed, with new dense pooling layers for segmentation of lesion regions in skin images. This network leads to highly accurate segmentation of lesions on skin lesion datasets, which outperforms state-of-the-art algorithms in the skin lesion segmentation. © 2019 Elsevier Ltd",10.1016/j.compmedimag.2019.101658,Deep neural networks; Dense pooling layer; Melanoma; Skin cancer,63,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073561277&doi=10.1016%2fj.compmedimag.2019.101658&partnerID=40&md5=f0084ca9c7188de5d736611256b84048
Enhanced Skin Lesions Classification Using Deep Convolutional Networks,Mohamed E.H.; El-Behaidy W.H.,2019,1,1,0,0,0,Unique,0,,,,,,,"The recent development of machine learning and deep learning techniques for medical image analysis has led to the development of intelligent diagnosis systems that can help doctors make a better diagnosis to the patients' diseases. In particular, skin diagnostics is a field where these new techniques can be applied with a high rate of accuracy. This study aims to enhance the accuracy of skin lesions classification based on two factors. The first is deeply trained all layers of implemented pre-trained models. Whereas, the second is balancing the number of images within the seven classes of dataset used. The state-of-the-art convolutional neural networks MobileNet and DenseNet-121 were trained on HAM10000 dataset. The two models pass through three phases; preprocessing, training and evaluation. Firstly, the dataset is down sampled, splitted and augmented to resolve misbalancing problem. Then, both models are deeply trained and finally they are evaluated against baseline models without balancing the classes. Multiple metrics were used to evaluate our models; precision, recall, F1-score, specificity and ROC AUC. In addition, the micro-average and macro-average of all previous metrics to extend to multi-classification. The accuracy of MobileNet and DenseNet-121 reach 82.6% and 71.9% on unseen testing images, respectively on the original dataset (i.e. before balancing the dataset). Whereas, they reach 92.7% and 91.2% on unseen testing images, respectively after balancing the dataset. This enhancement proves the necessity of existence of balanced dataset for training, to have better performance. Furthermore, MobileNet after balancing dataset has out performed the highest accuracy of ISIC 2018 challenge on the same dataset by 4.2%. For that, this model is the recommended one as it is a light-weight model, suitable for mobile applications used by dermatologists and its accuracy is comparably equal to DenseNet121. © 2019 IEEE.",10.1109/ICICIS46948.2019.9014823,Convolution neural networks; Deep learning; MobileNet; multi-class classification; skin cancer; skin lesions,49,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083367637&doi=10.1109%2fICICIS46948.2019.9014823&partnerID=40&md5=ba19c224cbcd4941a3291f02ef6dd866
Automated Machine Learning for Short-term Electric Load Forecasting,Wang C.; Back T.; Hoos H.H.; Baratchi M.; Limmer S.; Olhofer M.,2019,0,1,0,0,0,Unique,0,,,,,,,"From detecting skin cancer to translating languages and to forecasting electricity consumption, machine learning is enabling advanced capabilities of computer systems across a broad range of important real-world applications. In this work, we present machine learning models for forecasting the consumption of electricity. Short-term electric load forecasting has been a fundamental concern in power operation systems for over a century. Energy load forecasting is of even greater importance, due to applications in the planning of demand side management, smart electric vehicles and other smart grid technologies. We use two state-of-the-art automated machine learning systems (auto-sklearn and TPOT), which automate model selection and hyperparameter optimization, to achieve maximum prediction accuracy, and compare their performance for the task of load prediction using two benchmark problems. These benchmarks are derived from real world load consumption tasks, namely household consumption from the UCI data repository and consumption data from an industrial office building. Our experimental results indicate great potential for improving the accuracy of energy consumption prediction by using automated machine learning approaches. © 2019 IEEE.",10.1109/SSCI44817.2019.9002839,automated machine learning; energy management; machine learning; short-term load forecasting,26,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080962832&doi=10.1109%2fSSCI44817.2019.9002839&partnerID=40&md5=7e88db27885c60e3939d2c4b8e722e44
Generalized lesion detector based on convolutional neural network,Wu H.; Deng J.-Z.,2019,0,1,0,0,0,Unique,0,,,,,,,"In current computer-aided diagnostic systems, existing detection functions are usually only for a specific type of lesion, such as skin lesions, pulmonary nodule lesions and liver lesions. However, in actual clinical diagnosis, many lesions are actually related. For example, pulmonary nodular lesions may metastasize and spread to lymph node areas or other body parts. The detection of a single site is not conducive to the doctor's comprehensive diagnosis of the condition. Multi-site lesion detection can detect lesion metastasis and treat it earlier, and can also explore the relationship between different lesions. In response to this situation, this thesis uses the Deeplesion dataset to establish a general lesion detection framework that can detect possible lesions through CT images of different parts of the body. Compared with the existing single-path computer-aided diagnosis system, this thesis studies and implements a general lesion detection system to explore the relationship between different lesions. This will help doctors to make a comprehensive clinical diagnosis and visualize the results. This thesis based on the Faster R-CNN network model. First it denoises and enhances the CT images. Then, the VGG16 network is used for feature extraction, and the feature map is obtained through the RPN network to obtain candidate suggestion regions. In view of the misdetection of missed detection, this thesis introduces a Gaussian weighted penalty function to improve the non-maximum suppression. Finally, Tkinter is used to create a GUI visualization interface for doctors to compare clinical diagnosis. © 2019 ACM.",10.1145/3377713.3377746,CT image; Faster R-CNN; Non-maximum suppression; RPN; Tkinter,0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081051436&doi=10.1145%2f3377713.3377746&partnerID=40&md5=a9eb28fe76ead7fd0419df3226f81b5d
Multi-Pooling Attention Learning for Melanoma Recognition,Liang R.; Wu Q.; Yang X.,2019,0,1,0,0,0,Unique,0,,,,,,,"Melanoma is a type of skin cancer with high mortality rate. Early diagnosis of malignant melanoma usually relies on the judgement of dermatologists. Recently, more and more research paid attention to classify skin lesion automatically by dermoscopy images, which is able to assist clinicians to diagnose quickly and accurately. However, there still remain some challenges on extraction of discriminative feature due to the inter-class similarity and intra-class variation. In this paper, we propose a novel multi-pooling attention learning for skin lesions classification, which consists of multiple types of pooling operations, attention mechanism and feature fusion. The multi-pooling layer with flexible pooling patterns is designed to capture more representative features. The attention mechanism has the ability to help our model focus on the lesion regions. Meanwhile, in order to deal with the issues of inter-class similarity and intra-class variation of skin lesions, we adopt a joint loss function to optimize the final results. Our proposed approach has been validated on ISIC2017 dataset that provided by IEEE International Symposium on Biomedical Imaging (ISBI) 2017 challenge for Skin Lesion Analysis Towards Melanoma Detection. The results show that our proposed network achieves superior performance over six top-ranking approaches in ISBI 2017 challenge leaderboard and five other methods. © 2019 IEEE.",10.1109/DICTA47822.2019.8945868,Convolutional neural network; Melanoma recognition; Multi-pooling attention learning,4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078699617&doi=10.1109%2fDICTA47822.2019.8945868&partnerID=40&md5=dee509a848e515898db04fef0fbf1bb4
Melanoma Skin Cancer Detection Based on ABCD Rule,Lattoofi N.F.; Al-Sharuee I.F.; Kamil M.Y.; Obaid A.H.; Mahidi A.A.; Omar A.A.; Saleh A.K.,2019,1,1,0,0,0,Unique,0,,,,,,,"Skin cancer is the most common cancers in the last years, especially in the human body; the Melanoma is the most destructive type of skin lesions. Detect cancer is important at the initial stage, but only an expert dermatologist can detect which one is non-melanoma and melanoma. Computer-aided diagnosis (CADs) application to skin cancer is relatively understudied. The purpose of this paper is the automated detection of Melanoma via digital image processing. In this project, the algorithm consists of automatic ABCD (asymmetry, border irregularity, colour, and dermoscopic structure) rule of dermoscopy lesions images is implemented. Before that, we use hair removal as a pre-processing step which is based on morphological filter and thresholding. Finally, the lesions are classified as either melanoma or benign. The used dataset is containing 200 dermoscopic images, where 120 are benign lesions and 80 malignant melanomas. The proposed method shows an accuracy of 93.2%, 92.59% specificity, and 90.15% sensitivity. © 2019 IEEE.",10.1109/CAS47993.2019.9075465,ABCD rule; computer-aided diagnosis; Feature extraction; Melanoma; Skin Cancer,25,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084605142&doi=10.1109%2fCAS47993.2019.9075465&partnerID=40&md5=5f40c74b17b5df66dfcb9729b5f73213
Classification of skin cancer dermoscopy images using transfer learning,Younis H.; Bhatti M.H.; Azeem M.,2019,1,1,0,0,0,First occurrence,0,,,,,,,"Cancer is the second death causing disease in the world. Skin cancer is a major type of cancer and increasing speedily over the past decades. The major causes of skin cancer are Ultraviolet radiation, smoking, DNA mutation and bad lifestyle. Skin cancer is diagnosed by employing clinical screening, dermoscopic analysis, histopathological examination and a biopsy. Early prognosis of skin cancer can help to cure cancer easily and It is a difficult task to diagnosis and classify skin cancer even for expert dermatologists at an early stage. Recent studies have shown that deep learning and transfer learning is very useful in the classification of skin cancer and medical diagnosis. In this paper, we propose an efficient way to classify skin cancer using deep learning. We have tuned the pre-trained MobileNet convolution neural network and trained over the HAM1000 skin lesion dataset. This transfer learning method has shown remarkable categorical accuracy, the weighted average of precision and recall 0.97, 0.90 and 0.91 respectively. This model is lightweight, fast and reliable. It will be helpful for dermatologists to prognosis the skin cancer at its early stage. © 2019 IEEE.",10.1109/ICET48972.2019.8994508,Convolution neural networks; Dermoscopy images; Skin cancer classification; Skin lesion,60,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080899579&doi=10.1109%2fICET48972.2019.8994508&partnerID=40&md5=6c2e35b34453213dfb9e0c6b17ae1fee
Skin lesion segmentation based on modification of SegNet neural networks,Ninh Q.C.; Tran T.-T.; Tran T.T.; Anh Xuan Tran T.; Pham V.-T.,2019,1,1,0,0,0,First occurrence,0,,,,,,,"Skin lesion segmentation plays an important role in automatic skin cancer diagnosis. One of the most dangerous types of this cancer is melanoma which requires an early and accurate detection. However, automatic melanoma segmentation on dermoscopic images is a challenging task since images are corrupted by noise like hairs, air bubbles, blood vessel... and with fuzzy boundaries. This paper presents a framework based on deep fully convolutional neural networks to automatically segment skin lesions in dermoscopic images. Particularly, the paper proposes a fully convolutional network (FCN) framework that is based on modification of the SegNet architecture. In particular, we propose to reduce the downsampling and upsampling layers in the original SegNet model, that reduces total learned parameters compared to the original SegNet model. The proposed approach is applied to segment images from ISIC 2017 dataset. Experimental results show the desired performances of the proposed approach in terms of metrics of Dice coefficient and Jaccard indexes. © 2019 IEEE.",10.1109/NICS48868.2019.9023862,Deep learning; Deep neural networks; Image segmentation; Skin cancer; Skin lesion segmentation,24,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082657857&doi=10.1109%2fNICS48868.2019.9023862&partnerID=40&md5=ec2f635dc48a012d0b8289f291f47030
The application of deep learning on fast skin cancer diagnosis,Liu Y.,2019,1,1,0,0,0,First occurrence,0,,,,,,,"Nowadays, health problems have been more and more important. In order to solve the difficulties of diagnosing skin cancer quickly and precisely, we applied a state-of-the-art deep convolutional neural network (CNN) architecture with transfer learning, to help diagnose various types of skin cancers. Combined with proper data augmentation and normalization, the designed model achieves state-of-the-art result, including f1-score to be as high as 0.83, which demonstrates a promising application of the deep neural network on visual diagnosis of skin illness. © 2019 IEEE.",10.1109/ITCA49981.2019.00034,Convolutional neural networks; MobileNet; Skin cancer diagnosis,3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085498657&doi=10.1109%2fITCA49981.2019.00034&partnerID=40&md5=dc42b1feb05971634f158f6906c9545a
Medical image learning from a few/few training samples: Melanoma segmentation study,Asaeikheybari G.; Green J.; Qian X.; Jiang H.; Huang M.-C.,2019,0,1,0,0,0,Unique,0,,,,,,,"Melanoma is a type of life-threatening skin cancer which starts in melanocytes. The five-year survival rate of melanoma will increase to 98 percent in case of being detected and diagnosed before involving lymph nodes. Hence, early detection of melanoma has a pivotal role in decreasing the related fatal rate. One of the most popular classes of early detection methods is dermoscopy image analysis, where color photos of skin lesions are processed to determine if a mole is malignant or not. In order to properly implement these techniques, these dermoscopy images must be separated into foreground (the mole) and background (the surrounding skin) in a process known as segmentation. Multiple Random Walker (MRW) and deep learning approaches have been used for melanoma segmentation in this paper. We design a MRW-based system, a semi-automatic approach, for segmentation of dermoscopy images. We investigate the effect of number of walkers on the results and find the optimal gradient calculation algorithm for our setup. We have also applied three state-of-the-art Convolutional Neural Networks (CNNs) including SegNet, U-Net and DeconvNet, designed for segmentation, and analyzed the procedure of segmentation and their performance on delineating melanoma. Finally, we investigate the selection of the best approach adaptively based on the size of the available training masked images. The results reveal that MRW-based segmentation approach is a promising selection when training set images are limited while the CNN architectures are decent choice in the presence of large training set. © 2019 Elsevier Inc.",10.1016/j.smhl.2019.100088,Deep learning; Dermoscopy images; Image segmentation; Melanoma; Multiple random walker approach,10,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074829867&doi=10.1016%2fj.smhl.2019.100088&partnerID=40&md5=53ffbeb2ebd4e57db2130ef55cea71ad
A modified inception-v4 for imbalanced skin cancer classification dataset,Emara T.; Afify H.M.; Ismail F.H.; Hassanien A.E.,2019,1,1,0,0,0,Unique,0,,,,,,,"Deep learning architectures, especially deep convolutional neural networks (CNN) achieve high accuracy on object classification and localization tasks. Achieving such high accuracy requires powerful devices. In this paper, rather than an ensemble of multiple complex models, a single Inception-v4 model is adapted to classify extracted from the HAM10000 dataset. The proposed model is enhanced by employing feature reuse using long residual connection in which the features extracted from earlier layers are concatenated with the high-level layers to increase the model classification performance. The dataset used in this study is imbalanced; therefore, a data sampling approach is used to mitigate the data imbalance effect. The proposed architecture achieves an accuracy of 94.7% using the provided test set at the official benchmark for the International Skin Imaging Collaboration (ISIC) 2018. © 2019 IEEE.",10.1109/ICCES48960.2019.9068110,Convolution neural network; Deep learning; Inception v4; Skin cancer classification,40,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084702131&doi=10.1109%2fICCES48960.2019.9068110&partnerID=40&md5=f552366a60ce942ab0ce42a3132a915c
Skin lesion classification using convolution neural networks,Rajasekhar K.S.; Ranga Babu T.,2019,1,1,0,0,0,Unique,0,,,,,,,"Skin cancer is one of the deadliest disease found in humans. These skin cancers are of various types like Basal Cell Carcinoma(BCC), Melanoma, Nevus, Seborrheic Keratosis (SK), Squamous Cell Carcinoma (SCC). Some of the skin cancers can be identified visually, but in order to diagnose a skin cancer patient should have to undergo for a biopsy test and it takes a long time to diagnose. To overcome this an automated skin lesion classification system has to be developed. In this work, a basic architecture of the Convolution Neural Network(CNN) model is used to classify different skin lesions. The proposed model achieved better accuracy for SCC Vs SK, BCC Vs SK, Melanoma Vs Nevus and Melanoma Vs SK are 0.9741, 0.9867, 0.9506 and 0.9734 respectively for 25 epochs when compared to the other related works. © 2019, Indian Journal of Public Health Research and Development. All rights reserved.",10.37506/v10/i12/2019/ijphrd/192205,Basal Cell Carcinomsa; CNN; Melanoma; Nevus; Seborrheic Keratosis; Skin cancer; Squamous Cell Carcinoma; Training Accuracy; Validation Accuracy,6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089762603&doi=10.37506%2fv10%2fi12%2f2019%2fijphrd%2f192205&partnerID=40&md5=72fbe99208b1dc02ce176a0aa62e15ba
Convolutional neural network based skin lesion analysis for classifying melanoma,Guha S.R.; Haque S.M.R.,2019,1,1,0,0,0,First occurrence,0,,,,,,,"In a human body skin is the core part, which helps to cover the muscles, bones what's more with the entire body. These days numerous people are suffering from skin diseases. Melanoma is the enormous type of skin malignant growth and the extent of these skin diseases is increasing day by day. Recognizing the type of skin disease automatically from the images can assist in the quick diagnosis and enhanced accuracy saving valuable time. Here, a machine learning based technique using convolutional neural network (CNN) for classifying seven types of skin diseases has been proposed. Transfer learning, along with CNN, has been used to improve the classification accuracy on the International Skin Imaging Collaboration 2018 (ISIC) dataset. Evidence of 11% increase in the accuracy by using transfer learning than using only CNN has been found. Compared to some existing works, performance of this proposed method is promising. © 2019 IEEE.",10.1109/STI47673.2019.9067979,Convolutional neural network; Melanoma; Skin lesion; Transfer learning; VGG-16,18,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084306095&doi=10.1109%2fSTI47673.2019.9067979&partnerID=40&md5=0646da5a743fb0923935450d35d890f4
Segmenting melanoma Lesion using Single Shot Detector (SSD) and Level Set Segmentation Technique,Rashid F.; Irtaza A.; Nida N.; Javed A.; Malik H.; Malik K.M.,2019,0,1,0,0,0,First occurrence,0,,,,,,,"Melanoma is a lethal type of skin cancer that orginates fron melanocytes cells of skin and it is responsible of several deaths annually due to exposure of ultraviolet radiations. Early diagnosis and proper treatment of melanoma significantly improves the patient's survival rate. In the computer aided diagnosis, the automatic segmentation is first step in early and accurate diagnosis of the Melanoma lesion area. However, the presence of natural or clinical artifacts hinders the precise lesion segmentation. The goal of our work is to establish a novel pipeline that automatically pre-process, localize and then segment the melanoma lesion precisely and improve its segmentation accuracy. In our proposed method, dermoscopic images are segmented in three steps: 1. Preprocessing using morphological operations to remove hair. 2. Localization of melanoma lesion by utilizing a deep convolutional neural network named as Single-Shot Detection (SSD) network, 3. Segmentation using level set algorithm. The proposed approach was evaluated on ISBI 2016 challenge dataset (Skin Lesion Analysis Towards Melanoma Detection Challenge Dataset). On ISIC 2016, our method achieved an average of Jc, Di and Ac as 0.82, 0.901 and 0.90 respectively. The results of the segmentation are also compared with the state-of-the-art methods to justify the effectiveness of the proposed approach. © 2019 IEEE.",10.1109/MACS48846.2019.9024823,CAD tool; Deep learning; level-set segmentation; Melanoma localization; SSD,6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082450349&doi=10.1109%2fMACS48846.2019.9024823&partnerID=40&md5=080f55bc761df1893fcf7e2b514e2652
DermoNet: densely linked convolutional neural network for efficient skin lesion segmentation,Baghersalimi S.; Bozorgtabar B.; Schmid-Saugeon P.; Ekenel H.K.; Thiran J.-P.,2019,1,1,0,0,0,First occurrence,0,,,,,,,"Recent state-of-the-art methods for skin lesion segmentation are based on convolutional neural networks (CNNs). Even though these CNN-based segmentation approaches are accurate, they are computationally expensive. In this paper, we address this problem and propose an efficient fully convolutional neural network, named DermoNet. In DermoNet, due to our densely connected convolutional blocks and skip connections, network layers can reuse information from their preceding layers and ensure high accuracy in later network layers. By doing so, we take advantage of the capability of high-level feature representations learned at intermediate layers with varying scales and resolutions for lesion segmentation. Quantitative evaluation is conducted on three well-established public benchmark datasets: the ISBI 2016, ISBI 2017, and the PH2 datasets. The experimental results show that our proposed approach outperforms the state-of-the-art algorithms on these three datasets. We also compared the runtime performance of DermoNet with two other related architectures, which are fully convolutional networks and U-Net. The proposed approach is found to be faster and suitable for practical applications. © 2019, The Author(s).",10.1186/s13640-019-0467-y,Fully convolutional neural networks; Lesion segmentation,43,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069431103&doi=10.1186%2fs13640-019-0467-y&partnerID=40&md5=0b4db481f52a9b31a11ff3fe34113a31
Detection of Skin Cancer Lesions from Digital Images with Image Processing Techniques,Waghulde M.; Kulkarni S.; Phadke G.,2019,1,1,0,0,0,Unique,0,,,,,,,"Melanoma, a kind of skin cancer, could be a category of cancer that originates from the pigment which includes the cells named melanocytes. Melanomas normally appear within not only the skin, but also may rarely occur within the eyes, intestines, or mouth. In women melanomas most ordinarily found on the legs, on the other hand in men, they are most typical on the rear side. Generally, these are originated from a mole with regarding changes as well as they increase in size, asymmetrical edges, and modification in skin breakdown, itchiness, or color. Melanoma is one of the life-Threatening kinds of carcinoma. There is an increase in incidence rates of skin cancer, specifically between non-Hispanic white females and males, however, the chances of survival are high detected in an early stages. In this project, we are taking the help of the image processing techniques for detecting melanoma in the image. Firstly, we will apply the preprocessing technique in order to make the image noise free. Median filters will be used for filtration of the image. After that, we will transform the image into an HSI color image. Active shape segmentation and texture segmentation techniques will be used for segmenting the image. For feature extraction, GLCM Feature Extraction algorithm is used. Finally, we will apply the probabilistic neural network (PNN) classifier to classify the image either as normal or melanoma. © 2019 IEEE.",10.1109/PuneCon46936.2019.9105886,Active and texture segmentation; GSLM; Median filter; PNN; Skin Cancer,8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086736194&doi=10.1109%2fPuneCon46936.2019.9105886&partnerID=40&md5=709c86f773628897d2b1f264b7cc2705
Kernel sparse representation based model for skin lesions segmentation and classification,Moradi N.; Mahdavi-Amiri N.,2019,1,1,0,0,0,Unique,0,,,,,,,"Background and Objectives: Melanoma is a dangerous kind of skin disease with a high death rate, and its prevalence has increased rapidly in recent years. Diagnosis of melanoma in a primary phase can be helpful for its cure. Due to costs for dermatology, we need an automatic system to diagnose melanoma through lesion images. Methods: Here, we propose a sparse representation based method for segmentation and classification of lesion images. The main idea of our framework is based on a kernel sparse representation, which produces discriminative sparse codes to represent features in a high-dimensional feature space. Our novel formulation for discriminative kernel sparse coding jointly learns a kernel-based dictionary and a linear classifier. We also present an adaptive K-SVD algorithm for kernel dictionary and classifier learning. Results: We test our approach for both segmentation and classification tasks. The evaluation results on both dermoscopic and digital datasets demonstrate our approach to be competitive as compared to the available state-of-the-art methods, with the advantage of not needing any pre-processing. Conclusions: Our method is insensitive to noise and image conditions and can be used effectively for challenging skin lesions. Our approach is so extensive to be adapted to various medical image segmentations. © 2019",10.1016/j.cmpb.2019.105038,Classification; Kernel dictionary learning; Melanoma recognition; Skin lesion segmentation; Sparse representation,49,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070751705&doi=10.1016%2fj.cmpb.2019.105038&partnerID=40&md5=61b97c9dde86b97fdf73e685ec9e7b3c
Real-time classification and detection of citrus based on improved single short multibox detecter; [基于改进SSD的柑橘实时分类检测],Li S.; Hu D.; Gao S.; Lin J.; An X.; Zhu M.,2019,0,1,0,0,0,Unique,0,,,,,,,"Manually classifying citrus based on its surface defects is tedious and time-consuming and a new real-time method is proposed in this paper based on the improved SSD deep learning model. In the testing bench of the waxing machine, 2 500 images of a variety of citrus species were taken, of which 2 000 were randomly selected as training set and 500 as testing set. Among them, the method classified 19 507 as normal, 9 097 skin defects and 4 327 mechanically damaged. Considering that traditional methods using near-infrared spectra, support vector machines, HSV and RGB color space model are inefficient to detect surface defects of citrus and can only identify one, we proposed an improved method to calculate the image using the one-stage detection model - SSD-ResNet18. The method gets the feature maps through backbone first, and then predicts the number of boundary boxes from the feature maps before determining the location and category of citrus using confidence and non-maximum suppression. This can detect a batch of citrus. In the proposed method, we used the mAP (mean average precision) as the precision index and the mean detection time as the speed index. Optimization in the proposed method was solved using the SGD (stochastic gradient descent) algorithm. The learning scheduler was based on cosine decay, enabling the learning rate to drop to 0 at the end of the training period. This ensures the lost value during the training period to continuously decline. As the model was stable at the end of the training period, it can be saved at the end of the training for further use. While the VGG16 was used as the original SSD backbone, it needs a multitude of parameters and is hence computationally inefficient. We replaced it with the ResNet18, which is approximately 100 times more efficient than the VGG16. An improved feature map was obtained from the analysis of the effective sensory field of different feature maps and the size of citrus in the map, the anchor in which was obtained using the K-means clustering algorithm from the manual label box. The suitable image resolution for the proposed model was obtained by comparing images taken at five resolutions: 512×512 pixels, 640×640 pixels, 768×768 pixels, 896×896 pixels and 1024×1024 pixels. The results showed that the accuracy of the mAP of SSD-ResNet18 was 87.89%, improving 0.34 percentage points higher than the original SSD. The average detecting time of the SSD-ResNet18 was 20.72 ms, reduced by 436.90% compared to the original SSD's 108.83 ms. The accuracy of the AP of SSD-ResNet18 was 94.72%, 85.79% and 83.17%, respectively, for detecting normal, skin lesion and mechanical damage. We compared MobileNetV3, ESPNetV2, VoVNet39 and ResNet18 as backbones and did not find significant difference between their accuracy, but ResNet18 was 10.52 ms, 16.78 ms and 36.76 ms less than MobileNetV3, ESPNetV2 and VoVNet39 in detection time, respectively. The method proposed in the paper meets the requirement on detecting speed in real-time citrus production line and can effectively classify and detect a multitude of citrus simultaneously. © 2019, Editorial Department of the Transactions of the Chinese Society of Agricultural Engineering. All right reserved.",10.11975/j.issn.1002-6819.2019.24.036,Citrus; Deep learning; Models; Nondestructive detection; Object recognition; ResNet18; SSD; Surface defects,39,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081004295&doi=10.11975%2fj.issn.1002-6819.2019.24.036&partnerID=40&md5=cb35d8dc964078117bcb93962e3e2b63
Genetic Programming for Multiple Feature Construction in Skin Cancer Image Classification,Ain Q.U.; Xue B.; Al-Sahaf H.; Zhang M.,2019,1,1,0,0,0,First occurrence,0,,,,,,,"Skin cancer is a common cancer worldwide, with melanoma being the most deadly form which is treatable when diagnosed at an early stage. This study develops a novel classification approach using multi-tree genetic programming (GP), which not only targets melanoma detection but is also capable of distinguishing between ten different classes of skin cancer effectively from lesion images. Selecting a suitable feature extraction method and the way different types of features are combined are important aspects to achieve performance gains. Existing approaches remain unable to effectively design a way to combine various features. Moreover, they have not used multi-channel multi-resolution spatial/frequency information for effective feature construction. In this work, wavelet-based texture features from multiple color channels are employed which preserve all the local, global, color and texture information concurrently. Local Binary Pattern, lesion color variation, and geometrical border shape features are also extracted from various color channels. The performance of the proposed method is evaluated using two skin image datasets and compared with an existing multi-tree GP method, ten single-tree GP methods, and six commonly used classification algorithms. The results reveal the goodness of the proposed method which significantly outperformed all these classification methods and demonstrate the potential to help dermatologist in making a diagnosis in real-time situations. © 2019 IEEE.",10.1109/IVCNZ48456.2019.8961001,,13,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078706804&doi=10.1109%2fIVCNZ48456.2019.8961001&partnerID=40&md5=bc5967ebc9cfb2e49b3357001b6d4cd5
An Enhanced Model for Skin Disease Detection using Dragonfly Optimization based Deep Neural Network,Melbin K.; Raj Y.J.V.,2019,1,1,0,0,0,First occurrence,0,,,,,,,"In this paper, we have proposed an efficient skin disease identification approach using enhanced deep neural network model. The database images are segmented using enhanced level set approach-based segmentation. Feature extraction is carried out for all the images to retrieve the feature vector using GLCM. Finally, dragonfly optimization-based deep neural network is utilized for the classification of skin diseases. The system is implemented in the working platform of MATLAB, and the proposed dragonfly based DNN is evaluated using existing methods such as SVM, ANN for different evaluation metrics such as accuracy, sensitivity, and specificity to show the system efficiency. © 2019 IEEE.",10.1109/I-SMAC47947.2019.9032458,Accuracy; and Dragonfly optimization; Deep neural network; Dermatology; GLCM feature extraction; Segmentation; Skin disease,15,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083035889&doi=10.1109%2fI-SMAC47947.2019.9032458&partnerID=40&md5=43d029a98f1323e811e45e05e17a9a80
Spectral indexes obtained by implementation of the fractional Fourier and Hermite transform for the diagnosis of malignant melanoma,Garza-Flores E.; Guerra-Rosas E.; Álvarez-Borrego J.,2019,0,1,0,0,0,Unique,0,,,,,,,"Many people suffer from different skin diseases, which can be diverse and varied. Most skin diseases cause disorders in the skin, such as changes in color, texture, and appearance manifesting in spots, swelling, scaling, ulcers, etc. One of the diseases that represents a serious health problem is skin cancer. The most dangerous skin cancer is malignant melanoma, which can cause death if not detected early. Therefore, development of new and accurate diagnosis methodologies to increase the chance of early detection is important. In this work, an analysis to discriminate between malignant melanoma and three types of benign skin lesions–melanocytic nevus, dermatofibroma, and seborrheic keratosis–is realized by calculating spectral indexes based on the real and imaginary parts of a fractional nonlinear filter obtained by affecting the modulus of the fractional Fourier transform by an exponent k. The fractional spectral indexes were calculated by working with selected sub-images obtained by dividing the input image. Also, a variation was implemented when the Hermite transform is used to calculate the fractional nonlinear filter. Discrimination between malignant melanoma and benign skin lesions was achieved with a 99.7% confidence level. © 2019 Optical Society of America under the terms of the OSA Open Access Publishing Agreement",10.1364/BOE.10.006043,,4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078697927&doi=10.1364%2fBOE.10.006043&partnerID=40&md5=dbb3e90fdc544502531fa0bda2974810
Dermatologic Hyperspectral Imaging System for Skin Cancer Diagnosis Assistance,Fabelo H.; Carretero G.; Almeida P.; Garcia A.; Hernandez J.A.; Godtliebsen F.; Melian V.; Martinez B.; Beltran P.; Ortega S.; Marrero M.; Callico G.M.; Sarmiento R.; Castano I.,2019,1,1,0,0,0,Unique,0,,,,,,,"This paper presents the development of a dermatological acquisition system based on hyperspectral (HS) imaging for the assistance in the diagnosis of pigmented skin lesions (PSLs). The developed system is able to capture HS images of 50×50 pixels and 125 spectral bands in the VNIR (Visual and Near Infrared) region between 450 and 950 nm, using a cold light halogen illumination device. The system is able to capture images of a size of 12×12 mm in less than 1 second. Employing this system, a preliminary database of 49 HS images of PSLs from 36 patients was generated. The data was labeled in four different classes and classified using a supervised machine learning method optimized by means of a genetic algorithm. The results obtained in these preliminary experiments demonstrate the potential of the developed system to perform a rapid and accurate assistance in the skin cancer diagnosis task during clinical routine practice. © 2019 IEEE.",10.1109/DCIS201949030.2019.8959869,Hyperspectral imaging; Random Forest; Skin cancer; Snapshot hyperspectral cameras; Supervised Learning; Support Vector Machines,24,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078952094&doi=10.1109%2fDCIS201949030.2019.8959869&partnerID=40&md5=86138125fc7b3d4f79387510cd58b4d6
Melanoma Classification on Dermoscopy Skin Images using Bag Tree Ensemble Classifier,Lynn N.C.; War N.,2019,1,1,0,0,0,First occurrence,0,,,,,,,"Melanoma classification on dermoscopy skin images is a demanding work as a result of the low contrast of the lesion images, the intra-structural variants of melanomas, the much visually likeliness level of whether melanoma or non-melanoma lesions, and the covering of hair and ruler marker artifacts. In this study, the malignant melanoma skin cancer classification system is proposed with the aid of correctly classify melanoma skin cancer. The system involves three main steps: segmentation, feature extraction and classification. Ahead of the segmentation process, the preprocessing skin lesion images is processed for getting rid of the covered hair artifacts. In the segmentation step, the input preprocessed lesion image is segmented by using the proposed texture filter-based segmentation method. Then, the extraction of features with the underlying ABCD (Asymmetry, Border, Color, Differential Texture) dermatology rules using shape, edge, colored and textural features are computed from the segmented region. Lastly, the extracted features are classified to identify if the skin image is malignant melanoma or non-melanoma with the use of bag tree ensemble classifier. The system performance is evaluated with the use of the benchmarking datasets: PH2 dataset, ISBI2016 dataset and ISIC2017 dataset. According to the experimental results, the proposed design allows for both reliable classification of real world dermoscopy images and feasible operation time with today's standard PC computing platforms. To address the class imbalance in the dataset and to yield the improved classification performance, the experiments are also analyzed not only on original imbalanced dataset but also on balancing datasets: undersampled and oversampled datasets. The system works well and provides both high sensitivity and specificity according to the experimental results on the oversampled dataset with bag tree ensemble classifier to leading to statistically better performance compared to original imbalanced dataset. © 2019 IEEE.",10.1109/AITC.2019.8920908,Dermoscopy Skin Image; Ensemble Classification; Feature Extraction; Melanoma; Segmentation,11,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077787011&doi=10.1109%2fAITC.2019.8920908&partnerID=40&md5=c12a53b946bcdedf6f2b3a81eab9833c
Improved skin lesion edge detection method using Ant Colony Optimization,Sengupta S.; Mittal N.; Modi M.,2019,1,1,0,0,0,Unique,0,,,,,,,"Background: Skin lesion edge detection is a significant step in developing an automatized diagnostic system. The efficient diagnostic system leads to correct identification and detection of skin lesion diseases. In this paper, ant colony optimization (ACO) technique is used to improve the edge contour of skin lesion images. Material and Method: Firstly, a three-stage preprocessing methodology involving color space conversion, contrast enhancement, and filtering is applied to improve the skin lesion image quality. The edge map is obtained by applying three types of conventional edge detection methods namely Canny, Sobel, and Prewitt. Thereafter, ACO is applied on these images to produce an improved edge contour. Result: The improvement of the proposed methodology is quantitatively verified by analysis of the entropy of the final image obtained by conventional and proposed techniques. Conclusion: From the result analysis, we can conclude that introduction of ACO has increased the efficiency of the conventional edge detection method in skin lesion images. © 2019 John Wiley & Sons A/S. Published by John Wiley & Sons Ltd",10.1111/srt.12744,Ant Colony Optimization; Canny; edge detection; Prewitt; skin lesions; Sobel,32,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067876114&doi=10.1111%2fsrt.12744&partnerID=40&md5=505d5a56e5e78584f4e8cc2df701fd12
Machine Learning Techniques for Automated Melanoma Detection,Vocaturo E.; Perna D.; Zumpano E.,2019,0,1,0,0,0,First occurrence,0,,,,,,,"The malignant melanoma is one of the most aggressive forms of skin cancer. Modern Dermatology recognizes early diagnosis as a fundamental role in reducing the mortality rate and to guarantee less invasive treatments for patients. Computer-Aided Diagnosis (CAD) systems are increasingly adopted for the early diagnosis of skin lesions. These systems consist of different phases that must be chosen appropriately based on the characteristics of digital images aiming to obtain a reliable diagnosis. Acquisition, pre-processing, segmentation, feature extraction and selection, and finally classification of dermoscopic images hold challenges to be faced and overcome to improve the automatic diagnosis of dangerous lesions such as melanoma. The classification phase is particularly delicate: over time, a series of automatic learning algorithms have been proposed to better face this issue. In this paper, we refer to the various machine learning approaches that have been proposed and that provide inspiration for the implementation of effective frameworks. © 2019 IEEE.",10.1109/BIBM47256.2019.8983165,CAD Systems; Machine Learning; Melanoma Classification,41,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084332077&doi=10.1109%2fBIBM47256.2019.8983165&partnerID=40&md5=c73afea2299bb9fc2bd45e662bbd0202
Attention-guided deep convolutional neural networks for skin cancer classification,Aggarwal A.; Das N.; Sreedevi I.,2019,1,1,0,0,0,First occurrence,0,,,,,,,"Skin cancer is a silently killing disease which commonly goes unnoticed in its primitive stage but proves to be deadly later on. Hence, it needs to be detected and classified in the early stages itself. The advent of machine learning as well as deep learning based classification techniques has made this task possible. Deep convolutional neural networks (D-CNNs) have the ability to extract universal and dataset-specific features for the image classification task. But the classification of skin cancer images remains a challenging task due to the absence of balanced class images, difference between images of the same class, similarity between inter-class images and the inefficiency in focusing on the semantically significant areas of the image. To improve the performance of these D-CNNs, we incorporate the attention mechanism that focuses on the regions of importance in an image. In that regard, we propose an attention-guided D-CNN for classification of skin cancer. It is observed from the classification results that a model with attention boosts the accuracy of a normal D-CNN architecture by approximately 12%. Our research work contributes significantly to the field of biomedical image processing by providing a mechanism to improve performance of D-CNNs and facilitating early detection of skin cancer. © 2019 IEEE.",10.1109/IPTA.2019.8936100,Attention; Computer vision; Convolutional neural networks; Deep learning; Dermoscopy; Fine tuning; Skin cancer classification; Transfer learning,16,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077965756&doi=10.1109%2fIPTA.2019.8936100&partnerID=40&md5=7b0b5b14c699de63fd53e337ab6ad37f
Early diagnosis of skin cancer by ultrasound frequency analysis,Kia S.; Setayeshi S.; Pouladian M.; Ardehali S.H.,2019,1,1,0,0,0,Unique,0,,,,,,,"The diagnosis of cancer by modern computer tools, at the very first stages of the incident, is a very important issue that has involved many researchers. In the meantime, skin cancer is a great deal of research because many people are involved with it. The purpose of this paper is to introduce an innovative method based on tissue frequency analyzes to obtain the accurate and real-time evaluation of skin cancers. According to the Biological resonance theory, body cells have natural and unique frequencies based on their biological fluctuations, which, if the structure, profile and cellular status change, its frequency also varies. This concept and theory is considered as the basis for analyzing skin tissue health in the proposed method. Reflected ultrasound waves from tissue have been processed and studied based on frequency analysis as a new method for early detection and diagnosis of accurate location and type of skin diseases. The developed algorithm was approved through 400 patients from CRED; its ability to evaluate benign and malignant skin lesions was shown (AUC = 0.959), with comparable clinical precision; as for the selected threshold, sensitivity, and specificity were 93.8% and 97.3%, respectively. Therefore, this method can detect skin malignancy with an accurate, noninvasive and real-time procedure. © 2019 The Authors. Journal of Applied Clinical Medical Physics published by Wiley Periodicals, Inc. on behalf of American Association of Physicists in Medicine.",10.1002/acm2.12671,biological resonance theory; discrete cosine transform; early detection; frequency analyzes; skin cancer diagnosis; skin sonography,12,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074583583&doi=10.1002%2facm2.12671&partnerID=40&md5=5c205500056ff593110e8b39ba9b1a8d
Intelligent skin cancer diagnosis using improved particle swarm optimization and deep learning models,Tan T.Y.; Zhang L.; Lim C.P.,2019,1,1,0,0,0,Unique,0,,,,,,,"In this research, we propose an intelligent decision support system for skin cancer detection. Since generating an effective lesion representation is a vital step to ensure the success of lesion classification, the discriminative power of different types of features is exploited. Specifically, we combine clinically important asymmetry, border irregularity, colour and dermoscopic structure features with texture features extracted using Grey Level Run Length Matrix, Local Binary Patterns, and Histogram of Oriented Gradients operators for lesion representation. Then, we propose two enhanced Particle Swarm Optimization (PSO) models for feature optimization. The first model employs adaptive acceleration coefficients, multiple remote leaders, in-depth sub-dimension feature search and re-initialization mechanisms to overcome stagnation. The second model uses random acceleration coefficients, instead of adaptive ones, based on non-linear circle, sine and helix functions, respectively, to increase diversification and intensification. Ensemble classifiers are also constructed with each base model trained using each optimized feature subset. A deep convolutional neural network is devised whose hyper-parameters are fine-tuned using the proposed PSO models. Extensive experimental studies using dermoscopic skin lesion data, medical data from the UCI machine learning repository, and ALL-IDB2 image data are conducted to evaluate the model efficiency systematically. The results from empirical evaluations and statistical tests indicate the superiority of the proposed models over other advanced PSO variants and classical search methods pertaining to discriminative feature selection and optimal hyper-parameter identification for deep learning networks in lesion classification as well as other disease diagnosis. © 2019",10.1016/j.asoc.2019.105725,Deep and ensemble classifier; Evolutionary algorithm; Feature selection; Hyper-parameter tuning; Skin cancer detection,127,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071145352&doi=10.1016%2fj.asoc.2019.105725&partnerID=40&md5=b3c38fddcba32b6ef267ced7ef4f29f1
Automatic detection of melanoma with yolo deep convolutional neural networks,Nie Y.; Sommella P.; O'Nils M.; Liguori C.; Lundgren J.,2019,0,1,0,0,0,First occurrence,0,,,,,,,"In the past three years, deep convolutional neural networks (DCNNs) have achieved promising results in detecting skin cancer. However, improving the accuracy and efficiency of the automatic detection of melanoma is still urgent due to the visual similarity of benign and malignant dermoscopic images. There is also a need for fast and computationally effective systems for mobile applications targeting caregivers and homes. This paper presents the You Only Look Once (Yolo) algorithms, which are based on DCNNs applied to the detection of melanoma. The Yolo algorithms comprise YoloV1, YoloV2, and YoloV3, whose methodology first resets the input image size and then divides the image into several cells. According to the position of the detected object in the cell, the network will try to predict the bounding box of the object and the class confidence score. Our test results indicate that the mean average precision (mAP) of Yolo can exceed 0.82 with a training set of only 200 images, proving that this method has great advantages for detecting melanoma in lightweight system applications. © 2019 IEEE.",10.1109/EHB47216.2019.8970033,Image processing; Melanoma; Object Detection; Yolo,72,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079350541&doi=10.1109%2fEHB47216.2019.8970033&partnerID=40&md5=ba82adf540a1922621d62d38c7d5713a
Deep learning for actinic keratosis classification,Nanni L.; Paci M.; Maguolo G.; Ghidoni S.,2019,0,1,0,0,0,Unique,0,,,,,,,"Classification of biological images plays a crucial role in many biological problems, e.g. recognition of cell phenotypes and maturation levels, localization of cell organelles and histopathological classification, and holds the potential to support early diagnosis, which is critical in disease prevention. In this paper, we tested different ensemble of canonical and deep classifiers to provide accurate identification of actinic keratosis (AK), one of the most common skin lesions that could degenerate into lethal squamous cell carcinomas. We used a clinical image dataset to build and test different ensembles of support vector machines trained by handcrafted descriptors and convolutional neural networks (CNNs) for which we experimented different learning rates, augmentation techniques (e.g. warping) and topologies. Our results show that the proposed ensemble obtains performance comparable to the state of the art. To reproduce the experiments reported in this paper, the MATLAB code of all the descriptors is available at https://github.com/LorisNanni. © 2020 the Author(s), licensee AIMS Press.",10.3934/ElectrEng.2020.1.47,Actinic keratosis; Bioimage classifications; Convolutional neural networks; Deep learning; Microscopy imaging classification,7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091422920&doi=10.3934%2fElectrEng.2020.1.47&partnerID=40&md5=c90ef025d801894a3609cf53a2a49e4a
Dangerousness of dysplastic nevi: A Multiple Instance Learning Solution for Early Diagnosis,Vocaturo E.; Zumpano E.,2019,0,1,0,0,0,First occurrence,0,,,,,,,"Malignant melanoma is responsible for the highest number of deaths related to skin lesions. However, early diagnosis may allow positive treatment of this terrible form of cancer. The similarities of melanoma with other skin lesions such as dysplastic nevi, however, constitute a pitfall for early diagnosis. The research community is committed to proposing software solutions that favor the computerized analysis of lesions for melanoma detection. The proposed algorithms and methods have had as main focus the dichotomous distinction of melanoma from benign lesions and they rarely focused on the case of melanoma against dysplastic nevi. This challenge is much more difficult due to the similarity of the injuries. Currently, there is debate about dysplastic nevi syndrome, or rather about the number of moles present on the human body as potential melanoma risk factors. In this document, we consider the challenging task of applying a multi-instance learning (MIL) algorithm for discriminating melanoma from dysplastic nevi and outline an even more complex challenge related to the classification of dysplastic nevi from common nevi. Since the results appear promising, we conclude that a MIL technique could be at the basis of more sophisticated tools useful to skin lesion detection. © 2019 IEEE.",10.1109/BIBM47256.2019.8983056,Dermoscopy imaging Classification; Dysplastic Moles; Melanoma; Multiple Instance Learning,28,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084334103&doi=10.1109%2fBIBM47256.2019.8983056&partnerID=40&md5=ec863ce116aeaa604d72375667aa3dec
Transfer learning based method for two-step skin cancer images classification,Moldovan D.,2019,1,1,0,0,0,First occurrence,0,,,,,,,Classification of skin cancer images is an important research challenge because the number of people is expected to increase significantly in the next years and consequently the number of people that might have skin cancer in one phase of life will increase accordingly. Some types of skin cancer can be treated successfully if they are detected in the early stages and thus the study of the skin cancer images using the latest technological innovations might lead to better results than in the case when traditional methods are applied. In this article is presented a method for the classification of skin cancer images that consists of two steps and which is based on transfer learning and deep learning. The classification models are developed in Python using the PyTorch machine learning library and the dataset used as experimental support for testing and validating the transfer learning based method is Human Against Machine with 10000 training images (HAM10000) dataset. In the first step the accuracy of the prediction model for testing data is 85% and in the second step the accuracy of the prediction model for testing data is 75%. © 2019 IEEE.,10.1109/EHB47216.2019.8970067,Classification; Deep learning; HAM10000; Skin cancer; Transfer learning,32,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079344049&doi=10.1109%2fEHB47216.2019.8970067&partnerID=40&md5=6acd8398ab20e47e0355a5be718b696d
Can skin cancer diagnosis be transformed by AI?,Esteva A.; Topol E.,2019,1,0,0,0,0,Unique,0,,,,,,,[No abstract available],10.1016/S0140-6736(19)32726-6,,25,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074779730&doi=10.1016%2fS0140-6736%2819%2932726-6&partnerID=40&md5=095099b61a985f77a9a000ee517c5026
Weakly Supervised Vitiligo Segmentation in Skin Image through Saliency Propagation,Bian Z.; Xia S.; Xia C.; Shao M.,2019,1,1,0,0,0,Unique,0,,,,,,,"Vitiligo is a skin disorder where pale or white patches develop due to the lack or absence of melanocytes. Vitiligo affects around 0.5% to 1% of the world's population, and it may have a profound psychological impact on patients' quality of life. In this paper, we present a novel weakly supervised framework to segment vitiligo regions with high quality, which is a fundamental task for the assessment of vitiligo. The proposed framework starts with pre-training a classification network using only image-level labels. Then we observed that the activation map obtained from the image classification network could be further exploited and introduced into the saliency propagation process as useful information. Finally, the saliency propagation process is performed on the graph built on superpixels to obtain a meaningful saliency map. These three steps lead to a compelling yet elegant method. Moreover, we propose a new large vitiligo image dataset named Vit2019. To the best of our knowledge, this is currently the first dataset for image segmentation of vitiligo diseases. Experimental results demonstrate the superiority of the proposed model over state-of-the-arts. © 2019 IEEE.",10.1109/BIBM47256.2019.8983145,convolutional neural network; saliency propagation; vitiligo; weakly-supervised segmentation,17,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084331451&doi=10.1109%2fBIBM47256.2019.8983145&partnerID=40&md5=4b09f5ddf61351837bec38fa80737790
Pigmented skin lesions classification using convolutional neural networks,Naronglerdrit P.; Mporas I.; Perikos I.; Paraskevas M.,2019,1,1,0,0,0,First occurrence,0,,,,,,,In this paper we present an architecture for classification of pigmented skin lesions from dermatoscopic images. The architecture is using image pre-processing for natural hair removal and image segmentation for extraction of the skin lesion area. The segmented images were processed by a convolutional neural network classifier. The training process was done by using the Keras and TensorFlow python packets with CUDA supported. The best performance was achieved by a convolutional neural network architecture with three convolution layers and the classification accuracy was equal to 76.83%. © 2019 IEEE.,10.1109/BIA48344.2019.8967469,convolutional neural network; CUDA computing; dermatoscopy; image classification,5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079269023&doi=10.1109%2fBIA48344.2019.8967469&partnerID=40&md5=5cfaccdc3ad595df56c36356f8ea0b97
Automated Melanoma Recognition in Dermoscopy Images via Very Deep Residual Networks,Prathiba M.; Jose D.; Saranya R.; Nandhinidevi,2019,0,1,0,0,0,First occurrence,0,,,,,,,"Automated melanoma recognition using image processing technique from the available dermoscopic images in deep learning is difficult task because of the contrast and variation of melanoma in skin. It is mainly a non-invasive method so that it cannot contact with skin more forcefully. To overcome these disadvantages this research work proposes a method using very deep convolutional neural networks (CNNs). For more accurate classification in this method we are using FCRN and CNN with the effective training limited data. Initially, Performance of Segmentation is done using residual networks using a image from the dataset followed by Classification by neural networks to check the abnormalities in skin. In this kind of classification technique the network has more specified features from the segmented portion alone. The proposed technique is mainly evaluated on datasets and experimental results that would show the performance in histogram and PSNR ratio. © 2019 IOP Publishing Ltd. All rights reserved.",10.1088/1757-899X/561/1/012107,,21,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075455778&doi=10.1088%2f1757-899X%2f561%2f1%2f012107&partnerID=40&md5=3c530d67c57f02dee59bafe59f2b6b2a
Skin Disease Recognition Method Based on Multi-Model Fusion of Convolutional Neural Network; [多卷积神经网络模型融合的皮肤病识别方法],Xu M.; Guo L.; Song P.; Chi Y.; Du S.; Geng S.; Zhang Y.,2019,1,1,0,0,0,Unique,0,,,,,,,"To solve the problem that the clinical features of basal cell carcinoma and seborrheic keratosis in skin diseases are very similar and difficult to classify, a multi-model fusion method of convolutional neural network (CNN) for dermatological recognition is proposed. The transfer learning method is used to train various CNN models, such as ResNet, Xception, and DensNet, to obtain the best recognition result for each model. Then, following the traditional fusion principle, voting and mean square error are considered as loss functions to fuse these three models to improve the recognition accuracy. To eliminate the influence of noise on skin disease recognition, and to heighten the accuracy and generalization ability of the proposed model, the maximum correntropy criterion (MCC) is used as the objective function of the multi-CNN fusion model, and the gradient ascent method is used to learn the contribution weight of different models according to the final results, thus a multi-CNN fusion model based on MCC is established. Experimental analysis is performed on the established basal cell carcinoma and seborrheic keratosis datasets. Compared with the prediction results of several single-model methods, the proposed multi-model fusion method achieves higher recognition accuracy. And compared with the traditional model fusion method, the proposed MCC-based multi-CNN fusion classification model gains strong generalization ability and can more effectively eliminate noise, it achieves an accuracy of 97.07%, exceeding that of the CNN single-model method and traditional multi-model fusion method. © 2019, Editorial Office of Journal of Xi'an Jiaotong University. All right reserved.",10.7652/xjtuxb201911018,Convolutional neural network; Dermatological recognition; Maximum correntropy criterion; Mean square error; Multi-model fusion method,4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076712032&doi=10.7652%2fxjtuxb201911018&partnerID=40&md5=12f7a58a69a4d2db824f38d4ff3cf298
Identification of Melanoma through Dermoscopy Image using Learning Vector Quantization,Purnamawati S.; Rahmat R.F.; Faza S.; Lumbantobing A.J.,2019,0,1,0,0,0,Unique,0,,,,,,,"Melanoma is one of the rare and malignant types of skin cancer. There are numerous ways to detect the melanoma, and one of them is through doctor diagnosis. A doctor can detect melanoma after a thorough medical check-up. If the patient has symptoms of melanoma, a biopsy will be carried out. This process requires a long time making it inconvenient. Therefore, an approach of the image processing system is necessary to assist the experts in diagnosing melanoma. The process consists of image input using the dermoscopy image, a pre-processing process of grey-scaling and median filtering, and feature extraction using Grey-Level Co-Occurrence Matrix (GLCM). In the final step, a classification process will be performed using learning vector quantization. Based on the experimental test, the system generated an accuracy of 83.33% in identifying melanoma cancer. © 2019 IOP Publishing Ltd. All rights reserved.",10.1088/1757-899X/648/1/012027,,1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075259098&doi=10.1088%2f1757-899X%2f648%2f1%2f012027&partnerID=40&md5=22057f810f54dc69fa7d214205cd64fb
Time-Independent Prediction of Burn Depth Using Deep Convolutional Neural Networks,Cirillo M.D.; Mirdell R.; Sjöberg F.; Pham T.D.,2019,0,1,0,0,0,Unique,0,,,,,,,"We present in this paper the application of deep convolutional neural networks (CNNs), which is a state-of-the-art artificial intelligence (AI) approach in machine learning, for automated time-independent prediction of burn depth. Color images of four types of burn depth injured in first few days, including normal skin and background, acquired by a TiVi camera were trained and tested with four pretrained deep CNNs: VGG-16, GoogleNet, ResNet-50, and ResNet-101. In the end, the best 10-fold cross-validation results obtained from ResNet-101 with an average, minimum, and maximum accuracy are 81.66, 72.06, and 88.06%, respectively; and the average accuracy, sensitivity, and specificity for the four different types of burn depth are 90.54, 74.35, and 94.25%, respectively. The accuracy was compared with the clinical diagnosis obtained after the wound had healed. Hence, application of AI is very promising for prediction of burn depth and, therefore, can be a useful tool to help in guiding clinical decision and initial treatment of burn wounds. © 2019 American Burn Association 2019. All rights reserved.",10.1093/jbcr/irz103,,42,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073579386&doi=10.1093%2fjbcr%2firz103&partnerID=40&md5=95bed82b45dcd709b7e96bbc31709715
Gabor wavelet-based deep learning for skin lesion classification,Serte S.; Demirel H.,2019,1,1,0,0,0,Unique,0,,,,,,,"Skin cancer cases are increasing and becoming one of the main problems worldwide. Skin cancer is known as a malignant type of skin lesion, and early detection and treatment are necessary. Malignant melanoma and seborrheic keratosis are known as common skin lesion types. A fast and accurate medical diagnosis of these lesions is crucial. In this study, a novel Gabor wavelet-based deep convolutional neural network is proposed for the detection of malignant melanoma and seborrheic keratosis. The proposed method is based on the decomposition of input images into seven directional sub-bands. Seven sub-band images and the input image are used as inputs to eight parallel CNNs to generate eight probabilistic predictions. Decision fusion based on the sum rule is utilized to classify the skin lesion. Gabor based approach provides directional decomposition where each sub-band gives isolated decisions that can be fused for improved overall performance. The results show that the proposed method outperforms alternative methods in the literature developed for skin cancer detection. © 2019 Elsevier Ltd",10.1016/j.compbiomed.2019.103423,Convolutional neural networks; Gabor wavelets; Model fusion,104,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071857392&doi=10.1016%2fj.compbiomed.2019.103423&partnerID=40&md5=e3cff57985f4a19665c6f9011ae34940
Varicose ulcer(C6) wound image tissue classification using multidimensional convolutional neural networks,Rajathi V.; Bhavani R.R.; Wiselin Jiji G.,2019,0,1,0,0,0,Unique,0,,,,,,,"Varicose ulcers occur due to improper functioning of venous valves in legs. These ulcers are the severe external signs of vein-related problems, such as chronic pain, leg swelling and leg heaviness. The aim of the proposed methodology is to increase better diagnosis and treatment results by computer-assisted tissue classification (granulation, slough, necrotic and epithelial) of varicose ulcer using the Multidimensional Convolutional Neural Network as a deep learning architecture. This work consists of (i) preprocessing to remove the flash light reflection from the RGB wound images, (ii) active contour segmentation to segment the wounded areas from the skin and (iii) Multidimensional convolutional neural network for which the segmented images and their corresponding ground truth images are given as input. After CNN training, the fully connected layer gives the output as segmented images which include different types of tissues which are to be predicted. The Multidimensional Convolutional Neural Network structure of the layer can be modified by defining the layer structure using Matlab functions to get more accurate results for tissue classification. The proposed approach is evaluated using metrics with efficient performance rates of average accuracy (99.55%), specificity (98.06%) and sensitivity (95.66%). Experiments conducted on varicose ulcer wound image aim to improve healing status and skin health conditions based on the texture of the tissue. © 2019, © 2019 The Royal Photographic Society.",10.1080/13682199.2019.1663083,active contour segmentation; Active venous ulcer; flash light removal; Multidimensional Convolutional Neural network,32,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074280974&doi=10.1080%2f13682199.2019.1663083&partnerID=40&md5=7bfbfd18fba87b00a6a2fff8aa269fe9
Deep Learning Based Integrated Classification and Image Retrieval System for Early Skin Cancer Detection,Layode O.; Alam T.; Rahman M.M.,2019,1,1,0,0,0,Unique,0,,,,,,,"Skin cancer is one of the most frequent cancers among human beings. Diagnosing an unknown skin lesion is the first step to determine appropriate treatment. This paper proposes an integrated classification and retrieval based Decision Support System (DSS) for skin cancer detection with an 'easy to use' user interface by applying fusion and ensemble techniques in deep feature spaces. The descriptiveness and discriminative power of features extracted from dermoscopic images are critical to achieve good classification and retrieval performances. In this work, several deep features are extracted based on using transfer learning in several pre-trained Convolutional Neural Networks (CNNs) and Logistic Regression and Support Vector Machine (SVM) models are built as ensembles of classifiers on top of these feature vectors. Furthermore, the content-based image retrieval (CBIR) technique uses the same deep features by fusing those in different feature combinations using a canonical correlation analysis. Based on image-based visual queries submitted by dermatologists, this system would respond by displaying relevant images of pigmented skin lesions of past cases as well as classifying the image category as different types of skin cancer. The system has been trained on a dermoscopic image dataset consists of 1300 images of ten different classes. The best classification (85%) and retrieval accuracies are achieved in a test data set when feature fusion and ensemble techniques are used in all available deep feature spaces. This integrated system would reduce the visual observation error of human operators and enhance clinical decision support for early screening of kin cancers.  © 2019 IEEE.",10.1109/AIPR47015.2019.9174586,Classification; Computer Aided Diagnosis; Deep Learning; Dermoscopy; Image Retrieval; Melanoma; Skin Cancer,10,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090853767&doi=10.1109%2fAIPR47015.2019.9174586&partnerID=40&md5=af4c652e6e2ec847e490eda87cd59736
Diagnosis of melanoma from dermoscopic images using a deep depthwise separable residual convolutional network,Sarkar R.; Chatterjee C.C.; Hazra A.,2019,0,1,0,0,0,Unique,0,,,,,,,"Melanoma is one of the four major types of skin cancers caused by malignant growth in the melanocyte cells. It is the rarest one, accounting to only 1% of all skin cancer cases. However, it is the deadliest among all the skin cancer types. Owing to its rarity, efficient diagnosis of the disease becomes rather difficult. Here, a deep depthwise separable residual convolutional algorithm is introduced to perform binary melanoma classification on a dermoscopic skin lesion image dataset. Prior to training the model with the dataset noise removal from the images using non-local means filter is performed followed by enhancement using contrast-limited adaptive histogram equilisation over discrete wavelet transform algorithm. Images are fed to the model as multi-channel image matrices with channels chosen across multiple color spaces based on their ability to optimize the performance of the model. Proper lesion detection and classification ability of the model are tested by monitoring the gradient weighted class activation maps and saliency maps, respectively. Dynamic effectiveness of the model is shown through its performance in multiple skin lesion image datasets. The proposed model achieved an ACC of 99.50% on international skin imaging collaboration (ISIC), 96.77% on PH2, 94.44% on DermIS and 95.23% on MED-NODE datasets. © The Institution of Engineering and Technology 2019.",10.1049/iet-ipr.2018.6669,,47,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073693636&doi=10.1049%2fiet-ipr.2018.6669&partnerID=40&md5=1c9ff2e38937093c1e181db673994047
HCET-G2: Dermoscopic Skin Lesion Segmentation via Hybrid Cross Entropy Thresholding using Gaussian and Gamma Distributions,Rawas S.; El-Zaart A.,2019,1,1,0,0,0,First occurrence,0,,,,,,,"Malignant melanoma has been seen as one of the most precarious form of human cancer. The detection of skin cancer in early stage can be helpful to save human life. Computer vision plays an important role in skin cancer detection. It has been proved its importance in detecting the cancer in its early stage which can be helpful to cure it. Accurate segmentation is one of the key steps in medical image diagnosis. Moreover, developing a precise segmentation of skin cancer images leads to better feature diagnosis, extractions, and classification. This paper develops a novel segmentation method for skin cancer images based on hybrid cross entropy thresholding techniques to find an optimum extraction of region that reflect the presence of skin cancer. The proposed methodology tackles the problem of finding the optimal thresholding using hybrid combination of both Gaussian and Gamma distributions. To evaluate the effectiveness of the proposed method, two benchmark skin lesion dermoscopic images datasets are: PH2 and ISIC 2017. The obtained results indicate that the proposed hybrid combination methodology gave better result and achieves 75% accuracy in skin cancer detection compared to other benchmark segmentation techniques. © 2019 IEEE.",10.1109/ICDS47004.2019.8942339,Dermoscopic; Gamma Distribution; Gaussian Distribution; Hybrid Distribution; Melanoma; Minimum Cross Entropy; Segmentation,7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078223876&doi=10.1109%2fICDS47004.2019.8942339&partnerID=40&md5=13a351c92534e227067c7a8776add03e
Disease Classification based on Dermoscopic Skin Images Using Convolutional Neural Network in Teledermatology System,Purnama I.K.E.; Hernanda A.K.; Ratna A.A.P.; Nurtanio I.; Hidayati A.N.; Purnomo M.H.; Nugroho S.M.S.; Rachmadi R.F.,2019,1,1,0,0,0,First occurrence,0,,,,,,,"We have proposed a system of classification and detection of skin diseases that can be applied to Teledermatology. This system will classify skin diseases on dermoscopic images using the Deep Learning algorithm, Convolutional Neural Network (CNN). Dermoscopic image data in this study from MNIST HAM10000 dataset which amounts to 10,015 images and published by International Skin Image Collaboration (ISIC). The dataset is divided into seven class of skin diseases which fall into the category of skin cancer. The image classification process will use two pre-trained CNN models, MobileNet v1 and Inception V3. The model results from the learning process will be applied to a web-classifier. The comparison of predictive accuracy shows that the web-classifier using the CNN Inception V3 model has an accuracy value of 72% while the web-classifier that uses the MobileNet v1 model has an accuracy value of 58%. © 2019 IEEE.",10.1109/CENIM48368.2019.8973303,Convolutional Neural Network; Deep Learning; Dermoscopic Image; Skin Diseases,16,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084436135&doi=10.1109%2fCENIM48368.2019.8973303&partnerID=40&md5=3a09de787a3b6f401b746585ae274968
Melanoma segmentation and classification using deep learning,Seeja R.D.; Suresh A.,2019,0,1,0,0,0,Unique,0,,,,,,,"Melanoma is the most destructive form of skin cancer. Early diagnosis of melanoma can be curable. At the same time accurate diagnosis is very essential because of the similarities of melanoma and benign lesions. Hence computerized recognition approaches are highly demanded for dermoscopy images. The main purpose of this research is to develop an automatic system to improve the classification performance of melanoma.The effectiveness of this framework is evaluated on ISBI 2016 Skin Lesion Analysis towards Melanoma Detection Challenge dataset. Initially deep learning based U-Net algorithm is used to segment the lesion region from the nearby healthy skin and then extract discriminate features with the help of Convolutional Neural Network. VGG16 Net algorithm is used to classify every lesion in a dermoscopic image as a Benign or Melanoma. Results are found from classification with and without segmented images. Classification with segmented images produces accuracy of 83.18%, Sensitivity of 95.53%, and specificity of 96.22%. Based on these values the deep learning based classification with segmented images produces better result and it helps to improve the diagnosis performance. The proposed method would constitute a valuable support for physicians in every day clinical practice. © BEIESP.",10.35940/ijitee.L2516.1081219,Convolutional Neural Networks; Deep learning; Dermoscopy; Lesion Segmentation; Melanoma,10,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073796526&doi=10.35940%2fijitee.L2516.1081219&partnerID=40&md5=b28c30ec02f3c60974189a4f6eb8feea
Artificial neural network based diagnostic system for melanoma skin cancer; [Melanom cilt kanseri için yapay sinir aǧi tabanli tani sistemi],Ileri R.; Latifoglu F.; Icer S.,2019,1,1,0,0,0,Unique,0,,,,,,,"Nowadays, skin cancer is a life-threatening disease that causes human death. The human body contains melanocytic cells and these cells are found in the skin. Abnormal growth of melanocytic cells causes skin cancer. This disease can be diagnosed by an expert dermatologist as a result of the interpretation of dermoscopy images by ABCD rule. Because the diagnosis is made by physicians, there are some problems such as misdiagnosis due to human errors. Therefore, in order to solve these problems, computer-assisted diagnosis is necessary to diagnose skin cancer to assist the doctor. The aim of this study was to determine melanoma skin cancer using image processing techniques. In the study, different Artificial Neural Network (ANN) models were applied and their classifier performances were obtained as Multilayer Perceptron (MLP) 99.8 %, Patern Recognition Neetwork 98.3 %, Support Vector Machines 96.7 % and K nearest neighborhood (KNN) 95 %. © 2019 IEEE.",10.1109/TIPTEKNO.2019.8894930,Artifical Neural Network; Image Processing; Skin Cancer,0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075591184&doi=10.1109%2fTIPTEKNO.2019.8894930&partnerID=40&md5=83bbef07ade7139675c4468b9eb3a6ab
Automated segmentation of pigmented skin lesions images for smartphone applications,Pirnog I.; Marcu I.; Oprea C.,2019,1,1,0,0,0,First occurrence,0,,,,,,,Automated prescreening of pigmented skin lesions is crucial for melanoma early detection and cure solution identification. All computer aided methods and applications use image segmentation for pigmentary lesion extraction. State of the art segmentation methods offer good results for macroscopic skin lesion images captured standard cameras. The aim of this paper is to address the pigmented skin lesion segmentation issue for images captured in uncontrolled environment using smartphone cameras. © 2019 IEEE.,10.1109/SMICND.2019.8923938,Active contours; Melanoma assessment; Saturation thresholding; Skin lesion segmentation; Smartphone applications,2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078474456&doi=10.1109%2fSMICND.2019.8923938&partnerID=40&md5=1035975c74e0cd5a8c58bfdd96d3bbba
Generating Synthetic Medical Images by Using GAN to Improve CNN Performance in Skin Cancer Classification,Sedigh P.; Sadeghian R.; Masouleh M.T.,2019,1,1,0,0,0,Unique,0,,,,,,,"One of the main reasons of slow progress in using deep learning methods for cancer detection is the lack of data, especially the annotated data which is usually used for supervised learning algorithms. This paper presents a Convolutional Neural Network (CNN) to detect skin cancer. The primary database which is used to train the designed CNN algorithm has 97 members (50 benign and 47 malignant), which are collected from the International Skin Imaging Collaboration (ISIC). In order to compensate the lack of data for training the proposed CNN algorithm, a Generative Adversarial Network (GAN) is designed to produce synthetic skin cancer images. The classification performance of the designed trained CNN without the obtained synthetic images is near 53%, but by adding the synthetic images to the primary database the performance of the model is increased to 71%. © 2019 IEEE.",10.1109/ICRoM48714.2019.9071823,Artificial Intelligence; Convlutional Neural Networks; Generative Adversarial Network; Skin Cancer Detection,61,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084359811&doi=10.1109%2fICRoM48714.2019.9071823&partnerID=40&md5=d5aa36554c165d37a0a7b67da507d50d
Bimodal Skin Cancer Image Segmentation Based on Different Parameter Shapes of Gamma Distribution,Kassem R.; Chehade W.E.H.; El-Zaart A.,2019,1,1,0,0,0,First occurrence,0,,,,,,,"Cancer describes a type of malady distinguished by uncontrolled growth and division of abnormal cells. Skin cancer is one the most commonly diagnosed cancer. Image-based computer aided diagnosis (CAD) systems have significant potential for screening and can help discover cancer in its earlier stages. The bottleneck of the CAD system is the skin image segmentation. Image thresholding techniques are the most used for image segmentation. Statistical approaches are widely used in image thresholding. Due to the simplicity of its mathematical formula, different skin image thresholding techniques used Gaussian distribution as a model of data image. However, that distribution has a limitation when the histogram modes of the image has non-symmetric shapes. Gamma distribution has symmetric and non-symmetric shapes and has been used to improve the skin image thresholding. That technique assumed that the shape of each mode in the histogram is constant. However, the shape of each mode in the skin image histogram can be vary inside the image itself. In this paper, our contribution is to use different parameter shape for each mode in order to improve the quality of skin cancer image segmentation. Experimental results showed that the improved technique has better results than existing techniques using performance measures. © 2019 IEEE.",10.1109/ICDS47004.2019.8942312,Gamma distribution; Segmentation; Skin Cancer; Thresholding,2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078229285&doi=10.1109%2fICDS47004.2019.8942312&partnerID=40&md5=987917fd1f104960d9d8d20f39ec4aa4
Convolutional Neural Networks for classifying skin lesions,Pai K.; Giridharan A.,2019,1,1,0,0,0,First occurrence,0,,,,,,,"The usage of Deep Learning has immensely increased in the present years. Convolutional Neural Networks, Recurrent Neural Networks, Generative Adversarial Networks, Variational Auto Encoders are among the prominent architectures in Deep Learning. Convolutional Neural Networks architecture has signified high accuracy and performance for image classification problems. On the other hand skin cancer if recognized or treated early is almost curable. The proposed model in the paper uses Convolutional Neural Networks to predict and classify seven different types of skin lesions. A website is developed for the real time usage of the model, which can predict the three most probable types of skin lesions for a given image. The observations and results are based on the experiment conducted using the MNIST:HAM10000 dataset which consists of 10000 labelled images. © 2019 IEEE.",10.1109/TENCON.2019.8929461,Computer Vision; Convolutional Neural Networks; Deep Learning; VGG,36,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077719507&doi=10.1109%2fTENCON.2019.8929461&partnerID=40&md5=8581d7aca0b545a5cfa01aad42ff198c
"Label-Free Non-linear Multimodal Optical Microscopy—Basics, Development, and Applications",Mazumder N.; Balla N.K.; Zhuo G.-Y.; Kistenev Y.V.; Kumar R.; Kao F.-J.; Brasselet S.; Nikolaev V.V.; Krivova N.A.,2019,0,1,0,0,0,Unique,0,,,,,,,"Non-linear optical (NLO) microscopy has proven to be a powerful tool especially for tissue imaging with sub-cellular resolution, high penetration depth, endogenous contrast specificity, pinhole-less optical sectioning capability. In this review, we discuss label-free non-linear optical microscopes including the two-photon fluorescence (TPF), fluorescence lifetime imaging microscopy (FLIM), polarization-resolved second harmonic generation (SHG) and coherent anti-Stokes Raman scattering (CARS) techniques with various samples. The non-linear signals are generated from collagen in tissue (SHG), amylopectin from starch granules (SHG), sarcomere structure of fresh muscle (SHG), elastin in skin (TPF), nicotinamide adenine dinucleotide (NADH) in cells (TPF), and lipid droplets in cells (CARS). Again, the non-linear signals are very specific to the molecular structure of the sample and its relative orientation to the polarization of the incident light. Thus, polarization-resolved non-linear optical microscopy provides high image contrast and quantitative estimate of sample orientation. An overview of the advancements on polarization-resolved SHG microscopy including Stokes vector based polarimetry, circular dichroism, and susceptibility are also presented in this review article. The working principles and corresponding implements of above-mentioned microscopy techniques are elucidated. The potential of time-resolved TPF lifetime imaging microscopy (TP-FLIM) is explored by imaging endogenous fluorescence of NAD(P)H, a key coenzyme in cellular metabolic processes. We also discuss single laser source time-resolved multimodal CARS-FLIM microscopy using time-correlated single-photon counting (TCSPC) in combination with continuum generation from photonic crystal fiber (PCF). Using examples, we demonstrate that the multimodal NLO microscopy is a powerful tool to assess the molecular specificity with high resolution. © Copyright © 2019 Mazumder, Balla, Zhuo, Kistenev, Kumar, Kao, Brasselet, Nikolaev and Krivova.",10.3389/fphy.2019.00170,coherent anti-stokes Raman scattering; collagen; fluorescence lifetime imaging; nicotinamide adenine dinucleotide; non-linear optical microscopy; second harmonic generation; two-photon fluorescence microscopy,43,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075240495&doi=10.3389%2ffphy.2019.00170&partnerID=40&md5=845188ad80e0b066bc72d8e176058646
Features for melanoma lesions: Extraction and classification,Vocaturo E.; Caroprese L.; Zumpano E.,2019,0,1,0,0,0,First occurrence,0,,,,,,,"Computer vision systems are increasingly used for the early detection of skin cancers. Recognizing the first sign of melanoma is very important because if melanoma is found and treated in its primary stage the chances for long-term survival are excellent. On the contrary, as it progresses its treatment becomes increasingly harder and it has worse outcome. The various proposals of computer vision systems are characterized by some fundamental common phases: image acquisition, pre-processing, segmentation, features extraction and finally classification. Feature extraction aims at extracting the features from the lesion image in order to characterize the melanoma and feed the classifier. The recent research provided many different feature extraction algorithms for melanoma diagnosis from dermoscopy images from the simplest to the most sophisticated. Features are typically extracted using digital image processing methods (i.e., segmentation, edge detection and color and structure processing), and an open discussion about the meaning of these features and the objective ways of measuring them is ongoing. This paper is a contribution to the feature extraction phase as it describes the most frequently used features in the elaboration of computer vision systems and reports a description of recent works for feature extraction and classification. © 2019 Association for Computing Machinery.",10.1145/3358695.3360898,Computer vision systems; Feature descriptor; Malignant melanoma; Medical image analysis,19,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074365642&doi=10.1145%2f3358695.3360898&partnerID=40&md5=31f09a8c6b74c5ebb449db3d1a699bf8
Ensembles of Convolutional Neural Networks for Skin Lesion Dermoscopy Images Classification,Hilmy M.A.; Sasongko P.S.,2019,1,1,0,0,0,Unique,0,,,,,,,"Skin cancer is a public health problem with more than 123, 000 new cases diagnosed worldwide every year. System skin cancer screening reliable automatic will provide a great help for doctors to detect skin lesions as early as possible. The efficiency of deep learning based methods has recently outperformed conventional image processing methods in terms of classification. This study applied an ensemble of CNN to classify 7 categories of skin lesions. The preprocessing stage is hair removal, image resizing, and image augmentation. Model evaluation results with 1, 440 test data indicate that the ensemble model achieve the best accuracy of 91.7% with a combination of learning rate parameters of le-3 and the use of dropouts in the model architecture. © 2019 IEEE.",10.1109/ICICoS48119.2019.8982484,convolutional neural network; deep learning; ensemble; skin lesions,10,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081107005&doi=10.1109%2fICICoS48119.2019.8982484&partnerID=40&md5=2fa4a9dc09e77ddd0a3d6fb0c2f879bb
Diagnosis methods of skin lesions in dermoscopic images: A survey,Zaqout I.,2019,1,1,0,0,0,Unique,0,,,,,,,"Extraordinary work has been placed into the advancement of finding strategies for the most perilous kind of skin diseases - Melanoma. Melanoma, generally called malignant melanoma, is a sort of malignant growth that is made from the pigment-covering cells known as melanocytes. This paper reviews the common diagnostic methods which are Menzies, 7-point checklist, CASH, ABCD, CHAOS, BLINCK, and TADA. These methods are used to segment and classify skin lesions into benign or malignant in dermoscopic images. © 2019 IEEE.",10.1109/ICPET.2019.00026,classification; Dermoscopy; segmentation; skin lesion,2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078019205&doi=10.1109%2fICPET.2019.00026&partnerID=40&md5=b831ef2e72c717ee747ba8f84256c977
Skin lesion segmentation by using deep learning techniques,Hasan S.N.; Gezer M.; Azeez R.A.; Gulsecen S.,2019,1,1,0,0,0,First occurrence,0,,,,,,,"Skin cancer is a common disease among middle-aged and elderly white-skinned people. It is divided into many types in terms of medical criteria. Malign melanoma is one of the most dangerous and fatal cancer types, it can be treated if detected early. The main focus of this paper is to provide a precise, effective, robust and automated way to segment the lesion in order to facilitate the classification of the lesion with high accuracy during the early diagnosis of skin cancer. This process consists of two stages. In the first stage, image processing techniques (Image Enhancement, Linear Filtering, and Image Restoration) are used to obtain images free of artifacts such as hair and ruler marks. The second stage which is the important part of this paper is to modify a U-Net architecture and propose a 46-layered structure of U-Net to obtain a successful lesion segmentation rate. In this study, experiments were performed on two different U-Net architectures (U-Net 32, and U-Net 46). © 2019 IEEE.",10.1109/TIPTEKNO.2019.8895078,Deep Learning; Dermoscopy Images; Dice-coefficient; Jaccard; Skin lesion; U-Net Convolutional Neural Network,22,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075619538&doi=10.1109%2fTIPTEKNO.2019.8895078&partnerID=40&md5=5f69a6e7424813f1dcd698e57fdd5543
Association between Surgical Skin Markings in Dermoscopic Images and Diagnostic Performance of a Deep Learning Convolutional Neural Network for Melanoma Recognition,Winkler J.K.; Fink C.; Toberer F.; Enk A.; Deinlein T.; Hofmann-Wellenhof R.; Thomas L.; Lallas A.; Blum A.; Stolz W.; Haenssle H.A.,2019,1,1,0,0,0,Unique,0,,,,,,,"Importance: Deep learning convolutional neural networks (CNNs) have shown a performance at the level of dermatologists in the diagnosis of melanoma. Accordingly, further exploring the potential limitations of CNN technology before broadly applying it is of special interest. Objective: To investigate the association between gentian violet surgical skin markings in dermoscopic images and the diagnostic performance of a CNN approved for use as a medical device in the European market. Design and Setting: A cross-sectional analysis was conducted from August 1, 2018, to November 30, 2018, using a CNN architecture trained with more than 120 000 dermoscopic images of skin neoplasms and corresponding diagnoses. The association of gentian violet skin markings in dermoscopic images with the performance of the CNN was investigated in 3 image sets of 130 melanocytic lesions each (107 benign nevi, 23 melanomas). Exposures: The same lesions were sequentially imaged with and without the application of a gentian violet surgical skin marker and then evaluated by the CNN for their probability of being a melanoma. In addition, the markings were removed by manually cropping the dermoscopic images to focus on the melanocytic lesion. Main Outcomes and Measures: Sensitivity, specificity, and area under the curve (AUC) of the receiver operating characteristic (ROC) curve for the CNN's diagnostic classification in unmarked, marked, and cropped images. Results: In all, 130 melanocytic lesions (107 benign nevi and 23 melanomas) were imaged. In unmarked lesions, the CNN achieved a sensitivity of 95.7% (95% CI, 79%-99.2%) and a specificity of 84.1% (95% CI, 76.0%-89.8%). The ROC AUC was 0.969. In marked lesions, an increase in melanoma probability scores was observed that resulted in a sensitivity of 100% (95% CI, 85.7%-100%) and a significantly reduced specificity of 45.8% (95% CI, 36.7%-55.2%, P <.001). The ROC AUC was 0.922. Cropping images led to the highest sensitivity of 100% (95% CI, 85.7%-100%), specificity of 97.2% (95% CI, 92.1%-99.0%), and ROC AUC of 0.993. Heat maps created by vanilla gradient descent backpropagation indicated that the blue markings were associated with the increased false-positive rate. Conclusions and Relevance: This study's findings suggest that skin markings significantly interfered with the CNN's correct diagnosis of nevi by increasing the melanoma probability scores and consequently the false-positive rate. A predominance of skin markings in melanoma training images may have induced the CNN's association of markings with a melanoma diagnosis. Accordingly, these findings suggest that skin markings should be avoided in dermoscopic images intended for analysis by a CNN. © 2019 American Medical Association. All rights reserved.",10.1001/jamadermatol.2019.1735,,262,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070989510&doi=10.1001%2fjamadermatol.2019.1735&partnerID=40&md5=e105d1488c35e7bcd835bf2645a3ce68
RethNet: Object-by-object learning for detecting facial skin problems,Bekmirzaev S.; Oh S.; Yo S.,2019,1,1,0,0,0,Unique,0,,,,,,,"Semantic segmentation is a hot topic in computer vision where the most challenging tasks of object detection and recognition have been handling by the success of semantic segmentation approaches. We propose a concept of objectby-object learning technique to detect 11 types of facial skin lesions using semantic segmentation methods. Detecting individual skin lesion in a dense group is a challenging task, because of ambiguities in the appearance of the visual data. We observe that there exist co-occurrent visual relations between object classes (e.g., wrinkle and age spot, or papule and whitehead, etc.). In fact, rich contextual information significantly helps to handle the issue. Therefore, we propose REthinker blocks that are composed of the locally constructed convLSTM/Conv3D layers and SE module as a one-shot attention mechanism whose responsibility is to increase network's sensitivity in the local and global contextual representation that supports to capture ambiguously appeared objects and co-occurrence interactions between object classes. Experiments show that our proposed model reached MIoU of 79.46% on the test of a prepared dataset, representing a 15.34% improvement over Deeplab v3+ (MIoU of 64.12%). © 2019 IEEE.",10.1109/ICCVW.2019.00054,Fine grained object categorization; Object detection; Semantic segmentation,3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082442702&doi=10.1109%2fICCVW.2019.00054&partnerID=40&md5=790bf0439a9dc52c7fc4257b8c26a93e
Melanoma segmentation using bio-medical image analysis for smarter mobile healthcare,Jamil U.; Sajid A.; Hussain M.; Aldabbas O.; Alam A.; Shafiq M.U.,2019,0,1,0,0,0,Unique,0,,,,,,,"Dermoscopy is an excellent method of detecting melanoma in its early stages. Skin is the principal organ of human body. It covers bones, muscles and all parts of the body. Melanoma is rare, but it is the most dangerous form of skin cancer. It is curable if it is detectedin its early stages. Digital dermoscopy help dermatologists in theexamination of cancerous skin lesions. It enables doctors to capture microscopic images of moles by using amobile phone, corresponding application or any handy scope device. Segmentation is used to divide the image into different segments. Segmentation, classification and feature extraction are the three fundamental stages of arecognition system that helps in matching the analysis of skin lesion. Melanoma occurs due to the presence of Melanocytes in the body. With the use of dermoscopy, the dermatologists can examine individual lesions more closely. In our paper, we have proposed an approach that can automatically preprocess the image and then segment the lesion.The gradient magnitude of the image is calculatedto filter the images. We have marked the foreground objects to segment the lesion from background precisely. The proposed technique is tested on European dataset of dermoscopic images. Results of segmented images are compared with other competitors to exhibit the superiority of the recommended approach. Matlab 2016a is used for successful simulation of the experiment. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.",10.1007/s12652-019-01218-0,,34,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061211791&doi=10.1007%2fs12652-019-01218-0&partnerID=40&md5=6534c2b4a88da2ec36578fd60f997c01
Melanoma identification with content based image classification using bit plane features,Das R.; Arshad M.; Manjhi P.K.; Mahanta H.S.,2019,0,1,0,0,0,Unique,0,,,,,,,"Augmented episodes of melanoma, a curable skin cancer variety of antagonistic nature, have stimulated the advancements in designing systems for computer aided diagnosis of the disease. Clinical diagnosis includes primary vetting of the symptoms followed by a biopsy and necessary medical examinations. However, computer based classification of the clinical images of dermoscopy have the potential to diminish the exertion of the dermatologist by offering a computer aided opinion independent of medical know-how. Assorted methods are proposed in recent times including the deep learning techniques for computer based melanoma recognition. But, most of the techniques have enhanced computational overhead which has added to the computational complexity of the entire system. In this work, the authors have attempted to design light-weight feature extraction techniques from high level bit planes of dermoscopic images by ignoring the noisy slices of bit planes for robust feature extraction. The proposed method of feature extraction is tested with three different classifiers for specificity and sensitivity outputs of the dermoscopic images. The results of classification have outclassed the performance of state-of-the-art feature extraction techniques. © BEIESP.",10.35940/ijitee.L2673.1081219,Binarization; Bit Plane; Classification; Dermoscopy; Medical Imaging; Melanoma; uLBP,0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073983717&doi=10.35940%2fijitee.L2673.1081219&partnerID=40&md5=9f59aa1b8fc843521b0f87c4661913d2
Adaptation and evaluation of deep learning techniques for skin segmentation on novel abdominal dataset,Topiwala A.; Al-Zogbi L.; Fleiter T.; Krieger A.,2019,1,1,0,0,0,First occurrence,0,,,,,,,"Skin segmentation plays an important role in a wide variety of biomedical image processing applications, such as skin cancer identification, skin lesion detection, and wound isolation. However, contemporary research has been mainly based on facial and hand skin datasets, with no other body regions considered for skin pixels sampling. Segmenting skin specifically in the abdominal region can aid in robotic abdominal surgeries and treatment procedures, such as robot-assisted laparoscopic surgeries and abdominal ultrasounds. A robust and highly accurate abdominal skin detection technique thus becomes imperative. To this end, we compiled a novel dataset of 1,400 segmented abdominal pictures and adapted and compared four abdominal skin segmentation techniques: one based on thresholding and three deep learning techniques, namely a fully connected neural network for pixel-level classification, and two convolution-based networks, U-Net and Mask-RCNN. We show that the U-Net model outperforms the other segmentation techniques, resulting in a pixel-to-pixel mean cross-validation accuracy of 95.51% on our Abdominal dataset. The incorporation of the Abdominal dataset in the training helped improve the abdominal skin segmentation accuracy by 10.19%. The U-Net model proved to be computationally the fastest, enabling real time skin segmentation with a processing rate of 37 frames per second. © 2019 IEEE.",10.1109/BIBE.2019.00141,Deep Learning; Semantic Skin Dataset; Semantic Skin Segmentation,20,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078574668&doi=10.1109%2fBIBE.2019.00141&partnerID=40&md5=7bc1b5319e4fee368fb934229d6ef1ce
Detection of melanoma with multiple machine learning classifiers in dermoscopy images; [Dermoskopik görüntülerdeki melanomun çoklu makine öǧrenmesi siniflandiricilari ile tespiti],Yildiz U.E.; Kilic V.,2019,0,1,0,0,0,Unique,0,,,,,,,"Skin cancer cases, in recent years, has become increasingly widespread because of increasing the effect of ultraviolet radiation as a result of thinning and perforation of the ozone layer in the atmosphere. The fact that melanoma, one of the most lethal types of skin cancer, can be treated at a high rate in early diagnosis has increased the interest in the studies in this field. In this study is focused on machine learning approaches that can be used in the diagnosis of melanoma in dermoscopic images. In the first step, color and texture features of images accessed from the dermoscopic image database were extracted with image processing techniques. In the second step, by using these features machine learning classifiers in different program environments have been trained and tested. Results from the proposed method indicated that melanoma can be detected with 97 % accuracy. © 2019 IEEE.",10.1109/TIPTEKNO.2019.8895042,Image processing; Machine learning; Melanoma,1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075621423&doi=10.1109%2fTIPTEKNO.2019.8895042&partnerID=40&md5=df4beeeefbf633595ccce8ee3bd019a5
An automatic classification of dermoscopy image with multilayer perceptron using weka,Angel N.; Sudha K.,2019,0,1,0,0,0,Unique,0,,,,,,,Skin cancer a distressing disease (or) an abnormality. The growth starts from the human body’s epidermis. Skin cancer treatments depend primarily upon the sign and location of the tumour. Computerized image analysis influences the accurate assessment of skin cancer in an effective manner. Skin cancer affects people in various parts of the body. A computer method on the pigment skin image should be examined to diagnose the skin cancer precisely. This is the dermatologist’s pre-screening system for early diagnosis. The associated and the proposed work is compared and examined. The proposed work gives the report on the classification of lesions from the dermoscopy images with basic steps such as pre-processing and classification. Here GLCM and Multilayer Perceptron analysis is used to differentiate the features. The simulation measures the accurate diagnosis of the image of ground truth and the segmented image and confirms the accuracy values up to 98% for Classification. © BEIESP.,10.35940/ijitee.L2539.1081219,Disceretize; GLCM; Multilayer Perceptron; Training; Weka,1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073786761&doi=10.35940%2fijitee.L2539.1081219&partnerID=40&md5=c12a957c04754c4df3ee02c387128a43
Computational diagnosis of skin lesions from dermoscopic images using combined features,Oliveira R.B.; Pereira A.S.; Tavares J.M.R.S.,2019,1,1,0,0,0,First occurrence,0,,,,,,,"There has been an alarming increase in the number of skin cancer cases worldwide in recent years, which has raised interest in computational systems for automatic diagnosis to assist early diagnosis and prevention. Feature extraction to describe skin lesions is a challenging research area due to the difficulty in selecting meaningful features. The main objective of this work is to find the best combination of features, based on shape properties, colour variation and texture analysis, to be extracted using various feature extraction methods. Several colour spaces are used for the extraction of both colour- and texture-related features. Different categories of classifiers were adopted to evaluate the proposed feature extraction step, and several feature selection algorithms were compared for the classification of skin lesions. The developed skin lesion computational diagnosis system was applied to a set of 1104 dermoscopic images using a cross-validation procedure. The best results were obtained by an optimum-path forest classifier with very promising results. The proposed system achieved an accuracy of 92.3%, sensitivity of 87.5% and specificity of 97.1% when the full set of features was used. Furthermore, it achieved an accuracy of 91.6%, sensitivity of 87% and specificity of 96.2%, when 50 features were selected using a correlation-based feature selection algorithm. © 2018, The Natural Computing Applications Forum.",10.1007/s00521-018-3439-8,Co-occurrence matrix; Discrete wavelet transform; Feature extraction and selection; Fractal dimension analysis,46,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044236718&doi=10.1007%2fs00521-018-3439-8&partnerID=40&md5=14537dd60081b0a8ac604e8861a7fa7b
Superior skin cancer classification by the combination of human and artificial intelligence,Hekler A.; Utikal J.S.; Enk A.H.; Hauschild A.; Weichenthal M.; Maron R.C.; Berking C.; Haferkamp S.; Klode J.; Schadendorf D.; Schilling B.; Holland-Letz T.; Izar B.; von Kalle C.; Fröhling S.; Brinker T.J.; Schmitt L.; Peitsch W.K.; Hoffmann F.; Becker J.C.; Drusio C.; Jansen P.; Lodde G.; Sammet S.; Sondermann W.; Ugurel S.; Zader J.; Salzmann M.; Schäfer S.; Schäkel K.; Winkler J.; Wölbing P.; Asper H.; Bohne A.-S.; Brown V.; Burba B.; Deffaa S.; Dietrich C.; Dietrich M.; Drerup K.A.; Egberts F.; Erkens A.-S.; Greven S.; Harde V.; Jost M.; Kaeding M.; Kosova K.; Lischner S.; Maagk M.; Messinger A.L.; Metzner M.; Motamedi R.; Rosenthal A.-C.; Seidl U.; Stemmermann J.; Torz K.; Velez J.G.; Haiduk J.; Alter M.; Bär C.; Bergenthal P.; Gerlach A.; Holtorf C.; Karoglan A.; Kindermann S.; Kraas L.; Felcht M.; Gaiser M.R.; Klemke C.-D.; Kurzen H.; Leibing T.; Müller V.; Reinhard R.R.; Winter F.; Eicher L.; Hartmann D.; Heppt M.; Kilian K.; Krammer S.; Lill D.; Niesert A.-C.; Oppel E.; Sattler E.; Senner S.; Wallmichrath J.; Wolff H.; Gesierich A.; Giner T.; Glutsch V.; Kerstan A.; Presser D.; Schrüfer P.; Schummer P.; Stolze I.; Weber J.; Drexler K.; Mickler M.; Stauner C.T.; Thiem A.,2019,1,1,0,0,0,Unique,0,,,,,,,"Background: In recent studies, convolutional neural networks (CNNs) outperformed dermatologists in distinguishing dermoscopic images of melanoma and nevi. In these studies, dermatologists and artificial intelligence were considered as opponents. However, the combination of classifiers frequently yields superior results, both in machine learning and among humans. In this study, we investigated the potential benefit of combining human and artificial intelligence for skin cancer classification. Methods: Using 11,444 dermoscopic images, which were divided into five diagnostic categories, novel deep learning techniques were used to train a single CNN. Then, both 112 dermatologists of 13 German university hospitals and the trained CNN independently classified a set of 300 biopsy-verified skin lesions into those five classes. Taking into account the certainty of the decisions, the two independently determined diagnoses were combined to a new classifier with the help of a gradient boosting method. The primary end-point of the study was the correct classification of the images into five designated categories, whereas the secondary end-point was the correct classification of lesions as either benign or malignant (binary classification). Findings: Regarding the multiclass task, the combination of man and machine achieved an accuracy of 82.95%. This was 1.36% higher than the best of the two individual classifiers (81.59% achieved by the CNN). Owing to the class imbalance in the binary problem, sensitivity, but not accuracy, was examined and demonstrated to be superior (89%) to the best individual classifier (CNN with 86.1%). The specificity in the combined classifier decreased from 89.2% to 84%. However, at an equal sensitivity of 89%, the CNN achieved a specificity of only 81.5% Interpretation: Our findings indicate that the combination of human and artificial intelligence achieves superior results over the independent results of both of these systems. © 2019 The Author(s)",10.1016/j.ejca.2019.07.019,Artificial intelligence; Deep learning; Melanoma; Skin cancer,292,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069037204&doi=10.1016%2fj.ejca.2019.07.019&partnerID=40&md5=aa8bc09e2f12f5764ae39331bb09cbbf
Bi-directional ConvLSTM U-net with densley connected convolutions,Azad R.; Asadi-Aghbolaghi M.; Fathy M.; Escalera S.,2019,0,1,0,0,0,First occurrence,0,,,,,,,"In recent years, deep learning-based networks have achieved state-of-the-art performance in medical image segmentation. Among the existing networks, U-Net has been successfully applied on medical image segmentation. In this paper, we propose an extension of U-Net, Bi-directional ConvLSTM U-Net with Densely connected convolutions (BCDU-Net), for medical image segmentation, in which we take full advantages of U-Net, bi-directional ConvLSTM (BConvLSTM) and the mechanism of dense convolutions. Instead of a simple concatenation in the skip connection of U-Net, we employ BConvLSTM to combine the feature maps extracted from the corresponding encoding path and the previous decoding up-convolutional layer in a non-linear way. To strengthen feature propagation and encourage feature reuse, we use densely connected convolutions in the last convolutional layer of the encoding path. Finally, we can accelerate the convergence speed of the proposed network by employing batch normalization (BN). The proposed model is evaluated on three datasets of: retinal blood vessel segmentation, skin lesion segmentation, and lung nodule segmentation, achieving state-of-the-art performance. © 2019 IEEE.",10.1109/ICCVW.2019.00052,BConvLSTM; Convolutional neural networks; Medical imaging; Semantic segmentation; U net,392,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082445435&doi=10.1109%2fICCVW.2019.00052&partnerID=40&md5=aff560860b47e08c517aea0c7a4d1505
Non-Invasive Bilirubin Level Quantification and Jaundice Detection by Sclera Image Processing,Miah M.M.M.; Tazim R.J.; Johora F.T.; Al Imran M.I.; Surma S.S.; Islam F.; Shabab R.; Shahnaz C.; Subhana A.,2019,0,1,0,0,0,Unique,0,,,,,,,"The yellow discoloration of the skin and sclera are the symptoms of excessive bilirubin in the blood. Bilirubin level in human body is increased when the blood system is not capable of removing the sufficient amount of bilirubin from the blood. Jaundice is only recognizable to the naked eye in severe stages, but a ubiquitous test using computer vision and machine learning can detect milder forms of jaundice. The conventional processes of measuring bilirubin level are time consuming, costly and invasive in nature. In this paper, an image processing based non-invasive technique for determining the bilirubin level in blood of human body is presented where the degree of yellowness of the sclera is used to quantify the level of bilirubin. The non-invasive technique can efficiently and quickly detect jaundice problem while reducing the pain compared to the conventional technique. However, the process presented in this paper is applicable mostly for adults. The total system is designed for a community clinic where the number of patients is large and the report of the bilirubin test as well as the treatment for the patients is to be provided at a very low cost within shortest possible time. © 2019 IEEE.",10.1109/GHTC46095.2019.9033059,bilirubin; hyperbilirubinemia; invasive; jaundice; neonatal; non-invasive; sclera; skin; yellowness,13,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082703021&doi=10.1109%2fGHTC46095.2019.9033059&partnerID=40&md5=b07ca033255804499420110f05f77c15
Segmentation of Skin Lesion Using Harris Corner Detection and Region Growing,Imtiaz I.; Ahmed I.; Ahmad M.; Ullah K.; Adnan A.; Ahmad M.,2019,1,1,0,0,0,First occurrence,0,,,,,,,"Nowadays skin diseases are considered as one of the common cause of human illness, and if not detected or diagnosed at early stage, it can be more harmful. With advancement in computer vision and image processing various techniques have been developed for diagnoses of skin diseases. This work mainly focused on simple yet effective technique for segmentation of skin lesions. It is also robust for extracting the region of interest whose background and foreground color is bit similar. It automatically segments skin lesion of arbitrary shapes and sizes. The proposed technique is mainly based on three major modules namely preprocessing, segmentation and post-processing. In pre-processing different color models are used for extraction of single channel followed by filtering to remove noise. In the second module, segmentation is preformed using Harris corner detector, seed selection and region growing segmentation. Finally morphological operation is performed as post-processing comprising of region filling and dilation. The experimentation results shows the performance of proposed model by achieving accuracy of 95%. © 2019 IEEE.",10.1109/UEMCON47517.2019.8993034,Harris corner detection; Region growing; Segmentation; Skin lesion,6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080115790&doi=10.1109%2fUEMCON47517.2019.8993034&partnerID=40&md5=ad71693f9215ccb02641228b6c0117ff
Segmentation of Lesion in Dermoscopy Images Using Dense-Residual Network with Adversarial Learning,Tu W.; Liu X.; Hu W.; Pan Z.; Xu X.; Li B.,2019,0,1,0,0,0,First occurrence,0,,,,,,,"In the field of medical images, skin lesion segmentation in dermoscopic images is a challenging task due to the irregular and blurring edges of the lesion and the presence of various artifacts. With the successful application of generative antagonistic network (GAN), a new neural network for skin lesion segmentation is proposed. The encoder-decoder with Dense-Residual block is used in the segmentation network which enables the network to be trained more efficiently. A multi-scale objective loss function is introduced to utilize deep supervision. We combine Jaccard distance and End Point Error which can solve lesion-background imbalance problem in pixel-level classification for skin lesion segmentation and also alleviate the problem of boundary ambiguity. A joint loss function is finally used, which includes a multi-scale objective loss function, End Point Error and Jaccard distance content loss function. Experiment results show that our algorithm is superior to other state-of-the-art algorithms on the ISBI2017. © 2019 IEEE.",10.1109/ICIP.2019.8803029,adversarial learning; convolutional neural networks; Dense-Residual block; dermoscopic image; skin lesion,7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076809676&doi=10.1109%2fICIP.2019.8803029&partnerID=40&md5=dc5879556d6240f5219a8bee34ce03b1
Systematic outperformance of 112 dermatologists in multiclass skin cancer image classification by convolutional neural networks,Maron R.C.; Weichenthal M.; Utikal J.S.; Hekler A.; Berking C.; Hauschild A.; Enk A.H.; Haferkamp S.; Klode J.; Schadendorf D.; Jansen P.; Holland-Letz T.; Schilling B.; von Kalle C.; Fröhling S.; Gaiser M.R.; Hartmann D.; Gesierich A.; Kähler K.C.; Wehkamp U.; Karoglan A.; Bär C.; Brinker T.J.; Schmitt L.; Peitsch W.K.; Hoffmann F.; Becker J.C.; Drusio C.; Lodde G.; Sammet S.; Sondermann W.; Ugurel S.; Zader J.; Salzmann M.; Schäfer S.; Schäkel K.; Winkler J.; Wölbing P.; Asper H.; Bohne A.-S.; Brown V.; Burba B.; Deffaa S.; Dietrich C.; Dietrich M.; Drerup K.A.; Egberts F.; Erkens A.-S.; Greven S.; Harde V.; Jost M.; Kaeding M.; Kosova K.; Lischner S.; Maagk M.; Messinger A.L.; Metzner M.; Motamedi R.; Rosenthal A.-C.; Seidl U.; Stemmermann J.; Torz K.; Velez J.G.; Haiduk J.; Alter M.; Bergenthal P.; Gerlach A.; Holtorf C.; Kindermann S.; Kraas L.; Felcht M.; Klemke C.-D.; Kurzen H.; Leibing T.; Müller V.; Reinhard R.R.; Winter F.; Eicher L.; Heppt M.; Kilian K.; Krammer S.; Lill D.; Niesert A.-C.; Oppel E.; Sattler E.; Senner S.; Wallmichrath J.; Wolff H.; Giner T.; Glutsch V.; Kerstan A.; Presser D.; Schrüfer P.; Schummer P.; Stolze I.; Weber J.; Drexler K.; Mickler M.; Stauner C.T.; Thiem A.,2019,1,1,0,0,0,Unique,0,,,,,,,"Background: Recently, convolutional neural networks (CNNs) systematically outperformed dermatologists in distinguishing dermoscopic melanoma and nevi images. However, such a binary classification does not reflect the clinical reality of skin cancer screenings in which multiple diagnoses need to be taken into account. Methods: Using 11,444 dermoscopic images, which covered dermatologic diagnoses comprising the majority of commonly pigmented skin lesions commonly faced in skin cancer screenings, a CNN was trained through novel deep learning techniques. A test set of 300 biopsy-verified images was used to compare the classifier's performance with that of 112 dermatologists from 13 German university hospitals. The primary end-point was the correct classification of the different lesions into benign and malignant. The secondary end-point was the correct classification of the images into one of the five diagnostic categories. Findings: Sensitivity and specificity of dermatologists for the primary end-point were 74.4% (95% confidence interval [CI]: 67.0–81.8%) and 59.8% (95% CI: 49.8–69.8%), respectively. At equal sensitivity, the algorithm achieved a specificity of 91.3% (95% CI: 85.5–97.1%). For the secondary end-point, the mean sensitivity and specificity of the dermatologists were at 56.5% (95% CI: 42.8–70.2%) and 89.2% (95% CI: 85.0–93.3%), respectively. At equal sensitivity, the algorithm achieved a specificity of 98.8%. Two-sided McNemar tests revealed significance for the primary end-point (p < 0.001). For the secondary end-point, outperformance (p < 0.001) was achieved except for basal cell carcinoma (on-par performance). Interpretation: Our findings show that automated classification of dermoscopic melanoma and nevi images is extendable to a multiclass classification problem, thus better reflecting clinical differential diagnoses, while still outperforming dermatologists at a significant level (p < 0.001). © 2019 The Author(s)",10.1016/j.ejca.2019.06.013,Artificial intelligence; Melanoma; Skin cancer; Skin cancer screening,182,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069038904&doi=10.1016%2fj.ejca.2019.06.013&partnerID=40&md5=a73968ddeacb3e9da8e3bd76141493b4
AI Recognition in Skin Pathologies Detection,Gavrilov D.; Lazarenko L.; Zakirov E.,2019,1,1,0,0,0,First occurrence,0,,,,,,,"Skin cancer is the most common type of cancer [1]. Between different malignant skin pathology melanoma is the most fleeting and mortality. Despite the superficial location of pathologies, only half of patients seek medical assistance on the early stages[2]. Treatment on the early (epidermal) stage provides a significantly higher chance of recovery. To assist a wide range of people in the early skin cancer detection, a software package was developed. The software based on deep convolutional neural networks technology. This complex allows to classify normal and malignant pathology on the uploaded photos. In clinical practice doctors use the ABCDE symptom's complex. This complex characterizes the observation of pigment spot asymmetry, border irregularities, color unevenness, diameter, and evolution [3]. The machine learning approach involves the computer evaluating similar factors when processing multiple images of different skin formations. The paper presents an algorithm for classification of skin lesions into pathology and norm using convolutional neural network architecture Xception with prior images segmentation. The upper classifying layers were frozen and new ones were added to classify skin diseases in the pre-trained neural network Xception. As a result, the classification of benign and malignant skin tumors provided at least 89% accuracy. At the moment, the result of research work is designed in form of application software that allows to download the image of pigmented skin spots from the camera. It is available on http://skincheckup.online. © 2019 IEEE.",10.1109/IC-AIAI48757.2019.00017,artificial intelligence; CNN; medical information systems; neural networks; Preventive care; recommendation systems,17,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081593633&doi=10.1109%2fIC-AIAI48757.2019.00017&partnerID=40&md5=23f1f3bb153f9762bd6217c3d06021a9
Region Extraction and Classification of Skin Cancer: A Heterogeneous framework of Deep CNN Features Fusion and Reduction,Saba T.; Khan M.A.; Rehman A.; Marie-Sainte S.L.,2019,1,1,0,0,0,First occurrence,0,,,,,,,"Cancer is one of the leading causes of deaths in the last two decades. It is either diagnosed malignant or benign – depending upon the severity of the infection and the current stage. The conventional methods require a detailed physical inspection by an expert dermatologist, which is time-consuming and imprecise. Therefore, several computer vision methods are introduced lately, which are cost-effective and somewhat accurate. In this work, we propose a new automated approach for skin lesion detection and recognition using a deep convolutional neural network (DCNN). The proposed cascaded design incorporates three fundamental steps including; a) contrast enhancement through fast local Laplacian filtering (FlLpF) along HSV color transformation; b) lesion boundary extraction using color CNN approach by following XOR operation; c) in-depth features extraction by applying transfer learning using Inception V3 model prior to feature fusion using hamming distance (HD) approach. An entropy controlled feature selection method is also introduced for the selection of the most discriminant features. The proposed method is tested on PH2 and ISIC 2017 datasets, whereas the recognition phase is validated on PH2, ISBI 2016, and ISBI 2017 datasets. From the results, it is concluded that the proposed method outperforms several existing methods and attained accuracy 98.4% on PH2 dataset, 95.1% on ISBI dataset and 94.8% on ISBI 2017 dataset. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.",10.1007/s10916-019-1413-3,Augmentation; Boundary extraction; Contrast improvement; Deep learning; Features selection; Skin cancer,235,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069492342&doi=10.1007%2fs10916-019-1413-3&partnerID=40&md5=e98d2ad9f2cf636652f747392f27d0f5
Class Centroid Based Convolutional Neural Network for Skin Cancer Detection,Nugroho K.A.,2019,1,1,0,0,0,Unique,0,,,,,,,"Detecting skin cancer from dermoscopy image is oneamong applications where deep neural network has been the state of the art. In contrast to previous studies which addressed lesion segmentation or ensemble learning, the proposed study aims to evaluate a network training method which minimizes the distance between instance and a pre-defined class centroid via regression. A fine-Tuned classification network and a non-finetuned network were also evaluated for comparison. The results demonstrated that the proposed strategy performed comparably equal to the classification network which optimized with cross entropy loss function. Moreover, principal component analysis was also performed to better understand the characteristics of the generated features. The visualization of principal components indicates that regression network generated different pattern compared to the classification network. © 2019 IEEE.",10.1109/BioMIC48413.2019.9034872,centroid; regression; ResNet,1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083275603&doi=10.1109%2fBioMIC48413.2019.9034872&partnerID=40&md5=46d49395ee89ddab8a32539fe06152e3
Skin lesion segmentation in dermoscopic images with combination of yolo and grabcut algorithm,Ünver H.M.; Ayan E.,2019,1,1,0,0,0,Unique,0,,,,,,,"Skin lesion segmentation has a critical role in the early and accurate diagnosis of skin cancer by computerized systems. However, automatic segmentation of skin lesions in dermoscopic images is a challenging task owing to difficulties including artifacts (hairs, gel bubbles, ruler markers), indistinct boundaries, low contrast and varying sizes and shapes of the lesion images. This paper proposes a novel and effective pipeline for skin lesion segmentation in dermoscopic images combining a deep convolutional neural network named as You Only Look Once (YOLO) and the GrabCut algorithm. This method performs lesion segmentation using a dermoscopic image in four steps: 1. Removal of hairs on the lesion, 2. Detection of the lesion location, 3. Segmentation of the lesion area from the background, 4. Post-processing with morphological operators. The method was evaluated on two publicly well-known datasets, that is the PH2 and the ISBI 2017 (Skin Lesion Analysis Towards Melanoma Detection Challenge Dataset). The proposed pipeline model has achieved a 90% sensitivity rate on the ISBI 2017 dataset, outperforming other deep learning-based methods. The method also obtained close results according to the results obtained from other methods in the literature in terms of metrics of accuracy, specificity, Dice coefficient, and Jaccard index. © 2019 by the authors.",10.3390/diagnostics9030072,Convolutional neural networks; GrabCut; Melanoma; Skin cancer; Skin lesion segmentation; Yolo,245,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072617653&doi=10.3390%2fdiagnostics9030072&partnerID=40&md5=fc2895624d15216353c9f1b30199e309
Dermoscopic Image Segmentation Through the Enhanced High-Level Parsing and Class Weighted Loss,Wang X.; DIng H.; Jiang X.,2019,0,1,0,0,0,First occurrence,0,,,,,,,"Accurate skin lesion segmentation plays an important role in the computer aided analysis of melanoma. It is a challenging task due to the variation of skin lesion appearance, the low contrast with background, and the existence of the artifacts in dermoscopic images. In this paper, we try to boost the skin lesion segmentation performance based on the fully convolutional neural network. To this end, we first propose an enhanced high-level parsing (EHP) module to generate meaningful feature representation for skin lesion and make more precise delineation of the detailed lesion structure. Furthermore, to handle the imbalance data distribution of skin lesion and background, we propose a class weighted loss (CWL) to achieve more consistent lesion prediction. Experiment results evaluated on ISBI 2017 database demonstrate the effectiveness and robustness of the proposed architecture on skin lesion segmentation, achieving new state-of-the-art prediction performance. © 2019 IEEE.",10.1109/ICIP.2019.8802999,class weighed loss; enhanced high-level parsing; fully convolutional neural network; Skin lesion segmentation,11,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076813391&doi=10.1109%2fICIP.2019.8802999&partnerID=40&md5=c060c0a1b77fd3c1ae89be6ace25fc17
Skin disorder diagnosis with ambiguity reduction assisted by lesion color adaptation,Petrellis N.,2019,1,1,0,0,0,Unique,0,,,,,,,"A smart phone application based on a low complexity image processing technique and a novel fuzzy-like classification method are presented for skin disorder diagnosis. The proposed classification method takes into consideration the size and color features of skin lesions rather than their shape and texture. The classification rules are determined after processing statistically a small number of representative training photographs. Consequently, they can be defined by an end user that is not necessarily skilled in computer science. The application presented in this paper can serve as a complementary tool for a dermatologist to continuously monitor remotely his patients. The accuracy of the diagnosis that is based only on the image processing outcomes, ranges between 85.3% and 97.7% using 5 only representative photographs as a “training set” (corresponding from 9% to 24% of the test set per disease). The achieved accuracy can be improved (up to 17%), if the photographs are processed using a specific color adaptation technique. The small fraction of training photographs can be scaled up if the size of the test set is increased but it is expected that a limited number of training photographs will be sufficient in order to achieve an acceptable accuracy for a test set of any size. This accuracy can be further improved if other factors are taken into consideration (progression of the symptoms, information provided by the user, etc). © 2019 the Author(s), licensee AIMS Press.",10.3934/ElectrEng.2019.3.290,Color adaptation; Histograms; Image processing; Lesions; Mobile apps; Skin disorders; Skin infections,0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091247798&doi=10.3934%2fElectrEng.2019.3.290&partnerID=40&md5=e9e29fce3262056e697b09fa5d40da1b
Artificial Intelligence in Skin Cancer,Reiter O.; Rotemberg V.; Kose K.; Halpern A.C.,2019,1,1,0,0,0,First occurrence,0,,,,,,,"Purpose: To review recent developments in artificial intelligence for skin cancer diagnosis. Recent Findings: Major breakthroughs in recent years are likely related to advancements in utilization of convolutional neural networks (CNNs) for dermatologic image analysis, especially dermoscopy. Recent studies have shown that CNN-based approaches perform as well as or even better than human raters in diagnosing close-up and dermoscopic images of skin lesions in a simulated static environment. Several limitations for the development of AI include the need for large data pipelines and ground truth diagnoses, lack of metadata, and lack of rigorous widely accepted standards. Summary: Despite recent breakthroughs, adoption of AI in clinical settings for dermatology is in early stages. Close collaboration between researchers and clinicians may provide the opportunity to investigate implementation of AI in clinical settings to provide real benefit for both clinicians and patients. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.",10.1007/s13671-019-00267-0,Artificial intelligence; Convolutional neural networks; Machine learning; Melanoma; Non-melanoma skin cancer; Skin cancer,18,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069684462&doi=10.1007%2fs13671-019-00267-0&partnerID=40&md5=3ae2b1f8cc56b72888e1b0d61646894b
Mammogram segmentation methods: A brief review,Padhi S.; Rup S.; Saxena S.; Mohanty F.,2019,0,1,0,0,0,First occurrence,0,,,,,,,"Being the prime reason, after skin cancer, of high mortality rate among women in present day, breast cancer requires correct diagnosis and precise treatment at its earliest stage. From the time of the advent of diagnosis tools, medical practitioners have left no stone unturned in their efforts of delivering timely medication to the patients; but often human error has resulted in either death due to dosage of medicines resulting from wrongly detected malignancies or due to negligence arising from not detecting the tumors at the right time. Hence, computer-aided diagnosis (CADx) has come into light as a key tool in statistically analyzing medical images obtained from various imaging machines and classifying the specimens into the categories of normal, benign, and malignant. A major step involved in it is the segmentation of the medical image into various regions and determining the required region-of-interest (ROI) from them. Automated image segmentation is quintessential today in order to extract the correct suspicious regions for diagnosis, instead of relying on erroneous human eye judgment. The following study aims to compare and analyze the effectiveness of some existing segmentation methods used to extract the ROIs for analysis of digital mammograms for breast cancer detection. © 2019 IEEE.",10.1109/ICCT46177.2019.8968781,Breast cancer; Computer-aided diagnosis; Digital mammography; Medical Imaging; Segmentation,3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079273664&doi=10.1109%2fICCT46177.2019.8968781&partnerID=40&md5=9585bea723447e5b8874fc566374e68e
Efficient skin lesion segmentation using separable-Unet with stochastic weight averaging,Tang P.; Liang Q.; Yan X.; Xiang S.; Sun W.; Zhang D.; Coppola G.,2019,1,1,0,0,0,Unique,0,,,,,,,"Background and objective: Efficient segmentation of skin lesion in dermoscopy images can improve the classification accuracy of skin diseases, which provides a powerful approach for the dermatologists in examining pigmented skin lesions. However, the segmentation is challenging due to the low contrast of skin lesions from a captured image, fuzzy and indistinct lesion boundaries, huge variety of interclass variation of melanomas, the existence of artifacts, etc. In this work, an efficient and accurate melanoma region segmentation method is proposed for computer-aided diagnostic systems. Method: A skin lesion segmentation (SLS) method based on the separable-Unet with stochastic weight averaging is proposed in this work. Specifically, the proposed Separable-Unet framework takes advantage of the separable convolutional block and U-Net architectures, which can extremely capture the context feature channel correlation and higher semantic feature information to enhance the pixel-level discriminative representation capability of fully convolutional networks (FCN). Further, considering that the over-fitting is a local optimum (or sub-optimum) problem, a scheme based on stochastic weight averaging is introduced, which can obtain much broader optimum and better generalization. Results: The proposed method is evaluated in three publicly available datasets. The experimental results showed that the proposed approach segmented the skin lesions with an average Dice coefficient of 93.03% and Jaccard index of 89.25% for the International Skin Imaging Collaboration (ISIC) 2016 Skin Lesion Challenge (SLC) dataset, 86.93% and 79.26% for the ISIC 2017 SLC, and 94.13% and 89.40% for the PH2 dataset, respectively. The proposed approach is compared with other state-of-the-art methods, and the results demonstrate that the proposed approach outperforms them for SLS on both melanoma and non-melanoma cases. Segmentation of a potential lesion with the proposed approach in a dermoscopy image requires less than 0.05 s of processing time, which is roughly 30 times faster than the second best method (regarding the value of Jaccard index) for the ISIC 2017 dataset with the same hardware configuration. Conclusions: We concluded that using the separable convolutional block and U-Net architectures with stochastic weight averaging strategy could enable to obtain better pixel-level discriminative representation capability. Moreover, the considerably decreased computation time suggests that the proposed approach has potential for practical computer-aided diagnose systems, besides provides a segmentation for the specific analysis with improved segmentation performance. © 2019 Elsevier B.V.",10.1016/j.cmpb.2019.07.005,Real-time segmentation; Separable convolutional block; Skin lesion segmentation; Stochastic weight averaging,160,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068764142&doi=10.1016%2fj.cmpb.2019.07.005&partnerID=40&md5=73a61d2972e6941d7a2cd0006657e017
Classification of Skin Lesions by using Extended-Incremental Convolutional Neural Network,Chopade A.,2019,1,1,0,0,0,Unique,0,,,,,,,"Order of skin sores in different dangerous sort assumes a pivotal job in diagnosing different, neighborhood and quality related, ailments in the field of therapeutic science. Grouping of these sores in a few carcinogenic sorts i.e Melanoma(MEL), Melanomic Neves(NV), Basal Cell Carcinoma(BCC), Actinic Keratosis(AKIEC), Benign Keratosis(BKL )Dermatofibroma(DF) and Vascular Lesion(VASC) gives some understanding about the infection. Skin malignancy is the most deadly kind of malignancy however in the event that these infections are recognized in beginning times, at that point patients can have a high recurrence of recuperation. A few ways to deal with programmed arrangement have been investigated by numerous creators, utilizing different systems and methodologies however this paper proposed an extended version of novel Incremental methodology for Convolution Neural Network on dermoscopy pictures for characterization of skin sores in different skin malignant growths. This is a summed up methodologym subsequently can be executed in different calculations for accomplishing higher exactness. Worldwide Skin Imaging Collaboration (ISIC) 2018 test dataset is utilized in this paper. The methodology utilized in this paper yields an accuracy of more than 95%. © 2019 IEEE.",10.1109/ICICT46931.2019.8977638,Dermoscopy image; Extended Incremental Convolutional Neural Network(ICNN); Incremental Convolutional Neural Network(ICNN); Lesion classification; Skin lesions,4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084946368&doi=10.1109%2fICICT46931.2019.8977638&partnerID=40&md5=3ffb3d4cdcb620e4463716aaf1a38717
Clinical image identification of basal cell carcinoma and pigmented nevi based on convolutional neural network,Xie B.; He X.; Huang W.; Shen M.; Li F.; Zhao S.,2019,0,1,0,0,0,Unique,0,,,,,,,"Objective: To construct an intelligent assistant diagnosis model based on the clinical images of basal cell carcinoma (BCC) and pigmented nevi in Chinese by using the advanced convolutional neural network (CNN). Methods: Based on the Xiangya Medical Big Data Platform, we constructed a large-scale clinical irflage dataset of skin diseases according to Chinese ethnicity and the Xiangya Skin Disease Dataset. We evaluated the performance of 5 mainstream CNN models (ResNet50, InceptionV3, InceptionResNetV2, DenseNetl21, and Xception) on a subset of BCC and pigmented nevi of this dataset. We also analyzed the basis of the diagnosis results in the form of heatmaps. We compared the optimal CNN classification model with 30 professional dermatologists. Results: The Xiangya Skin Disease Dataset contains 150 223 clinical images with lesion annotations, covering 543 skin diseases, and each image in the dataset contains support for pathological gold standards and the patient's overall medical history. On the test set of 349 BCC and 497 pigmented nevi, the optimal CNN model was Xception, and its classification accuracy can reach 93.596, of which the area under curve (AUC) values were 0.974 and 0.969, respectively. The results of the heatmap showed that the CNN model can indeed learn the characteristics associated with disease identification. The ability of the Xception model to identify clinical images of BCC and Nevi was basically comparable to that of professional dermatologists. Conclusion: This study is the first assistant diagnosis study for skin tumor based on Chinese ethnic clinical dataset. It proves that CNN model has the ability to distinguish between Chinese ethnicity's BCC and Nevi, and lays a solid foundation for the following application of artificial intelligence in the diagnosis and treatment for skin tumors. © 2019 Journal of Central South University (Medical Sciences). All rights reserved.",10.11817/j.issn.1672-7347.2019.190205,Artificial intelligence; Assistant diagnosis; Basal cell carcinoma; Chinese ethnicity; Clinical image; Convolutional neural network; Pigmented nevi,10,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074115592&doi=10.11817%2fj.issn.1672-7347.2019.190205&partnerID=40&md5=90b8bad830ab6016d539d735bec2c138
Attention Residual Learning for Skin Lesion Classification,Zhang J.; Xie Y.; Xia Y.; Shen C.,2019,1,1,0,0,0,First occurrence,0,,,,,,,"Automated skin lesion classification in dermoscopy images is an essential way to improve the diagnostic performance and reduce melanoma deaths. Although deep convolutional neural networks (DCNNs) have made dramatic breakthroughs in many image classification tasks, accurate classification of skin lesions remains challenging due to the insufficiency of training data, inter-class similarity, intra-class variation, and the lack of the ability to focus on semantically meaningful lesion parts. To address these issues, we propose an attention residual learning convolutional neural network (ARL-CNN) model for skin lesion classification in dermoscopy images, which is composed of multiple ARL blocks, a global average pooling layer, and a classification layer. Each ARL block jointly uses the residual learning and a novel attention learning mechanisms to improve its ability for discriminative representation. Instead of using extra learnable layers, the proposed attention learning mechanism aims to exploit the intrinsic self-attention ability of DCNNs, i.e., using the feature maps learned by a high layer to generate the attention map for a low layer. We evaluated our ARL-CNN model on the ISIC-skin 2017 dataset. Our results indicate that the proposed ARL-CNN model can adaptively focus on the discriminative parts of skin lesions, and thus achieve the state-of-the-art performance in skin lesion classification.",10.1109/TMI.2019.2893944,,481,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062898963&doi=10.1109%2fTMI.2019.2893944&partnerID=40&md5=4292b7208774e9bf18f5c5414795c1fa
Automated deep learning design for medical image classification by health-care professionals with no coding experience: a feasibility study,Faes L.; Wagner S.K.; Fu D.J.; Liu X.; Korot E.; Ledsam J.R.; Back T.; Chopra R.; Pontikos N.; Kern C.; Moraes G.; Schmid M.K.; Sim D.; Balaskas K.; Bachmann L.M.; Denniston A.K.; Keane P.A.,2019,0,1,0,0,0,Unique,0,,,,,,,"Background: Deep learning has the potential to transform health care; however, substantial expertise is required to train such models. We sought to evaluate the utility of automated deep learning software to develop medical image diagnostic classifiers by health-care professionals with no coding—and no deep learning—expertise. Methods: We used five publicly available open-source datasets: retinal fundus images (MESSIDOR); optical coherence tomography (OCT) images (Guangzhou Medical University and Shiley Eye Institute, version 3); images of skin lesions (Human Against Machine [HAM] 10000), and both paediatric and adult chest x-ray (CXR) images (Guangzhou Medical University and Shiley Eye Institute, version 3 and the National Institute of Health [NIH] dataset, respectively) to separately feed into a neural architecture search framework, hosted through Google Cloud AutoML, that automatically developed a deep learning architecture to classify common diseases. Sensitivity (recall), specificity, and positive predictive value (precision) were used to evaluate the diagnostic properties of the models. The discriminative performance was assessed using the area under the precision recall curve (AUPRC). In the case of the deep learning model developed on a subset of the HAM10000 dataset, we did external validation using the Edinburgh Dermofit Library dataset. Findings: Diagnostic properties and discriminative performance from internal validations were high in the binary classification tasks (sensitivity 73·3–97·0%; specificity 67–100%; AUPRC 0·87–1·00). In the multiple classification tasks, the diagnostic properties ranged from 38% to 100% for sensitivity and from 67% to 100% for specificity. The discriminative performance in terms of AUPRC ranged from 0·57 to 1·00 in the five automated deep learning models. In an external validation using the Edinburgh Dermofit Library dataset, the automated deep learning model showed an AUPRC of 0·47, with a sensitivity of 49% and a positive predictive value of 52%. Interpretation: All models, except the automated deep learning model trained on the multilabel classification task of the NIH CXR14 dataset, showed comparable discriminative performance and diagnostic properties to state-of-the-art performing deep learning algorithms. The performance in the external validation study was low. The quality of the open-access datasets (including insufficient information about patient flow and demographics) and the absence of measurement for precision, such as confidence intervals, constituted the major limitations of this study. The availability of automated deep learning platforms provide an opportunity for the medical community to enhance their understanding in model development and evaluation. Although the derivation of classification models without requiring a deep understanding of the mathematical, statistical, and programming principles is attractive, comparable performance to expertly designed models is limited to more elementary classification tasks. Furthermore, care should be placed in adhering to ethical principles when using these automated models to avoid discrimination and causing harm. Future studies should compare several application programming interfaces on thoroughly curated datasets. Funding: National Institute for Health Research and Moorfields Eye Charity. © 2019 The Author(s). Published by Elsevier Ltd. This is an Open Access article under the CC BY 4.0 license.",10.1016/S2589-7500(19)30108-6,,234,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071729503&doi=10.1016%2fS2589-7500%2819%2930108-6&partnerID=40&md5=887d3a84b6ed49a7713eb05853fda8fe
Deep neural networks are superior to dermatologists in melanoma image classification,Brinker T.J.; Hekler A.; Enk A.H.; Berking C.; Haferkamp S.; Hauschild A.; Weichenthal M.; Klode J.; Schadendorf D.; Holland-Letz T.; von Kalle C.; Fröhling S.; Schilling B.; Utikal J.S.,2019,0,1,0,0,0,Unique,0,,,,,,,"Background: Melanoma is the most dangerous type of skin cancer but is curable if detected early. Recent publications demonstrated that artificial intelligence is capable in classifying images of benign nevi and melanoma with dermatologist-level precision. However, a statistically significant improvement compared with dermatologist classification has not been reported to date. Methods: For this comparative study, 4204 biopsy-proven images of melanoma and nevi (1:1) were used for the training of a convolutional neural network (CNN). New techniques of deep learning were integrated. For the experiment, an additional 804 biopsy-proven dermoscopic images of melanoma and nevi (1:1) were randomly presented to dermatologists of nine German university hospitals, who evaluated the quality of each image and stated their recommended treatment (19,296 recommendations in total). Three McNemar's tests comparing the results of the CNN's test runs in terms of sensitivity, specificity and overall correctness were predefined as the main outcomes. Findings: The respective sensitivity and specificity of lesion classification by the dermatologists were 67.2% (95% confidence interval [CI]: 62.6%–71.7%) and 62.2% (95% CI: 57.6%–66.9%). In comparison, the trained CNN achieved a higher sensitivity of 82.3% (95% CI: 78.3%–85.7%) and a higher specificity of 77.9% (95% CI: 73.8%–81.8%). The three McNemar's tests in 2 × 2 tables all reached a significance level of p < 0.001. This significance level was sustained for both subgroups. Interpretation: For the first time, automated dermoscopic melanoma image classification was shown to be significantly superior to both junior and board-certified dermatologists (p < 0.001). © 2019 The Authors",10.1016/j.ejca.2019.05.023,Artificial intelligence; Deep learning; Melanoma; Skin cancer,256,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069046206&doi=10.1016%2fj.ejca.2019.05.023&partnerID=40&md5=7f30d41b68d5fae472b240510320c52f
Fully automated identification of skin morphology in raster-scan optoacoustic mesoscopy using artificial intelligence,Moustakidis S.; Omar M.; Aguirre J.; Mohajerani P.; Ntziachristos V.,2019,1,1,0,0,0,Unique,0,,,,,,,"Purpose: Identification of morphological characteristics of skin lesions is of vital importance in diagnosing diseases with dermatological manifestations. This task is often performed manually or in an automated way based on intensity level. Recently, ultra-broadband raster-scan optoacoustic mesoscopy (UWB-RSOM) was developed to offer unique cross-sectional optical imaging of the skin. A machine learning (ML) approach is proposed here to enable, for the first time, automated identification of skin layers in UWB-RSOM data. Materials and methods: The proposed method, termed SkinSeg, was applied to coronal UWB-RSOM images obtained from 12 human participants. SkinSeg is a multi-step methodology that integrates data processing and transformation, feature extraction, feature selection, and classification. Various image features and learning models were tested for their suitability at discriminating skin layers including traditional machine learning along with more advanced deep learning algorithms. An support vector machines-based postprocessing approach was finally applied to further improve the classification outputs. Results: Random forest proved to be the most effective technique, achieving mean classification accuracy of 86.89% evaluated based on a repeated leave-one-out strategy. Insights about the features extracted and their effect on classification accuracy are provided. The highest accuracy was achieved using a small group of four features and remained at the same level or was even slightly decreased when more features were included. Convolutional neural networks provided also promising results at a level of approximately 85%. The application of the proposed postprocessing technique was proved to be effective in terms of both testing accuracy and three-dimensional visualization of classification maps. Conclusions: SkinSeg demonstrated unique potential in identifying skin layers. The proposed method may facilitate clinical evaluation, monitoring, and diagnosis of diseases linked to skin inflammation, diabetes, and skin cancer. © 2019 American Association of Physicists in Medicine",10.1002/mp.13725,diagnostic imaging; feature extraction; machine learning; skin morphology recognition; UWB-RSOM,15,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070696579&doi=10.1002%2fmp.13725&partnerID=40&md5=bea6619ea647add9b74046f5dc06e673
Prediction of melanoma evolution in melanocytic nevi via artificial intelligence: A call for prospective data,Sondermann W.; Utikal J.S.; Enk A.H.; Schadendorf D.; Klode J.; Hauschild A.; Weichenthal M.; French L.E.; Berking C.; Schilling B.; Haferkamp S.; Fröhling S.; von Kalle C.; Brinker T.J.,2019,0,1,0,0,0,Unique,0,,,,,,,"Recent research revealed the superiority of artificial intelligence over dermatologists to diagnose melanoma from images. However, 30–50% of all melanomas and more than half of those in young patients evolve from initially benign lesions. Despite its high relevance for melanoma screening, neither clinicians nor computers are yet able to reliably predict a nevus’ oncologic transformation. The cause of this lies in the static nature of lesion presentation in the current standard of care, both for clinicians and algorithms. The status quo makes it difficult to train algorithms (and clinicians) to precisely assess the likelihood of a benign skin lesion to transform into melanoma. In addition, it inhibits the precision of current algorithms since ‘evolution’ image features may not be part of their decision. The current literature reveals certain types of melanocytic nevi (i.e. ‘spitzoid’ or ‘dysplastic’ nevi) and criteria (i.e. visible vasculature) that, in general, appear to have a higher chance to transform into melanoma. However, owing to the cumulative nature of oncogenic mutations in melanoma, a more fine-grained early morphologic footprint is likely to be detectable by an algorithm. In this perspective article, the concept of melanoma prediction is further explored by the discussion of the evolution of melanoma, the concept for training of such a nevi classifier and the implications of early melanoma prediction for clinical practice. In conclusion, the authors believe that artificial intelligence trained on prospective image data could be transformative for skin cancer diagnostics by (a) predicting melanoma before it occurs (i.e. pre-in situ) and (b) further enhancing the accuracy of current melanoma classifiers. Necessary prospective images for this research are obtained via free mole-monitoring mobile apps. © 2019 The Authors",10.1016/j.ejca.2019.07.009,Artificial intelligence; Deep learning; Melanoma; Prediction; Skin cancer,35,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069038315&doi=10.1016%2fj.ejca.2019.07.009&partnerID=40&md5=7a1f23c16b2188a46a0fad62209037cb
Dermoscopy in China: Current status and future prospective,Shen X.; Yu R.-X.; Shen C.-B.; Li C.-X.; Jing Y.; Zheng Y.-J.; Wang Z.-Y.; Xue K.; Xu F.; Yu J.-B.; Meng R.-S.; Cui Y.,2019,0,1,0,0,0,Unique,0,,,,,,,"Objective: Dermoscopy is a useful technique for improving the diagnostic accuracy of various types of skin disorders. In China, dermoscopy has been widely accepted, and domestic researchers have made tremendous progress in the field of dermoscopy. The main purpose of this review is to summarize the current status of dermoscopy in China and identify its future directions. Data sources: Articles included in this review were obtained by searching the following databases: Wanfang, China National Knowledge Infrastructure, PubMed, and the Web of Science. We focused on research published before 2019 with keywords including dermoscopy, dermoscopic, dermoscope and trichoscopy. Study selection: A total of 50 studies were selected. Of these studies, 20 studies were in Chinese and 30 in English, research samples of all the studies were collected from Chinese populations. Results: Since 2000, more than 380 articles about dermoscopy have been published in domestic or foreign journals. Dermoscopy can improve the diagnostic accuracy of neoplastic diseases, evaluating the therapeutic effect of treatment, and determining the treatment endpoint, and it can also assist in the differential diagnosis of inflammatory diseases and in the assessment of the severity of the disease. In addition, researches about the applications of dermoscopy during surgical treatment have been published. Training courses aiming to improve the diagnostic ability of dermatologists, either face-to-face or online, have been offered. The Chinese Skin Image Database, launched in 2017 as a work platform for dermatologists, has promoted the development of dermoscopy in China. Computer-aided diagnostic systems based on the Chinese population are ready for use. In the future, cooperation, resource sharing, talent development, image management, and computer-aided diagnosis will be important directions for the development of dermoscopy in China. Conclusion: Dermoscopy has been widely used and developed in China, however, it still needs to address more challenges in the future. Copyright © 2019 The Chinese Medical Association.",10.1097/CM9.0000000000000396,China; Current status; Dermoscopy; Future,25,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071336999&doi=10.1097%2fCM9.0000000000000396&partnerID=40&md5=a01fffe30716aef3f0922b8df997110f
Melanoma diagnosis from dermoscopy images using artificial neural network,Majumder S.; Ullah M.A.; Dhar J.P.,2019,0,1,0,0,0,First occurrence,0,,,,,,,"Among all skin cancers, melanoma is the most serious and unpredictable type of skin cancer although it is less common. Up to now, skin biopsy is the most reliable way of diagnosing melanoma. To avoid this invasive and costly biopsy, melanoma detection from dermoscopy images has been introduced for last few decades. But it is very challenging due to low interclass variance between melanoma and non-melanoma images, and high intraclass variance in melanoma images. A new approach for diagnosing melanoma skin cancer from dermoscopy images based on fundamental ABCD (Asymmetry, Border, Color, and Diameter) rule associated with shape, size and color properties of the images is presented in this paper. Two new features related to area and perimeter of the lesion image are proposed in this paper along with the other existing features which are distinguishing between melanoma and benign images. Dull razor algorithm is applied for black hair removal from the input images and Chan-Vese method is employed for segmentation. The extracted features are applied to an ANN model for training and finally detecting melanoma images from the input images. 98% overall accuracy is achieved in this approach. This promising result would be able to assist dermatologist for making decision clinically. © 2019 IEEE.",10.1109/ICAEE48663.2019.8975434,Artificial Neural Network; Chan Vese Method; Feature Extraction; Image Pre-processing; Melanoma; Segmentation; Skin Cancer,8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079344589&doi=10.1109%2fICAEE48663.2019.8975434&partnerID=40&md5=a414adb2120d4a69ae94ab64ce7b8834
Cancer diagnosis using deep learning: A bibliographic review,Munir K.; Elahi H.; Ayub A.; Frezza F.; Rizzi A.,2019,0,1,0,0,0,Unique,0,,,,,,,"In this paper, we first describe the basics of the field of cancer diagnosis, which includes steps of cancer diagnosis followed by the typical classification methods used by doctors, providing a historical idea of cancer classification techniques to the readers. These methods include Asymmetry, Border, Color and Diameter (ABCD) method, seven-point detection method, Menzies method, and pattern analysis. They are used regularly by doctors for cancer diagnosis, although they are not considered very efficient for obtaining better performance. Moreover, considering all types of audience, the basic evaluation criteria are also discussed. The criteria include the receiver operating characteristic curve (ROC curve), Area under the ROC curve (AUC), F1 score, accuracy, specificity, sensitivity, precision, dice-coefficient, average accuracy, and Jaccard index. Previously used methods are considered inefficient, asking for better and smarter methods for cancer diagnosis. Artificial intelligence and cancer diagnosis are gaining attention as a way to define better diagnostic tools. In particular, deep neural networks can be successfully used for intelligent image analysis. The basic framework of how this machine learning works on medical imaging is provided in this study, i.e., pre-processing, image segmentation and post-processing. The second part of this manuscript describes the different deep learning techniques, such as convolutional neural networks (CNNs), generative adversarial models (GANs), deep autoencoders (DANs), restricted Boltzmann’s machine (RBM), stacked autoencoders (SAE), convolutional autoencoders (CAE), recurrent neural networks (RNNs), long short-term memory (LTSM), multi-scale convolutional neural network (M-CNN), multi-instance learning convolutional neural network (MIL-CNN). For each technique, we provide Python codes, to allow interested readers to experiment with the cited algorithms on their own diagnostic problems. The third part of this manuscript compiles the successfully applied deep learning models for different types of cancers. Considering the length of the manuscript, we restrict ourselves to the discussion of breast cancer, lung cancer, brain cancer, and skin cancer. The purpose of this bibliographic review is to provide researchers opting to work in implementing deep learning and artificial neural networks for cancer diagnosis a knowledge from scratch of the state-of-the-art achievements. © 2019 by the authors.",10.3390/cancers11091235,Convolutional neural networks (CNNs); Deep autoencoders (DANs); Deep learning; Generative adversarial models (GANs); Long short-term memory (LTSM); Recurrent neural networks (RNNs); Restricted Boltzmann’s machine (RBM),338,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071841965&doi=10.3390%2fcancers11091235&partnerID=40&md5=5c9ef6e22291320690a9e58b6ae923a2
Hybrid Lempel–Ziv–Welch and clipped histogram equalization based medical image compression,Manimekalai M.A.P.; Vasanthi N.A.,2019,0,1,0,0,0,First occurrence,0,,,,,,,"Nowadays, the medical images upsurge because of numerous major disease predictions. The medical image size needed vast volumes of memory and taking additional bandwidth for storage as well as transmission. With the aim of decreasing the size of the storage and as well for greater transmission image compression is needed. The prior research presented a completely automatic technique for skin lesion segmentation by leveraging 19-layer deep convolutional neural networks (CNNs), which is skilled end to-end and does not depend on past acquittance of the data. On the other hand it contains problem with storage for the period of the medical image transmission and transmission speed. With the aim of resolving this issue the presented system developed a compression method. In this research, magnetic resonance imaging are pre-processed by means of median filter. The preprocessed image is split into region of interest (ROI) and non region of interest by means of deep fully convolutional networks with Jaccard distance. Subsequent to the ROI segmentation, the ROI edge is taken out and encrypted with Freeman chain coding. At that point the ROI part is compressed by hybrid Lempel–Ziv–Welch and clipped histogram equalization (CHE). In CHE, ideal threshold value is chosen by means of particle swarm optimization technique for enhancing the brightness maintenance. The Non ROI part is compressed by means of enhanced zero tree wavelet (EZW). In this EZW technique, a preliminary threshold is chosen by making use of firefly algorithm. Lastly the decompression is carried out at the receiving end. The experimentation outcomes prove that the presented method attains greater performance when matched up with the previous technique in regard to compression ratio, peak signal to noise ratio and mean square error. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.",10.1007/s10586-018-1761-7,Lossless compression and enhanced zero tree wavelet (EZW); MRI image; Region of interest,12,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042219427&doi=10.1007%2fs10586-018-1761-7&partnerID=40&md5=533bc12d3acbd307a05da06a2f7e952e
First-order Feature Extraction Methods for Image Texture and Melanoma Skin Cancer Detection,Wati M.; Haviluddin; Puspitasari N.; Budiman E.; Rahim R.,2019,1,1,0,0,0,Unique,0,,,,,,,"Skin cancer is a disease characterized by the growth of uncontrolled skin cells, which can damage surrounding tissue and spread to other body parts. The purpose of this study was to facilitate early recognition of skin cancer by applying the first-order extraction method using 6 parameters i.e. contrast, variance, standard deviation, kurtosis, mean and smoothness, for feature extraction based on texture to obtain a good level of accuracy and classification methods using Multilayer Perceptron Neural Network (MLP NN). The results of diagnostic identification consist of 2 outputs, i.e. melanoma and not melanoma. From the research, accuracy measurements were obtained through 4 sets of test images using melanoma and non-melanoma images and the results showed that the lowest level of accuracy was 81.81% and the highest level of accuracy was 85.71% so that the overall accuracy rate is 83.86%. © 2019 Published under licence by IOP Publishing Ltd.",10.1088/1742-6596/1230/1/012013,,15,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073463736&doi=10.1088%2f1742-6596%2f1230%2f1%2f012013&partnerID=40&md5=2da7b55e7e510fe60864a8b8af28cc66
Risk-aware machine learning classifier for skin lesion diagnosis,Mobiny A.; Singh A.; Van Nguyen H.,2019,1,1,0,0,0,Unique,0,,,,,,,"Knowing when a machine learning system is not confident about its prediction is crucial in medical domains where safety is critical. Ideally, a machine learning algorithm should make a prediction only when it is highly certain about its competency, and refer the case to physicians otherwise. In this paper, we investigate how Bayesian deep learning can improve the performance of the machine–physician team in the skin lesion classification task. We used the publicly available HAM10000 dataset, which includes samples from seven common skin lesion categories: Melanoma (MEL), Melanocytic Nevi (NV), Basal Cell Carcinoma (BCC), Actinic Keratoses and Intraepithelial Carcinoma (AKIEC), Benign Keratosis (BKL), Dermatofibroma (DF), and Vascular (VASC) lesions. Our experimental results show that Bayesian deep networks can boost the diagnostic performance of the standard DenseNet-169 model from 81.35% to 83.59% without incurring additional parameters or heavy computation. More importantly, a hybrid physician–machine workflow reaches a classification accuracy of 90% while only referring 35% of the cases to physicians. The findings are expected to generalize to other medical diagnosis applications. We believe that the availability of risk-aware machine learning methods will enable a wider adoption of machine learning technology in clinical settings. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.",10.3390/jcm8081241,Bayesian deep network; Model uncertainty; Monte Carlo dropout; Physician-friendly machine learning; Skin lesion,79,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079980134&doi=10.3390%2fjcm8081241&partnerID=40&md5=b1fd16afe3a14b3d23aa67504ff1f078
Multi-grid phase field skin tumor segmentation in 3D ultrasound images,Nguyen K.L.; Delachartre P.; Berthier M.,2019,1,1,0,0,0,First occurrence,0,,,,,,,"The aim of this paper is to present a new method for skin tumor segmentation in the 3D ultrasound images. We consider a variational formulation, the energy of which combines a diffuse interface phase field model (regularization term) and a log-likelihood computed using nonparametric estimates (data attachment term). We propose a multi-grid implementation with the exact solutions which has the advantage to avoid space discretization and numerical instabilities. The resulting algorithm is simple and easy to implement in multi-dimensions. Concerning applications, we focus on skin tumor segmentation. The clinical dataset used for the experiments is composed of 12 images with the ground truth given by a dermatologist. Comparisons with the reference methods show that the proposed method is more robust to the choice of the volume initialization. Moreover, thanks to the flexibility introduced by the diffuse interface, the sensitivity increases by 12% if the initialization is inside the lesion, and the Dice index increases by 59%, if the initialization covers the entire lesion. These results show that this new method is well designed to tackle the problem of underestimation of tumor volumes. © 1992-2012 IEEE.",10.1109/TIP.2019.2900587,3D ultrasound images; exact solutions; multi-grid algorithm; non-parametric estimation; phase field model; tumor segmentation,7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067275346&doi=10.1109%2fTIP.2019.2900587&partnerID=40&md5=b4be7b9d571789a6d7ecdc0fc8a39b1a
A scheme to classify skin through geographic distribution of tonalities using fuzzy based classification approach,Hernandez-Matamoros A.; Fujita H.; Nakano-Miyatake M.; Perez-Meana H.; Escamilla-Hernandez E.,2019,1,1,0,0,0,Unique,0,,,,,,,"The skin recognition is a topic that has been studying since some years ago using machine learning and artificial vision, nowadays this topic has many applications in the medical industry, for example, cancer detection, injuries, mood recognition, telemedicine, among other applications. In this industry, if we can classify the skin tonalities, we able to limit the diseases that attack each type of skin tonality. Many papers have studied skin recognition, where the goal is the recognition of the skin in a picture or video, they need to have a good database and powerful algorithms of machine learning. This paper proposes a system able to segment the skin through the map and the recognition of the skin in an image. The results show that is possible to generate a skin geographic distribution; it gives the opportunity to classify the skin tonalities, for another hand, we tested the proposed system to recognize skin showing interesting results for different tonalities of skin. © 2019 The authors and IOS Press. All rights reserved.",10.3233/FAIA190034,Clustering; Fuzzy logic; RGB color model; Skin,0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082028176&doi=10.3233%2fFAIA190034&partnerID=40&md5=ce5008e08c1501e332a00f0e013cfcfa
Skin Cancer Diagnosis by Using Fuzzy Logic and GLCM,Ghali F.,2019,1,1,0,0,0,Unique,0,,,,,,,"Image processing is one of the most strong and popular computer science technologies increasingly used today especially with medical sciences. It's commonly used to diagnose and detect many kinds of cancer diseases early such as skin cancer, and others. In this paper two techniques have been used to detect Skin Cancer. These two techniques are Fuzzy logic and GLCM (Gray Level Co-occurrence Matrix) where they can distinguish among cancerous skin and non-cancerous. The distinguish operation is based on extracted featured values from GLCM. The features GLCM include are Contrast, Correlation, Energy, Entropy, and Homogeneity. However, our contribution is a new algorithm for diagnosis two phase, the first is the normal situation and second is the skin cancer. After the design and implementation of the algorithm the result was good as we can see in the implementation section. © Published under licence by IOP Publishing Ltd.",10.1088/1742-6596/1279/1/012020,,5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070600586&doi=10.1088%2f1742-6596%2f1279%2f1%2f012020&partnerID=40&md5=d89eb79dd3533e86a79946fdf9d34a0e
Firefly algorithm approach for rational bézier border reconstruction of skin lesions from macroscopic medical images,Galvez A.; Iglesias A.; Ugail H.; You L.; Haron H.; Habib Z.,2019,1,0,0,0,0,First occurrence,0,,,,,,,"Image segmentation is a fundamental step for image processing of medical images. One of the most important tasks in this step is border reconstruction, which consists of constructing a border curve separating the organ or tissue of interest from the image background. This problem can be formulated as an optimization problem, where the border curve is computed through data fitting procedures from a collection of data points assumed to lie on the boundary of the object under analysis. However, standard mathematical optimization techniques do not provide satisfactory solutions to this problem. Some recent papers have applied evolutionary computation techniques to tackle this issue. Such works are only focused on the polynomial case, ignoring the more powerful (but also more difficult) case of rational curves. In this paper, we address this problem with rational Bézier curves by applying the firefly algorithm, a popular bio-inspired swarm intelligence technique for optimization. Experimental results on medical images of melanomas show that this method performs well and can be successfully applied to this problem. © 2019 IEEE.",10.1109/SKIMA47702.2019.8982465,Border reconstruction; Bézier curves; Firefly algorithm; Image segmentation; Medical images; Rational curves; Skin lesions; Swarm intelligence,1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081064434&doi=10.1109%2fSKIMA47702.2019.8982465&partnerID=40&md5=f21709470e82fe1d603cc44a4142d9a0
Skin Transcriptome of Middle-Aged Women Supplemented With Natural Herbo-mineral Shilajit Shows Induction of Microvascular and Extracellular Matrix Mechanisms,Das A.; S. El Masry M.; Gnyawali S.C.; Ghatak S.; Singh K.; Stewart R.; Lewis M.; Saha A.; Gordillo G.; Khanna S.,2019,1,1,0,0,0,Unique,0,,,,,,,"Objective: Shilajit is a pale-brown to blackish-brown organic mineral substance available from Himalayan rocks. We demonstrated that in type I obese humans, shilajit supplementation significantly upregulated extracellular matrix (ECM)–related genes in the skeletal muscle. Such an effect was highly synergistic with exercise. The present study (clinicaltrials.gov NCT02762032) aimed to evaluate the effects of shilajit supplementation on skin gene expression profile and microperfusion in healthy adult females. Methods: The study design comprised six total study visits including a baseline visit (V1) and a final 14-week visit (V6) following oral shilajit supplementation (125 or 250 mg bid). A skin biopsy of the left inner upper arm of each subject was collected at visit 2 and visit 6 for gene expression profiling using Affymetrix Clariom™ D Assay. Skin perfusion was determined by MATLAB processing of dermascopic images. Transcriptome data were normalized and subjected to statistical analysis. The differentially regulated genes were subjected to Ingenuity Pathway Analysis (IPA®). The expression of the differentially regulated genes identified by IPA® were verified using real-time polymerase chain reaction (RT-PCR). Results: Supplementation with shilajit for 14 weeks was not associated with any reported adverse effect within this period. At a higher dose (250 mg bid), shilajit improved skin perfusion when compared to baseline or the placebo. Pathway analysis identified shilajit-inducible genes relevant to endothelial cell migration, growth of blood vessels, and ECM which were validated by quantitative real-time polymerase chain reaction (RT-PCR) analysis. Conclusions: This work provides maiden evidence demonstrating that oral shilajit supplementation in adult healthy women induced genes relevant to endothelial cell migration and growth of blood vessels. Shilajit supplementation improved skin microperfusion. © 2019, © 2019 American College of Nutrition.",10.1080/07315724.2018.1564088,aging; dietary supplementation; ECM; Shilajit; skin perfusion,19,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067072441&doi=10.1080%2f07315724.2018.1564088&partnerID=40&md5=d7a36c87c61d8506f674f8e1b28f1183
An intelligent inflammatory skin lesions classification scheme for mobile devices,Hameed N.; Shabut A.; Hameed F.; Cirestea S.; Hossain A.,2019,1,1,0,0,0,Unique,0,,,,,,,"Illness directly affecting the skin is the fourth most frequent cause of all human disease, and is seeking the attention of researchers. In this research work, one such effort is made by proposing a mobile-enabled expert system named 'i-Rash' for the classification of inflammatory skin lesions. i-Rash can classify the skin image into one of the four non-overlapping classes, i.e. healthy, acne, eczema, and psoriasis. The classification model for i-Rash is trained using deep learning model SqueezeNet. The pre-trained SqueezeNet is re-trained on the skin image dataset using transfer learning approach. The i-Rash classification model is trained and tested on 1856 images. The trained model is only of 3MB size and is capable of classifying an unseen image in a fraction of seconds with an accuracy, sensitivity, and specificity of 97.21%, 94.42% and 98.14% respectively. i-Rash is based on a client-server architecture and can serve in initial classification of skin lesions, hence, can play a very important role in minimising the global burden caused by skin diseases. © 2019 IEEE.",10.1109/iCCECE46942.2019.8941851,Acne classification; Deep learning; Eczema classification; Psoriasis classification; Skin lesions classification; SqueezeNet,9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073323608&doi=10.1109%2fiCCECE46942.2019.8941851&partnerID=40&md5=dfa3e97738128e2bfdf954ccb9db9b43